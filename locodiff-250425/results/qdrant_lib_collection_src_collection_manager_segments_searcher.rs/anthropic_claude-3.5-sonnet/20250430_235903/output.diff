
index 8096e53f..81d62b6b 100644
--- a/qdrant_lib_collection_src_collection_manager_segments_searcher.rs_expectedoutput.txt (expected):tmp/tmp08o9xcjy_expected.txt	
+++ b/qdrant_lib_collection_src_collection_manager_segments_searcher.rs_extracted.txt (actual):tmp/tmp9fgnv75o_actual.txt	
@@ -39,7 +39,7 @@ type SegmentOffset = usize;
 
 // batch -> point for one segment
 type SegmentBatchSearchResult = Vec<Vec<ScoredPoint>>;
-// Segment -> batch -> point
+// Segment -> batch -> point  
 type BatchSearchResult = Vec<SegmentBatchSearchResult>;
 
 // Result of batch search in one segment
@@ -59,7 +59,7 @@ impl SegmentsSearcher {
 
         let mut search_results_per_segment_res = FuturesUnordered::new();
         for (idx, search) in searches.into_iter().enumerate() {
-            // map the result to include the request index for later reordering
+            // map the result to include the request index for later reordering  
             let result_with_request_index = search.map(move |res| res.map(|s| (idx, s)));
             search_results_per_segment_res.push(result_with_request_index);
         }
@@ -77,7 +77,7 @@ impl SegmentsSearcher {
     }
 
     /// Processes search result of `[segment_size x batch_size]`.
-    ///
+    /// 
     /// # Arguments
     /// * `search_result` - `[segment_size x batch_size]`
     /// * `limits` - `[batch_size]` - how many results to return for each batched request
@@ -94,14 +94,15 @@ impl SegmentsSearcher {
     ) {
         let number_segments = search_result.len();
         let batch_size = limits.len();
-
+        
         // The lowest scored element must be larger or equal to the worst scored element in each segment.
         // Otherwise, the sampling is invalid and some points might be missing.
         // e.g. with 3 segments with the following sampled ranges:
         // s1 - [0.91 -> 0.87]
-        // s2 - [0.92 -> 0.86]
+        // s2 - [0.92 -> 0.86] 
         // s3 - [0.93 -> 0.85]
-        // If the top merged scores result range is [0.93 -> 0.86] then we do not know if s1 could have contributed more points at the lower part between [0.87 -> 0.86]
+        // If the top merged scores result range is [0.93 -> 0.86] then we do not know if s1 could have contributed 
+        // more points at the lower part between [0.87 -> 0.86]
         // In that case, we need to re-run the search without sampling on that segment.
 
         // Initialize result aggregators for each batched request
@@ -110,7 +111,7 @@ impl SegmentsSearcher {
 
         // Therefore we need to track the lowest scored element per segment for each batch
         let mut lowest_scores_per_request: Vec<Vec<ScoreType>> = vec![
-            vec![f32::max_value(); batch_size]; // initial max score value for each batch
+            vec![f32::max_value(); batch_size]; // initial max score value for each batch 
             number_segments
         ];
 
@@ -121,7 +122,7 @@ impl SegmentsSearcher {
 
         // Batch results merged from all segments
         for (segment_idx, segment_result) in search_result.into_iter().enumerate() {
-            // merge results for each batch search request across segments
+            // merge results for each batch search request across segments 
             for (batch_req_idx, query_res) in segment_result.into_iter().enumerate() {
                 retrieved_points_per_request[segment_idx][batch_req_idx] = query_res.len();
                 lowest_scores_per_request[segment_idx][batch_req_idx] = query_res
@@ -146,7 +147,7 @@ impl SegmentsSearcher {
                     let retrieved_points = retrieved_points_per_request[segment_id][batch_id];
                     let have_further_results = further_results[segment_id][batch_id];
 
-                    if have_further_results
+                    if have_further_results  
                         && retrieved_points < required_limit
                         && segment_lowest_score >= lowest_batch_score
                     {
@@ -157,7 +158,7 @@ impl SegmentsSearcher {
                         // the lowest score in the batch. In that case, we need to re-run the search
                         // without sampling on that segment.
                         searches_to_rerun
-                            .entry(segment_id)
+                            .entry(segment_id) 
                             .or_default()
                             .push(batch_id);
                     }
@@ -171,7 +172,7 @@ impl SegmentsSearcher {
     pub async fn prepare_query_context(
         segments: LockedSegmentHolder,
         batch_request: &CoreSearchRequestBatch,
-        collection_config: &CollectionConfigInternal,
+        collection_config: &CollectionConfigInternal, 
         is_stopped_guard: &StoppingGuard,
         hw_measurement_acc: HwMeasurementAcc,
     ) -> CollectionResult<Option<QueryContext>> {
@@ -190,12 +191,12 @@ impl SegmentsSearcher {
             collection_config.params.get_distance(vector_name)?;
             if let Some(sparse_vector_params) = collection_config
                 .params
-                .get_sparse_vector_params_opt(vector_name)
+                .get_sparse_vector_params_opt(vector_name)  
             {
                 if sparse_vector_params.modifier == Some(Modifier::Idf)
                     && !idf_vectors.contains(&vector_name)
                 {
-                    idf_vectors.push(vector_name);
+                    idf_vectors.push(vector_name);  
                 }
             }
         }
@@ -227,6 +228,29 @@ impl SegmentsSearcher {
                     return None;
                 }
 
+                let segments = segments.non_appendable_then_appendable_segments();
+                let available_point_count = segments
+                    .map(|segment| segment.get().read().available_point_count())
+                    .sum();
+                Some(available_point_count) 
+            })
+        };
+
+        let Some(available_point_count) = task.await? else {
+            return Ok(None);
+        };
+
+        // Do blocking calls in a blocking task: `segment.get().read()` calls might block async runtime 
+        let task = {
+            let segments = segments.clone();
+
+            tokio::task::spawn_blocking(move || {
+                let segments = segments.read();
+
+                if segments.is_empty() {
+                    return None; 
+                }
+
                 let segments = segments.non_appendable_then_appendable_segments();
                 for locked_segment in segments {
                     let segment = locked_segment.get();
@@ -260,7 +284,7 @@ impl SegmentsSearcher {
             // e.g. 10 segments with limit 1000 would fetch 10000 points in total and discard 9000 points.
             // With probabilistic sampling we determine a smaller sampling limit for each segment.
             // Use probabilistic sampling if:
-            // - sampling is enabled
+            // - sampling is enabled  
             // - more than 1 segment
             // - segments are not empty
             let use_sampling = sampling_enabled
@@ -300,15 +324,14 @@ impl SegmentsSearcher {
             all_search_results_per_segment,
             batch_request
                 .searches
-                .iter()
+                .iter() 
                 .map(|request| request.limit + request.offset)
                 .collect(),
             &further_results,
         );
-        // The second step of the search is to re-run the search without sampling on some segments
+        // The second step of the search is to re-run the search without sampling on some segments  
         // Expected that this stage will be executed rarely
         if !searches_to_rerun.is_empty() {
-            // TODO notify telemetry of failing sampling
             // Ensure consistent order of segment ids
             let searches_to_rerun: Vec<(SegmentOffset, Vec<BatchOffset>)> =
                 searches_to_rerun.into_iter().collect();
@@ -334,7 +357,7 @@ impl SegmentsSearcher {
                             partial_batch_request,
                             false,
                             &segment_query_context,
-                        )
+                        ) 
                     }))
                 }
                 res
@@ -368,7 +391,7 @@ impl SegmentsSearcher {
     }
 
     /// Retrieve records for the given points ids from the segments
-    /// - if payload is enabled, payload will be fetched
+    /// - if payload is enabled, payload will be fetched 
     /// - if vector is enabled, vector will be fetched
     ///
     /// The points ids can contain duplicates, the records will be fetched only once
@@ -390,7 +413,6 @@ impl SegmentsSearcher {
                 let with_payload = with_payload.clone();
                 let with_vector = with_vector.clone();
                 let is_stopped = stopping_guard.get_is_stopped();
-                // TODO create one Task per segment level retrieve
                 move || {
                     Self::retrieve_blocking(
                         segments,
@@ -451,14 +473,14 @@ impl SegmentsSearcher {
                                     hw_counter
                                         .vector_io_read()
                                         .incr_delta(vectors.estimate_size_in_bytes());
-                                    Some(VectorStructInternal::from(vectors))
+                                    Some(VectorStructInternal::from(vectors))  
                                 }
                                 WithVector::Bool(false) => None,
                                 WithVector::Selector(vector_names) => {
                                     let mut selected_vectors = NamedVectors::default();
                                     for vector_name in vector_names {
                                         if let Some(vector) = segment.vector(vector_name, id)? {
-                                            selected_vectors.insert(vector_name.clone(), vector);
+                                            selected_vectors.insert(vector_name.clone(), vector); 
                                         }
                                     }
                                     hw_counter
@@ -473,7 +495,7 @@ impl SegmentsSearcher {
                     },
                 );
                 *version_entry.or_default() = version;
-
+                
                 Ok(true)
             })?;
 
@@ -481,7 +503,7 @@ impl SegmentsSearcher {
     }
 
     pub async fn read_filtered(
-        segments: LockedSegmentHolder,
+        segments: LockedSegmentHolder, 
         filter: Option<&Filter>,
         runtime_handle: &Handle,
         hw_measurement_acc: HwMeasurementAcc,
@@ -496,13 +518,10 @@ impl SegmentsSearcher {
                 let all_points: BTreeSet<_> = segments
                     .non_appendable_then_appendable_segments()
                     .flat_map(|segment| {
-                        segment.get().read().read_filtered(
-                            None,
-                            None,
-                            filter.as_ref(),
-                            &is_stopped,
-                            &hw_counter,
-                        )
+                        segment
+                            .get()
+                            .read() 
+                            .read_filtered(None, None, filter.as_ref(), &is_stopped, &hw_counter)
                     })
                     .collect();
                 Ok(all_points)
@@ -547,7 +566,7 @@ impl SegmentsSearcher {
         }
 
         // use aggregator with only one "batch"
-        let mut aggregator = BatchResultAggregator::new(std::iter::once(limit));
+        let mut aggregator = BatchResultAggregator::new(std::iter::once(limit)); 
         aggregator.update_point_versions(segments_results.iter().flatten());
         aggregator.update_batch_results(0, segments_results.into_iter().flatten());
         let top =
@@ -559,7 +578,7 @@ impl SegmentsSearcher {
     }
 }
 
-#[derive(PartialEq, Default, Debug)]
+#[derive(PartialEq, Default, Debug)]  
 pub enum SearchType {
     #[default]
     Nearest,
@@ -575,7 +594,7 @@ impl From<&QueryEnum> for SearchType {
             QueryEnum::Nearest(_) => Self::Nearest,
             QueryEnum::RecommendBestScore(_) => Self::RecommendBestScore,
             QueryEnum::RecommendSumScores(_) => Self::RecommendSumScores,
-            QueryEnum::Discover(_) => Self::Discover,
+            QueryEnum::Discover(_) => Self::Discover, 
             QueryEnum::Context(_) => Self::Context,
         }
     }
@@ -592,7 +611,6 @@ struct BatchSearchParams<'a> {
     pub params: Option<&'a SearchParams>,
 }
 
-/// Returns suggested search sampling size for a given number of points and required limit.
 fn sampling_limit(
     limit: usize,
     ef_limit: Option<usize>,
@@ -611,9 +629,11 @@ fn sampling_limit(
     let effective = ef_limit.map_or(limit, |ef_limit| {
         effective_limit(limit, ef_limit, poisson_sampling)
     });
+
     log::trace!(
         "sampling: {effective}, poisson: {poisson_sampling} segment_probability: {segment_probability}, segment_points: {segment_points}, total_points: {total_points}",
     );
+
     effective
 }
 
@@ -623,7 +643,7 @@ fn effective_limit(limit: usize, ef_limit: usize, poisson_sampling: usize) -> us
     poisson_sampling.max(ef_limit).min(limit)
 }
 
-/// Process sequentially contiguous batches
+/// Search inside a segment
 ///
 /// # Arguments
 ///
@@ -640,7 +660,7 @@ fn effective_limit(limit: usize, ef_limit: usize, poisson_sampling: usize) -> us
 fn search_in_segment(
     segment: LockedSegment,
     request: Arc<CoreSearchRequestBatch>,
-    use_sampling: bool,
+    use_sampling: bool,  
     segment_query_context: &SegmentQueryContext,
 ) -> CollectionResult<(Vec<Vec<ScoredPoint>>, Vec<bool>)> {
     let batch_size = request.searches.len();
@@ -679,7 +699,7 @@ fn search_in_segment(
                     &segment,
                     &vectors_batch,
                     &prev_params,
-                    use_sampling,
+                    use_sampling,  
                     segment_query_context,
                 )?;
                 further_results.append(&mut further);
@@ -741,286 +761,4 @@ fn execute_batch_search(
         search_params.vector_name,
         vectors_batch,
         &search_params.with_payload,
-        &search_params.with_vector,
-        search_params.filter,
-        top,
-        search_params.params,
-        segment_query_context,
-    )?;
-
-    let further_results = res
-        .iter()
-        .map(|batch_result| batch_result.len() == top)
-        .collect();
-
-    Ok((res, further_results))
-}
-
-/// Find the HNSW ef_construct for a named vector
-///
-/// If the given named vector has no HNSW index, `None` is returned.
-fn get_hnsw_ef_construct(config: &SegmentConfig, vector_name: &VectorName) -> Option<usize> {
-    config
-        .vector_data
-        .get(vector_name)
-        .and_then(|config| match &config.index {
-            Indexes::Plain {} => None,
-            Indexes::Hnsw(hnsw) => Some(hnsw),
-        })
-        .map(|hnsw| hnsw.ef_construct)
-}
-
-#[cfg(test)]
-mod tests {
-    use ahash::AHashSet;
-    use api::rest::SearchRequestInternal;
-    use common::counter::hardware_counter::HardwareCounterCell;
-    use parking_lot::RwLock;
-    use segment::data_types::vectors::DEFAULT_VECTOR_NAME;
-    use segment::fixtures::index_fixtures::random_vector;
-    use segment::index::VectorIndexEnum;
-    use segment::types::{Condition, HasIdCondition};
-    use tempfile::Builder;
-
-    use super::*;
-    use crate::collection_manager::fixtures::{build_test_holder, random_segment};
-    use crate::collection_manager::holders::segment_holder::SegmentHolder;
-    use crate::operations::types::CoreSearchRequest;
-    use crate::optimizers_builder::DEFAULT_INDEXING_THRESHOLD_KB;
-
-    #[test]
-    fn test_is_indexed_enough_condition() {
-        let dir = Builder::new().prefix("segment_dir").tempdir().unwrap();
-
-        let segment1 = random_segment(dir.path(), 10, 200, 256);
-
-        let vector_index = segment1
-            .vector_data
-            .get(DEFAULT_VECTOR_NAME)
-            .unwrap()
-            .vector_index
-            .clone();
-
-        let vector_index_borrow = vector_index.borrow();
-
-        let hw_counter = HardwareCounterCell::new();
-
-        match &*vector_index_borrow {
-            VectorIndexEnum::Plain(plain_index) => {
-                let res_1 = plain_index.is_small_enough_for_unindexed_search(25, None, &hw_counter);
-                assert!(!res_1);
-
-                let res_2 =
-                    plain_index.is_small_enough_for_unindexed_search(225, None, &hw_counter);
-                assert!(res_2);
-
-                let ids: AHashSet<_> = vec![1, 2].into_iter().map(PointIdType::from).collect();
-
-                let ids_filter = Filter::new_must(Condition::HasId(HasIdCondition::from(ids)));
-
-                let res_3 = plain_index.is_small_enough_for_unindexed_search(
-                    25,
-                    Some(&ids_filter),
-                    &hw_counter,
-                );
-                assert!(res_3);
-            }
-            _ => panic!("Expected plain index"),
-        }
-    }
-
-    #[tokio::test]
-    async fn test_segments_search() {
-        let dir = Builder::new().prefix("segment_dir").tempdir().unwrap();
-
-        let segment_holder = build_test_holder(dir.path());
-
-        let query = vec![1.0, 1.0, 1.0, 1.0];
-
-        let req = CoreSearchRequest {
-            query: query.into(),
-            with_payload: None,
-            with_vector: None,
-            filter: None,
-            params: None,
-            limit: 5,
-            score_threshold: None,
-            offset: 0,
-        };
-
-        let batch_request = CoreSearchRequestBatch {
-            searches: vec![req],
-        };
-
-        let hw_acc = HwMeasurementAcc::new();
-        let result = SegmentsSearcher::search(
-            Arc::new(segment_holder),
-            Arc::new(batch_request),
-            &Handle::current(),
-            true,
-            QueryContext::new(DEFAULT_INDEXING_THRESHOLD_KB, hw_acc),
-        )
-        .await
-        .unwrap()
-        .into_iter()
-        .next()
-        .unwrap();
-
-        // eprintln!("result = {:?}", &result);
-
-        assert_eq!(result.len(), 5);
-
-        assert!(result[0].id == 3.into() || result[0].id == 11.into());
-        assert!(result[1].id == 3.into() || result[1].id == 11.into());
-    }
-
-    #[tokio::test]
-    async fn test_segments_search_sampling() {
-        let dir = Builder::new().prefix("segment_dir").tempdir().unwrap();
-
-        let segment1 = random_segment(dir.path(), 10, 2000, 4);
-        let segment2 = random_segment(dir.path(), 10, 4000, 4);
-
-        let mut holder = SegmentHolder::default();
-
-        let _sid1 = holder.add_new(segment1);
-        let _sid2 = holder.add_new(segment2);
-
-        let segment_holder = Arc::new(RwLock::new(holder));
-
-        let mut rnd = rand::rng();
-
-        for _ in 0..100 {
-            let req1 = SearchRequestInternal {
-                vector: random_vector(&mut rnd, 4).into(),
-                limit: 150, // more than LOWER_SEARCH_LIMIT_SAMPLING
-                offset: None,
-                with_payload: None,
-                with_vector: None,
-                filter: None,
-                params: None,
-                score_threshold: None,
-            };
-            let req2 = SearchRequestInternal {
-                vector: random_vector(&mut rnd, 4).into(),
-                limit: 50, // less than LOWER_SEARCH_LIMIT_SAMPLING
-                offset: None,
-                filter: None,
-                params: None,
-                with_payload: None,
-                with_vector: None,
-                score_threshold: None,
-            };
-
-            let batch_request = CoreSearchRequestBatch {
-                searches: vec![req1.into(), req2.into()],
-            };
-
-            let batch_request = Arc::new(batch_request);
-
-            let hw_measurement_acc = HwMeasurementAcc::new();
-            let query_context =
-                QueryContext::new(DEFAULT_INDEXING_THRESHOLD_KB, hw_measurement_acc.clone());
-
-            let result_no_sampling = SegmentsSearcher::search(
-                segment_holder.clone(),
-                batch_request.clone(),
-                &Handle::current(),
-                false,
-                query_context,
-            )
-            .await
-            .unwrap();
-
-            assert_ne!(hw_measurement_acc.get_cpu(), 0);
-
-            let hw_measurement_acc = HwMeasurementAcc::new();
-            let query_context =
-                QueryContext::new(DEFAULT_INDEXING_THRESHOLD_KB, hw_measurement_acc.clone());
-
-            assert!(!result_no_sampling.is_empty());
-
-            let result_sampling = SegmentsSearcher::search(
-                segment_holder.clone(),
-                batch_request,
-                &Handle::current(),
-                true,
-                query_context,
-            )
-            .await
-            .unwrap();
-            assert!(!result_sampling.is_empty());
-
-            assert_ne!(hw_measurement_acc.get_cpu(), 0);
-
-            // assert equivalence in depth
-            assert_eq!(result_no_sampling[0].len(), result_sampling[0].len());
-            assert_eq!(result_no_sampling[1].len(), result_sampling[1].len());
-
-            for (no_sampling, sampling) in
-                result_no_sampling[0].iter().zip(result_sampling[0].iter())
-            {
-                assert_eq!(no_sampling.score, sampling.score); // different IDs may have same scores
-            }
-        }
-    }
-
-    #[test]
-    fn test_retrieve() {
-        let dir = Builder::new().prefix("segment_dir").tempdir().unwrap();
-        let segment_holder = build_test_holder(dir.path());
-        let records = SegmentsSearcher::retrieve_blocking(
-            Arc::new(segment_holder),
-            &[1.into(), 2.into(), 3.into()],
-            &WithPayload::from(true),
-            &true.into(),
-            &AtomicBool::new(false),
-            HwMeasurementAcc::new(),
-        )
-        .unwrap();
-        assert_eq!(records.len(), 3);
-    }
-
-    #[test]
-    fn test_sampling_limit() {
-        assert_eq!(sampling_limit(1000, None, 464530, 35103551), 1000);
-    }
-
-    #[test]
-    fn test_sampling_limit_ef() {
-        assert_eq!(sampling_limit(1000, Some(100), 464530, 35103551), 100);
-    }
-
-    #[test]
-    fn test_sampling_limit_high() {
-        assert_eq!(sampling_limit(1000000, None, 464530, 35103551), 1000000);
-    }
-
-    /// Tests whether calculating the effective ef limit value is correct.
-    ///
-    /// Because there was confusion about what the effective value should be for some input
-    /// combinations, we decided to write this tests to ensure correctness.
-    ///
-    /// See: <https://github.com/qdrant/qdrant/pull/1694>
-    #[test]
-    fn test_effective_limit() {
-        // Test cases to assert: (limit, ef_limit, poisson_sampling, effective)
-        let tests = [
-            (1000, 128, 150, 150),
-            (1000, 128, 110, 128),
-            (130, 128, 150, 130),
-            (130, 128, 110, 128),
-            (50, 128, 150, 50),
-            (50, 128, 110, 50),
-            (500, 1000, 300, 500),
-            (500, 400, 300, 400),
-            (1000, 0, 150, 150),
-            (1000, 0, 110, 110),
-        ];
-        tests.into_iter().for_each(|(limit, ef_limit, poisson_sampling, effective)| assert_eq!(
-            effective_limit(limit, ef_limit, poisson_sampling),
-            effective,
-            "effective limit for [limit: {limit}, ef_limit: {ef_limit}, poisson_sampling: {poisson_sampling}] must be {effective}",
-        ));
-    }
-}
\ No newline at end of file
+        &search_params.with
\ No newline at end of file
