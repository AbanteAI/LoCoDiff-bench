
index 8096e53f..98ac8926 100644
--- a/qdrant_lib_collection_src_collection_manager_segments_searcher.rs_expectedoutput.txt (expected):tmp/tmpnmkbrvhb_expected.txt	
+++ b/qdrant_lib_collection_src_collection_manager_segments_searcher.rs_extracted.txt (actual):tmp/tmpts360j25_actual.txt	
@@ -1,10 +1,11 @@
-use std::collections::BTreeSet;
 use std::collections::hash_map::Entry;
-use std::sync::Arc;
+use std::collections::BTreeSet;
 use std::sync::atomic::AtomicBool;
+use std::sync::Arc;
 
 use ahash::AHashMap;
 use common::counter::hardware_accumulator::HwMeasurementAcc;
+use common::counter::hardware_counter::HardwareCounterCell;
 use common::types::ScoreType;
 use futures::stream::FuturesUnordered;
 use futures::{FutureExt, TryStreamExt};
@@ -87,7 +88,7 @@ impl SegmentsSearcher {
     pub(crate) fn process_search_result_step1(
         search_result: BatchSearchResult,
         limits: Vec<usize>,
-        further_results: &[Vec<bool>],
+        further_searches: &[Vec<bool>],
     ) -> (
         BatchResultAggregator,
         AHashMap<SegmentOffset, Vec<BatchOffset>>,
@@ -144,7 +145,7 @@ impl SegmentsSearcher {
                 for segment_id in 0..number_segments {
                     let segment_lowest_score = lowest_scores_per_request[segment_id][batch_id];
                     let retrieved_points = retrieved_points_per_request[segment_id][batch_id];
-                    let have_further_results = further_results[segment_id][batch_id];
+                    let have_further_results = further_searches[segment_id][batch_id];
 
                     if have_further_results
                         && retrieved_points < required_limit
@@ -246,6 +247,7 @@ impl SegmentsSearcher {
         runtime_handle: &Handle,
         sampling_enabled: bool,
         query_context: QueryContext,
+        hw_measurement_acc: &HwMeasurementAcc,
     ) -> CollectionResult<Vec<Vec<ScoredPoint>>> {
         let query_context_arc = Arc::new(query_context);
 
@@ -270,6 +272,7 @@ impl SegmentsSearcher {
             segments
                 .map(|segment| {
                     let query_context_arc_segment = query_context_arc.clone();
+                    let hw_collector = hw_measurement_acc.new_collector();
 
                     let search = runtime_handle.spawn_blocking({
                         let (segment, batch_request) = (segment.clone(), batch_request.clone());
@@ -277,12 +280,17 @@ impl SegmentsSearcher {
                             let segment_query_context =
                                 query_context_arc_segment.get_segment_query_context();
 
-                            search_in_segment(
+                            let res = search_in_segment(
                                 segment,
                                 batch_request,
                                 use_sampling,
                                 &segment_query_context,
-                            )
+                            );
+
+                            hw_collector
+                                .merge_from_cell(segment_query_context.take_hardware_counter());
+
+                            res
                         }
                     });
                     (segment, search)
@@ -324,17 +332,22 @@ impl SegmentsSearcher {
                             .map(|batch_id| batch_request.searches[*batch_id].clone())
                             .collect(),
                     });
+                    let hw_collector = hw_measurement_acc.new_collector();
 
                     res.push(runtime_handle.spawn_blocking(move || {
                         let segment_query_context =
                             query_context_arc_segment.get_segment_query_context();
 
-                        search_in_segment(
+                        let result = search_in_segment(
                             segment,
                             partial_batch_request,
                             false,
                             &segment_query_context,
-                        )
+                        );
+
+                        hw_collector.merge_from_cell(segment_query_context.take_hardware_counter());
+
+                        result
                     }))
                 }
                 res
@@ -629,6 +642,7 @@ fn effective_limit(limit: usize, ef_limit: usize, poisson_sampling: usize) -> us
 ///
 /// * `segment` - Locked segment to search in
 /// * `request` - Batch of search requests
+/// * `total_points` - Number of points in all segments combined
 /// * `use_sampling` - If true, try to use probabilistic sampling
 /// * `query_context` - Additional context for the search
 ///
@@ -1017,10 +1031,14 @@ mod tests {
             (1000, 0, 150, 150),
             (1000, 0, 110, 110),
         ];
-        tests.into_iter().for_each(|(limit, ef_limit, poisson_sampling, effective)| assert_eq!(
-            effective_limit(limit, ef_limit, poisson_sampling),
-            effective,
-            "effective limit for [limit: {limit}, ef_limit: {ef_limit}, poisson_sampling: {poisson_sampling}] must be {effective}",
-        ));
+        tests.into_iter().for_each(
+            |(limit, ef_limit, poisson_sampling, effective)| {
+                assert_eq!(
+                    effective_limit(limit, ef_limit, poisson_sampling),
+                    effective,
+                    "effective limit for [limit: {limit}, ef_limit: {ef_limit}, poisson_sampling: {poisson_sampling}] must be {effective}",
+                )
+            },
+        );
     }
 }
\ No newline at end of file
