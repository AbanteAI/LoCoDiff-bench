
index 8096e53f4..5d48b8923 100644
--- a/qdrant_lib_collection_src_collection_manager_segments_searcher.rs_expectedoutput.txt (expected):tmp/tmpxnb_2l7p_expected.txt	
+++ b/qdrant_lib_collection_src_collection_manager_segments_searcher.rs_extracted.txt (actual):tmp/tmphe7wnxf6_actual.txt	
@@ -263,9 +263,8 @@ impl SegmentsSearcher {
             // - sampling is enabled
             // - more than 1 segment
             // - segments are not empty
-            let use_sampling = sampling_enabled
-                && segments_lock.len() > 1
-                && query_context_arc.available_point_count() > 0;
+            let use_sampling =
+                sampling_enabled && segments_lock.len() > 1 && query_context_arc.available_point_count() > 0;
 
             segments
                 .map(|segment| {
@@ -276,7 +275,6 @@ impl SegmentsSearcher {
                         move || {
                             let segment_query_context =
                                 query_context_arc_segment.get_segment_query_context();
-
                             search_in_segment(
                                 segment,
                                 batch_request,
@@ -289,7 +287,6 @@ impl SegmentsSearcher {
                 })
                 .unzip()
         };
-
         // perform search on all segments concurrently
         // the resulting Vec is in the same order as the segment searches were provided.
         let (all_search_results_per_segment, further_results) =
@@ -328,7 +325,6 @@ impl SegmentsSearcher {
                     res.push(runtime_handle.spawn_blocking(move || {
                         let segment_query_context =
                             query_context_arc_segment.get_segment_query_context();
-
                         search_in_segment(
                             segment,
                             partial_batch_request,
@@ -390,7 +386,6 @@ impl SegmentsSearcher {
                 let with_payload = with_payload.clone();
                 let with_vector = with_vector.clone();
                 let is_stopped = stopping_guard.get_is_stopped();
-                // TODO create one Task per segment level retrieve
                 move || {
                     Self::retrieve_blocking(
                         segments,
@@ -592,31 +587,6 @@ struct BatchSearchParams<'a> {
     pub params: Option<&'a SearchParams>,
 }
 
-/// Returns suggested search sampling size for a given number of points and required limit.
-fn sampling_limit(
-    limit: usize,
-    ef_limit: Option<usize>,
-    segment_points: usize,
-    total_points: usize,
-) -> usize {
-    // shortcut empty segment
-    if segment_points == 0 {
-        return 0;
-    }
-    let segment_probability = segment_points as f64 / total_points as f64;
-    let poisson_sampling =
-        find_search_sampling_over_point_distribution(limit as f64, segment_probability);
-
-    // if no ef_limit was found, it is a plain index => sampling optimization is not needed.
-    let effective = ef_limit.map_or(limit, |ef_limit| {
-        effective_limit(limit, ef_limit, poisson_sampling)
-    });
-    log::trace!(
-        "sampling: {effective}, poisson: {poisson_sampling} segment_probability: {segment_probability}, segment_points: {segment_points}, total_points: {total_points}",
-    );
-    effective
-}
-
 /// Determines the effective ef limit value for the given parameters.
 fn effective_limit(limit: usize, ef_limit: usize, poisson_sampling: usize) -> usize {
     // Prefer the highest of poisson_sampling/ef_limit, but never be higher than limit
@@ -630,7 +600,7 @@ fn effective_limit(limit: usize, ef_limit: usize, poisson_sampling: usize) -> us
 /// * `segment` - Locked segment to search in
 /// * `request` - Batch of search requests
 /// * `use_sampling` - If true, try to use probabilistic sampling
-/// * `query_context` - Additional context for the search
+/// * `segment_query_context` - Additional context for the search
 ///
 /// # Returns
 ///
@@ -756,6 +726,30 @@ fn execute_batch_search(
     Ok((res, further_results))
 }
 
+fn sampling_limit(
+    limit: usize,
+    ef_limit: Option<usize>,
+    segment_points: usize,
+    total_points: usize,
+) -> usize {
+    // shortcut empty segment
+    if segment_points == 0 {
+        return 0;
+    }
+    let segment_probability = segment_points as f64 / total_points as f64;
+    let poisson_sampling =
+        find_search_sampling_over_point_distribution(limit as f64, segment_probability);
+
+    // if no ef_limit was found, it is a plain index => sampling optimization is not needed.
+    let effective = ef_limit.map_or(limit, |ef_limit| {
+        effective_limit(limit, ef_limit, poisson_sampling)
+    });
+    log::trace!(
+        "sampling: {effective}, poisson: {poisson_sampling} segment_probability: {segment_probability}, segment_points: {segment_points}, total_points: {total_points}",
+    );
+    effective
+}
+
 /// Find the HNSW ef_construct for a named vector
 ///
 /// If the given named vector has no HNSW index, `None` is returned.
@@ -932,8 +926,6 @@ mod tests {
             .await
             .unwrap();
 
-            assert_ne!(hw_measurement_acc.get_cpu(), 0);
-
             let hw_measurement_acc = HwMeasurementAcc::new();
             let query_context =
                 QueryContext::new(DEFAULT_INDEXING_THRESHOLD_KB, hw_measurement_acc.clone());
@@ -951,8 +943,6 @@ mod tests {
             .unwrap();
             assert!(!result_sampling.is_empty());
 
-            assert_ne!(hw_measurement_acc.get_cpu(), 0);
-
             // assert equivalence in depth
             assert_eq!(result_no_sampling[0].len(), result_sampling[0].len());
             assert_eq!(result_no_sampling[1].len(), result_sampling[1].len());
@@ -980,47 +970,4 @@ mod tests {
         .unwrap();
         assert_eq!(records.len(), 3);
     }
-
-    #[test]
-    fn test_sampling_limit() {
-        assert_eq!(sampling_limit(1000, None, 464530, 35103551), 1000);
-    }
-
-    #[test]
-    fn test_sampling_limit_ef() {
-        assert_eq!(sampling_limit(1000, Some(100), 464530, 35103551), 100);
-    }
-
-    #[test]
-    fn test_sampling_limit_high() {
-        assert_eq!(sampling_limit(1000000, None, 464530, 35103551), 1000000);
-    }
-
-    /// Tests whether calculating the effective ef limit value is correct.
-    ///
-    /// Because there was confusion about what the effective value should be for some input
-    /// combinations, we decided to write this tests to ensure correctness.
-    ///
-    /// See: <https://github.com/qdrant/qdrant/pull/1694>
-    #[test]
-    fn test_effective_limit() {
-        // Test cases to assert: (limit, ef_limit, poisson_sampling, effective)
-        let tests = [
-            (1000, 128, 150, 150),
-            (1000, 128, 110, 128),
-            (130, 128, 150, 130),
-            (130, 128, 110, 128),
-            (50, 128, 150, 50),
-            (50, 128, 110, 50),
-            (500, 1000, 300, 500),
-            (500, 400, 300, 400),
-            (1000, 0, 150, 150),
-            (1000, 0, 110, 110),
-        ];
-        tests.into_iter().for_each(|(limit, ef_limit, poisson_sampling, effective)| assert_eq!(
-            effective_limit(limit, ef_limit, poisson_sampling),
-            effective,
-            "effective limit for [limit: {limit}, ef_limit: {ef_limit}, poisson_sampling: {poisson_sampling}] must be {effective}",
-        ));
-    }
 }
\ No newline at end of file
