
index 8096e53f..c0f8dc6a 100644
--- a/qdrant_lib_collection_src_collection_manager_segments_searcher.rs_expectedoutput.txt (expected):tmp/tmp9383ppdo_expected.txt	
+++ b/qdrant_lib_collection_src_collection_manager_segments_searcher.rs_extracted.txt (actual):tmp/tmp5uo3j3pp_actual.txt	
@@ -1,15 +1,17 @@
-use std::collections::BTreeSet;
 use std::collections::hash_map::Entry;
+use std::collections::{BTreeSet, HashMap};
 use std::sync::Arc;
 use std::sync::atomic::AtomicBool;
 
 use ahash::AHashMap;
 use common::counter::hardware_accumulator::HwMeasurementAcc;
+use common::counter::hardware_counter::HardwareCounterCell;
 use common::types::ScoreType;
 use futures::stream::FuturesUnordered;
 use futures::{FutureExt, TryStreamExt};
 use itertools::Itertools;
 use ordered_float::Float;
+use parking_lot::RwLock;
 use segment::common::operation_error::OperationError;
 use segment::data_types::named_vectors::NamedVectors;
 use segment::data_types::query_context::{FormulaContext, QueryContext, SegmentQueryContext};
@@ -110,7 +112,7 @@ impl SegmentsSearcher {
 
         // Therefore we need to track the lowest scored element per segment for each batch
         let mut lowest_scores_per_request: Vec<Vec<ScoreType>> = vec![
-            vec![f32::max_value(); batch_size]; // initial max score value for each batch
+            vec![f32::MAX; batch_size]; // initial max score value for each batch
             number_segments
         ];
 
@@ -217,25 +219,21 @@ impl SegmentsSearcher {
         }
 
         // Do blocking calls in a blocking task: `segment.get().read()` calls might block async runtime
-        let task = {
-            let segments = segments.clone();
+        let task = tokio::task::spawn_blocking(move || {
+            let segments = segments.read();
 
-            tokio::task::spawn_blocking(move || {
-                let segments = segments.read();
-
-                if segments.is_empty() {
-                    return None;
-                }
+            if segments.is_empty() {
+                return None;
+            }
 
-                let segments = segments.non_appendable_then_appendable_segments();
-                for locked_segment in segments {
-                    let segment = locked_segment.get();
-                    let segment_guard = segment.read();
-                    segment_guard.fill_query_context(&mut query_context);
-                }
-                Some(query_context)
-            })
-        };
+            let segments = segments.non_appendable_then_appendable_segments();
+            for locked_segment in segments {
+                let segment = locked_segment.get();
+                let segment_guard = segment.read();
+                segment_guard.fill_query_context(&mut query_context);
+            }
+            Some(query_context)
+        });
 
         Ok(task.await?)
     }
@@ -270,7 +268,6 @@ impl SegmentsSearcher {
             segments
                 .map(|segment| {
                     let query_context_arc_segment = query_context_arc.clone();
-
                     let search = runtime_handle.spawn_blocking({
                         let (segment, batch_request) = (segment.clone(), batch_request.clone());
                         move || {
@@ -363,7 +360,7 @@ impl SegmentsSearcher {
             }
         }
 
-        let top_scores: Vec<_> = result_aggregator.into_topk();
+        let top_scores = result_aggregator.into_topk();
         Ok(top_scores)
     }
 
@@ -390,6 +387,7 @@ impl SegmentsSearcher {
                 let with_payload = with_payload.clone();
                 let with_vector = with_vector.clone();
                 let is_stopped = stopping_guard.get_is_stopped();
+                let hw_measurement_acc = hw_measurement_acc.clone();
                 // TODO create one Task per segment level retrieve
                 move || {
                     Self::retrieve_blocking(
@@ -424,7 +422,6 @@ impl SegmentsSearcher {
                 let version = segment.point_version(id).ok_or_else(|| {
                     OperationError::service_error(format!("No version for point {id}"))
                 })?;
-
                 // If we already have the latest point version, keep that and continue
                 let version_entry = point_version.entry(id);
                 if matches!(&version_entry, Entry::Occupied(entry) if *entry.get() >= version) {
@@ -480,36 +477,6 @@ impl SegmentsSearcher {
         Ok(point_records)
     }
 
-    pub async fn read_filtered(
-        segments: LockedSegmentHolder,
-        filter: Option<&Filter>,
-        runtime_handle: &Handle,
-        hw_measurement_acc: HwMeasurementAcc,
-    ) -> CollectionResult<BTreeSet<PointIdType>> {
-        let stopping_guard = StoppingGuard::new();
-        let filter = filter.cloned();
-        runtime_handle
-            .spawn_blocking(move || {
-                let is_stopped = stopping_guard.get_is_stopped();
-                let segments = segments.read();
-                let hw_counter = hw_measurement_acc.get_counter_cell();
-                let all_points: BTreeSet<_> = segments
-                    .non_appendable_then_appendable_segments()
-                    .flat_map(|segment| {
-                        segment.get().read().read_filtered(
-                            None,
-                            None,
-                            filter.as_ref(),
-                            &is_stopped,
-                            &hw_counter,
-                        )
-                    })
-                    .collect();
-                Ok(all_points)
-            })
-            .await?
-    }
-
     /// Rescore results with a formula that can reference payload values.
     ///
     /// Aggregates rescores from the segments.
@@ -550,13 +517,42 @@ impl SegmentsSearcher {
         let mut aggregator = BatchResultAggregator::new(std::iter::once(limit));
         aggregator.update_point_versions(segments_results.iter().flatten());
         aggregator.update_batch_results(0, segments_results.into_iter().flatten());
-        let top =
-            aggregator.into_topk().into_iter().next().ok_or_else(|| {
-                OperationError::service_error("expected first result of aggregator")
-            })?;
+        let top = aggregator.into_topk().into_iter().next().ok_or_else(|| {
+            OperationError::service_error("expected first result of aggregator")
+        })?;
 
         Ok(top)
     }
+
+    pub async fn read_filtered(
+        segments: LockedSegmentHolder,
+        filter: Option<&Filter>,
+        runtime_handle: &Handle,
+        hw_measurement_acc: HwMeasurementAcc,
+    ) -> CollectionResult<BTreeSet<PointIdType>> {
+        let stopping_guard = StoppingGuard::new();
+        let filter = filter.cloned();
+        runtime_handle
+            .spawn_blocking(move || {
+                let is_stopped = stopping_guard.get_is_stopped();
+                let segments = segments.read();
+                let hw_counter = hw_measurement_acc.get_counter_cell();
+                let all_points: BTreeSet<_> = segments
+                    .non_appendable_then_appendable_segments()
+                    .flat_map(|segment| {
+                        segment.get().read().read_filtered(
+                            None,
+                            None,
+                            filter.as_ref(),
+                            &is_stopped,
+                            &hw_counter,
+                        )
+                    })
+                    .collect();
+                Ok(all_points)
+            })
+            .await?
+    }
 }
 
 #[derive(PartialEq, Default, Debug)]
@@ -593,12 +589,7 @@ struct BatchSearchParams<'a> {
 }
 
 /// Returns suggested search sampling size for a given number of points and required limit.
-fn sampling_limit(
-    limit: usize,
-    ef_limit: Option<usize>,
-    segment_points: usize,
-    total_points: usize,
-) -> usize {
+fn sampling_limit(limit: usize, ef_limit: Option<usize>, segment_points: usize, total_points: usize) -> usize {
     // shortcut empty segment
     if segment_points == 0 {
         return 0;
@@ -630,7 +621,7 @@ fn effective_limit(limit: usize, ef_limit: usize, poisson_sampling: usize) -> us
 /// * `segment` - Locked segment to search in
 /// * `request` - Batch of search requests
 /// * `use_sampling` - If true, try to use probabilistic sampling
-/// * `query_context` - Additional context for the search
+/// * `segment_query_context` - Additional context for the search
 ///
 /// # Returns
 ///
@@ -736,6 +727,21 @@ fn execute_batch_search(
         search_params.top
     };
 
+    let ignore_plain_index = search_params
+        .params
+        .map(|p| p.indexed_only)
+        .unwrap_or(false);
+    if ignore_plain_index
+        && !read_segment.is_search_optimized(
+            segment_query_context.search_optimized_threshold(),
+            search_params.vector_name,
+            search_params.filter,
+            segment_query_context.get_hardware_counter(),
+        )?
+    {
+        let batch_len = vectors_batch.len();
+        return Ok((vec![vec![]; batch_len], vec![false; batch_len]));
+    }
     let vectors_batch = &vectors_batch.iter().collect_vec();
     let res = read_segment.search_batch(
         search_params.vector_name,
@@ -772,6 +778,8 @@ fn get_hnsw_ef_construct(config: &SegmentConfig, vector_name: &VectorName) -> Op
 
 #[cfg(test)]
 mod tests {
+    use std::collections::HashSet;
+
     use ahash::AHashSet;
     use api::rest::SearchRequestInternal;
     use common::counter::hardware_counter::HardwareCounterCell;
@@ -853,12 +861,13 @@ mod tests {
         };
 
         let hw_acc = HwMeasurementAcc::new();
+        let query_context = QueryContext::new(DEFAULT_INDEXING_THRESHOLD_KB, hw_acc);
         let result = SegmentsSearcher::search(
             Arc::new(segment_holder),
             Arc::new(batch_request),
             &Handle::current(),
             true,
-            QueryContext::new(DEFAULT_INDEXING_THRESHOLD_KB, hw_acc),
+            query_context,
         )
         .await
         .unwrap()
@@ -916,15 +925,13 @@ mod tests {
                 searches: vec![req1.into(), req2.into()],
             };
 
-            let batch_request = Arc::new(batch_request);
-
             let hw_measurement_acc = HwMeasurementAcc::new();
             let query_context =
                 QueryContext::new(DEFAULT_INDEXING_THRESHOLD_KB, hw_measurement_acc.clone());
 
             let result_no_sampling = SegmentsSearcher::search(
                 segment_holder.clone(),
-                batch_request.clone(),
+                Arc::new(batch_request.clone()),
                 &Handle::current(),
                 false,
                 query_context,
@@ -942,7 +949,7 @@ mod tests {
 
             let result_sampling = SegmentsSearcher::search(
                 segment_holder.clone(),
-                batch_request,
+                Arc::new(batch_request),
                 &Handle::current(),
                 true,
                 query_context,
@@ -1017,10 +1024,14 @@ mod tests {
             (1000, 0, 150, 150),
             (1000, 0, 110, 110),
         ];
-        tests.into_iter().for_each(|(limit, ef_limit, poisson_sampling, effective)| assert_eq!(
-            effective_limit(limit, ef_limit, poisson_sampling),
-            effective,
-            "effective limit for [limit: {limit}, ef_limit: {ef_limit}, poisson_sampling: {poisson_sampling}] must be {effective}",
-        ));
+        tests
+            .into_iter()
+            .for_each(|(limit, ef_limit, poisson_sampling, effective)| {
+                assert_eq!(
+                    effective_limit(limit, ef_limit, poisson_sampling),
+                    effective,
+                    "effective limit for [limit: {limit}, ef_limit: {ef_limit}, poisson_sampling: {poisson_sampling}] must be {effective}",
+                )
+            });
     }
 }
\ No newline at end of file
