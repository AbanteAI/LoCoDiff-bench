--- qdrant_lib_collection_src_collection_manager_segments_searcher.rs_expectedoutput.txt (expected)+++ qdrant_lib_collection_src_collection_manager_segments_searcher.rs_extracted.txt (actual)@@ -1,7 +1,7 @@+use std::collections::hash_map::Entry;
 use std::collections::BTreeSet;
-use std::collections::hash_map::Entry;
+use std::sync::atomic::AtomicBool;
 use std::sync::Arc;
-use std::sync::atomic::AtomicBool;
 
 use ahash::AHashMap;
 use common::counter::hardware_accumulator::HwMeasurementAcc;
@@ -228,12 +228,10 @@                 }
 
                 let segments = segments.non_appendable_then_appendable_segments();
-                for locked_segment in segments {
-                    let segment = locked_segment.get();
-                    let segment_guard = segment.read();
-                    segment_guard.fill_query_context(&mut query_context);
-                }
-                Some(query_context)
+                let available_point_count = segments
+                    .map(|segment| segment.get().read().available_point_count())
+                    .sum();
+                Some(available_point_count)
             })
         };
 
@@ -253,8 +251,8 @@         let (locked_segments, searches): (Vec<_>, Vec<_>) = {
             // Unfortunately, we have to do `segments.read()` twice, once in blocking task
             // and once here, due to `Send` bounds :/
-            let segments_lock = segments.read();
-            let segments = segments_lock.non_appendable_then_appendable_segments();
+            let segments = segments.read();
+            let segments = segments.non_appendable_then_appendable_segments();
 
             // Probabilistic sampling for the `limit` parameter avoids over-fetching points from segments.
             // e.g. 10 segments with limit 1000 would fetch 10000 points in total and discard 9000 points.
@@ -263,9 +261,7 @@             // - sampling is enabled
             // - more than 1 segment
             // - segments are not empty
-            let use_sampling = sampling_enabled
-                && segments_lock.len() > 1
-                && query_context_arc.available_point_count() > 0;
+            let use_sampling = sampling_enabled && segments.len() > 1 && available_point_count > 0;
 
             segments
                 .map(|segment| {
@@ -316,7 +312,6 @@             let secondary_searches: Vec<_> = {
                 let mut res = vec![];
                 for (segment_id, batch_ids) in searches_to_rerun.iter() {
-                    let query_context_arc_segment = query_context_arc.clone();
                     let segment = locked_segments[*segment_id].clone();
                     let partial_batch_request = Arc::new(CoreSearchRequestBatch {
                         searches: batch_ids
@@ -328,7 +323,6 @@                     res.push(runtime_handle.spawn_blocking(move || {
                         let segment_query_context =
                             query_context_arc_segment.get_segment_query_context();
-
                         search_in_segment(
                             segment,
                             partial_batch_request,
@@ -630,7 +624,7 @@ /// * `segment` - Locked segment to search in
 /// * `request` - Batch of search requests
 /// * `use_sampling` - If true, try to use probabilistic sampling
-/// * `query_context` - Additional context for the search
+/// * `segment_query_context` - Additional context for the search
 ///
 /// # Returns
 ///
@@ -996,12 +990,6 @@         assert_eq!(sampling_limit(1000000, None, 464530, 35103551), 1000000);
     }
 
-    /// Tests whether calculating the effective ef limit value is correct.
-    ///
-    /// Because there was confusion about what the effective value should be for some input
-    /// combinations, we decided to write this tests to ensure correctness.
-    ///
-    /// See: <https://github.com/qdrant/qdrant/pull/1694>
     #[test]
     fn test_effective_limit() {
         // Test cases to assert: (limit, ef_limit, poisson_sampling, effective)
