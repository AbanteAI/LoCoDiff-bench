--- qdrant_lib_collection_src_collection_manager_segments_searcher.rs_expectedoutput.txt (expected)+++ qdrant_lib_collection_src_collection_manager_segments_searcher.rs_extracted.txt (actual)@@ -1,5 +1,5 @@+use std::collections::hash_map::Entry;
 use std::collections::BTreeSet;
-use std::collections::hash_map::Entry;
 use std::sync::Arc;
 use std::sync::atomic::AtomicBool;
 
@@ -216,13 +216,12 @@                 })
         }
 
-        // Do blocking calls in a blocking task: `segment.get().read()` calls might block async runtime
         let task = {
             let segments = segments.clone();
 
             tokio::task::spawn_blocking(move || {
+                // Do blocking calls in a blocking task: `segment.get().read()` calls might block async runtime
                 let segments = segments.read();
-
                 if segments.is_empty() {
                     return None;
                 }
@@ -248,6 +247,29 @@         query_context: QueryContext,
     ) -> CollectionResult<Vec<Vec<ScoredPoint>>> {
         let query_context_arc = Arc::new(query_context);
+
+        // Do blocking calls in a blocking task: `segment.get().read()` calls might block async runtime
+        let task = {
+            let segments = segments.clone();
+
+            tokio::task::spawn_blocking(move || {
+                let segments = segments.read();
+
+                if segments.is_empty() {
+                    return None;
+                }
+
+                let segments = segments.non_appendable_then_appendable_segments();
+                let available_point_count = segments
+                    .map(|segment| segment.get().read().available_point_count())
+                    .sum();
+                Some(available_point_count)
+            })
+        };
+
+        let Some(available_point_count) = task.await? else {
+            return Ok(Vec::new());
+        };
 
         // Using block to ensure `segments` variable is dropped in the end of it
         let (locked_segments, searches): (Vec<_>, Vec<_>) = {
@@ -270,13 +292,11 @@             segments
                 .map(|segment| {
                     let query_context_arc_segment = query_context_arc.clone();
-
                     let search = runtime_handle.spawn_blocking({
                         let (segment, batch_request) = (segment.clone(), batch_request.clone());
                         move || {
                             let segment_query_context =
                                 query_context_arc_segment.get_segment_query_context();
-
                             search_in_segment(
                                 segment,
                                 batch_request,
@@ -316,7 +336,6 @@             let secondary_searches: Vec<_> = {
                 let mut res = vec![];
                 for (segment_id, batch_ids) in searches_to_rerun.iter() {
-                    let query_context_arc_segment = query_context_arc.clone();
                     let segment = locked_segments[*segment_id].clone();
                     let partial_batch_request = Arc::new(CoreSearchRequestBatch {
                         searches: batch_ids
@@ -324,11 +343,10 @@                             .map(|batch_id| batch_request.searches[*batch_id].clone())
                             .collect(),
                     });
-
+                    let query_context_arc_segment = query_context_arc.clone();
                     res.push(runtime_handle.spawn_blocking(move || {
                         let segment_query_context =
                             query_context_arc_segment.get_segment_query_context();
-
                         search_in_segment(
                             segment,
                             partial_batch_request,
@@ -367,13 +385,6 @@         Ok(top_scores)
     }
 
-    /// Retrieve records for the given points ids from the segments
-    /// - if payload is enabled, payload will be fetched
-    /// - if vector is enabled, vector will be fetched
-    ///
-    /// The points ids can contain duplicates, the records will be fetched only once
-    ///
-    /// If an id is not found in the segments, it won't be included in the output.
     pub async fn retrieve(
         segments: LockedSegmentHolder,
         points: &[PointIdType],
@@ -550,10 +561,9 @@         let mut aggregator = BatchResultAggregator::new(std::iter::once(limit));
         aggregator.update_point_versions(segments_results.iter().flatten());
         aggregator.update_batch_results(0, segments_results.into_iter().flatten());
-        let top =
-            aggregator.into_topk().into_iter().next().ok_or_else(|| {
-                OperationError::service_error("expected first result of aggregator")
-            })?;
+        let top = aggregator.into_topk().into_iter().next().ok_or_else(|| {
+            OperationError::service_error("expected first result of aggregator")
+        })?;
 
         Ok(top)
     }
@@ -592,7 +602,6 @@     pub params: Option<&'a SearchParams>,
 }
 
-/// Returns suggested search sampling size for a given number of points and required limit.
 fn sampling_limit(
     limit: usize,
     ef_limit: Option<usize>,
@@ -604,8 +613,7 @@         return 0;
     }
     let segment_probability = segment_points as f64 / total_points as f64;
-    let poisson_sampling =
-        find_search_sampling_over_point_distribution(limit as f64, segment_probability);
+    let poisson_sampling = find_search_sampling_over_point_distribution(limit as f64, segment_probability);
 
     // if no ef_limit was found, it is a plain index => sampling optimization is not needed.
     let effective = ef_limit.map_or(limit, |ef_limit| {
@@ -662,7 +670,7 @@             filter: search_query.filter.as_ref(),
             with_payload: WithPayload::from(with_payload_interface),
             with_vector: search_query.with_vector.clone().unwrap_or_default(),
-            top: search_query.limit + search_query.offset,
+            top: search_query.limit + search_query.offset.unwrap_or(0),
             params: search_query.params.as_ref(),
         };
 
@@ -772,6 +780,7 @@ 
 #[cfg(test)]
 mod tests {
+    use std::collections::hash_map::Entry;
     use ahash::AHashSet;
     use api::rest::SearchRequestInternal;
     use common::counter::hardware_counter::HardwareCounterCell;
@@ -845,7 +854,7 @@             params: None,
             limit: 5,
             score_threshold: None,
-            offset: 0,
+            offset: None,
         };
 
         let batch_request = CoreSearchRequestBatch {
