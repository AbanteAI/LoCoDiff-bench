
index a458d5593..738352c99 100644
--- a/qdrant_lib_collection_src_collection_manager_optimizers_segment_optimizer.rs_expectedoutput.txt (expected):tmp/tmp4xz8th5b_expected.txt	
+++ b/qdrant_lib_collection_src_collection_manager_optimizers_segment_optimizer.rs_extracted.txt (actual):tmp/tmpv5ltufio_actual.txt	
@@ -10,7 +10,7 @@ use common::disk::dir_size;
 use io::storage_version::StorageVersion;
 use itertools::Itertools;
 use parking_lot::{Mutex, RwLockUpgradableReadGuard};
-use segment::common::operation_error::{OperationResult, check_process_stopped};
+use segment::common::operation_error::{check_process_stopped, OperationResult};
 use segment::common::operation_time_statistics::{
     OperationDurationsAggregator, ScopeDurationMeasurer,
 };
@@ -26,7 +26,6 @@ use crate::collection_manager::holders::segment_holder::{
     LockedSegment, LockedSegmentHolder, SegmentId,
 };
 use crate::config::CollectionParams;
-use crate::operations::config_diff::DiffConfig;
 use crate::operations::types::{CollectionError, CollectionResult};
 
 const BYTES_IN_KB: usize = 1024;
@@ -135,8 +134,8 @@ pub trait SegmentOptimizer {
                 *size += vector_size;
             }
 
-            space_occupied =
-                space_occupied.and_then(|acc| match dir_size(locked_segment.data_path()) {
+            space_occupied = space_occupied
+                .and_then(|acc| match dir_size(locked_segment.data_path()) {
                     Ok(size) => Some(size + acc),
                     Err(err) => {
                         log::debug!(
@@ -150,19 +149,6 @@ pub trait SegmentOptimizer {
         }
 
         let space_needed = space_occupied.map(|x| 2 * x);
-
-        // Ensure temp_path exists
-
-        if !self.temp_path().exists() {
-            std::fs::create_dir_all(self.temp_path()).map_err(|err| {
-                CollectionError::service_error(format!(
-                    "Could not create temp directory `{}`: {}",
-                    self.temp_path().display(),
-                    err
-                ))
-            })?;
-        }
-
         let space_available = match fs4::available_space(self.temp_path()) {
             Ok(available) => Some(available),
             Err(err) => {
@@ -311,7 +297,6 @@ pub trait SegmentOptimizer {
     ///
     /// Original segments are pushed into `segments`, proxies removed.
     /// Returns IDs on restored segments
-    ///
     fn unwrap_proxy(
         &self,
         segments: &LockedSegmentHolder,
@@ -341,12 +326,7 @@ pub trait SegmentOptimizer {
 
     /// Checks if optimization cancellation is requested.
     fn check_cancellation(&self, stopped: &AtomicBool) -> CollectionResult<()> {
-        if stopped.load(Ordering::Relaxed) {
-            return Err(CollectionError::Cancelled {
-                description: "optimization cancelled by service".to_string(),
-            });
-        }
-        Ok(())
+        check_process_stopped(stopped).map_err(|e| CollectionError::from(e))
     }
 
     /// Unwraps proxy, adds temp segment into collection and returns a `Cancelled` error.
@@ -441,20 +421,18 @@ pub trait SegmentOptimizer {
             segment_builder.update(
                 &segment_guards.iter().map(Deref::deref).collect_vec(),
                 stopped,
+                hw_counter,
             )?;
         }
 
-        // Apply index changes to segment builder
-        // Indexes are only used for defragmentation in segment builder, so versions are ignored
-        for (field_name, change) in proxy_changed_indexes.read().iter_unordered() {
-            match change {
-                ProxyIndexChange::Create(schema, _) => {
-                    segment_builder.add_indexed_field(field_name.to_owned(), schema.to_owned());
-                }
-                ProxyIndexChange::Delete(_) => {
-                    segment_builder.remove_indexed_field(field_name);
-                }
-            }
+        for field in proxy_changed_indexes.read().iter_unordered().map(|(field_name, change)| field_name) {
+            segment_builder.remove_indexed_field(field);
+        }
+        for (field, schema_type) in proxy_changed_indexes.read().iter_unordered().filter_map(|(field_name, change)| match change {
+            proxy_segment::ProxyIndexChange::Create(schema, _) => Some((field_name, schema)),
+            proxy_segment::ProxyIndexChange::Delete(_) => None,
+        }) {
+            segment_builder.add_indexed_field(field.to_owned(), schema_type.to_owned());
         }
 
         // 000 - acquired
@@ -560,7 +538,7 @@ pub trait SegmentOptimizer {
     /// New optimized segment should be added into `segments`.
     /// If there were any record changes during the optimization - an additional plain segment will be created.
     ///
-    /// Returns id of the created optimized segment. If no optimization was done - returns None
+    /// Returns number of points in the created optimized segment. If no optimization was done - returns 0
     fn optimize(
         &self,
         segments: LockedSegmentHolder,
@@ -715,13 +693,13 @@ pub trait SegmentOptimizer {
                         optimized_segment.delete_field_index(*version, field_name)?;
                     }
                 }
-                self.check_cancellation(stopped)?;
             }
 
             let deleted_points = proxy_deleted_points.read();
             let points_diff = deleted_points
                 .iter()
                 .filter(|&(point_id, _version)| !already_remove_points.contains(point_id));
+            let optimized_segment_version = optimized_segment.version();
             for (&point_id, &versions) in points_diff {
                 // Delete points here with their operation version, that'll bump the optimized
                 // segment version and will ensure we flush the new changes
