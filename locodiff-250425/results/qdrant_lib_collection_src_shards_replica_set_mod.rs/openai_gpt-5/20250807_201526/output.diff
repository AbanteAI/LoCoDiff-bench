
index 1a8af4043..461bb6382 100644
--- a/qdrant_lib_collection_src_shards_replica_set_mod.rs_expectedoutput.txt (expected):tmp/tmpmz3o9dqs_expected.txt	
+++ b/qdrant_lib_collection_src_shards_replica_set_mod.rs_extracted.txt (actual):tmp/tmpjm5ux4pa_actual.txt	
@@ -1,4 +1,3 @@
-pub mod clock_set;
 mod execute_read_operation;
 mod locally_disabled_peers;
 mod read_ops;
@@ -43,6 +42,7 @@ use crate::shards::replica_set::clock_set::ClockSet;
 use crate::shards::shard::{PeerId, Shard, ShardId};
 use crate::shards::shard_config::ShardConfig;
 
+//
 //    │    Collection Created
 //    │
 //    ▼
@@ -117,7 +117,8 @@ pub struct ShardReplicaSet {
 
 pub type AbortShardTransfer = Arc<dyn Fn(ShardTransfer, &str) + Send + Sync>;
 pub type ChangePeerState = Arc<dyn Fn(PeerId, ShardId) + Send + Sync>;
-pub type ChangePeerFromState = Arc<dyn Fn(PeerId, ShardId, Option<ReplicaState>) + Send + Sync>;
+pub type ChangePeerFromState =
+    Arc<dyn Fn(PeerId, ShardId, Option<ReplicaState>) + Send + Sync>;
 
 const REPLICA_STATE_FILE: &str = "replica_state.json";
 
@@ -208,8 +209,8 @@ impl ShardReplicaSet {
             replica_state: replica_state.into(),
             locally_disabled_peers: Default::default(),
             shard_path,
-            abort_shard_transfer_cb: abort_shard_transfer,
             notify_peer_failure_cb: on_peer_failure,
+            abort_shard_transfer_cb: abort_shard_transfer,
             channel_service,
             collection_id,
             collection_config,
@@ -446,14 +447,6 @@ impl ShardReplicaSet {
             .await
     }
 
-    pub fn wait_for_state_condition_sync<F>(&self, check: F, timeout: Duration) -> bool
-    where
-        F: Fn(&ReplicaSetState) -> bool,
-    {
-        let replica_state = self.replica_state.clone();
-        replica_state.wait_for(check, timeout)
-    }
-
     /// Wait for a local shard to get into `state`
     ///
     /// Uses a blocking thread internally.
@@ -491,6 +484,14 @@ impl ShardReplicaSet {
         .await
     }
 
+    pub fn wait_for_state_condition_sync<F>(&self, check: F, timeout: Duration) -> bool
+    where
+        F: Fn(&ReplicaSetState) -> bool,
+    {
+        let replica_state = self.replica_state.clone();
+        replica_state.wait_for(check, timeout)
+    }
+
     /// Wait for a replica set state condition to be true.
     ///
     /// Uses a blocking thread internally.
@@ -730,7 +731,6 @@ impl ShardReplicaSet {
                     self.optimizers_config.clone(),
                 )
                 .await?;
-
                 match state {
                     ReplicaState::Active
                     | ReplicaState::Listener
@@ -876,6 +876,80 @@ impl ShardReplicaSet {
         Ok(())
     }
 
+    /// Get shard recovery point for WAL.
+    pub(crate) async fn shard_recovery_point(&self) -> CollectionResult<RecoveryPoint> {
+        let local_shard = self.local.read().await;
+        let Some(local_shard) = local_shard.as_ref() else {
+            return Err(CollectionError::NotFound {
+                what: "Peer does not have local shard".into(),
+            });
+        };
+
+        local_shard.shard_recovery_point().await
+    }
+
+    /// Update the cutoff point for the local shard.
+    pub(crate) async fn update_shard_cutoff_point(
+        &self,
+        cutoff: &RecoveryPoint,
+    ) -> CollectionResult<()> {
+        let local_shard = self.local.read().await;
+        let Some(local_shard) = local_shard.as_ref() else {
+            return Err(CollectionError::NotFound {
+                what: "Peer does not have local shard".into(),
+            });
+        };
+
+        local_shard.update_cutoff(cutoff).await
+    }
+
+    pub(crate) fn get_snapshots_storage_manager(&self) -> CollectionResult<SnapshotStorageManager> {
+        SnapshotStorageManager::new(&self.shared_storage_config.snapshots_config)
+    }
+
+    pub(crate) async fn trigger_optimizers(&self) -> bool {
+        let shard = self.local.read().await;
+        let Some(shard) = shard.as_ref() else {
+            return false;
+        };
+        shard.trigger_optimizers();
+        true
+    }
+
+    /// Returns the estimated size of all local segments.
+    /// Since this locks all segments you should cache this value in performance critical scenarios!
+    pub(crate) async fn calculate_local_shard_stats(&self) -> Option<CollectionSizeStats> {
+        self.local
+            .read()
+            .await
+            .as_ref()
+            .map(|i| match i {
+                Shard::Local(local) => {
+                    let mut total_vector_size = 0;
+                    let mut total_payload_size = 0;
+                    let mut total_points = 0;
+
+                    for segment in local.segments.read().iter() {
+                        let size_info = segment.1.get().read().size_info();
+                        total_vector_size += size_info.vectors_size_bytes;
+                        total_payload_size += size_info.payloads_size_bytes;
+                        total_points += size_info.num_points;
+                    }
+
+                    Some(CollectionSizeStats {
+                        vector_storage_size: total_vector_size,
+                        payload_storage_size: total_payload_size,
+                        points_count: total_points,
+                    })
+                }
+                Shard::Proxy(_)
+                | Shard::ForwardProxy(_)
+                | Shard::QueueProxy(_)
+                | Shard::Dummy(_) => None,
+            })
+            .unwrap_or_default()
+    }
+
     pub async fn delete_local_points(
         &self,
         filter: Filter,
@@ -1054,7 +1128,8 @@ impl ShardReplicaSet {
 
     fn notify_peer_failure(&self, peer_id: PeerId, from_state: Option<ReplicaState>) {
         log::debug!("Notify peer failure: {peer_id}");
-        self.notify_peer_failure_cb.deref()(peer_id, self.shard_id, from_state)
+        self.notify_peer_failure_cb
+            .deref()(peer_id, self.shard_id, from_state)
     }
 
     fn abort_shard_transfer(&self, transfer: ShardTransfer, reason: &str) {
@@ -1068,80 +1143,6 @@ impl ShardReplicaSet {
 
         self.abort_shard_transfer_cb.deref()(transfer, reason)
     }
-
-    /// Get shard recovery point for WAL.
-    pub(crate) async fn shard_recovery_point(&self) -> CollectionResult<RecoveryPoint> {
-        let local_shard = self.local.read().await;
-        let Some(local_shard) = local_shard.as_ref() else {
-            return Err(CollectionError::NotFound {
-                what: "Peer does not have local shard".into(),
-            });
-        };
-
-        local_shard.shard_recovery_point().await
-    }
-
-    /// Update the cutoff point for the local shard.
-    pub(crate) async fn update_shard_cutoff_point(
-        &self,
-        cutoff: &RecoveryPoint,
-    ) -> CollectionResult<()> {
-        let local_shard = self.local.read().await;
-        let Some(local_shard) = local_shard.as_ref() else {
-            return Err(CollectionError::NotFound {
-                what: "Peer does not have local shard".into(),
-            });
-        };
-
-        local_shard.update_cutoff(cutoff).await
-    }
-
-    pub(crate) fn get_snapshots_storage_manager(&self) -> CollectionResult<SnapshotStorageManager> {
-        SnapshotStorageManager::new(&self.shared_storage_config.snapshots_config)
-    }
-
-    pub(crate) async fn trigger_optimizers(&self) -> bool {
-        let shard = self.local.read().await;
-        let Some(shard) = shard.as_ref() else {
-            return false;
-        };
-        shard.trigger_optimizers();
-        true
-    }
-
-    /// Returns the estimated size of all local segments.
-    /// Since this locks all segments you should cache this value in performance critical scenarios!
-    pub(crate) async fn calculate_local_shard_stats(&self) -> Option<CollectionSizeStats> {
-        self.local
-            .read()
-            .await
-            .as_ref()
-            .map(|i| match i {
-                Shard::Local(local) => {
-                    let mut total_vector_size = 0;
-                    let mut total_payload_size = 0;
-                    let mut total_points = 0;
-
-                    for segment in local.segments.read().iter() {
-                        let size_info = segment.1.get().read().size_info();
-                        total_vector_size += size_info.vectors_size_bytes;
-                        total_payload_size += size_info.payloads_size_bytes;
-                        total_points += size_info.num_points;
-                    }
-
-                    Some(CollectionSizeStats {
-                        vector_storage_size: total_vector_size,
-                        payload_storage_size: total_payload_size,
-                        points_count: total_points,
-                    })
-                }
-                Shard::Proxy(_)
-                | Shard::ForwardProxy(_)
-                | Shard::QueueProxy(_)
-                | Shard::Dummy(_) => None,
-            })
-            .unwrap_or_default()
-    }
 }
 
 /// Represents a replica set state
