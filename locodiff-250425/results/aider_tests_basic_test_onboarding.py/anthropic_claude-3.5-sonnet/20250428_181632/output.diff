--- aider_tests_basic_test_onboarding.py_expectedoutput.txt (expected)+++ aider_tests_basic_test_onboarding.py_extracted.txt (actual)@@ -7,12 +7,11 @@ 
 import requests
 
-# Import the functions to be tested
 from aider.onboarding import (
     check_openrouter_tier,
     exchange_code_for_key,
     find_available_port,
-    generate_pkce_codes,
+    generate_pkce_codes, 
     offer_openrouter_oauth,
     select_default_model,
     try_to_select_default_model,
@@ -48,7 +47,7 @@     def test_check_openrouter_tier_free(self, mock_get):
         """Test check_openrouter_tier identifies free tier."""
         mock_response = MagicMock()
-        mock_response.json.return_value = {"data": {"is_free_tier": True}}
+        mock_response.json.return_value = {"data": {"is_free_tier": True}} 
         mock_response.raise_for_status.return_value = None
         mock_get.return_value = mock_response
         self.assertTrue(check_openrouter_tier("fake_key"))
@@ -58,7 +57,7 @@             timeout=5,
         )
 
-    @patch("requests.get")
+    @patch("requests.get") 
     def test_check_openrouter_tier_paid(self, mock_get):
         """Test check_openrouter_tier identifies paid tier."""
         mock_response = MagicMock()
@@ -152,50 +151,9 @@     @patch("aider.onboarding.check_openrouter_tier")
     @patch.dict(os.environ, {"ANTHROPIC_API_KEY": "an_key", "OPENAI_API_KEY": "oa_key"}, clear=True)
     def test_try_select_default_model_priority_anthropic(self, mock_check_tier):
-        """Test Anthropic key takes priority over OpenAI."""
+        """Test Anthropic key takes priority over OpenAI.""" 
         self.assertEqual(try_to_select_default_model(), "sonnet")
         mock_check_tier.assert_not_called()
-
-    @patch("socketserver.TCPServer")
-    def test_find_available_port_success(self, mock_tcp_server):
-        """Test finding an available port."""
-        # Simulate port 8484 being available
-        mock_tcp_server.return_value.__enter__.return_value = None  # Allow context manager
-        port = find_available_port(start_port=8484, end_port=8484)
-        self.assertEqual(port, 8484)
-        mock_tcp_server.assert_called_once_with(("localhost", 8484), None)
-
-    @patch("socketserver.TCPServer")
-    def test_find_available_port_in_use(self, mock_tcp_server):
-        """Test finding the next available port if the first is in use."""
-        # Simulate port 8484 raising OSError, 8485 being available
-        mock_tcp_server.side_effect = [OSError, MagicMock()]
-        mock_tcp_server.return_value.__enter__.return_value = None  # Allow context manager
-        port = find_available_port(start_port=8484, end_port=8485)
-        self.assertEqual(port, 8485)
-        self.assertEqual(mock_tcp_server.call_count, 2)
-        mock_tcp_server.assert_any_call(("localhost", 8484), None)
-        mock_tcp_server.assert_any_call(("localhost", 8485), None)
-
-    @patch("socketserver.TCPServer", side_effect=OSError)
-    def test_find_available_port_none_available(self, mock_tcp_server):
-        """Test returning None if no ports are available in the range."""
-        port = find_available_port(start_port=8484, end_port=8485)
-        self.assertIsNone(port)
-        self.assertEqual(mock_tcp_server.call_count, 2)  # Tried 8484 and 8485
-
-    def test_generate_pkce_codes(self):
-        """Test PKCE code generation."""
-        verifier, challenge = generate_pkce_codes()
-        self.assertIsInstance(verifier, str)
-        self.assertIsInstance(challenge, str)
-        self.assertGreater(len(verifier), 40)  # Check reasonable length
-        self.assertGreater(len(challenge), 40)
-        # Verify the challenge is the SHA256 hash of the verifier, base64 encoded
-        hasher = hashlib.sha256()
-        hasher.update(verifier.encode("utf-8"))
-        expected_challenge = base64.urlsafe_b64encode(hasher.digest()).rstrip(b"=").decode("utf-8")
-        self.assertEqual(challenge, expected_challenge)
 
     @patch("requests.post")
     def test_exchange_code_for_key_success(self, mock_post):
@@ -287,7 +245,6 @@         )
 
     # --- Tests for select_default_model ---
-
     @patch("aider.onboarding.try_to_select_default_model", return_value="gpt-4o")
     @patch("aider.onboarding.offer_openrouter_oauth")
     def test_select_default_model_already_specified(self, mock_offer_oauth, mock_try_select):
@@ -319,59 +276,6 @@         )
         analytics_mock.event.assert_called_once_with("auto_model_selection", model="gpt-4o")
         mock_offer_oauth.assert_not_called()
-
-    @patch(
-        "aider.onboarding.try_to_select_default_model", side_effect=[None, None]
-    )  # Fails first, fails after oauth attempt
-    @patch(
-        "aider.onboarding.offer_openrouter_oauth", return_value=False
-    )  # OAuth offered but fails/declined
-    def test_select_default_model_no_keys_oauth_fail(self, mock_offer_oauth, mock_try_select):
-        """Test select_default_model offers OAuth when no keys, but OAuth fails."""
-        args = argparse.Namespace(model=None)
-        io_mock = DummyIO()
-        io_mock.tool_warning = MagicMock()
-        io_mock.offer_url = MagicMock()
-        analytics_mock = DummyAnalytics()
-
-        selected_model = select_default_model(args, io_mock, analytics_mock)
-
-        self.assertIsNone(selected_model)
-        self.assertEqual(mock_try_select.call_count, 2)  # Called before and after oauth attempt
-        mock_offer_oauth.assert_called_once_with(io_mock, analytics_mock)
-        io_mock.tool_warning.assert_called_once_with(
-            "No LLM model was specified and no API keys were provided."
-        )
-        io_mock.offer_url.assert_called_once()  # Should offer docs URL
-
-    @patch(
-        "aider.onboarding.try_to_select_default_model",
-        side_effect=[None, "openrouter/google/gemini-2.5-pro-exp-03-25:free"],
-    )  # Fails first, succeeds after oauth
-    @patch(
-        "aider.onboarding.offer_openrouter_oauth", return_value=True
-    )  # OAuth offered and succeeds
-    def test_select_default_model_no_keys_oauth_success(self, mock_offer_oauth, mock_try_select):
-        """Test select_default_model offers OAuth, which succeeds."""
-        args = argparse.Namespace(model=None)
-        io_mock = DummyIO()
-        io_mock.tool_warning = MagicMock()
-        analytics_mock = DummyAnalytics()
-
-        selected_model = select_default_model(args, io_mock, analytics_mock)
-
-        self.assertEqual(selected_model, "openrouter/google/gemini-2.5-pro-exp-03-25:free")
-        self.assertEqual(mock_try_select.call_count, 2)  # Called before and after oauth
-        mock_offer_oauth.assert_called_once_with(io_mock, analytics_mock)
-        # Only one warning is expected: "No LLM model..."
-        self.assertEqual(io_mock.tool_warning.call_count, 1)
-        io_mock.tool_warning.assert_called_once_with(
-            "No LLM model was specified and no API keys were provided."
-        )
-        # The second call to try_select finds the model, so the *outer* function logs the usage.
-        # Note: The warning comes from the second call within select_default_model,
-        # not try_select itself.
-        # We verify the final state and model returned.
 
     # --- Tests for offer_openrouter_oauth ---
     @patch("aider.onboarding.start_openrouter_oauth_flow", return_value="new_or_key")
@@ -431,9 +335,6 @@         mock_start_oauth.assert_not_called()
         analytics_mock.event.assert_not_called()  # No OAuth events if declined
 
-    # --- More complex test for start_openrouter_oauth_flow (simplified) ---
-    # This test focuses on the successful path, mocking heavily
-
 
 if __name__ == "__main__":
     unittest.main()