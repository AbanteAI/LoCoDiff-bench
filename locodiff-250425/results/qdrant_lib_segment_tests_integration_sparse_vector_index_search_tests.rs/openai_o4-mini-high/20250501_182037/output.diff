--- qdrant_lib_segment_tests_integration_sparse_vector_index_search_tests.rs_expectedoutput.txt (expected)+++ qdrant_lib_segment_tests_integration_sparse_vector_index_search_tests.rs_extracted.txt (actual)@@ -8,17 +8,16 @@ use io::storage_version::VERSION_FILE;
 use itertools::Itertools;
 use rand::SeedableRng;
-use rand::rngs::StdRng;
 use segment::common::operation_error::OperationResult;
 use segment::data_types::named_vectors::NamedVectors;
 use segment::data_types::vectors::{QueryVector, VectorInternal};
 use segment::entry::entry_point::SegmentEntry;
+use segment::fixture_for_all_indices;
 use segment::fixtures::payload_fixtures::STR_KEY;
 use segment::fixtures::sparse_fixtures::{fixture_sparse_index, fixture_sparse_index_from_iter};
+use segment::index::hnsw_index::num_rayon_threads;
 use segment::index::sparse_index::sparse_index_config::{SparseIndexConfig, SparseIndexType};
-use segment::index::sparse_index::sparse_vector_index::{
-    SparseVectorIndex, SparseVectorIndexOpenArgs,
-};
+use segment::index::sparse_index::sparse_vector_index::{SparseVectorIndex, SparseVectorIndexOpenArgs};
 use segment::index::{PayloadIndex, VectorIndex, VectorIndexEnum};
 use segment::json_path::JsonPath;
 use segment::segment::Segment;
@@ -31,7 +30,7 @@     VectorStorageDatatype,
 };
 use segment::vector_storage::VectorStorage;
-use segment::{fixture_for_all_indices, payload_json};
+use segment::{payload_json};
 use sparse::common::sparse_vector::SparseVector;
 use sparse::common::sparse_vector_fixture::{random_full_sparse_vector, random_sparse_vector};
 use sparse::common::types::DimId;
@@ -55,9 +54,10 @@ /// Full scan threshold to force plain search
 const LARGE_FULL_SCAN_THRESHOLD: usize = 10 * NUM_VECTORS;
 
+/// Name of the sparse vector field in tests
 const SPARSE_VECTOR_NAME: &VectorName = "sparse_vector";
 
-/// Expects the filter to match ALL points in order to compare the results with/without filter
+/// Compares search results with and without a filter (that matches all points)
 fn compare_sparse_vectors_search_with_without_filter(full_scan_threshold: usize) {
     let mut rnd = StdRng::seed_from_u64(43);
 
@@ -71,60 +71,50 @@         data_dir.path(),
     );
 
-    // random query vectors
+    // Prepare a filter that matches everything
+    let filter = Filter::new_must_not(Condition::Field(FieldCondition::new_match(
+        JsonPath::new(STR_KEY),
+        STR_KEY.to_owned().into(),
+    )));
+
+    let stopped = AtomicBool::new(false);
     let attempts = 1000;
     let query_vectors = (0..attempts)
         .map(|_| random_sparse_vector(&mut rnd, MAX_SPARSE_DIM))
         .collect::<Vec<_>>();
 
-    // filter matches everything
-    let filter = Filter::new_must_not(Condition::Field(FieldCondition::new_match(
-        JsonPath::new(STR_KEY),
-        STR_KEY.to_owned().into(),
-    )));
-
-    // compares results with and without filters
-    // expects the filter to have no effect on the results because the filter matches everything
     for query in query_vectors {
         let maximum_number_of_results = sparse_vector_index.max_result_count(&query);
-        // get all results minus 10 to force a bit of pruning
         let top = max(1, maximum_number_of_results.saturating_sub(10));
         let query_vector: QueryVector = query.clone().into();
-        // with filter
+
         let index_results_filter = sparse_vector_index
-            .search(
-                &[&query_vector],
-                Some(&filter),
-                top,
-                None,
-                &Default::default(),
-            )
-            .unwrap();
-
-        // without filter
+            .search(&[&query_vector], Some(&filter), top, None, &Default::default())
+            .unwrap();
+
         let index_results_no_filter = sparse_vector_index
             .search(&[&query_vector], None, top, None, &Default::default())
             .unwrap();
 
-        assert_eq!(index_results_filter.len(), index_results_no_filter.len());
-
-        for (filter_result, no_filter_result) in index_results_filter
-            .iter()
-            .zip(index_results_no_filter.iter())
+        assert_eq!(
+            index_results_filter.len(),
+            index_results_no_filter.len()
+        );
+
+        for (filter_result, no_filter_result) in
+            index_results_filter.iter().zip(index_results_no_filter.iter())
         {
             assert_eq!(
                 filter_result.len(),
                 no_filter_result.len(),
                 "query = {query:#?}, filter_result = {filter_result:#?} no_filter_result = {no_filter_result:#?}",
             );
-            // skip zero scores because index skips non-overlapping points, but plain search does not
             for (filter_result, no_filter_result) in filter_result
                 .iter()
                 .filter(|s| s.score != 0.0)
                 .zip(no_filter_result.iter().filter(|s| s.score != 0.0))
             {
                 if filter_result.idx != no_filter_result.idx {
-                    // we do not break ties when identical scores
                     assert_eq!(filter_result.score, no_filter_result.score);
                 } else {
                     assert_eq!(filter_result, no_filter_result);
@@ -136,30 +126,24 @@ 
 #[test]
 fn sparse_vector_index_ram_filter_search() {
-    // very low full scan threshold to force usage of inverted index
     compare_sparse_vectors_search_with_without_filter(LOW_FULL_SCAN_THRESHOLD);
 }
 
 #[test]
 fn sparse_vector_index_fallback_plain_search() {
-    // very high full scan threshold to force fallback to plain search
     compare_sparse_vectors_search_with_without_filter(NUM_VECTORS + 1);
 }
 
 /// Checks that the sparse vector index is consistent with the underlying storage
-#[cfg(test)]
 fn check_index_storage_consistency<T: InvertedIndex>(sparse_vector_index: &SparseVectorIndex<T>) {
     let borrowed_vector_storage = sparse_vector_index.vector_storage().borrow();
     let point_count = borrowed_vector_storage.available_vector_count();
     let hw_counter = HardwareCounterCell::disposable();
     for id in 0..point_count as PointOffsetType {
-        // assuming no deleted points
         let vector = borrowed_vector_storage.get_vector(id);
         let vector: &SparseVector = vector.as_vec_ref().try_into().unwrap();
-        let remapped_vector = sparse_vector_index
-            .indices_tracker()
-            .remap_vector(vector.to_owned());
-        // check posting lists are consistent with storage
+        let remapped_vector = sparse_vector_index.indices_tracker().remap_vector(vector.to_owned());
+
         for (dim_id, dim_value) in remapped_vector
             .indices
             .iter()
@@ -169,7 +153,6 @@                 .inverted_index()
                 .get(*dim_id, &hw_counter)
                 .unwrap();
-            // assert posting list sorted by record id
             assert!(
                 posting_list
                     .clone()
@@ -177,14 +160,13 @@                     .tuple_windows()
                     .all(|(w0, w1)| w0.record_id < w1.record_id),
             );
-            // assert posted list contains record id
             assert!(
                 posting_list
                     .into_std_iter()
                     .any(|e| e.record_id == id && e.weight == *dim_value),
             );
         }
-        // check the vector can be found via search using large top
+
         let top = sparse_vector_index.max_result_count(vector);
         let query_vector: QueryVector = vector.to_owned().into();
         let results = sparse_vector_index
@@ -196,7 +178,6 @@ 
 #[test]
 fn sparse_vector_index_consistent_with_storage() {
-    let stopped = AtomicBool::new(false);
     let mut rnd = StdRng::seed_from_u64(42);
 
     let data_dir = Builder::new().prefix("data_dir").tempdir().unwrap();
@@ -208,22 +189,19 @@         data_dir.path(),
     );
 
-    // check consistency with underlying RAM inverted index
     check_index_storage_consistency(&sparse_vector_ram_index);
 
     let mmap_index_dir = Builder::new().prefix("mmap_index_dir").tempdir().unwrap();
-
-    // create mmap sparse vector index
     let mut sparse_index_config = sparse_vector_ram_index.config();
     sparse_index_config.index_type = SparseIndexType::Mmap;
-    let sparse_vector_mmap_index: SparseVectorIndex<InvertedIndexCompressedMmap<f32>> =
+    let mut sparse_vector_mmap_index: SparseVectorIndex<InvertedIndexCompressedMmap<f32>> =
         SparseVectorIndex::open(SparseVectorIndexOpenArgs {
             config: sparse_index_config,
             id_tracker: sparse_vector_ram_index.id_tracker().clone(),
             vector_storage: sparse_vector_ram_index.vector_storage().clone(),
             payload_index: sparse_vector_ram_index.payload_index().clone(),
             path: mmap_index_dir.path(),
-            stopped: &stopped,
+            stopped: &AtomicBool::new(false),
             tick_progress: || (),
         })
         .unwrap();
@@ -233,49 +211,19 @@         sparse_vector_ram_index.indexed_vector_count()
     );
 
-    // check consistency with underlying mmap inverted index
     check_index_storage_consistency(&sparse_vector_mmap_index);
-
-    // drop and reload index
-    drop(sparse_vector_mmap_index);
-
-    // load index from memmap file
-    let mut sparse_index_config = sparse_vector_ram_index.config();
-    sparse_index_config.index_type = SparseIndexType::Mmap;
-    let sparse_vector_mmap_index: SparseVectorIndex<InvertedIndexCompressedMmap<f32>> =
-        SparseVectorIndex::open(SparseVectorIndexOpenArgs {
-            config: sparse_index_config,
-            id_tracker: sparse_vector_ram_index.id_tracker().clone(),
-            vector_storage: sparse_vector_ram_index.vector_storage().clone(),
-            payload_index: sparse_vector_ram_index.payload_index().clone(),
-            path: mmap_index_dir.path(),
-            stopped: &stopped,
-            tick_progress: || (),
-        })
-        .unwrap();
-
-    assert_eq!(
-        sparse_vector_mmap_index.indexed_vector_count(),
-        sparse_vector_ram_index.indexed_vector_count()
-    );
-
-    // check consistency with underlying mmap inverted index
-    check_index_storage_consistency(&sparse_vector_mmap_index);
 }
 
 #[test]
 fn sparse_vector_index_load_missing_mmap() {
-    let data_dir = Builder::new().prefix("data_dir").tempdir().unwrap();
     let sparse_vector_index: OperationResult<SparseVectorIndex<InvertedIndexCompressedMmap<f32>>> =
         fixture_sparse_index_from_iter(
-            data_dir.path(),
+            Builder::new().prefix("data_dir").tempdir().unwrap().path(),
             [].iter().cloned(),
             10_000,
             SparseIndexType::Mmap,
         );
-    // absent configuration file for mmap are ignored
-    // a new index is created
-    assert!(sparse_vector_index.is_ok())
+    assert!(sparse_vector_index.is_ok());
 }
 
 #[test]
@@ -284,8 +232,7 @@     let mut rnd = StdRng::seed_from_u64(42);
 
     let data_dir = Builder::new().prefix("data_dir").tempdir().unwrap();
-
-    let sparse_vector_index = fixture_sparse_index_from_iter::<InvertedIndexRam>(
+    let sparse_vector_index = fixture_sparse_index_from_iter::<InvertedIndexRam, _>(
         data_dir.path(),
         (0..NUM_VECTORS).map(|_| random_sparse_vector(&mut rnd, MAX_SPARSE_DIM)),
         LOW_FULL_SCAN_THRESHOLD,
@@ -293,32 +240,21 @@     )
     .unwrap();
 
-    // sanity check (all indexed, no deleted points)
-    assert_eq!(
-        sparse_vector_index
-            .id_tracker()
-            .borrow()
-            .available_point_count(),
+    assert_eq!(
+        sparse_vector_index.id_tracker().borrow().available_point_count(),
         sparse_vector_index.indexed_vector_count()
     );
     assert_eq!(
-        sparse_vector_index
-            .id_tracker()
-            .borrow()
-            .deleted_point_count(),
+        sparse_vector_index.id_tracker().borrow().deleted_point_count(),
         0
     );
 
-    // query index
     let query_vector: QueryVector = random_sparse_vector(&mut rnd, MAX_SPARSE_DIM).into();
     let before_deletion_results: Vec<_> = sparse_vector_index
         .search(&[&query_vector], None, top, None, &Default::default())
         .unwrap();
 
-    // pick a point to delete
     let deleted_idx = before_deletion_results[0][0].idx;
-
-    // delete a point
     let deleted_external = sparse_vector_index
         .id_tracker()
         .borrow_mut()
@@ -337,14 +273,10 @@             .is_deleted_point(deleted_idx),
     );
     assert_eq!(
-        sparse_vector_index
-            .id_tracker()
-            .borrow()
-            .deleted_point_count(),
+        sparse_vector_index.id_tracker().borrow().deleted_point_count(),
         1
     );
 
-    // assert that the deleted point is no longer in the index
     let after_deletion_results: Vec<_> = sparse_vector_index
         .search(&[&query_vector], None, top, None, &Default::default())
         .unwrap();
@@ -361,8 +293,6 @@     let mut rnd = StdRng::seed_from_u64(42);
 
     let data_dir = Builder::new().prefix("data_dir").tempdir().unwrap();
-
-    // setup index
     let sparse_vector_index = fixture_sparse_index::<InvertedIndexCompressedImmutableRam<f32>, _>(
         &mut rnd,
         NUM_VECTORS,
@@ -371,7 +301,6 @@         data_dir.path(),
     );
 
-    // query index by payload
     let field_name = "field";
     let field_value = "important value";
     let filter = Filter::new_must(Condition::Field(FieldCondition::new_match(
@@ -379,30 +308,19 @@         field_value.to_owned().into(),
     )));
 
-    // query all sparse dimension to get all points
     let query_vector: QueryVector = random_full_sparse_vector(&mut rnd, MAX_SPARSE_DIM).into();
     let before_result = sparse_vector_index
-        .search(
-            &[&query_vector],
-            Some(&filter),
-            10,
-            None,
-            &Default::default(),
-        )
+        .search(&[&query_vector], Some(&filter), 10, None, &Default::default())
         .unwrap();
     assert_eq!(before_result.len(), 1);
     assert_eq!(before_result[0].len(), 0);
 
-    let hw_counter = HardwareCounterCell::new();
-
-    // create payload field index
     let mut payload_index = sparse_vector_index.payload_index().borrow_mut();
     payload_index
-        .set_indexed(&JsonPath::new(field_name), Keyword, &hw_counter)
+        .set_indexed(&JsonPath::new(field_name), Keyword, &HardwareCounterCell::new())
         .unwrap();
     drop(payload_index);
 
-    // assert payload field index created and empty
     let payload_index = sparse_vector_index.payload_index().borrow();
     let indexed_fields = payload_index.indexed_fields();
     assert_eq!(
@@ -415,37 +333,27 @@     assert_eq!(field_index[0].count_indexed_points(), 0);
     drop(payload_index);
 
-    // add payload on the first half of the points
-    let half_indexed_count = sparse_vector_index.indexed_vector_count() / 2;
-    let payload = payload_json! {field_name: field_value};
-    let hw_counter = HardwareCounterCell::new();
     let mut payload_index = sparse_vector_index.payload_index().borrow_mut();
-    for idx in 0..half_indexed_count {
+    for idx in 0..NUM_VECTORS {
         payload_index
-            .set_payload(idx as PointOffsetType, &payload, &None, &hw_counter)
+            .set_payload(idx as PointOffsetType, &payload_json! {field_name: field_value}, &None, &HardwareCounterCell::new())
             .unwrap();
     }
     drop(payload_index);
 
-    // assert payload index updated
-    let payload_index = sparse_vector_index.payload_index().borrow();
-    let field_indexes = &payload_index.field_indexes;
-    let field_index = field_indexes.get(&JsonPath::new(field_name)).unwrap();
-    assert_eq!(field_index[0].count_indexed_points(), half_indexed_count);
-    drop(payload_index);
-
-    // request all points with payload
-    let after_result = sparse_vector_index
-        .search(
-            &[&query_vector],
-            Some(&filter),
-            half_indexed_count * 2, // original top
-            None,
-            &Default::default(),
-        )
-        .unwrap();
-    assert_eq!(after_result.len(), 1);
-    assert_eq!(after_result[0].len(), half_indexed_count); // expect half of the points
+    let after_plain_results = sparse_vector_index
+        .search(&[&query_vector], Some(&filter), NUM_VECTORS, None, &Default::default())
+        .unwrap();
+    assert_eq!(after_plain_results.len(), 1);
+    assert_eq!(after_plain_results[0].len(), NUM_VECTORS);
+
+    assert_eq!(
+        sparse_vector_index
+            .get_telemetry_data(TelemetryDetail::default())
+            .filtered_small_cardinality
+            .count,
+        2
+    );
 }
 
 #[test]
@@ -453,7 +361,6 @@     let mut rnd = StdRng::seed_from_u64(42);
 
     let data_dir = Builder::new().prefix("data_dir").tempdir().unwrap();
-    // setup index
     let sparse_vector_index = fixture_sparse_index::<InvertedIndexCompressedImmutableRam<f32>, _>(
         &mut rnd,
         NUM_VECTORS,
@@ -462,59 +369,32 @@         data_dir.path(),
     );
 
-    // query index by payload
-    let field_name = "field";
-    let field_value = "important value";
     let filter = Filter::new_must(Condition::Field(FieldCondition::new_match(
-        JsonPath::new(field_name),
-        field_value.to_owned().into(),
+        JsonPath::new("field"),
+        "important value".to_owned().into(),
     )));
-
-    // query all sparse dimension to get all points
     let query_vector: QueryVector = random_full_sparse_vector(&mut rnd, MAX_SPARSE_DIM).into();
 
-    // empty when searching payload index directly
     let before_plain_results = sparse_vector_index
-        .search(
-            &[&query_vector],
-            Some(&filter),
-            10,
-            None,
-            &Default::default(),
-        )
-        .unwrap();
-
+        .search(&[&query_vector], Some(&filter), 10, None, &Default::default())
+        .unwrap();
     assert_eq!(before_plain_results.len(), 1);
     assert_eq!(before_plain_results[0].len(), 0);
 
-    let payload = payload_json! {field_name: field_value};
-
-    let hw_counter = HardwareCounterCell::new();
-
-    // add payload to all points
     let mut payload_index = sparse_vector_index.payload_index().borrow_mut();
     for idx in 0..NUM_VECTORS {
         payload_index
-            .set_payload(idx as PointOffsetType, &payload, &None, &hw_counter)
+            .set_payload(idx as PointOffsetType, &payload_json! {"field": "important value"}, &None, &HardwareCounterCell::new())
             .unwrap();
     }
     drop(payload_index);
 
-    // same results when searching payload index directly
     let after_plain_results = sparse_vector_index
-        .search(
-            &[&query_vector],
-            Some(&filter),
-            NUM_VECTORS,
-            None,
-            &Default::default(),
-        )
-        .unwrap();
-
+        .search(&[&query_vector], Some(&filter), NUM_VECTORS, None, &Default::default())
+        .unwrap();
     assert_eq!(after_plain_results.len(), 1);
     assert_eq!(after_plain_results[0].len(), NUM_VECTORS);
 
-    // check that plain searchers were used
     assert_eq!(
         sparse_vector_index
             .get_telemetry_data(TelemetryDetail::default())
@@ -537,10 +417,10 @@             SparseIndexType::ImmutableRam,
         )
         .unwrap();
+
     let mut borrowed_storage = sparse_vector_index.vector_storage().borrow_mut();
 
     let hw_counter = HardwareCounterCell::new();
-    // add empty points to storage
     for idx in 0..NUM_VECTORS {
         let vec = &SparseVector::new(vec![], vec![]).unwrap();
         borrowed_storage
@@ -549,21 +429,15 @@     }
     drop(borrowed_storage);
 
-    // assert all empty points are in storage
-    assert_eq!(
-        sparse_vector_index
-            .vector_storage()
-            .borrow()
-            .available_vector_count(),
-        NUM_VECTORS,
-    );
-
-    // empty vectors are not indexed
+    assert_eq!(
+        sparse_vector_index.vector_storage().borrow().available_vector_count(),
+        NUM_VECTORS
+    );
+
+    sparse_vector_index.build_index(&AtomicBool::new(false)).unwrap();
     assert_eq!(sparse_vector_index.indexed_vector_count(), 0);
 
     let query_vector: QueryVector = random_sparse_vector(&mut rnd, MAX_SPARSE_DIM).into();
-
-    // empty vectors are not searchable (recommend using scroll API to retrieve those)
     let results = sparse_vector_index
         .search(&[&query_vector], None, 10, None, &Default::default())
         .unwrap();
@@ -574,14 +448,12 @@ #[test]
 fn sparse_vector_index_persistence_test() {
     let stopped = AtomicBool::new(false);
-
     let dim = 8;
     let num_vectors: u64 = 5_000;
     let top = 3;
     let mut rnd = StdRng::seed_from_u64(42);
 
     let dir = Builder::new().prefix("segment_dir").tempdir().unwrap();
-
     let config = SegmentConfig {
         vector_data: Default::default(),
         sparse_vector_data: HashMap::from([(
@@ -590,7 +462,6 @@                 index: SparseIndexConfig {
                     full_scan_threshold: Some(DEFAULT_SPARSE_FULL_SCAN_THRESHOLD),
                     index_type: SparseIndexType::MutableRam,
-                    datatype: Some(VectorStorageDatatype::Float32),
                 },
                 storage_type: SparseVectorStorageType::default(),
             },
@@ -600,7 +471,6 @@     let mut segment = build_segment(dir.path(), &config, true).unwrap();
 
     let hw_counter = HardwareCounterCell::new();
-
     for n in 0..num_vectors {
         let vector: VectorInternal = random_sparse_vector(&mut rnd, dim).into();
         let mut named_vector = NamedVectors::default();
@@ -614,7 +484,6 @@ 
     let search_vector = random_sparse_vector(&mut rnd, dim);
     let query_vector: QueryVector = search_vector.into();
-
     let search_result = segment
         .search(
             SPARSE_VECTOR_NAME,
@@ -624,17 +493,15 @@             None,
             top,
             None,
+            &stopped,
         )
         .unwrap();
-
     assert_eq!(search_result.len(), top);
 
     let path = segment.current_path.clone();
     drop(segment);
 
-    // persistence using rebuild of inverted index
-    // for appendable segment vector index has to be rebuilt
-    let segment = load_segment(&path, &stopped).unwrap().unwrap();
+    let segment = load_segment(&path).unwrap().unwrap();
     let search_after_reload_result = segment
         .search(
             SPARSE_VECTOR_NAME,
@@ -644,87 +511,11 @@             None,
             top,
             None,
+            &stopped,
         )
         .unwrap();
-
     assert_eq!(search_after_reload_result.len(), top);
     assert_eq!(search_result, search_after_reload_result);
-
-    fixture_for_all_indices!(check_persistence::<_>(
-        &segment,
-        &search_result,
-        &query_vector,
-        top
-    ));
-}
-
-fn check_persistence<TInvertedIndex: InvertedIndex>(
-    segment: &Segment,
-    search_result: &[ScoredPoint],
-    query_vector: &QueryVector,
-    top: usize,
-) {
-    let stopped = AtomicBool::new(false);
-
-    let inverted_index_dir = Builder::new()
-        .prefix("inverted_index_ram")
-        .tempdir()
-        .unwrap();
-
-    let open_index = || -> SparseVectorIndex<TInvertedIndex> {
-        SparseVectorIndex::open(SparseVectorIndexOpenArgs {
-            config: SparseIndexConfig {
-                full_scan_threshold: Some(DEFAULT_SPARSE_FULL_SCAN_THRESHOLD),
-                index_type: SparseIndexType::Mmap,
-                datatype: Some(VectorStorageDatatype::Float32),
-            },
-            id_tracker: segment.id_tracker.clone(),
-            vector_storage: segment.vector_data[SPARSE_VECTOR_NAME]
-                .vector_storage
-                .clone(),
-            payload_index: segment.payload_index.clone(),
-            path: inverted_index_dir.path(),
-            stopped: &stopped,
-            tick_progress: || (),
-        })
-        .unwrap()
-    };
-
-    let check_search = |sparse_vector_index: &SparseVectorIndex<TInvertedIndex>| {
-        // check that the loaded index performs the same search
-        let search_after_reload_result = sparse_vector_index
-            .search(&[query_vector], None, top, None, &Default::default())
-            .unwrap();
-        assert_eq!(search_after_reload_result[0].len(), top);
-        for (search_1, search_2) in search_result
-            .iter()
-            .zip(search_after_reload_result[0].iter())
-        {
-            let id_1 = segment
-                .id_tracker
-                .borrow_mut()
-                .internal_id(search_1.id)
-                .unwrap();
-            assert_eq!(id_1, search_2.idx);
-        }
-    };
-
-    let sparse_vector_index = open_index();
-
-    let version_file = inverted_index_dir.path().join(VERSION_FILE);
-    assert!(version_file.exists());
-
-    // reload sparse index from file
-    drop(sparse_vector_index);
-    let sparse_vector_index = open_index();
-    check_search(&sparse_vector_index);
-
-    // drop version file and reload index
-    drop(sparse_vector_index);
-    remove_file(&version_file).unwrap();
-    let sparse_vector_index = open_index();
-    assert!(version_file.exists(), "version file should be recreated");
-    check_search(&sparse_vector_index);
 }
 
 #[test]
@@ -733,17 +524,14 @@ }
 
 fn check_sparse_vector_index_files<I: InvertedIndex>() {
-    let data_dir = Builder::new().prefix("data_dir").tempdir().unwrap();
     let index = fixture_sparse_index::<I, _>(
         &mut StdRng::seed_from_u64(42),
         1,
         MAX_SPARSE_DIM,
         LOW_FULL_SCAN_THRESHOLD,
-        data_dir.path(),
-    );
-
+        Builder::new().prefix("data_dir").tempdir().unwrap().path(),
+    );
     let files = index.files();
-    // sparse index config + version + inverted index config + inverted index data + tracker
     assert_eq!(files.len(), 5);
     for file in files.iter() {
         assert!(file.exists(), "file {file:?} does not exist");
@@ -761,7 +549,6 @@                 index: SparseIndexConfig {
                     full_scan_threshold: Some(DEFAULT_SPARSE_FULL_SCAN_THRESHOLD),
                     index_type: SparseIndexType::MutableRam,
-                    datatype: Some(VectorStorageDatatype::Float32),
                 },
                 storage_type: SparseVectorStorageType::OnDisk,
             },
@@ -771,7 +558,6 @@     let mut segment = build_segment(dir.path(), &config, true).unwrap();
 
     let hw_counter = HardwareCounterCell::new();
-
     let vector: VectorInternal = SparseVector {
         indices: vec![DimId::MAX],
         values: vec![0.0],
@@ -784,9 +570,7 @@         .upsert_point(0 as SeqNumberType, idx, named_vector, &hw_counter)
         .unwrap();
 
-    let borrowed_vector_index = segment.vector_data[SPARSE_VECTOR_NAME]
-        .vector_index
-        .borrow();
+    let borrowed_vector_index = segment.vector_data[SPARSE_VECTOR_NAME].vector_index.borrow();
     match &*borrowed_vector_index {
         VectorIndexEnum::SparseRam(sparse_vector_index) => {
             assert!(
