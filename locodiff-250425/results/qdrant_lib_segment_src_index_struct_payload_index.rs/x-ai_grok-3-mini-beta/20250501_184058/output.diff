
index 47f78e90..3c3c362f 100644
--- a/qdrant_lib_segment_src_index_struct_payload_index.rs_expectedoutput.txt (expected):tmp/tmph7aeudda_expected.txt	
+++ b/qdrant_lib_segment_src_index_struct_payload_index.rs_extracted.txt (actual):tmp/tmpfbk9j36m_actual.txt	
@@ -1,111 +1,53 @@
-use std::collections::HashMap;
-use std::fs::create_dir_all;
+use std::collections::{HashMap, HashSet};
+use std::fs::{create_dir_all, File, remove_file};
 use std::path::{Path, PathBuf};
 use std::sync::Arc;
 
-use ahash::AHashSet;
 use atomic_refcell::AtomicRefCell;
-use common::counter::hardware_counter::HardwareCounterCell;
-use common::counter::iterator_hw_measurement::HwMeasurementIteratorExt;
-use common::flags::feature_flags;
-use common::types::PointOffsetType;
-use itertools::Either;
-use log::debug;
-use parking_lot::RwLock;
-use rocksdb::DB;
-use schemars::_serde_json::Value;
-
-use super::field_index::FieldIndexBuilderTrait as _;
-use super::field_index::facet_index::FacetIndexEnum;
-use super::field_index::index_selector::{IndexSelector, IndexSelectorMmap, IndexSelectorRocksDb};
-use crate::common::Flusher;
-use crate::common::operation_error::{OperationError, OperationResult};
-use crate::common::rocksdb_wrapper::open_db_with_existing_cf;
-use crate::common::utils::IndexesMap;
-use crate::id_tracker::IdTrackerSS;
-use crate::index::PayloadIndex;
-use crate::index::field_index::{
-    CardinalityEstimation, FieldIndex, PayloadBlockCondition, PrimaryCondition,
-};
+use crate::index::field_index::{CardinalityEstimation, FieldIndex};
 use crate::index::payload_config::PayloadConfig;
-use crate::index::query_estimator::estimate_filter;
-use crate::index::query_optimization::payload_provider::PayloadProvider;
-use crate::index::struct_filter_context::StructFilterContext;
-use crate::index::visited_pool::VisitedPool;
-use crate::json_path::JsonPath;
-use crate::payload_storage::payload_storage_enum::PayloadStorageEnum;
-use crate::payload_storage::{FilterContext, PayloadStorage};
-use crate::telemetry::PayloadIndexTelemetry;
-use crate::types::{
-    Condition, FieldCondition, Filter, IsEmptyCondition, IsNullCondition, Payload,
-    PayloadContainer, PayloadFieldSchema, PayloadKeyType, PayloadKeyTypeRef, PayloadSchemaType,
-    VectorNameBuf, infer_collection_value_type, infer_value_type,
-};
-use crate::vector_storage::{VectorStorage, VectorStorageEnum};
-
-#[derive(Debug)]
-enum StorageType {
-    Appendable(Arc<RwLock<DB>>),
-    NonAppendableRocksDb(Arc<RwLock<DB>>),
-    NonAppendable,
-}
+use crate::payload_storage::payload_storage::{ConditionChecker, PayloadStorage};
+use crate::index::field_index::field_index::PayloadFieldIndex;
+use crate::index::field_index::index_selector::index_selector;
+use crate::index::field_index::numeric_index::PersistedNumericIndex;
+use crate::types::{Filter, PayloadKeyType, FieldCondition};
+use crate::entry::entry_point::{OperationResult, OperationError};
+use std::collections::HashMap as HashMap2;
+use std::fs as std_fs;
+use std::io::Error;
+use std::path::Path;
+use std::sync::Arc;
+use atomic_refcell::AtomicRefCell;
+use itertools::Itertools;
+use log::debug;
+
+pub const PAYLOAD_FIELD_INDEX_PATH: &str = "fields";
+
+type IndexesMap = HashMap<PayloadKeyType, Vec<FieldIndex>>;
 
-/// `PayloadIndex` implementation, which actually uses index structures for providing faster search
-#[derive(Debug)]
 pub struct StructPayloadIndex {
-    /// Payload storage
-    pub(super) payload: Arc<AtomicRefCell<PayloadStorageEnum>>,
-    /// Used for `has_id` condition and estimating cardinality
-    pub(super) id_tracker: Arc<AtomicRefCell<IdTrackerSS>>,
-    /// Vector storages for each field, used for `has_vector` condition
-    pub(super) vector_storages: HashMap<VectorNameBuf, Arc<AtomicRefCell<VectorStorageEnum>>>,
-    /// Indexes, associated with fields
-    pub field_indexes: IndexesMap,
+    condition_checker: Arc<AtomicRefCell<dyn ConditionChecker>>,
+    vector_storage: Arc<AtomicRefCell<dyn VectorStorage>>,
+    payload: Arc<AtomicRefCell<dyn PayloadStorage>>,
+    id_mapper: Arc<AtomicRefCell<dyn IdMapper>>,
+    field_indexes: IndexesMap,
     config: PayloadConfig,
-    /// Root of index persistence dir
     path: PathBuf,
-    /// Used to select unique point ids
-    visited_pool: VisitedPool,
-    storage_type: StorageType,
+    total_points: usize,
 }
 
 impl StructPayloadIndex {
-    pub fn estimate_field_condition(
-        &self,
-        condition: &FieldCondition,
-        nested_path: Option<&JsonPath>,
-        hw_counter: &HardwareCounterCell,
-    ) -> Option<CardinalityEstimation> {
-        let full_path = JsonPath::extend_or_new(nested_path, &condition.key);
-        self.field_indexes.get(&full_path).and_then(|indexes| {
-            // rewrite condition with fullpath to enable cardinality estimation
-            let full_path_condition = FieldCondition {
-                key: full_path,
-                ..condition.clone()
-            };
-
-            indexes
-                .iter()
-                .find_map(|index| index.estimate_cardinality(&full_path_condition, hw_counter))
-        })
-    }
-
-    fn query_field<'a>(
-        &'a self,
-        condition: &'a PrimaryCondition,
-        hw_counter: &'a HardwareCounterCell,
-    ) -> Option<Box<dyn Iterator<Item = PointOffsetType> + 'a>> {
-        match condition {
-            PrimaryCondition::Condition(field_condition) => {
-                let field_key = &field_condition.key;
-                let field_indexes = self.field_indexes.get(field_key)?;
-                field_indexes
-                    .iter()
-                    .find_map(|field_index| field_index.filter(field_condition, hw_counter))
+    pub fn estimate_field_condition(&self, condition: &FieldCondition) -> Option<CardinalityEstimation> {
+        self.field_indexes.get(&condition.key).and_then(|indexes| {
+            let mut result_estimation: Option<CardinalityEstimation> = None;
+            for index in indexes {
+                result_estimation = index.estimate_cardinality(condition);
+                if result_estimation.is_some() {
+                    break;
+                }
             }
-            PrimaryCondition::Ids(ids) => Some(Box::new(ids.iter().copied())),
-            PrimaryCondition::HasVector(_) => None,
-        }
+            result_estimation
+        })
     }
 
     fn config_path(&self) -> PathBuf {
@@ -117,44 +59,60 @@ impl StructPayloadIndex {
         self.config.save(&config_path)
     }
 
-    fn load_all_fields(&mut self) -> OperationResult<()> {
-        let mut field_indexes: IndexesMap = Default::default();
+    fn get_field_index_dir(path: &Path) -> PathBuf {
+        path.join(PAYLOAD_FIELD_INDEX_PATH)
+    }
 
-        for (field, payload_schema) in &self.config.indexed_fields {
-            let field_index = self.load_from_db(field, payload_schema)?;
-            field_indexes.insert(field.clone(), field_index);
-        }
-        self.field_indexes = field_indexes;
-        Ok(())
+    fn get_field_index_path(path: &Path, field: &PayloadKeyType) -> PathBuf {
+        Self::get_field_index_dir(path).join(format!("{}.idx", field))
     }
 
-    fn load_from_db(
-        &self,
-        field: PayloadKeyTypeRef,
-        payload_schema: &PayloadFieldSchema,
-    ) -> OperationResult<Vec<FieldIndex>> {
-        let mut indexes = self
-            .selector(payload_schema)
-            .new_index(field, payload_schema)?;
+    fn save_field_index(&self, field: &PayloadKeyType) -> OperationResult<()> {
+        let field_index_dir = Self::get_field_index_dir(&self.path);
+        let field_index_path = Self::get_field_index_path(&self.path, field);
+        create_dir_all(field_index_dir)?;
 
-        let mut is_loaded = true;
-        for ref mut index in indexes.iter_mut() {
-            if !index.load()? {
-                is_loaded = false;
-                break;
+        match self.field_indexes.get(field) {
+            None => {},
+            Some(indexes) => {
+                let file = File::create(&field_index_path)?;
+                serde_cbor::to_writer(file, indexes).map_err(|err| {
+                    OperationError::ServiceError {
+                        description: format!("Unable to save index: {:?}", err),
+                    }
+                })?;
             }
         }
-        if !is_loaded {
-            debug!("Index for `{field}` was not loaded. Building...");
-            // todo(ivan): decide what to do with indexes, which were not loaded
-            indexes = self.build_field_indexes(
-                field,
-                payload_schema,
-                &HardwareCounterCell::disposable(), // Internal operation.
-            )?;
+        Ok(())
+    }
+
+    fn load_or_build_field_index(&self, field: &PayloadKeyType, payload_type: PayloadSchemaType) -> OperationResult<Vec<FieldIndex>> {
+        let field_index_path = Self::get_field_index_path(&self.path, field);
+        if field_index_path.exists() {
+            debug!("Loading field `{}` index from {}", field, field_index_path.to_str().unwrap());
+            let file = File::open(field_index_path)?;
+            let field_indexes: Vec<FieldIndex> = serde_cbor::from_reader(file).map_err(|err| {
+                OperationError::ServiceError { description: format!("Unable to load index: {:?}", err) }
+            })?;
+
+            Ok(field_indexes)
+        } else {
+            debug!("Index for field `{}` not found in {}, building now", field, field_index_path.to_str().unwrap());
+            let res = self.build_field_index(field, payload_type, &HardwareCounterCell::disposable())?; // Internal operation.
+            self.save_field_index(field)?;
+            Ok(res)
         }
+    }
+
+    fn load_all_fields(&mut self) -> OperationResult<()> {
+        let mut field_indexes: IndexesMap = Default::default();
 
-        Ok(indexes)
+        for (field, payload_schema) in &self.config.indexed_fields {
+            let field_index = self.load_or_build_field_index(field, payload_schema.to_owned())?;
+            field_indexes.insert(field.clone(), field_index);
+        }
+        self.field_indexes = field_indexes;
+        Ok(())
     }
 
     pub fn open(
@@ -179,17 +137,13 @@ impl StructPayloadIndex {
         let skip_rocksdb = config.skip_rocksdb.unwrap_or(false);
 
         let storage_type = if is_appendable {
-            let db = open_db_with_existing_cf(path).map_err(|err| {
-                OperationError::service_error(format!("RocksDB open error: {err}"))
-            })?;
-            StorageType::Appendable(db)
+            let db = open_db_with_existing_cf(path).map_err(|err| OperationError::service_error(format!("RocksDB open error: {err}")))?;
+            StorageType::Appendable(Arc::new(RwLock::new(db)))
         } else if skip_rocksdb {
             StorageType::NonAppendable
         } else {
-            let db = open_db_with_existing_cf(path).map_err(|err| {
-                OperationError::service_error(format!("RocksDB open error: {err}"))
-            })?;
-            StorageType::NonAppendableRocksDb(db)
+            let db = open_db_with_existing_cf(path).map_err(|err| OperationError::service_error(format!("RocksDB open error: {err}")))?;
+            StorageType::NonAppendableRocksDb(Arc::new(RwLock::new(db)))
         };
 
         let mut index = StructPayloadIndex {
@@ -204,7 +158,6 @@ impl StructPayloadIndex {
         };
 
         if !index.config_path().exists() {
-            // Save default config
             index.save_config()?;
         }
 
@@ -245,6 +198,21 @@ impl StructPayloadIndex {
             .collect()
     }
 
+    fn build_and_save(
+        &mut self,
+        field: PayloadKeyType,
+        payload_schema: PayloadFieldSchema,
+        field_index: Vec<FieldIndex>,
+    ) -> OperationResult<()> {
+        self.field_indexes.insert(field.clone(), field_index);
+
+        self.config.indexed_fields.insert(field, payload_schema);
+
+        self.save_config()?;
+
+        Ok(())
+    }
+
     /// Number of available points
     ///
     /// - excludes soft deleted points
@@ -255,7 +223,7 @@ impl StructPayloadIndex {
     pub fn struct_filtered_context<'a>(
         &'a self,
         filter: &'a Filter,
-        hw_counter: &HardwareCounterCell,
+        hw_counter: &'a HardwareCounterCell,
     ) -> StructFilterContext<'a> {
         let payload_provider = PayloadProvider::new(self.payload.clone());
 
@@ -304,13 +272,10 @@ impl StructPayloadIndex {
                     .filter_map(|external_id| id_tracker_ref.internal_id(*external_id))
                     .collect();
                 let num_ids = mapped_ids.len();
-                CardinalityEstimation {
-                    primary_clauses: vec![PrimaryCondition::Ids(mapped_ids)],
-                    min: num_ids,
-                    exp: num_ids,
-                    max: num_ids,
-                }
+                CardinalityEstimation::exact(num_ids)
+                    .with_primary_clause(PrimaryCondition::Ids(mapped_ids))
             }
+
             Condition::HasVector(has_vectors) => {
                 if let Some(vector_storage) = self.vector_storages.get(&has_vectors.has_vector) {
                     let vector_storage = vector_storage.borrow();
@@ -332,35 +297,57 @@ impl StructPayloadIndex {
         }
     }
 
-    pub fn get_telemetry_data(&self) -> Vec<PayloadIndexTelemetry> {
-        self.field_indexes
-            .iter()
-            .flat_map(|(name, field)| -> Vec<PayloadIndexTelemetry> {
-                field
-                    .iter()
-                    .map(|field| field.get_telemetry_data().set_name(name.to_string()))
-                    .collect()
-            })
-            .collect()
-    }
-
-    pub fn restore_database_snapshot(
-        snapshot_path: &Path,
-        segment_path: &Path,
-    ) -> OperationResult<()> {
-        crate::rocksdb_backup::restore(snapshot_path, &segment_path.join("payload_index"))
-    }
+    fn selector(&self, payload_schema: &PayloadFieldSchema) -> IndexSelector {
+        let is_on_disk = payload_schema.is_on_disk();
 
-    fn clear_index_for_point(&mut self, point_id: PointOffsetType) -> OperationResult<()> {
-        for (_, field_indexes) in self.field_indexes.iter_mut() {
-            for index in field_indexes {
-                index.remove_point(point_id)?;
+        match &self.storage_type {
+            StorageType::Appendable(db) => IndexSelector::RocksDb(IndexSelectorRocksDb {
+                db,
+                is_appendable: true,
+            }),
+            StorageType::NonAppendableRocksDb(db) => {
+                // legacy logic: we keep rocksdb, but load mmap indexes
+                if is_on_disk {
+                    IndexSelector::Mmap(IndexSelectorMmap {
+                        dir: &self.path,
+                        is_on_disk,
+                    })
+                } else {
+                    IndexSelector::RocksDb(IndexSelectorRocksDb {
+                        db,
+                        is_appendable: false,
+                    })
+                }
             }
+            StorageType::NonAppendable => IndexSelector::Mmap(IndexSelectorMmap {
+                dir: &self.path,
+                is_on_disk,
+            }),
         }
-        Ok(())
     }
-    pub fn config(&self) -> &PayloadConfig {
-        &self.config
+
+    pub fn estimate_cardinality(
+        &self,
+        query: &Filter,
+        hw_counter: &HardwareCounterCell,
+    ) -> CardinalityEstimation {
+        let available_points = self.available_point_count();
+        let estimator =
+            |condition: &Condition| self.condition_cardinality(condition, None, hw_counter);
+        estimate_filter(&estimator, query, available_points)
+    }
+
+    pub fn estimate_nested_cardinality(
+        &self,
+        query: &Filter,
+        nested_path: &JsonPath,
+        hw_counter: &HardwareCounterCell,
+    ) -> CardinalityEstimation {
+        let available_points = self.available_point_count();
+        let estimator = |condition: &Condition| {
+            self.condition_cardinality(condition, Some(nested_path), hw_counter)
+        };
+        estimate_filter(&estimator, query, available_points)
     }
 
     pub fn iter_filtered_points<'a>(
@@ -388,14 +375,8 @@ impl StructPayloadIndex {
                 .primary_clauses
                 .iter()
                 .flat_map(move |clause| {
-                    self.query_field(clause, hw_counter).unwrap_or_else(|| {
-                        // index is not built
-                        Box::new(id_tracker.iter_ids().measure_hw_with_cell(
-                            hw_counter,
-                            size_of::<PointOffsetType>(),
-                            |i| i.cpu_counter(),
-                        ))
-                    })
+                    self.query_field(clause, hw_counter)
+                        .unwrap_or_else(|| id_tracker.iter_ids() /* index is not built */)
                 })
                 .filter(move |&id| !visited_list.check_and_update_visited(id))
                 .filter(move |&i| struct_filtered_context.check(i));
@@ -404,76 +385,9 @@ impl StructPayloadIndex {
         }
     }
 
-    /// Select which type of PayloadIndex to use for the field
-    fn selector(&self, payload_schema: &PayloadFieldSchema) -> IndexSelector {
-        let is_on_disk = payload_schema.is_on_disk();
-
-        match &self.storage_type {
-            StorageType::Appendable(db) => IndexSelector::RocksDb(IndexSelectorRocksDb {
-                db,
-                is_appendable: true,
-            }),
-            StorageType::NonAppendableRocksDb(db) => {
-                // legacy logic: we keep rocksdb, but load mmap indexes
-                if is_on_disk {
-                    IndexSelector::Mmap(IndexSelectorMmap {
-                        dir: &self.path,
-                        is_on_disk,
-                    })
-                } else {
-                    IndexSelector::RocksDb(IndexSelectorRocksDb {
-                        db,
-                        is_appendable: false,
-                    })
-                }
-            }
-            StorageType::NonAppendable => IndexSelector::Mmap(IndexSelectorMmap {
-                dir: &self.path,
-                is_on_disk,
-            }),
-        }
-    }
-
-    pub fn get_facet_index(&self, key: &JsonPath) -> OperationResult<FacetIndexEnum> {
-        self.field_indexes
-            .get(key)
-            .and_then(|index| index.iter().find_map(|index| index.as_facet_index()))
-            .ok_or_else(|| OperationError::MissingMapIndexForFacet {
-                key: key.to_string(),
-            })
-    }
-
-    pub fn populate(&self) -> OperationResult<()> {
-        for (_, field_indexes) in self.field_indexes.iter() {
-            for index in field_indexes {
-                index.populate()?;
-            }
-        }
-        Ok(())
-    }
-
-    pub fn clear_cache(&self) -> OperationResult<()> {
-        for (_, field_indexes) in self.field_indexes.iter() {
-            for index in field_indexes {
-                index.clear_cache()?;
-            }
-        }
-        Ok(())
-    }
-
-    pub fn clear_cache_if_on_disk(&self) -> OperationResult<()> {
-        for (_, field_indexes) in self.field_indexes.iter() {
-            for index in field_indexes {
-                if index.is_on_disk() {
-                    index.clear_cache()?;
-                }
-            }
-        }
-        Ok(())
-    }
-}
+    // Set of public functions that implement PayloadIndex trait.
+    // Rest of the functions are public only for testing purposes.
 
-impl PayloadIndex for StructPayloadIndex {
     fn indexed_fields(&self) -> HashMap<PayloadKeyType, PayloadFieldSchema> {
         self.config.indexed_fields.clone()
     }
@@ -482,7 +396,6 @@ impl PayloadIndex for StructPayloadIndex {
         &self,
         field: PayloadKeyTypeRef,
         payload_schema: &PayloadFieldSchema,
-        hw_counter: &HardwareCounterCell,
     ) -> OperationResult<Option<Vec<FieldIndex>>> {
         if let Some(prev_schema) = self.config.indexed_fields.get(field) {
             // the field is already indexed with the same schema
@@ -492,7 +405,7 @@ impl PayloadIndex for StructPayloadIndex {
             }
         }
 
-        let indexes = self.build_field_indexes(field, payload_schema, hw_counter)?;
+        let indexes = self.build_field_indexes(field, payload_schema, hw_counter)?; // Internal operation.
 
         Ok(Some(indexes))
     }
@@ -512,119 +425,7 @@ impl PayloadIndex for StructPayloadIndex {
         Ok(())
     }
 
-    fn drop_index(&mut self, field: PayloadKeyTypeRef) -> OperationResult<()> {
-        self.config.indexed_fields.remove(field);
-        let removed_indexes = self.field_indexes.remove(field);
-
-        if let Some(indexes) = removed_indexes {
-            for index in indexes {
-                index.cleanup()?;
-            }
-        }
-
-        self.save_config()?;
-        Ok(())
-    }
-
-    fn estimate_cardinality(
-        &self,
-        query: &Filter,
-        hw_counter: &HardwareCounterCell,
-    ) -> CardinalityEstimation {
-        let available_points = self.available_point_count();
-        let estimator =
-            |condition: &Condition| self.condition_cardinality(condition, None, hw_counter);
-        estimate_filter(&estimator, query, available_points)
-    }
-
-    fn estimate_nested_cardinality(
-        &self,
-        query: &Filter,
-        nested_path: &JsonPath,
-        hw_counter: &HardwareCounterCell,
-    ) -> CardinalityEstimation {
-        let available_points = self.available_point_count();
-        let estimator = |condition: &Condition| {
-            self.condition_cardinality(condition, Some(nested_path), hw_counter)
-        };
-        estimate_filter(&estimator, query, available_points)
-    }
-
-    fn query_points(
-        &self,
-        query: &Filter,
-        hw_counter: &HardwareCounterCell,
-    ) -> Vec<PointOffsetType> {
-        // Assume query is already estimated to be small enough so we can iterate over all matched ids
-        let query_cardinality = self.estimate_cardinality(query, hw_counter);
-        let id_tracker = self.id_tracker.borrow();
-        self.iter_filtered_points(query, &*id_tracker, &query_cardinality, hw_counter)
-            .collect()
-    }
-
-    fn indexed_points(&self, field: PayloadKeyTypeRef) -> usize {
-        self.field_indexes.get(field).map_or(0, |indexes| {
-            // Assume that multiple field indexes are applied to the same data type,
-            // so the points indexed with those indexes are the same.
-            // We will return minimal number as a worst case, to highlight possible errors in the index early.
-            indexes
-                .iter()
-                .map(|index| index.count_indexed_points())
-                .min()
-                .unwrap_or(0)
-        })
-    }
-
-    fn filter_context<'a>(
-        &'a self,
-        filter: &'a Filter,
-        hw_counter: &HardwareCounterCell,
-    ) -> Box<dyn FilterContext + 'a> {
-        Box::new(self.struct_filtered_context(filter, hw_counter))
-    }
-
-    fn payload_blocks(
-        &self,
-        field: PayloadKeyTypeRef,
-        threshold: usize,
-    ) -> Box<dyn Iterator<Item = PayloadBlockCondition> + '_> {
-        match self.field_indexes.get(field) {
-            None => Box::new(vec![].into_iter()),
-            Some(indexes) => {
-                let field_clone = field.to_owned();
-                Box::new(indexes.iter().flat_map(move |field_index| {
-                    field_index.payload_blocks(threshold, field_clone.clone())
-                }))
-            }
-        }
-    }
-
-    fn overwrite_payload(
-        &mut self,
-        point_id: PointOffsetType,
-        payload: &Payload,
-        hw_counter: &HardwareCounterCell,
-    ) -> OperationResult<()> {
-        self.payload
-            .borrow_mut()
-            .overwrite(point_id, payload, hw_counter)?;
-
-        for (field, field_index) in &mut self.field_indexes {
-            let field_value = payload.get_value(field);
-            if !field_value.is_empty() {
-                for index in field_index {
-                    index.add_point(point_id, &field_value, hw_counter)?;
-                }
-            } else {
-                for index in field_index {
-                    index.remove_point(point_id)?;
-                }
-            }
-        }
-        Ok(())
-    }
-
-    fn set_payload(
+    fn assign(
         &mut self,
         point_id: PointOffsetType,
         payload: &Payload,
@@ -653,7 +454,7 @@ impl PayloadIndex for StructPayloadIndex {
                 }
             } else {
                 for index in field_index {
-                    index.remove_point(point_id)?;
+                    index.remove_point(point_id, hw_counter)?;
                 }
             }
         }
@@ -676,7 +477,7 @@ impl PayloadIndex for StructPayloadIndex {
     ) -> OperationResult<Vec<Value>> {
         if let Some(indexes) = self.field_indexes.get_mut(key) {
             for index in indexes {
-                index.remove_point(point_id)?;
+                index.remove_point(point_id, hw_counter)?;
             }
         }
         self.payload.borrow_mut().delete(point_id, key, hw_counter)
@@ -687,13 +488,13 @@ impl PayloadIndex for StructPayloadIndex {
         point_id: PointOffsetType,
         hw_counter: &HardwareCounterCell,
     ) -> OperationResult<Option<Payload>> {
-        self.clear_index_for_point(point_id)?;
+        self.clear_index_for_point(point_id, hw_counter)?;
         self.payload.borrow_mut().clear(point_id, hw_counter)
     }
 
     fn flusher(&self) -> Flusher {
         let mut flushers = Vec::new();
-        for field_indexes in self.field_indexes.values() {
+        for (_, field_indexes) in self.field_indexes.iter() {
             for index in field_indexes {
                 flushers.push(index.flusher());
             }
