--- qdrant_lib_segment_src_vector_storage_dense_memmap_dense_vector_storage.rs_expectedoutput.txt (expected)+++ qdrant_lib_segment_src_vector_storage_dense_memmap_dense_vector_storage.rs_extracted.txt (actual)@@ -1,5 +1,5 @@ use std::borrow::Cow;
-use std::fs::{File, OpenOptions, create_dir_all};
+use std::fs::{create_dir_all, File, OpenOptions};
 use std::io::{self, Write};
 use std::mem::MaybeUninit;
 use std::ops::Range;
@@ -12,8 +12,8 @@ use memory::fadvise::clear_disk_cache;
 use memory::mmap_ops;
 
+use crate::common::operation_error::{check_process_stopped, OperationError, OperationResult};
 use crate::common::Flusher;
-use crate::common::operation_error::{OperationError, OperationResult, check_process_stopped};
 use crate::data_types::named_vectors::CowVector;
 use crate::data_types::primitive::PrimitiveVectorElement;
 use crate::data_types::vectors::{VectorElementType, VectorRef};
@@ -25,12 +25,12 @@ const VECTORS_PATH: &str = "matrix.dat";
 const DELETED_PATH: &str = "deleted.dat";
 
-/// Stores all dense vectors in mem-mapped file
+/// Stores all dense vectors in mem-mapped file.
 ///
 /// It is not possible to insert new vectors into mem-mapped storage,
-/// but possible to mark some vectors as removed
+/// but possible to mark some vectors as removed.
 ///
-/// Mem-mapped storage can only be constructed from another storage
+/// Mem-mapped storage can only be constructed from another storage.
 #[derive(Debug)]
 pub struct MemmapDenseVectorStorage<T: PrimitiveVectorElement> {
     vectors_path: PathBuf,
@@ -40,8 +40,7 @@ }
 
 impl<T: PrimitiveVectorElement> MemmapDenseVectorStorage<T> {
-    /// Populate all pages in the mmap.
-    /// Block until all pages are populated.
+    /// Prefetch all pages of the mmapâ€™ed files into memory.
     pub fn populate(&self) -> OperationResult<()> {
         if let Some(mmap_store) = &self.mmap_store {
             mmap_store.populate()?;
@@ -49,11 +48,23 @@         Ok(())
     }
 
-    /// Drop disk cache.
+    /// Advise the operating system that the data is no longer needed and can be evicted
+    /// from the page cache.
     pub fn clear_cache(&self) -> OperationResult<()> {
         clear_disk_cache(&self.vectors_path)?;
         clear_disk_cache(&self.deleted_path)?;
         Ok(())
+    }
+
+    pub fn get_mmap_vectors(&self) -> &MmapDenseVectors<T> {
+        self.mmap_store.as_ref().unwrap()
+    }
+
+    pub fn has_async_reader(&self) -> bool {
+        self.mmap_store
+            .as_ref()
+            .map(MmapDenseVectors::has_async_reader)
+            .unwrap_or(false)
     }
 }
 
@@ -62,12 +73,8 @@     dim: usize,
     distance: Distance,
 ) -> OperationResult<VectorStorageEnum> {
-    let storage = open_memmap_vector_storage_with_async_io_impl::<VectorElementType>(
-        path,
-        dim,
-        distance,
-        get_async_scorer(),
-    )?;
+    let storage =
+        open_memmap_vector_storage_with_async_io_impl::<VectorElementType>(path, dim, distance, get_async_scorer())?;
     Ok(VectorStorageEnum::DenseMemmap(storage))
 }
 
@@ -97,12 +104,8 @@     distance: Distance,
     with_async_io: bool,
 ) -> OperationResult<VectorStorageEnum> {
-    let storage = open_memmap_vector_storage_with_async_io_impl::<VectorElementType>(
-        path,
-        dim,
-        distance,
-        with_async_io,
-    )?;
+    let storage =
+        open_memmap_vector_storage_with_async_io_impl::<VectorElementType>(path, dim, distance, with_async_io)?;
     Ok(VectorStorageEnum::DenseMemmap(storage))
 }
 
@@ -124,19 +127,6 @@         mmap_store: Some(mmap_store),
         distance,
     }))
-}
-
-impl<T: PrimitiveVectorElement> MemmapDenseVectorStorage<T> {
-    pub fn get_mmap_vectors(&self) -> &MmapDenseVectors<T> {
-        self.mmap_store.as_ref().unwrap()
-    }
-
-    pub fn has_async_reader(&self) -> bool {
-        self.mmap_store
-            .as_ref()
-            .map(|x| x.has_async_reader())
-            .unwrap_or(false)
-    }
 }
 
 impl<T: PrimitiveVectorElement> DenseVectorStorage<T> for MemmapDenseVectorStorage<T> {
@@ -212,8 +202,8 @@         let with_async_io = self
             .mmap_store
             .take()
-            .map(|x| x.has_async_reader())
-            .unwrap_or(get_async_scorer());
+            .map(MmapDenseVectors::has_async_reader)
+            .unwrap_or_else(get_async_scorer);
 
         // Extend vectors file, write other vectors into it
         let mut vectors_file = open_append(&self.vectors_path)?;
@@ -221,19 +211,19 @@         for (offset, (other_vector, other_deleted)) in other_vectors.enumerate() {
             check_process_stopped(stopped)?;
             let vector = T::slice_from_float_cow(Cow::try_from(other_vector)?);
-            let raw_bites = mmap_ops::transmute_to_u8_slice(vector.as_ref());
-            vectors_file.write_all(raw_bites)?;
+            let raw_bytes = mmap_ops::transmute_to_u8_slice(vector.as_ref());
+            vectors_file.write_all(raw_bytes)?;
             end_index += 1;
 
             // Remember deleted IDs so we can propagate deletions later
             if other_deleted {
-                deleted_ids.push(start_index as PointOffsetType + offset as PointOffsetType);
+                deleted_ids.push(start_index + offset as PointOffsetType);
             }
         }
         vectors_file.sync_all()?;
         drop(vectors_file);
 
-        // Load store with updated files
+        // Reload store with updated files
         self.mmap_store.replace(MmapDenseVectors::open(
             &self.vectors_path,
             &self.deleted_path,
@@ -241,10 +231,7 @@             with_async_io,
         )?);
 
-        // Flush deleted flags into store
-        // We must do that in the updated store, and cannot do it in the previous loop. That is
-        // because the file backing delete storage must be resized, and for that we'd need to know
-        // the exact number of vectors beforehand. When opening the store it is done automatically.
+        // Propagate deletions
         let store = self.mmap_store.as_mut().unwrap();
         for id in deleted_ids {
             check_process_stopped(stopped)?;
@@ -285,7 +272,7 @@     }
 }
 
-/// Open a file shortly for appending
+/// Open a file for appending.
 fn open_append<P: AsRef<Path>>(path: P) -> io::Result<File> {
     OpenOptions::new().append(true).open(path)
 }
@@ -302,14 +289,14 @@     use tempfile::Builder;
 
     use super::*;
-    use crate::common::rocksdb_wrapper::{DB_VECTOR_CF, open_db};
+    use crate::common::rocksdb_wrapper::{open_db, DB_VECTOR_CF};
     use crate::data_types::vectors::{DenseVector, QueryVector};
     use crate::fixtures::payload_context_fixture::FixtureIdTracker;
     use crate::id_tracker::id_tracker_base::IdTracker;
     use crate::types::{PointIdType, QuantizationConfig, ScalarQuantizationConfig};
     use crate::vector_storage::dense::simple_dense_vector_storage::open_simple_dense_vector_storage;
     use crate::vector_storage::quantized::quantized_vectors::QuantizedVectors;
-    use crate::vector_storage::{DEFAULT_STOPPED, new_raw_scorer_for_test};
+    use crate::vector_storage::{new_raw_scorer_for_test, DEFAULT_STOPPED};
 
     #[test]
     fn test_basic_persistence() {
@@ -420,7 +407,6 @@         let res = raw_scorer.peek_top_all(2, &DEFAULT_STOPPED).unwrap();
 
         assert_eq!(res.len(), 2);
-
         assert_ne!(res[0].idx, 2);
 
         let res = raw_scorer
@@ -540,11 +526,7 @@         // Delete all
         storage.delete_vector(0 as PointOffsetType).unwrap();
         storage.delete_vector(4 as PointOffsetType).unwrap();
-        assert_eq!(
-            storage.deleted_vector_count(),
-            5,
-            "all vectors must be deleted"
-        );
+        assert_eq!(storage.deleted_vector_count(), 5, "all vectors must be deleted");
 
         let vector = vec![1.0, 0.0, 0.0, 0.0];
         let query = vector.as_slice().into();
@@ -558,7 +540,6 @@         assert!(closest.is_empty(), "must have no results, all deleted");
     }
 
-    /// Test that deleted points are properly transferred when updating from other storage.
     #[test]
     fn test_update_from_delete_points() {
         let dir = Builder::new().prefix("storage_dir").tempdir().unwrap();
@@ -624,23 +605,17 @@         let closest = scorer
             .peek_top_iter(&mut [0, 1, 2, 3, 4].iter().cloned(), 5, &DEFAULT_STOPPED)
             .unwrap();
-
-        drop(scorer);
-
         assert_eq!(closest.len(), 3, "must have 3 vectors, 2 are deleted");
         assert_eq!(closest[0].idx, 0);
         assert_eq!(closest[1].idx, 1);
         assert_eq!(closest[2].idx, 4);
+        drop(scorer);
 
         // Delete all
         storage.delete_vector(0 as PointOffsetType).unwrap();
         storage.delete_vector(1 as PointOffsetType).unwrap();
         storage.delete_vector(4 as PointOffsetType).unwrap();
-        assert_eq!(
-            storage.deleted_vector_count(),
-            5,
-            "all vectors must be deleted"
-        );
+        assert_eq!(storage.deleted_vector_count(), 5, "all vectors must be deleted");
     }
 
     #[test]
@@ -802,7 +777,6 @@             borrowed_id_tracker.deleted_point_bitslice(),
         )
         .unwrap();
-
         for i in 0..5 {
             let quant = scorer_quant.score_point(i);
             let orig = scorer_orig.score_point(i);
@@ -817,10 +791,11 @@         let quantization_files = quantized_vectors.files();
 
         // test save-load
+        let hardware_counter = HardwareCounterCell::new();
         let quantized_vectors = QuantizedVectors::load(&storage, dir.path()).unwrap();
         assert_eq!(files, storage.files());
         assert_eq!(quantization_files, quantized_vectors.files());
-        let hardware_counter = HardwareCounterCell::new();
+
         let scorer_quant = quantized_vectors
             .raw_scorer(
                 query.clone(),
