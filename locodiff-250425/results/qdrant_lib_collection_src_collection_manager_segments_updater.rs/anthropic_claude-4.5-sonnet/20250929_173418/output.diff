
index 3c0816e92..1155f95ed 100644
--- a/qdrant_lib_collection_src_collection_manager_segments_updater.rs_expectedoutput.txt (expected):tmp/tmpm8boqcg6_expected.txt	
+++ b/qdrant_lib_collection_src_collection_manager_segments_updater.rs_extracted.txt (actual):tmp/tmp_4ekugdl_actual.txt	
@@ -226,7 +226,7 @@ fn points_by_filter(
     hw_counter: &HardwareCounterCell,
 ) -> CollectionResult<Vec<PointIdType>> {
     let mut affected_points: Vec<PointIdType> = Vec::new();
-    // we don’t want to cancel this filtered read
+    // we don't want to cancel this filtered read
     let is_stopped = AtomicBool::new(false);
     segments.for_each_segment(|s| {
         let points = s.read_filtered(None, None, Some(filter), &is_stopped, hw_counter);
@@ -426,7 +426,7 @@ pub(crate) fn sync_points(
         .collect();
 
     let mut points_to_update: Vec<_> = Vec::new();
-    // we don’t want to cancel this filtered read
+    // we don't want to cancel this filtered read
     let is_stopped = AtomicBool::new(false);
     let _num_updated =
         segments.read_points(existing_point_ids.as_slice(), &is_stopped, |id, segment| {
@@ -482,278 +482,4 @@ pub(crate) fn upsert_points<'a, T>(
     hw_counter: &HardwareCounterCell,
 ) -> CollectionResult<usize>
 where
-    T: IntoIterator<Item = &'a PointStructPersisted>,
-{
-    let points_map: AHashMap<PointIdType, _> = points.into_iter().map(|p| (p.id, p)).collect();
-    let ids: Vec<PointIdType> = points_map.keys().copied().collect();
-
-    // Update points in writable segments
-    let updated_points = segments.apply_points_with_conditional_move(
-        op_num,
-        &ids,
-        |id, write_segment| {
-            let point = points_map[&id];
-            upsert_with_payload(
-                write_segment,
-                op_num,
-                id,
-                point.get_vectors(),
-                point.payload.as_ref(),
-                hw_counter,
-            )
-        },
-        |id, vectors, old_payload| {
-            let point = points_map[&id];
-            for (name, vec) in point.get_vectors() {
-                vectors.insert(name.into(), vec.to_owned());
-            }
-            if let Some(payload) = &point.payload {
-                *old_payload = payload.clone();
-            }
-        },
-        |_| false,
-        hw_counter,
-    )?;
-
-    let mut res = updated_points.len();
-    // Insert new points, which was not updated or existed
-    let new_point_ids = ids.iter().copied().filter(|x| !updated_points.contains(x));
-
-    {
-        let default_write_segment = segments.smallest_appendable_segment().ok_or_else(|| {
-            CollectionError::service_error("No appendable segments exists, expected at least one")
-        })?;
-
-        let segment_arc = default_write_segment.get();
-        let mut write_segment = segment_arc.write();
-        for point_id in new_point_ids {
-            let point = points_map[&point_id];
-            res += usize::from(upsert_with_payload(
-                &mut write_segment,
-                op_num,
-                point_id,
-                point.get_vectors(),
-                point.payload.as_ref(),
-                hw_counter,
-            )?);
-        }
-        RwLockWriteGuard::unlock_fair(write_segment);
-    };
-
-    Ok(res)
-}
-
-pub(crate) fn process_point_operation(
-    segments: &RwLock<SegmentHolder>,
-    op_num: SeqNumberType,
-    point_operation: PointOperations,
-    hw_counter: &HardwareCounterCell,
-) -> CollectionResult<usize> {
-    match point_operation {
-        PointOperations::DeletePoints { ids, .. } => {
-            delete_points(&segments.read(), op_num, &ids, hw_counter)
-        }
-        PointOperations::UpsertPoints(operation) => {
-            let points: Vec<_> = match operation {
-                PointInsertOperationsInternal::PointsBatch(batch) => {
-                    let batch_vectors = BatchVectorStructInternal::from(batch.vectors);
-                    let all_vectors = batch_vectors.into_all_vectors(batch.ids.len());
-                    let vectors_iter = batch.ids.into_iter().zip(all_vectors);
-                    match batch.payloads {
-                        None => vectors_iter
-                            .map(|(id, vectors)| PointStructPersisted {
-                                id,
-                                vector: VectorStructInternal::from(vectors).into(),
-                                payload: None,
-                            })
-                            .collect(),
-                        Some(payloads) => vectors_iter
-                            .zip(payloads)
-                            .map(|((id, vectors), payload)| PointStructPersisted {
-                                id,
-                                vector: VectorStructInternal::from(vectors).into(),
-                                payload,
-                            })
-                            .collect(),
-                    }
-                }
-                PointInsertOperationsInternal::PointsList(points) => points,
-            };
-            let res = upsert_points(&segments.read(), op_num, points.iter(), hw_counter)?;
-            Ok(res)
-        }
-        PointOperations::DeletePointsByFilter(filter) => {
-            delete_points_by_filter(&segments.read(), op_num, &filter, hw_counter)
-        }
-        PointOperations::SyncPoints(operation) => {
-            let (deleted, new, updated) = sync_points(
-                &segments.read(),
-                op_num,
-                operation.from_id,
-                operation.to_id,
-                &operation.points,
-                hw_counter,
-            )?;
-            Ok(deleted + new + updated)
-        }
-    }
-}
-
-pub(crate) fn process_vector_operation(
-    segments: &RwLock<SegmentHolder>,
-    op_num: SeqNumberType,
-    vector_operation: VectorOperations,
-    hw_counter: &HardwareCounterCell,
-) -> CollectionResult<usize> {
-    match vector_operation {
-        VectorOperations::UpdateVectors(operation) => {
-            update_vectors(&segments.read(), op_num, operation.points, hw_counter)
-        }
-        VectorOperations::DeleteVectors(ids, vector_names) => {
-            delete_vectors(&segments.read(), op_num, &ids.points, &vector_names)
-        }
-        VectorOperations::DeleteVectorsByFilter(filter, vector_names) => {
-            delete_vectors_by_filter(&segments.read(), op_num, &filter, &vector_names, hw_counter)
-        }
-    }
-}
-
-pub(crate) fn process_payload_operation(
-    segments: &RwLock<SegmentHolder>,
-    op_num: SeqNumberType,
-    payload_operation: PayloadOps,
-    hw_counter: &HardwareCounterCell,
-) -> CollectionResult<usize> {
-    match payload_operation {
-        PayloadOps::SetPayload(sp) => {
-            let payload: Payload = sp.payload;
-            if let Some(points) = sp.points {
-                set_payload(
-                    &segments.read(),
-                    op_num,
-                    &payload,
-                    &points,
-                    &sp.key,
-                    hw_counter,
-                )
-            } else if let Some(filter) = sp.filter {
-                set_payload_by_filter(
-                    &segments.read(),
-                    op_num,
-                    &payload,
-                    &filter,
-                    &sp.key,
-                    hw_counter,
-                )
-            } else {
-                Err(CollectionError::BadRequest {
-                    description: "No points or filter specified".to_string(),
-                })
-            }
-        }
-        PayloadOps::DeletePayload(dp) => {
-            if let Some(points) = dp.points {
-                delete_payload(&segments.read(), op_num, &points, &dp.keys, hw_counter)
-            } else if let Some(filter) = dp.filter {
-                delete_payload_by_filter(&segments.read(), op_num, &filter, &dp.keys, hw_counter)
-            } else {
-                Err(CollectionError::BadRequest {
-                    description: "No points or filter specified".to_string(),
-                })
-            }
-        }
-        PayloadOps::ClearPayload { ref points, .. } => {
-            clear_payload(&segments.read(), op_num, points, hw_counter)
-        }
-        PayloadOps::ClearPayloadByFilter(ref filter) => {
-            clear_payload_by_filter(&segments.read(), op_num, filter, hw_counter)
-        }
-        PayloadOps::OverwritePayload(sp) => {
-            let payload: Payload = sp.payload;
-            if let Some(points) = sp.points {
-                overwrite_payload(&segments.read(), op_num, &payload, &points, hw_counter)
-            } else if let Some(filter) = sp.filter {
-                overwrite_payload_by_filter(&segments.read(), op_num, &payload, &filter, hw_counter)
-            } else {
-                Err(CollectionError::BadRequest {
-                    description: "No points or filter specified".to_string(),
-                })
-            }
-        }
-    }
-}
-
-pub(crate) fn process_field_index_operation(
-    segments: &RwLock<SegmentHolder>,
-    op_num: SeqNumberType,
-    field_index_operation: &FieldIndexOperations,
-    hw_counter: &HardwareCounterCell,
-) -> CollectionResult<usize> {
-    match field_index_operation {
-        FieldIndexOperations::CreateIndex(index_data) => create_field_index(
-            &segments.read(),
-            op_num,
-            &index_data.field_name,
-            index_data.field_schema.as_ref(),
-            hw_counter,
-        ),
-        FieldIndexOperations::DeleteIndex(field_name) => {
-            delete_field_index(&segments.read(), op_num, field_name)
-        }
-    }
-}
-
-/// Max amount of points to delete in a batched deletion iteration.
-const DELETION_BATCH_SIZE: usize = 512;
-
-/// Deletes points from all segments matching the given filter
-pub(crate) fn delete_points_by_filter(
-    segments: &SegmentHolder,
-    op_num: SeqNumberType,
-    filter: &Filter,
-    hw_counter: &HardwareCounterCell,
-) -> CollectionResult<usize> {
-    let mut total_deleted = 0;
-    // we don’t want to cancel this filtered read
-    let is_stopped = AtomicBool::new(false);
-    let mut points_to_delete: AHashMap<_, _> = segments
-        .iter()
-        .map(|(segment_id, segment)| {
-            (
-                *segment_id,
-                segment.get().read().read_filtered(
-                    None,
-                    None,
-                    Some(filter),
-                    &is_stopped,
-                    hw_counter,
-                ),
-            )
-        })
-        .collect();
-
-    segments.apply_segments_batched(|s, segment_id| {
-        let Some(curr_points) = points_to_delete.get_mut(&segment_id) else {
-            return Ok(false);
-        };
-        if curr_points.is_empty() {
-            return Ok(false);
-        }
-
-        let mut deleted_in_batch = 0;
-        while let Some(point_id) = curr_points.pop() {
-            if s.delete_point(op_num, point_id, hw_counter)? {
-                total_deleted += 1;
-                deleted_in_batch += 1;
-            }
-
-            if deleted_in_batch >= DELETION_BATCH_SIZE {
-                break;
-            }
-        }
-
-        Ok(true)
-    })?;
-
-    Ok(total_deleted)
-}
\ No newline at end of file
+    T: IntoIterator<Item = &'a PointStructPersisted>,
\ No newline at end of file
