
index 3c0816e9..5b609147 100644
--- a/qdrant_lib_collection_src_collection_manager_segments_updater.rs_expectedoutput.txt (expected):tmp/tmpvymw5cdp_expected.txt	
+++ b/qdrant_lib_collection_src_collection_manager_segments_updater.rs_extracted.txt (actual):tmp/tmpw2w9yy8t_actual.txt	
@@ -1,7 +1,3 @@
-//! A collection of functions for updating points and payloads stored in segments
-
-use std::sync::atomic::AtomicBool;
-
 use ahash::{AHashMap, AHashSet};
 use common::counter::hardware_counter::HardwareCounterCell;
 use itertools::iproduct;
@@ -11,17 +7,14 @@ use segment::data_types::named_vectors::NamedVectors;
 use segment::data_types::vectors::{BatchVectorStructInternal, VectorStructInternal};
 use segment::entry::entry_point::SegmentEntry;
 use segment::json_path::JsonPath;
-use segment::types::{
-    Filter, Payload, PayloadFieldSchema, PayloadKeyType, PayloadKeyTypeRef, PointIdType,
-    SeqNumberType, VectorNameBuf,
-};
+use segment::types::{Filter, Payload, PayloadFieldSchema, PayloadKeyType, PayloadKeyTypeRef, PointIdType, SeqNumberType, VectorNameBuf};
+
+use std::sync::atomic::AtomicBool;
 
 use crate::collection_manager::holders::segment_holder::SegmentHolder;
 use crate::operations::FieldIndexOperations;
 use crate::operations::payload_ops::PayloadOps;
-use crate::operations::point_ops::{
-    PointInsertOperationsInternal, PointOperations, PointStructPersisted,
-};
+use crate::operations::point_ops::{PointInsertOperationsInternal, PointOperations, PointStructPersisted};
 use crate::operations::types::{CollectionError, CollectionResult};
 use crate::operations::vector_ops::{PointVectorsPersisted, VectorOperations};
 
@@ -37,11 +30,10 @@ pub(crate) fn check_unprocessed_points(
     }
 }
 
-/// Tries to delete points from all segments, returns number of actually deleted points
 pub(crate) fn delete_points(
     segments: &SegmentHolder,
     op_num: SeqNumberType,
-    ids: &[PointIdType],
+    ids: &[PointIdType], 
     hw_counter: &HardwareCounterCell,
 ) -> CollectionResult<usize> {
     let mut total_deleted_points = 0;
@@ -59,14 +51,12 @@ pub(crate) fn delete_points(
     Ok(total_deleted_points)
 }
 
-/// Update the specified named vectors of a point, keeping unspecified vectors intact.
 pub(crate) fn update_vectors(
     segments: &SegmentHolder,
     op_num: SeqNumberType,
     points: Vec<PointVectorsPersisted>,
     hw_counter: &HardwareCounterCell,
 ) -> CollectionResult<usize> {
-    // Build a map of vectors to update per point, merge updates on same point ID
     let mut points_map: AHashMap<PointIdType, NamedVectors> = AHashMap::new();
     for point in points {
         let PointVectorsPersisted { id, vector } = point;
@@ -85,11 +75,11 @@ pub(crate) fn update_vectors(
             batch,
             |id, write_segment| {
                 let vectors = points_map[&id].clone();
-                write_segment.update_vectors(op_num, id, vectors, hw_counter)
+                write_segment.update_vectors(op_num, id, vectors, hw_counter) 
             },
             |id, owned_vectors, _| {
                 for (vector_name, vector_ref) in points_map[&id].iter() {
-                    owned_vectors.insert(vector_name.to_owned(), vector_ref.to_owned());
+                    owned_vectors.insert(vector_name.into(), vector_ref.to_owned());
                 }
             },
             |_| false,
@@ -104,10 +94,9 @@ pub(crate) fn update_vectors(
 
 const VECTOR_OP_BATCH_SIZE: usize = 512;
 
-/// Delete the given named vectors for the given points, keeping other vectors intact.
 pub(crate) fn delete_vectors(
     segments: &SegmentHolder,
-    op_num: SeqNumberType,
+    op_num: SeqNumberType, 
     points: &[PointIdType],
     vector_names: &[VectorNameBuf],
 ) -> CollectionResult<usize> {
@@ -132,19 +121,17 @@ pub(crate) fn delete_vectors(
     Ok(total_deleted_points)
 }
 
-/// Delete the given named vectors for points matching the given filter, keeping other vectors intact.
 pub(crate) fn delete_vectors_by_filter(
     segments: &SegmentHolder,
     op_num: SeqNumberType,
     filter: &Filter,
-    vector_names: &[VectorNameBuf],
+    vector_names: &[VectorNameBuf], 
     hw_counter: &HardwareCounterCell,
 ) -> CollectionResult<usize> {
     let affected_points = points_by_filter(segments, filter, hw_counter)?;
     delete_vectors(segments, op_num, &affected_points, vector_names)
 }
 
-/// Batch size when modifying payload.
 const PAYLOAD_OP_BATCH_SIZE: usize = 512;
 
 pub(crate) fn overwrite_payload(
@@ -152,7 +139,7 @@ pub(crate) fn overwrite_payload(
     op_num: SeqNumberType,
     payload: &Payload,
     points: &[PointIdType],
-    hw_counter: &HardwareCounterCell,
+    hw_counter: &HardwareCounterCell, 
 ) -> CollectionResult<usize> {
     let mut total_updated_points = 0;
 
@@ -199,7 +186,7 @@ pub(crate) fn set_payload(
     for chunk in points.chunks(PAYLOAD_OP_BATCH_SIZE) {
         let updated_points = segments.apply_points_with_conditional_move(
             op_num,
-            chunk,
+            chunk, 
             |id, write_segment| write_segment.set_payload(op_num, id, payload, key, hw_counter),
             |_, _, old_payload| match key {
                 Some(key) => old_payload.merge_by_key(payload, key),
@@ -223,10 +210,9 @@ pub(crate) fn set_payload(
 fn points_by_filter(
     segments: &SegmentHolder,
     filter: &Filter,
-    hw_counter: &HardwareCounterCell,
+    hw_counter: &HardwareCounterCell
 ) -> CollectionResult<Vec<PointIdType>> {
     let mut affected_points: Vec<PointIdType> = Vec::new();
-    // we don’t want to cancel this filtered read
     let is_stopped = AtomicBool::new(false);
     segments.for_each_segment(|s| {
         let points = s.read_filtered(None, None, Some(filter), &is_stopped, hw_counter);
@@ -239,7 +225,7 @@ fn points_by_filter(
 pub(crate) fn set_payload_by_filter(
     segments: &SegmentHolder,
     op_num: SeqNumberType,
-    payload: &Payload,
+    payload: &Payload, 
     filter: &Filter,
     key: &Option<JsonPath>,
     hw_counter: &HardwareCounterCell,
@@ -287,7 +273,7 @@ pub(crate) fn delete_payload(
         total_deleted_points += updated_points.len();
     }
 
-    Ok(total_deleted_points)
+    Ok(total_deleted_points) 
 }
 
 pub(crate) fn delete_payload_by_filter(
@@ -325,11 +311,10 @@ pub(crate) fn clear_payload(
     Ok(total_updated_points)
 }
 
-/// Clear Payloads from all segments matching the given filter
 pub(crate) fn clear_payload_by_filter(
     segments: &SegmentHolder,
     op_num: SeqNumberType,
-    filter: &Filter,
+    filter: &Filter, 
     hw_counter: &HardwareCounterCell,
 ) -> CollectionResult<usize> {
     let points_to_clear = points_by_filter(segments, filter, hw_counter)?;
@@ -370,12 +355,6 @@ pub(crate) fn delete_field_index(
         .map_err(Into::into)
 }
 
-/// Upsert to a point ID with the specified vectors and payload in the given segment.
-///
-/// Returns
-/// - Ok(true) if the operation was successful and point replaced existing value
-/// - Ok(false) if the operation was successful and point was inserted
-/// - Err if the operation failed
 fn upsert_with_payload(
     segment: &mut RwLockWriteGuard<dyn SegmentEntry>,
     op_num: SeqNumberType,
@@ -391,19 +370,9 @@ fn upsert_with_payload(
     Ok(res)
 }
 
-/// Sync points within a given [from_id; to_id) range.
-///
-/// 1. Retrieve existing points for a range
-/// 2. Remove points, which are not present in the sync operation
-/// 3. Retrieve overlapping points, detect which one of them are changed
-/// 4. Select new points
-/// 5. Upsert points which differ from the stored ones
-///
-/// Returns:
-///     (number of deleted points, number of new points, number of updated points)
 pub(crate) fn sync_points(
     segments: &SegmentHolder,
-    op_num: SeqNumberType,
+    op_num: SeqNumberType, 
     from_id: Option<PointIdType>,
     to_id: Option<PointIdType>,
     points: &[PointStructPersisted],
@@ -411,50 +380,47 @@ pub(crate) fn sync_points(
 ) -> CollectionResult<(usize, usize, usize)> {
     let id_to_point: AHashMap<PointIdType, _> = points.iter().map(|p| (p.id, p)).collect();
     let sync_points: AHashSet<_> = points.iter().map(|p| p.id).collect();
-    // 1. Retrieve existing points for a range
+    
     let stored_point_ids: AHashSet<_> = segments
         .iter()
         .flat_map(|(_, segment)| segment.get().read().read_range(from_id, to_id))
         .collect();
-    // 2. Remove points, which are not present in the sync operation
+        
     let points_to_remove: Vec<_> = stored_point_ids.difference(&sync_points).copied().collect();
     let deleted = delete_points(segments, op_num, points_to_remove.as_slice(), hw_counter)?;
-    // 3. Retrieve overlapping points, detect which one of them are changed
+
     let existing_point_ids: Vec<_> = stored_point_ids
         .intersection(&sync_points)
         .copied()
         .collect();
 
     let mut points_to_update: Vec<_> = Vec::new();
-    // we don’t want to cancel this filtered read
     let is_stopped = AtomicBool::new(false);
-    let _num_updated =
-        segments.read_points(existing_point_ids.as_slice(), &is_stopped, |id, segment| {
-            let all_vectors = match segment.all_vectors(id) {
-                Ok(v) => v,
-                Err(OperationError::InconsistentStorage { .. }) => NamedVectors::default(),
-                Err(e) => return Err(e),
+    let _num_updated = segments.read_points(existing_point_ids.as_slice(), &is_stopped, |id, segment| {
+        let all_vectors = match segment.all_vectors(id) {
+            Ok(v) => v,
+            Err(OperationError::InconsistentStorage { .. }) => NamedVectors::default(),
+            Err(e) => return Err(e),
+        };
+        let payload = segment.payload(id, hw_counter)?;
+        let point = id_to_point.get(&id).unwrap();
+        if point.get_vectors() != all_vectors {
+            points_to_update.push(*point);
+            Ok(true)
+        } else {
+            let payload_match = match point.payload {
+                Some(ref p) => p == &payload,
+                None => Payload::default() == payload,
             };
-            let payload = segment.payload(id, hw_counter)?;
-            let point = id_to_point.get(&id).unwrap();
-            if point.get_vectors() != all_vectors {
+            if !payload_match {
                 points_to_update.push(*point);
                 Ok(true)
             } else {
-                let payload_match = match point.payload {
-                    Some(ref p) => p == &payload,
-                    None => Payload::default() == payload,
-                };
-                if !payload_match {
-                    points_to_update.push(*point);
-                    Ok(true)
-                } else {
-                    Ok(false)
-                }
+                Ok(false)
             }
-        })?;
+        }
+    })?;
 
-    // 4. Select new points
     let num_updated = points_to_update.len();
     let mut num_new = 0;
     sync_points.difference(&stored_point_ids).for_each(|id| {
@@ -462,7 +428,6 @@ pub(crate) fn sync_points(
         points_to_update.push(*id_to_point.get(id).unwrap());
     });
 
-    // 5. Upsert points which differ from the stored ones
     let num_replaced = upsert_points(segments, op_num, points_to_update, hw_counter)?;
     debug_assert!(
         num_replaced <= num_updated,
@@ -472,13 +437,10 @@ pub(crate) fn sync_points(
     Ok((deleted, num_new, num_updated))
 }
 
-/// Checks point id in each segment, update point if found.
-/// All not found points are inserted into random segment.
-/// Returns: number of updated points.
 pub(crate) fn upsert_points<'a, T>(
     segments: &SegmentHolder,
     op_num: SeqNumberType,
-    points: T,
+    points: T, 
     hw_counter: &HardwareCounterCell,
 ) -> CollectionResult<usize>
 where
@@ -487,7 +449,6 @@ where
     let points_map: AHashMap<PointIdType, _> = points.into_iter().map(|p| (p.id, p)).collect();
     let ids: Vec<PointIdType> = points_map.keys().copied().collect();
 
-    // Update points in writable segments
     let updated_points = segments.apply_points_with_conditional_move(
         op_num,
         &ids,
@@ -516,12 +477,11 @@ where
     )?;
 
     let mut res = updated_points.len();
-    // Insert new points, which was not updated or existed
     let new_point_ids = ids.iter().copied().filter(|x| !updated_points.contains(x));
 
     {
         let default_write_segment = segments.smallest_appendable_segment().ok_or_else(|| {
-            CollectionError::service_error("No appendable segments exists, expected at least one")
+            CollectionError::service_error("No appendable segments exists, expected at least one") 
         })?;
 
         let segment_arc = default_write_segment.get();
@@ -673,7 +633,7 @@ pub(crate) fn process_payload_operation(
             if let Some(points) = sp.points {
                 overwrite_payload(&segments.read(), op_num, &payload, &points, hw_counter)
             } else if let Some(filter) = sp.filter {
-                overwrite_payload_by_filter(&segments.read(), op_num, &payload, &filter, hw_counter)
+                overwrite_payload_by_filter(&segments.read(), op_num, &payload, &filter, hw_counter) 
             } else {
                 Err(CollectionError::BadRequest {
                     description: "No points or filter specified".to_string(),
@@ -693,7 +653,7 @@ pub(crate) fn process_field_index_operation(
         FieldIndexOperations::CreateIndex(index_data) => create_field_index(
             &segments.read(),
             op_num,
-            &index_data.field_name,
+            &index_data.field_name, 
             index_data.field_schema.as_ref(),
             hw_counter,
         ),
@@ -703,18 +663,13 @@ pub(crate) fn process_field_index_operation(
     }
 }
 
-/// Max amount of points to delete in a batched deletion iteration.
-const DELETION_BATCH_SIZE: usize = 512;
-
-/// Deletes points from all segments matching the given filter
 pub(crate) fn delete_points_by_filter(
     segments: &SegmentHolder,
     op_num: SeqNumberType,
     filter: &Filter,
-    hw_counter: &HardwareCounterCell,
+    hw_counter: &HardwareCounterCell,  
 ) -> CollectionResult<usize> {
     let mut total_deleted = 0;
-    // we don’t want to cancel this filtered read
     let is_stopped = AtomicBool::new(false);
     let mut points_to_delete: AHashMap<_, _> = segments
         .iter()
