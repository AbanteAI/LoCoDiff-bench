--- qdrant_lib_segment_src_index_field_index_full_text_index_text_index.rs_expectedoutput.txt (expected)+++ qdrant_lib_segment_src_index_field_index_full_text_index_text_index.rs_extracted.txt (actual)@@ -2,6 +2,7 @@ use std::path::PathBuf;
 use std::sync::Arc;
 
+use common::counter::hardware_accumulator::HwMeasurementAcc;
 use common::counter::hardware_counter::HardwareCounterCell;
 use common::types::PointOffsetType;
 use parking_lot::RwLock;
@@ -113,6 +114,34 @@         }
     }
 
+    fn document_from_tokens(&mut self, tokens: &BTreeSet<String>) -> Document {
+        match self {
+            Self::Mutable(index) => index.inverted_index.document_from_tokens(tokens),
+            Self::Immutable(index) => index.inverted_index.document_from_tokens(tokens),
+            Self::Mmap(index) => index.inverted_index.document_from_tokens(tokens),
+        }
+    }
+
+    fn index_document(
+        &mut self,
+        point_id: PointOffsetType,
+        document: Document,
+    ) -> OperationResult<()> {
+        match self {
+            Self::Mutable(index) => index.inverted_index.index_document(point_id, document),
+            Self::Immutable(index) => index.inverted_index.index_document(point_id, document),
+            Self::Mmap(index) => index.inverted_index.index_document(point_id, document),
+        }
+    }
+
+    fn remove_document(&mut self, point_id: PointOffsetType) -> bool {
+        match self {
+            Self::Mutable(index) => index.inverted_index.remove_document(point_id),
+            Self::Immutable(index) => index.inverted_index.remove_document(point_id),
+            Self::Mmap(index) => index.inverted_index.remove_document(point_id),
+        }
+    }
+
     fn filter<'a>(
         &'a self,
         query: ParsedQuery,
@@ -215,11 +244,10 @@         struct StoredDocument {
             tokens: BTreeSet<String>,
         }
-        serde_cbor::from_slice::<StoredDocument>(data)
-            .map_err(|e| {
-                OperationError::service_error(format!("Failed to deserialize document: {e}"))
-            })
-            .map(|doc| doc.tokens)
+        serde_cbor::from_slice::<StoredDocument>(data).map_err(|e| {
+            OperationError::service_error(format!("Failed to deserialize document: {e}"))
+        })
+        .map(|doc| doc.tokens)
     }
 
     pub fn get_telemetry_data(&self) -> PayloadIndexTelemetry {
@@ -253,7 +281,7 @@                 document_tokens.push(token_id);
             }
         });
-        Document::new(document_tokens)
+        Document { tokens: document_tokens }
     }
 
     #[cfg(test)]
@@ -423,4 +451,131 @@     ) -> Box<dyn Iterator<Item = PayloadBlockCondition> + '_> {
         self.payload_blocks(threshold, key)
     }
+}
+
+#[cfg(test)]
+mod tests {
+    use rstest::rstest;
+    use tempfile::Builder;
+
+    use super::*;
+    use crate::common::rocksdb_wrapper::open_db_with_existing_cf;
+    use crate::data_types::index::{TextIndexType, TokenizerType};
+    use crate::json_path::JsonPath;
+
+    fn filter_request(text: &str) -> FieldCondition {
+        FieldCondition::new_match(JsonPath::new("text"), Match::new_text(text))
+    }
+
+    #[rstest]
+    #[case(true)]
+    #[case(false)]
+    fn test_full_text_indexing(#[case] immutable: bool) {
+        let payloads: Vec<_> = vec![
+            serde_json::json!("The celebration had a long way to go and even in the silent depths of Multivac's underground chambers, it hung in the air."),
+            serde_json::json!("If nothing else, there was the mere fact of isolation and silence."),
+            serde_json::json!([
+                "For the first time in a decade, technicians were not scurrying about the vitals of the giant computer, ",
+                "the soft lights did not wink out their erratic patterns, the flow of information in and out had halted."
+            ]),
+            serde_json::json!("It would not be halted long, of course, for the needs of peace would be pressing."),
+            serde_json::json!("Yet now, for a day, perhaps for a week, even Multivac might celebrate the great time, and rest."),
+        ];
+
+        let temp_dir = Builder::new().prefix("test_dir").tempdir().unwrap();
+        let config = TextIndexParams {
+            r#type: TextIndexType::Text,
+            tokenizer: TokenizerType::Word,
+            min_token_len: None,
+            max_token_len: None,
+            lowercase: None,
+        };
+
+        {
+            let db = open_db_with_existing_cf(&temp_dir.path().join("test_db")).unwrap();
+
+            let mut index = FullTextIndex::builder(db, config.clone(), "text")
+                .make_empty()
+                .unwrap();
+
+            let hw_counter = HardwareCounterCell::disposable();
+            for (idx, payload) in payloads.iter().enumerate() {
+                index
+                    .add_point(idx as PointOffsetType, &[payload], &hw_counter)
+                    .unwrap();
+            }
+
+            assert_eq!(index.count_indexed_points(), payloads.len());
+
+            let filter_condition = filter_request("multivac");
+            let search_res: Vec<_> = index.filter(&filter_condition, &hw_counter).unwrap().collect();
+            assert_eq!(search_res, vec![0, 4]);
+
+            let filter_condition = filter_request("giant computer");
+            let search_res: Vec<_> = index.filter(&filter_condition, &hw_counter).unwrap().collect();
+            assert_eq!(search_res, vec![2]);
+
+            let filter_condition = filter_request("the great time");
+            let search_res: Vec<_> = index.filter(&filter_condition, &hw_counter).unwrap().collect();
+            assert_eq!(search_res, vec![4]);
+
+            index.remove_point(2).unwrap();
+            index.remove_point(3).unwrap();
+
+            let filter_condition = filter_request("giant computer");
+            assert!(index.filter(&filter_condition, &hw_counter).unwrap().next().is_none());
+
+            assert_eq!(index.count_indexed_points(), payloads.len() - 2);
+
+            let payload = serde_json::json!([
+                "The last question was asked for the first time, half in jest, on May 21, 2061,",
+                "at a time when humanity first stepped into the light."
+            ]);
+            index.add_point(3, &[&payload], &hw_counter).unwrap();
+
+            let payload = serde_json::json!([
+                "The question came about as a result of a five dollar bet over highballs, and it happened this way: "
+            ]);
+            index.add_point(4, &[&payload], &hw_counter).unwrap();
+
+            assert_eq!(index.count_indexed_points(), payloads.len() - 1);
+
+            index.flusher()().unwrap();
+        }
+
+        {
+            let db = open_db_with_existing_cf(&temp_dir.path().join("test_db")).unwrap();
+            let mut index = FullTextIndex::new_memory(db, config, "text", immutable);
+            let loaded = index.load().unwrap();
+            assert!(loaded);
+
+            let hw_counter = HardwareCounterCell::disposable();
+            assert_eq!(index.count_indexed_points(), 4);
+
+            let filter_condition = filter_request("multivac");
+            let search_res: Vec<_> = index.filter(&filter_condition, &hw_counter).unwrap().collect();
+            assert_eq!(search_res, vec![0]);
+
+            let filter_condition = filter_request("the");
+            let search_res: Vec<_> = index.filter(&filter_condition, &hw_counter).unwrap().collect();
+            assert_eq!(search_res, vec![0, 1, 3, 4]);
+
+            // check deletion
+            index.remove_point(0).unwrap();
+            let filter_condition = filter_request("multivac");
+            let search_res: Vec<_> = index.filter(&filter_condition, &hw_counter).unwrap().collect();
+            assert!(search_res.is_empty());
+            assert_eq!(index.count_indexed_points(), 3);
+
+            index.remove_point(3).unwrap();
+            let filter_condition = filter_request("the");
+            let search_res: Vec<_> = index.filter(&filter_condition, &hw_counter).unwrap().collect();
+            assert_eq!(search_res, vec![1, 4]);
+            assert_eq!(index.count_indexed_points(), 2);
+
+            // check deletion of non-existing point
+            index.remove_point(3).unwrap();
+            assert_eq!(index.count_indexed_points(), 2);
+        }
+    }
 }