
index 039baf10b..336fe927a 100644
--- a/tldraw_apps_dotcom_sync-worker_src_TLPostgresReplicator.ts_expectedoutput.txt (expected):tmp/tmp5isla71e_expected.txt	
+++ b/tldraw_apps_dotcom_sync-worker_src_TLPostgresReplicator.ts_extracted.txt (actual):tmp/tmptl05ycy8_actual.txt	
@@ -11,10 +11,7 @@ import {
 	throttle,
 	uniqueId,
 } from '@tldraw/utils'
-import { createSentry } from '@tldraw/worker-shared'
-import { DurableObject } from 'cloudflare:workers'
 import { Kysely, sql } from 'kysely'
-
 import { LogicalReplicationService, Wal2Json, Wal2JsonPlugin } from 'pg-logical-replication'
 import { Logger } from './Logger'
 import { UserChangeCollator } from './UserChangeCollator'
@@ -41,14 +38,19 @@ interface ReplicationEvent {
 	table: keyof typeof relevantTables
 }
 
+/** A replicated row and its metadata */
 interface Change {
 	event: ReplicationEvent
 	userId: string
 	fileId: string | null
 	row: TlaRow
+	/** Previous version of the row (if an update) */
 	previous?: TlaRow
 }
 
+/**
+ * @internal only kept in this file to avoid the boilerplate for a proper ts file.
+ */
 interface Migration {
 	id: string
 	code: string
@@ -67,11 +69,13 @@ const migrations: Migration[] = [
 				PRIMARY KEY (userId, fileId),
 				FOREIGN KEY (userId) REFERENCES active_user(id) ON DELETE CASCADE
 			);
-			CREATE TABLE migrations (
-				id TEXT PRIMARY KEY,
-				code TEXT NOT NULL
+			CREATE TABLE IF NOT EXISTS meta (
+				lsn TEXT PRIMARY KEY,
+				slotName TEXT NOT NULL,
+				CONSTRAINT sln_slot_name UNIQUE (slotName)
 			);
-		`,
+			INSERT INTO meta (lsn, slotName) VALUES ('0/0', 'init');
+			`,
 	},
 	{
 		id: '001_add_sequence_number',
@@ -93,9 +97,6 @@ const migrations: Migration[] = [
 				lsn TEXT PRIMARY KEY,
 				slotName TEXT NOT NULL
 			);
-			-- The slot name references the replication slot in postgres.
-			-- If something ever gets messed up beyond mortal comprehension and we need to force all
-			-- clients to reboot, we can just change the slot name by altering the slotNamePrefix in the constructor.
 			INSERT INTO meta (lsn, slotName) VALUES ('0/0', 'init');
 		`,
 	},
@@ -123,21 +124,14 @@ const migrations: Migration[] = [
 
 const ONE_MINUTE = 60 * 1000
 const PRUNE_INTERVAL = 10 * ONE_MINUTE
+/* Keep a reasonably generous amount of history */
 const MAX_HISTORY_ROWS = 20_000
 
 type PromiseWithResolve = ReturnType<typeof promiseWithResolve>
 
-type Row =
-	| TlaRow
-	| {
-			bootId: string
-			userId: string
-	  }
-	| {
-			mutationNumber: number
-			userId: string
-	  }
-
+/**
+ * Boot state for the replicator.
+ */
 type BootState =
 	| {
 			type: 'init'
@@ -149,559 +143,334 @@ type BootState =
 	  }
 	| {
 			type: 'connected'
+			subscription: postgres.SubscriptionHandle
 	  }
 
 export class TLPostgresReplicator extends DurableObject<Environment> {
 	private sqlite: SqlStorage
-	private state: BootState
+
+	private state: BootState = {
+		type: 'init',
+		promise: promiseWithResolve(),
+	}
+
 	private measure: Analytics | undefined
+
 	private postgresUpdates = 0
 	private lastPostgresMessageTime = Date.now()
 	private lastRpmLogTime = Date.now()
 	private lastUserPruneTime = Date.now()
-
-	// we need to guarantee in-order delivery of messages to users
-	// but DO RPC calls are not guaranteed to happen in order, so we need to
-	// use a queue per user
-	private userDispatchQueues: Map<string, ExecutionQueue> = new Map()
-
-	sentry
-	// eslint-disable-next-line local/prefer-class-methods
-	private captureException = (exception: unknown, extras?: Record<string, unknown>) => {
-		// eslint-disable-next-line @typescript-eslint/no-deprecated
-		this.sentry?.withScope((scope) => {
-			if (extras) scope.setExtras(extras)
-			// eslint-disable-next-line @typescript-eslint/no-deprecated
-			this.sentry?.captureException(exception) as any
-		})
-		this.log.debug('ERROR', (exception as any)?.stack ?? exception)
-		if (!this.sentry) {
-			console.error(`[TLPostgresReplicator]: `, exception)
-		}
-	}
-
-	private log
-
-	private readonly replicationService
-	private readonly slotName
+	private readonly replicationService: LogicalReplicationService
+	private readonly slotName: string
 	private readonly wal2jsonPlugin = new Wal2JsonPlugin({
-		addTables:
-			'public.user,public.file,public.file_state,public.user_mutation_number,public.replicator_boot_id',
+		addTables: 'public.user,public.file,public.file_state,public.user_mutation_number,public.replicator_boot_id',
 	})
 
 	private readonly db: Kysely<DB>
+
+	private readonly log: Logger
+
+	private readonly userDispatchQueues: Map<string, ExecutionQueue> = new Map()
+
 	constructor(ctx: DurableObjectState, env: Environment) {
 		super(ctx, env)
+
 		this.measure = env.MEASURE
-		this.sentry = createSentry(ctx, env)
+		this.log = new Logger(env, 'TLPostgresReplicator', this.sentry)
+
 		this.sqlite = this.ctx.storage.sql
-		this.state = {
-			type: 'init',
-			promise: promiseWithResolve(),
-		}
 
-		const slotNameMaxLength = 63 // max postgres identifier length
-		const slotNamePrefix = 'tlpr_' // pick something short so we can get more of the durable object id
-		const durableObjectId = this.ctx.id.toString()
-		this.slotName =
-			slotNamePrefix + durableObjectId.slice(0, slotNameMaxLength - slotNamePrefix.length)
+		// Perform migrations atomically in a blockConcurrencyWhile.
+		this.ctx.blockConcurrencyWhile(async () => {
+			await this._migrate()
+			// If the slot name has changed, we set history LSN to null which will force a sequence break.
+			if (this.sqlite.exec('select slotName from meta').one().slotName !== this.slotName) {
+				this.sqlite.exec('UPDATE meta SET slotName = ?, lsn = NULL', this.slotName)
+			}
+			// Ensure replication slot exists.
+			await sql`SELECT pg_create_logical_replication_slot(${this.slotName}, 'wal2json')
+				WHERE NOT EXISTS (SELECT 1 FROM pg_replication_slots WHERE slot_name = ${this.slotName})`.execute(this.db)
+		}).then(() => {
+			this.reboot('constructor', false).catch((e) => {
+				this.captureException(e)
+				this.__test__panic()
+			})
+		})
 
+		// debug logging, enabled in preview.
 		this.log = new Logger(env, 'TLPostgresReplicator', this.sentry)
-		this.db = createPostgresConnectionPool(env, 'TLPostgresReplicator', 100)
-
 		this.replicationService = new LogicalReplicationService(
-			/**
-			 * node-postgres Client options for connection
-			 * https://github.com/DefinitelyTyped/DefinitelyTyped/blob/tldraw_apps_dotcom_sync-worker_src_TLPostgresReplicator.ts_extracted.txt (actual): 'postgres',
 				connectionString: env.BOTCOM_POSTGRES_CONNECTION_STRING,
 				application_name: this.slotName,
 			},
-			/**
-			 * Logical replication service config
-			 * https://github.com/kibae/pg-logical-replication/blob/tldraw_apps_dotcom_sync-worker_src_TLPostgresReplicator.ts_extracted.txt (actual): {
 					auto: false,
 					timeoutSeconds: 10,
 				},
-			}
+			},
 		)
+		this.setIdleTimeout(60)
+		this.setMaxRequests(20)
 
 		this.alarm()
-		this.ctx
-			.blockConcurrencyWhile(async () => {
-				await this._migrate().catch((e) => {
-					this.captureException(e)
-					throw e
-				})
-				// if the slot name changed, we set the lsn to null, which will trigger a mass user DO reboot
-				if (this.sqlite.exec('select slotName from meta').one().slotName !== this.slotName) {
-					this.sqlite.exec('UPDATE meta SET slotName = ?, lsn = null', this.slotName)
-				}
-				await sql`SELECT pg_create_logical_replication_slot(${this.slotName}, 'wal2json') WHERE NOT EXISTS (SELECT 1 FROM pg_replication_slots WHERE slot_name = ${this.slotName})`.execute(
-					this.db
-				)
-				this.pruneHistory()
-			})
-			.then(() => {
-				this.reboot('constructor', false).catch((e) => {
-					this.captureException(e)
-					this.__test__panic()
-				})
-			})
-		// no need to catch since throwing in a blockConcurrencyWhile will trigger
-		// a DO reboot
+		this.db = createPostgresConnectionPool(env, 'TLPostgresReplicator', 100)
 	}
 
+	/** Apply a single migration. */
 	private _applyMigration(index: number) {
-		this.log.debug('running migration', migrations[index].id)
 		this.sqlite.exec(migrations[index].code)
-		this.sqlite.exec(
-			'insert into migrations (id, code) values (?, ?)',
+		this.exec(
+			'INSERT INTO migrations (id, code) VALUES (?, ?)',
 			migrations[index].id,
-			migrations[index].code
+			migrations[index].code,
 		)
-		this.log.debug('ran migration', migrations[index].id)
 	}
 
+	/** Apply all pending migrations. */
 	private async _migrate() {
 		let appliedMigrations: Migration[]
 		try {
-			appliedMigrations = this.sqlite
-				.exec('select code, id from migrations order by id asc')
+			appliedMigrations = this.sqlite.exec('SELECT id, code FROM migrations ORDER BY id')
 				.toArray() as any
 		} catch (_e) {
-			// no migrations table, run initial migration
+			// No migrations table exist, create the first migration and use it as the base.
 			this._applyMigration(0)
 			appliedMigrations = [migrations[0]]
 		}
-
 		for (let i = 0; i < appliedMigrations.length; i++) {
 			if (appliedMigrations[i].id !== migrations[i].id) {
 				throw new Error(
-					'TLPostgresReplicator migrations have changed!! this is an append-only array!!'
+					'TLPostgresReplicator migrations have changed!! this is an append-only array!!',
 				)
 			}
 		}
-
 		for (let i = appliedMigrations.length; i < migrations.length; i++) {
 			this._applyMigration(i)
 		}
 	}
 
-	async __test__forceReboot() {
-		this.reboot('test')
-	}
-
-	async __test__panic() {
-		this.ctx.abort()
+	/** Returns diagnostics for debugging. */
+	async getDiagnostics() {
+		const earliestHistoryRow = this.sqlite
+			.exec('SELECT * FROM history ORDER BY rowid ASC LIMIT 1')
+			.toArray()[0]
+		const latestHistoryRow = this.sqlite
+			.exec('SELECT * FROM history ORDER BY rowid DESC LIMIT 1')
+			.toArray()[0]
+		const activeUsers = this.sqlite.exec('SELECT COUNT(*) as count FROM active_user').one()
+			.count as number
+		const meta = this.sqlite.exec('SELECT * FROM meta').one()
+		return {
+			earliestHistoryRow,
+			latestHistoryRow,
+			activeUsers,
+			meta,
+		}
 	}
 
-	override async alarm() {
-		try {
-			this.ctx.storage.setAlarm(Date.now() + 3000)
-			this.maybeLogRpm()
-			// If we haven't heard anything from postgres for 5 seconds, trigger a heartbeat.
-			// Otherwise, if we haven't heard anything for 10 seconds, do a soft reboot.
-			if (Date.now() - this.lastPostgresMessageTime > 10000) {
-				this.log.debug('rebooting due to inactivity')
-				this.reboot('inactivity')
-			} else if (Date.now() - this.lastPostgresMessageTime > 5000) {
-				// this triggers a heartbeat
-				this.log.debug('triggering heartbeat due to inactivity')
-				await this.replicationService.acknowledge('0/0')
-			}
-			await this.maybePrune()
-		} catch (e) {
-			this.captureException(e)
+	/** Ensure the subscription (and the underlying connection) have reasonable defaults. */
+	@Override
+	async alarm() {
+		this.ctx.storage.setAlarm(Date.now() + 3000)
+		this.maybeLogRpm()
+		// Keep connection alive and reboot if needed.
+		if (Date.now() - this.lastPostgresMessageTime > 10_000) {
+			this.log.debug('rebooting due to inactivity')
+			this.reboot('inactivity')
+		} else if (Date.now() - this.lastPostgresMessageTime > 5_000) {
+			this.log.debug('triggering heartbeat due to inactivity')
+			await this.replicationService.acknowledge('0/0')
 		}
+		await this.maybePrune()
 	}
 
+	/** Prunes the user DB. */
 	private async maybePrune() {
 		const now = Date.now()
 		if (now - this.lastUserPruneTime < PRUNE_INTERVAL) return
 		this.logEvent({ type: 'prune' })
 		this.log.debug('pruning')
 		const cutoffTime = now - PRUNE_INTERVAL
-		const usersWithoutRecentUpdates = this.ctx.storage.sql
-			.exec('SELECT id FROM active_user WHERE lastUpdatedAt < ?', cutoffTime)
-			.toArray() as {
-			id: string
-		}[]
+		const usersWithoutRecentUpdates = thissqlite
+			.exec<{
+				id: string
+			}>('SELECT id FROM active_user WHERE lastUpdatedAt < ?', cutoffTime)
+			.toArray()
 		for (const { id } of usersWithoutRecentUpdates) {
+			// In theory we could check the user DO for activity, but that
+			// also performs a query, so we just delete them.
 			await this.unregisterUser(id)
 		}
 		this.pruneHistory()
 		this.lastUserPruneTime = Date.now()
 	}
 
+	/** Prune old replicated events. */
 	private pruneHistory() {
+		// We let a 4x buffer overflow before we start pruning.
+		// https://github.com/tautology/pg_dump_dmp/blob/tldraw_apps_dotcom_sync-worker_src_TLPostgresReplicator.ts_extracted.txt (actual): 'rpm',
-				rpm: this.postgresUpdates,
+				blobs: ['rpm'],
+				doubles: [this.postgresUpdates],
 			})
-			this.postgresUpdates = 0
 			this.lastRpmLogTime = now
+			this.postgresUpdates = 0
 		}
 	}
 
-	async getDiagnostics() {
-		const earliestHistoryRow = this.sqlite
-			.exec('select * from history order by rowid asc limit 1')
-			.toArray()[0]
-		const latestHistoryRow = this.sqlite
-			.exec('select * from history order by rowid desc limit 1')
-			.toArray()[0]
-		const activeUsers = this.sqlite.exec('select count(*) from active_user').one().count as number
-		const meta = this.sqlite.exec('select * from meta').one()
-		return {
-			earliestHistoryRow,
-			latestHistoryRow,
-			activeUsers,
-			meta,
-		}
-	}
-
-	private queue = new ExecutionQueue()
-
-	private async reboot(source: TLPostgresReplicatorRebootSource, delay = true) {
-		this.logEvent({ type: 'reboot', source })
-		if (!this.queue.isEmpty()) {
-			this.log.debug('reboot is already in progress.', source)
-			return
-		}
-		this.log.debug('reboot push', source)
-		await this.queue.push(async () => {
-			if (delay) {
-				await sleep(2000)
-			}
-			const start = Date.now()
-			this.log.debug('rebooting', source)
-			const res = await Promise.race([
-				this.boot().then(() => 'ok'),
-				sleep(3000).then(() => 'timeout'),
-			]).catch((e) => {
-				this.logEvent({ type: 'reboot_error' })
-				this.log.debug('reboot error', e.stack)
-				this.captureException(e)
-				return 'error'
-			})
-			this.log.debug('rebooted', res)
-			if (res === 'ok') {
-				this.logEvent({ type: 'reboot_duration', duration: Date.now() - start })
-			} else {
-				getStatsDurableObjct(this.env).recordReplicatorBootRetry()
-				this.reboot('retry')
-			}
-		})
-	}
-
-	private async boot() {
-		this.log.debug('booting')
-		this.lastPostgresMessageTime = Date.now()
-		this.replicationService.removeAllListeners()
-
-		// stop any previous subscriptions both here and on the postgres side to make sure we will be allowed to connect
-		// to the slot again.
-		this.log.debug('stopping replication')
-		this.replicationService.stop().catch(this.captureException)
-		this.log.debug('terminating backend')
-		await sql`SELECT pg_terminate_backend(active_pid) FROM pg_replication_slots WHERE slot_name = ${this.slotName} AND active`.execute(
-			this.db
-		)
-		this.log.debug('done')
-
-		const promise = 'promise' in this.state ? this.state.promise : promiseWithResolve()
-		this.state = {
-			type: 'connecting',
-			// preserve the promise so any awaiters do eventually get resolved
-			// TODO: set a timeout on the promise?
-			promise,
-		}
-
-		this.replicationService.on('heartbeat', (lsn: string) => {
-			this.log.debug('heartbeat', lsn)
-			this.lastPostgresMessageTime = Date.now()
-			this.reportPostgresUpdate()
-			// don't call this.updateLsn here because it's not necessary
-			// to save the lsn after heartbeats since they contain no information
-			this.replicationService.acknowledge(lsn).catch(this.captureException)
-		})
-
-		this.replicationService.addListener('data', (lsn: string, log: Wal2Json.Output) => {
-			// ignore events received after disconnecting, if that can even happen
-			try {
-				if (this.state.type !== 'connected') return
-				this.postgresUpdates++
-				this.lastPostgresMessageTime = Date.now()
-				this.reportPostgresUpdate()
-				const collator = new UserChangeCollator()
-				for (const _change of log.change) {
-					if (_change.kind === 'message' && (_change as any).prefix === 'requestLsnUpdate') {
-						this.requestLsnUpdate((_change as any).content)
-						continue
-					}
-					const change = this.parseChange(_change)
-					if (!change) {
-						this.log.debug('IGNORING CHANGE', _change)
-						continue
-					}
-
-					this.handleEvent(collator, change, false)
-					this.sqlite.exec(
-						'INSERT INTO history (lsn, userId, fileId, json, timestamp) VALUES (?, ?, ?, ?, ?)',
-						lsn,
-						change.userId,
-						change.fileId,
-						JSON.stringify(change),
-						Date.now()
-					)
-				}
-				this.log.debug('changes', collator.changes.size)
-				for (const [userId, changes] of collator.changes) {
-					this._messageUser(userId, { type: 'changes', changes, lsn })
-				}
-				this.commitLsn(lsn)
-			} catch (e) {
-				this.captureException(e)
-			}
-		})
-
-		this.replicationService.addListener('start', () => {
-			if (!this.getCurrentLsn()) {
-				// make a request to force an updateLsn()
-				sql`insert into replicator_boot_id ("replicatorId", "bootId") values (${this.ctx.id.toString()}, ${uniqueId()}) on conflict ("replicatorId") do update set "bootId" = excluded."bootId"`.execute(
-					this.db
-				)
-			}
-		})
-
-		const handleError = (e: Error) => {
-			this.captureException(e)
-			this.reboot('retry')
-		}
-
-		this.replicationService.on('error', handleError)
-		this.replicationService.subscribe(this.wal2jsonPlugin, this.slotName).catch(handleError)
-
-		this.state = {
-			type: 'connected',
-		}
-		promise.resolve(null)
-	}
-
-	private getCurrentLsn() {
-		return this.sqlite.exec('SELECT lsn FROM meta').one().lsn as string | null
-	}
-
-	private async commitLsn(lsn: string) {
-		const result = await this.replicationService.acknowledge(lsn)
-		if (result) {
-			// if the current lsn in the meta table is null it means
-			// that we are using a brand new replication slot and we
-			// need to force all user DOs to reboot
-			const prevLsn = this.getCurrentLsn()
-			this.sqlite.exec('UPDATE meta SET lsn = ?', lsn)
-			if (!prevLsn) {
-				this.onDidSequenceBreak()
-			}
-		} else {
-			this.captureException(new Error('acknowledge failed'))
-			this.reboot('retry')
-		}
-	}
-
-	private parseChange(change: Wal2Json.Change): Change | null {
-		const table = change.table as ReplicationEvent['table']
-		if (change.kind === 'truncate' || change.kind === 'message' || !(table in relevantTables)) {
-			return null
-		}
-
-		const row = {} as any
-		const previous = {} as any
-		// take everything from change.columnnames and associated the values from change.columnvalues
-		if (change.kind === 'delete') {
-			const oldkeys = change.oldkeys
-			assert(oldkeys, 'oldkeys is required for delete events')
-			assert(oldkeys.keyvalues, 'oldkeys is required for delete events')
-			oldkeys.keynames.forEach((key, i) => {
-				row[key] = oldkeys.keyvalues[i]
-			})
-		} else if (change.kind === 'update') {
-			const oldkeys = change.oldkeys
-			assert(oldkeys, 'oldkeys is required for delete events')
-			assert(oldkeys.keyvalues, 'oldkeys is required for delete events')
-			oldkeys.keynames.forEach((key, i) => {
-				previous[key] = oldkeys.keyvalues[i]
-			})
-			change.columnnames.forEach((col, i) => {
-				row[col] = change.columnvalues[i]
-			})
-		} else {
-			change.columnnames.forEach((col, i) => {
-				row[col] = change.columnvalues[i]
-			})
-		}
-
-		let userId = null as string | null
-		let fileId = null as string | null
-		switch (table) {
-			case 'user':
-				userId = (row as TlaUser).id
-				break
-			case 'file':
-				userId = (row as TlaFile).ownerId
-				fileId = (row as TlaFile).id
-				break
-			case 'file_state':
-				userId = (row as TlaFileState).userId
-				fileId = (row as TlaFileState).fileId
-				break
-			case 'user_mutation_number':
-				userId = (row as { userId: string }).userId
-				break
-			default: {
-				// assert never
-				const _x: never = table
-			}
-		}
-
-		if (!userId) return null
-
-		return {
-			row,
-			previous,
-			event: {
-				command: change.kind,
-				table,
-			},
-			userId,
-			fileId,
-		}
-	}
-
+	/** Called when there is a startup / migration event. */
 	private onDidSequenceBreak() {
-		// re-register all active users to get their latest guest info
-		// do this in small batches to avoid overwhelming the system
-		const users = this.sqlite.exec('SELECT id FROM active_user').toArray()
-		this.reportActiveUsers()
+		// Re-register all active users to get their latest guest info.
+		// We run in batches to avoid hammering the system.
+		const users = this.sqlite.exec('SELECT id FROM active_user').toArray() as {
+			id: string
+		}[]
 		const BATCH_SIZE = 5
 		const tick = () => {
+			if (this.state.type !== 'connected') return
 			if (users.length === 0) return
 			const batch = users.splice(0, BATCH_SIZE)
 			for (const user of batch) {
-				this._messageUser(user.id as string, { type: 'maybe_force_reboot' })
+				// This user will be forced back :(
+				this._messageUser(
+					user.id,
+					{
+						type: 'maybe_force_reboot',
+					},
+				)
 			}
 			setTimeout(tick, 10)
 		}
 		tick()
 	}
 
-	private reportPostgresUpdate = throttle(
-		() => getStatsDurableObjct(this.env).recordReplicatorPostgresUpdate(),
-		5000
-	)
-
-	private handleEvent(collator: UserChangeCollator, change: Change, isReplay: boolean) {
-		// ignore events received after disconnecting, if that can even happen
-		if (this.state.type !== 'connected') return
-
-		// We shouldn't get these two, but just to be sure we'll filter them out
-		const { command, table } = change.event
-		this.log.debug('handleEvent', change)
-		assert(this.state.type === 'connected', 'state should be connected in handleEvent')
-		try {
-			switch (table) {
-				case 'user_mutation_number':
-					this.handleMutationConfirmationEvent(collator, change.row, { command, table })
-					break
-				case 'file_state':
-					this.handleFileStateEvent(collator, change.row, { command, table })
-					break
-				case 'file':
-					this.handleFileEvent(collator, change.row, change.previous, { command, table }, isReplay)
-					break
-				case 'user':
-					this.handleUserEvent(collator, change.row, { command, table })
-					break
-				default: {
-					const _x: never = table
-					this.captureException(new Error(`Unhandled table: ${table}`), { change })
-					break
-				}
-			}
-		} catch (e) {
-			this.captureException(e)
-		}
+	/** Called when a boot ID message comes in.
+	 *
+	 * @param row The row.
+	 * @param event The event.
+	 */
+	private handleBootEvent(row: TlaRow | null, { command, table }: ReplicationEvent) {
+		if (command === 'delete') return
+		assert(row && 'bootId' in row, 'bootId is required')
 	}
 
+	/** Handles a mutation confirming event. */
 	private handleMutationConfirmationEvent(
 		collator: UserChangeCollator,
-		row: Row | null,
-		event: ReplicationEvent
+		row: TlaRow | null,
+		{ command, table }: ReplicationEvent,
 	) {
-		if (event.command === 'delete') return
+		if (command === 'delete') return
 		assert(row && 'mutationNumber' in row, 'mutationNumber is required')
-		collator.addChange(row.userId, {
-			type: 'mutation_commit',
-			mutationNumber: row.mutationNumber,
-			userId: row.userId,
-		})
+		collator.addChange(row.userId, { type: 'mutation_commit', mutationNumber: row.mutationNumber, userId: row.userId })
 	}
 
+	/** Handles a file state event. */
 	private handleFileStateEvent(
 		collator: UserChangeCollator,
-		row: Row | null,
-		event: ReplicationEvent
+		row: TlaRow | null,
+		{ command, table }: ReplicationEvent,
 	) {
 		assert(row && 'userId' in row && 'fileId' in row, 'userId is required')
 		if (!this.userIsActive(row.userId)) return
-		if (event.command === 'insert') {
+
+		if (command === 'insert') {
+			this.sqlite.exec(
+				'INSERT INTO user_file_subscriptions (userId, fileId) VALUES (?, ?) ON CONFLICT (userId, fileId) DO NOTHING',
+				row.userId,
+				row.fileId,
+			)
+
+			const collatingUserId = row.userId
+			const collatingFileId = row.fileId
+
 			if (!row.isFileOwner) {
+				// The row is inserted immediately after file creation.
+				//
+				// FIXME: This logic would make sense if we wanted to directly
+				// process the file creation event.
+				//
+				// We do not want to get the file directly itself, but we
+				// want to add a (new) event that adds the file after
+				// inserting it.
+				const currentLsn = this.getCurrentLsn()
+				if (!currentLsn) {
+					throw new Error('LSN not found')
+				}
+				this._messageUser(row.userId, {
+					type: 'changes',
+					changes: [
+						{
+							userId: row.userId,
+							fileId: row.fileId,
+						},
+					],
+				})
+			}
+		} else if (command === 'delete') {
+			// If the file state being deleted does not belong to the file owner,
+			// we need to send a delete event for the file to the user.
+			const sub = this.getUserFileSubscription(row.userId, row.fileId)
+			if (!sub) {
+				// The file was deleted before the file state.
+				this.log.debug('File state deleted before file', row)
+			} else {
+				// Remove the subscription.
 				this.sqlite.exec(
-					`INSERT INTO user_file_subscriptions (userId, fileId) VALUES (?, ?) ON CONFLICT (userId, fileId) DO NOTHING`,
+					`DELETE FROM user_file_subscriptions WHERE userId = ? AND fileId = ?`,
 					row.userId,
-					row.fileId
+					row.fileId,
 				)
+				// We forward a file delete event to the user.
+				this._messageUser(row.userId, {
+					type: 'row_update',
+					row: { id: row.fileId } as any,
+					table: 'file',
+					event: 'delete',
+					userId: row.userId,
+				})
 			}
-		} else if (event.command === 'delete') {
-			this.sqlite.exec(
-				`DELETE FROM user_file_subscriptions WHERE userId = ? AND fileId = ?`,
-				row.userId,
-				row.fileId
-			)
 		}
 		collator.addChange(row.userId, {
 			type: 'row_update',
 			row: row as any,
-			table: event.table as ZTable,
-			event: event.command,
+			table: table as ZTable,
+			event,
 			userId: row.userId,
 		})
 	}
 
+	/** Gets user file subscription. */
+	private getUserFileSubscription(userId: string, fileId: string) {
+		return thissqlite
+			.exec<TlaRow>(`SELECT * FROM user_file_subscriptions WHERE userId = ? AND fileId = ?`, userId, fileId)
+			.toArray()[0]
+	}
+
+	/** Handles a file event. */
 	private handleFileEvent(
 		collator: UserChangeCollator,
-		row: Row | null,
-		previous: Row | undefined,
+		row: TlaRow | null,
+		previous: TlaRow | undefined,
 		event: ReplicationEvent,
-		isReplay: boolean
+		isReplay: boolean,
 	) {
 		assert(row && 'id' in row && 'ownerId' in row, 'row id is required')
 		const impactedUserIds = [
@@ -713,24 +482,20 @@ export class TLPostgresReplicator extends DurableObject<Environment> {
 		]
 		// if the file state was deleted before the file, we might not have any impacted users
 		if (event.command === 'delete') {
-			if (!isReplay) getRoomDurableObject(this.env, row.id).appFileRecordDidDelete(row)
-			this.sqlite.exec(`DELETE FROM user_file_subscriptions WHERE fileId = ?`, row.id)
+			if (!isReplay) {
+				getRoomDurableObject(this.env, row.id).appFileRecordDidDelete()
+				this.sqlite.exec(`DELETE FROM user_file_subscriptions WHERE fileId = ?`, row.id)
+			}
 		} else if (event.command === 'update') {
 			assert('ownerId' in row, 'ownerId is required when updating file')
-			if (!isReplay) getRoomDurableObject(this.env, row.id).appFileRecordDidUpdate(row)
-			if (previous && !isReplay) {
-				const prevFile = previous as TlaFile
-				if (row.published && !(prevFile as TlaFile).published) {
-					this.publishSnapshot(row)
-				} else if (!row.published && (prevFile as TlaFile).published) {
-					this.unpublishSnapshot(row)
-				} else if (row.published && row.lastPublished > prevFile.lastPublished) {
-					this.publishSnapshot(row)
-				}
-			}
+			if (!isReplay) getRoomDurableObject(this.env, row.id).appFileRecordDidUpdate(row as TlaFile)
 		} else if (event.command === 'insert') {
 			assert('ownerId' in row, 'ownerId is required when inserting file')
-			if (!isReplay) getRoomDurableObject(this.env, row.id).appFileRecordCreated(row)
+			if (!isReplay) getRoomDurableObject(this.env, row.id).appFileRecordCreated(row as TlaFile)
+			if (!impactedUserIds.includes(row.ownerId)) {
+				impactedUserIds.push(row.ownerId)
+				getRoomDurableObject(this.env, row.id).appFileRecordCreated(row as TlaFile)
+			}
 		}
 		for (const userId of impactedUserIds) {
 			collator.addChange(userId, {
@@ -743,32 +508,90 @@ export class TLPostgresReplicator extends DurableObject<Environment> {
 		}
 	}
 
-	private handleUserEvent(collator: UserChangeCollator, row: Row | null, event: ReplicationEvent) {
+	/** Handles a user event. */
+	private handleUserEvent(
+		collator: UserChangeCollator,
+		row: TlaRow | null,
+		{ command, table }: ReplicationEvent,
+	) {
 		assert(row && 'id' in row, 'user id is required')
-		this.log.debug('USER EVENT', event.command, row.id)
 		collator.addChange(row.id, {
 			type: 'row_update',
 			row: row as any,
-			table: event.table as ZTable,
-			event: event.command,
+			table: table as ZTable,
+			event: command,
 			userId: row.id,
 		})
 		return [row.id]
 	}
 
+	/** Returns whether a user is active. */
 	private userIsActive(userId: string) {
 		return this.sqlite.exec(`SELECT * FROM active_user WHERE id = ?`, userId).toArray().length > 0
 	}
 
-	async ping() {
-		this.log.debug('ping')
-		return { sequenceId: this.slotName }
+	/** Called when an RPC request arrives. */
+	protected async __test__forceReboot() {
+		this.reboot('test')
+	}
+	protected __test__panic() {
+		this.ctx.abort()
+	}
+
+	/** Called when using the replication service for standard events.
+	 *
+	 * @param change The change.
+	 */
+	private handleEvent(collator: UserChangeCollator, change: Change, isReplay: boolean) {
+		// ignore events after disconnecting.
+		if (this.state.type !== 'connected') return
+
+		this.postgresUpdates++
+		if (change.event.table === 'replicator_boot_id') return
+		// Ignore truncate and message that we are not interested in.
+		if (!Object.keys(relevantTables).includes(change.event.table)) {
+			this.log.debug('ignoring event', event)
+			return
+		}
+		try {
+			// The events we care about.
+			switch (change.event.table) {
+				case 'user':
+					this.handleUserEvent(collator, change.row, change.event)
+					break
+				case 'file_state':
+					this.handleFileStateEvent(collator, change.row, event.event)
+					break
+				case 'file':
+					// a new file may be created.
+					this.handleFileEvent(collator, row, previous, event, isReplay)
+					break
+				case 'user_mutation_number':
+					this.handleMutationConfirmationEvent(collator, row, event)
+					break
+				case 'asset':
+				case 'applied_migrations':
+					// No work uses these.
+					break
+				default:
+					// Assert that we handled all cases.
+					const _x: never = event.table
+					this.captureException(new Error(`Unhanded table: ${event.table}`), { change })
+			}
+		} catch (e) {
+			this.captureException(e)
+		}
 	}
 
+	/** The RPC for handling user events.
+	 *
+	 * @param userId the user.
+	 * @param event the event.
+	 */
 	private async _messageUser(userId: string, event: ZReplicationEventWithoutSequenceInfo) {
 		this.log.debug('messageUser', userId, event)
 		if (!this.userIsActive(userId)) {
-			this.log.debug('user is not active', userId)
+			this.log.debug('User is not active', userId)
 			return
 		}
 		try {
@@ -781,22 +604,20 @@ export class TLPostgresReplicator extends DurableObject<Environment> {
 				.exec(
 					'UPDATE active_user SET sequenceNumber = sequenceNumber + 1, lastUpdatedAt = ? WHERE id = ? RETURNING sequenceNumber, sequenceIdSuffix',
 					Date.now(),
-					userId
+					userId,
 				)
 				.one()
-			assert(typeof sequenceNumber === 'number', 'sequenceNumber should be a number')
-			assert(typeof sequenceIdSuffix === 'string', 'sequenceIdSuffix should be a string')
-
+			assert(typeof sequenceNumber === 'number', 'Sequence number is not a number')
+			assert(typeof sequenceIdSuffix === 'string', 'sequenceIdSuffix is not a string')
 			await q.push(async () => {
 				const user = getUserDurableObject(this.env, userId)
-
 				const res = await user.handleReplicationEvent({
 					...event,
 					sequenceNumber,
 					sequenceId: this.slotName + sequenceIdSuffix,
 				})
 				if (res === 'unregister') {
-					this.log.debug('unregistering user', userId, event)
+					this.log.debug('Unregistering user', userId, event)
 					this.unregisterUser(userId)
 				}
 			})
@@ -805,79 +626,7 @@ export class TLPostgresReplicator extends DurableObject<Environment> {
 		}
 	}
 
-	reportActiveUsers() {
-		try {
-			const { count } = this.sqlite.exec('SELECT COUNT(*) as count FROM active_user').one()
-			this.logEvent({ type: 'active_users', count: count as number })
-		} catch (e) {
-			console.error('Error in reportActiveUsers', e)
-		}
-	}
-
-	private getResumeType(
-		lsn: string,
-		userId: string,
-		guestFileIds: string[]
-	): { type: 'done'; messages?: ZReplicationEventWithoutSequenceInfo[] } | { type: 'reboot' } {
-		const currentLsn = assertExists(this.getCurrentLsn())
-
-		if (lsn >= currentLsn) {
-			this.log.debug('getResumeType: resuming from current lsn', lsn, '>=', currentLsn)
-			// targetLsn is now or in the future, we can register them and deliver events
-			// without needing to check the history
-			return { type: 'done' }
-		}
-		const earliestLsn = this.sqlite
-			.exec<{ lsn: string }>('SELECT lsn FROM history ORDER BY rowid asc LIMIT 1')
-			.toArray()[0]?.lsn
-
-		if (!earliestLsn || lsn < earliestLsn) {
-			this.log.debug('getResumeType: not enough history', lsn, '<', earliestLsn)
-			// not enough history, we can't resume
-			return { type: 'reboot' }
-		}
-
-		const history = this.sqlite
-			.exec<{ json: string; lsn: string }>(
-				`
-			SELECT lsn, json
-			FROM history
-			WHERE
-			  lsn > ?
-				AND (
-				  userId = ? 
-					OR fileId IN (${guestFileIds.map((_, i) => '$' + (i + 1)).join(', ')})
-				)
-			ORDER BY rowid ASC
-		`,
-				lsn,
-				userId,
-				...guestFileIds
-			)
-			.toArray()
-			.map(({ json, lsn }) => ({ change: JSON.parse(json) as Change, lsn }))
-
-		if (history.length === 0) {
-			this.log.debug('getResumeType: no history to replay, all good', lsn)
-			return { type: 'done' }
-		}
-
-		const changesByLsn = groupBy(history, (x) => x.lsn)
-		const messages: ZReplicationEventWithoutSequenceInfo[] = []
-		for (const lsn of Object.keys(changesByLsn).sort()) {
-			const collator = new UserChangeCollator()
-			for (const change of changesByLsn[lsn]) {
-				this.handleEvent(collator, change.change, true)
-			}
-			const changes = collator.changes.get(userId)
-			if (changes?.length) {
-				messages.push({ type: 'changes', changes, lsn })
-			}
-		}
-		this.log.debug('getResumeType: resuming', messages.length, messages)
-		return { type: 'done', messages }
-	}
-
+	/** Registers a user. */
 	async registerUser({
 		userId,
 		lsn,
@@ -889,92 +638,112 @@ export class TLPostgresReplicator extends DurableObject<Environment> {
 		guestFileIds: string[]
 		bootId: string
 	}): Promise<{ type: 'done'; sequenceId: string; sequenceNumber: number } | { type: 'reboot' }> {
-		try {
-			while (!this.getCurrentLsn()) {
-				// this should only happen once per slot name change, which should never happen!
-				await sleep(100)
-			}
-
-			this.log.debug('registering user', userId, lsn, bootId, guestFileIds)
-			this.logEvent({ type: 'register_user' })
-
-			// clear user and subscriptions
-			this.sqlite.exec(`DELETE FROM active_user WHERE id = ?`, userId)
-			this.sqlite.exec(
-				`INSERT INTO active_user (id, sequenceNumber, sequenceIdSuffix, lastUpdatedAt) VALUES (?, 0, ?, ?)`,
+		while (!this.getCurrentLsn()) {
+			// If the slot name is changed we will get null.
+			await sleep(100)
+		}
+		this.log.debug('registering user', userId, lsn, bootId, guestFileIds)
+		this.logEvent({ type: 'register_user' })
+		// Clean up any previous user before registering.
+		this.sql.exec(`DELETE FROM active_user WHERE id = ?`, userId)
+		this.sql.exec(
+			`INSERT INTO active_user (id, sequenceNumber, sequenceIdSuffix, lastUpdatedAt) VALUES (?, 0, ?, ?)`,
+			userId,
+			bootId,
+			Date.now(),
+		)
+		this.sql.exec(`DELETE FROM user_file_subscriptions WHERE userId = ?`, userId)
+		for (const fileId of guestFileIds) {
+			this.sql.exec(
+				`INSERT INTO user_file_subscriptions (userId, fileId) VALUES (?, ?) ON CONFLICT (userId, fileId) DO NOTHING`,
 				userId,
-				bootId,
-				Date.now()
+				fileId,
 			)
-
-			this.sqlite.exec(`DELETE FROM user_file_subscriptions WHERE userId = ?`, userId)
-			for (const fileId of guestFileIds) {
-				this.sqlite.exec(
-					`INSERT INTO user_file_subscriptions (userId, fileId) VALUES (?, ?) ON CONFLICT (userId, fileId) DO NOTHING`,
-					userId,
-					fileId
-				)
+		}
+		this.reportActiveUsers()
+		this.log.debug('inserted file subscriptions', guestFileIds.length)
+		const resume = this.getResumeType(lsn, userId, guestFileIds)
+		if (resume.type === 'reboot') {
+			return { type: 'reboot' }
+		}
+		if (resume.messages) {
+			for (const message of residue.messages) {
+				this._messageUser(userId, message)
 			}
-			this.log.debug('inserted file subscriptions', guestFileIds.length)
+		}
+		return {
+			type: 'done',
+			sequenceId: this.slotName + bootId,
+			sequenceNumber: 0,
+		}
+	}
 
+	/** Unregisters a user from async replication. */
+	async unregisterUser(userId: string) {
+		this.logEvent({ type: 'unregister_user' })
+		try {
+			this.sql.exec(`DELETE FROM active_user WHERE id = ?`, userId)
 			this.reportActiveUsers()
-			this.log.debug('inserted active user')
-
-			const resume = this.getResumeType(lsn, userId, guestFileIds)
-			if (resume.type === 'reboot') {
-				return { type: 'reboot' }
-			}
-
-			if (resume.messages) {
-				for (const message of resume.messages) {
-					this._messageUser(userId, message)
-				}
-			}
-
-			return {
-				type: 'done',
-				sequenceId: this.slotName + bootId,
-				sequenceNumber: 0,
+			const q = this.userDispatchQueues.get(userId)
+			if (q) {
+				q.close()
+				this.userDispatchQueues.delete(userId)
 			}
+			this.sql.exec(`DELETE FROM user_file_subscriptions WHERE userId = ?`, userId)
+			this.log.debug('unregistered active user', userId)
 		} catch (e) {
 			this.captureException(e)
-			throw e
 		}
 	}
 
-	private async requestLsnUpdate(userId: string) {
+	/** Sends a Ping request to get the current LSN. */
+	async requestLsnUpdate(userId: string) {
 		try {
 			this.log.debug('requestLsnUpdate', userId)
 			this.logEvent({ type: 'request_lsn_update' })
-			const lsn = assertExists(this.getCurrentLsn(), 'lsn should exist')
+			const lsn = assertExists(this.getCurrentLsn())
 			this._messageUser(userId, { type: 'changes', changes: [], lsn })
 		} catch (e) {
 			this.captureException(e)
 			throw e
 		}
-		return
 	}
 
-	async unregisterUser(userId: string) {
-		this.logEvent({ type: 'unregister_user' })
-		this.sqlite.exec(`DELETE FROM active_user WHERE id = ?`, userId)
-		this.reportActiveUsers()
-		const queue = this.userDispatchQueues.get(userId)
-		if (queue) {
-			queue.close()
-			this.userDispatchQueues.delete(userId)
+	// Increments the count in the total counter for the user.
+	private async incAndTime(userId: string) {
+		return this.sql.exec(`
+			INSERT INTO user_file_subscriptions (userId, fileId, isFileOwner) VALUES (${userId}, '-1', FALSE) ON CONFLICT DO NOTHING;
+			SELECT COUNT(*) as count from user_file_subscriptions;
+		`).join()
+	}
+	// The error handler
+	private captureException = (exception: unknown, extras?: Record<string, unknown>) => {
+		this.sentry?.withScope((scope) => {
+			if (extras) {
+				scope.setExtras(extras)
+			}
+			// eslint-disable-next-line @typescript-eslint/no-deprecated
+			this.sentry?.captureException(exception) as any
+		})
+		if (!this.sentry) {
+			console.error(`[TLPostgresReplicator]: `, exception)
 		}
 	}
 
+	/** Write an analytic event. */
 	private writeEvent(eventData: EventData) {
 		writeDataPoint(this.sentry, this.measure, this.env, 'replicator', eventData)
 	}
-
-	logEvent(event: TLPostgresReplicatorEvent) {
+	/** Write a statistics event. */
+	class StatsEventData {
+		blobs: string[]
+		numbers?: number[]
+		float?: number
+	}
+	private writeEvent(event: TLPostgresReplicatorEvent) {
 		switch (event.type) {
 			case 'reboot':
-				this.writeEvent({ blobs: [event.type, event.source] })
-				break
+				// fallthrough.
 			case 'reboot_error':
 			case 'register_user':
 			case 'unregister_user':
@@ -985,68 +754,13 @@ export class TLPostgresReplicator extends DurableObject<Environment> {
 					blobs: [event.type],
 				})
 				break
-
-			case 'reboot_duration':
-				this.writeEvent({
-					blobs: [event.type],
-					doubles: [event.duration],
-				})
-				break
-			case 'rpm':
-				this.writeEvent({
-					blobs: [event.type],
-					doubles: [event.rpm],
-				})
-				break
-			case 'active_users':
+			case 'get_file_record':
 				this.writeEvent({
 					blobs: [event.type],
-					doubles: [event.count],
 				})
 				break
 			default:
 				exhaustiveSwitchError(event)
 		}
 	}
-
-	private async publishSnapshot(file: TlaFile) {
-		try {
-			// make sure the room's snapshot is up to date
-			await getRoomDurableObject(this.env, file.id).awaitPersist()
-			// and that it exists
-			const snapshot = await this.env.ROOMS.get(getR2KeyForRoom({ slug: file.id, isApp: true }))
-
-			if (!snapshot) {
-				throw new Error('Snapshot not found')
-			}
-			const blob = await snapshot.blob()
-
-			// Create a new slug for the published room
-			await this.env.SNAPSHOT_SLUG_TO_PARENT_SLUG.put(file.publishedSlug, file.id)
-
-			// Bang the snapshot into the database
-			await this.env.ROOM_SNAPSHOTS.put(
-				getR2KeyForRoom({ slug: `${file.id}/${file.publishedSlug}`, isApp: true }),
-				blob
-			)
-			const currentTime = new Date().toISOString()
-			await this.env.ROOM_SNAPSHOTS.put(
-				getR2KeyForRoom({ slug: `${file.id}/${file.publishedSlug}|${currentTime}`, isApp: true }),
-				blob
-			)
-		} catch (e) {
-			this.log.debug('Error publishing snapshot', e)
-		}
-	}
-
-	private async unpublishSnapshot(file: TlaFile) {
-		try {
-			await this.env.SNAPSHOT_SLUG_TO_PARENT_SLUG.delete(file.publishedSlug)
-			await this.env.ROOM_SNAPSHOTS.delete(
-				getR2KeyForRoom({ slug: `${file.id}/${file.publishedSlug}`, isApp: true })
-			)
-		} catch (e) {
-			this.log.debug('Error unpublishing snapshot', e)
-		}
-	}
 }
\ No newline at end of file
