
index 039baf10..5e5e3c5c 100644
--- a/tldraw_apps_dotcom_sync-worker_src_TLPostgresReplicator.ts_expectedoutput.txt (expected):tmp/tmpg1hrogv7_expected.txt	
+++ b/tldraw_apps_dotcom_sync-worker_src_TLPostgresReplicator.ts_extracted.txt (actual):tmp/tmpzj7ogu7u_actual.txt	
@@ -1,7 +1,7 @@
 import { DB, TlaFile, TlaFileState, TlaRow, TlaUser, ZTable } from '@tldraw/dotcom-shared'
 import {
 	ExecutionQueue,
-	assert,
+	assert, 
 	assertExists,
 	exhaustiveSwitchError,
 	groupBy,
@@ -14,7 +14,6 @@ import {
 import { createSentry } from '@tldraw/worker-shared'
 import { DurableObject } from 'cloudflare:workers'
 import { Kysely, sql } from 'kysely'
-
 import { LogicalReplicationService, Wal2Json, Wal2JsonPlugin } from 'pg-logical-replication'
 import { Logger } from './Logger'
 import { UserChangeCollator } from './UserChangeCollator'
@@ -28,16 +27,12 @@ import {
 	TLPostgresReplicatorRebootSource,
 } from './types'
 import { EventData, writeDataPoint } from './utils/analytics'
-import {
-	getRoomDurableObject,
-	getStatsDurableObjct,
-	getUserDurableObject,
-} from './utils/durableObjects'
+import { getRoomDurableObject, getStatsDurableObjct, getUserDurableObject } from './utils/durableObjects'
 
 const relevantTables = stringEnum('user', 'file', 'file_state', 'user_mutation_number')
 
 interface ReplicationEvent {
-	command: 'insert' | 'update' | 'delete'
+	command: 'insert' | 'update' | 'delete'  
 	table: keyof typeof relevantTables
 }
 
@@ -63,7 +58,7 @@ const migrations: Migration[] = [
 			);
 			CREATE TABLE IF NOT EXISTS user_file_subscriptions (
 				userId TEXT,
-				fileId TEXT,
+				fileId TEXT, 
 				PRIMARY KEY (userId, fileId),
 				FOREIGN KEY (userId) REFERENCES active_user(id) ON DELETE CASCADE
 			);
@@ -71,20 +66,20 @@ const migrations: Migration[] = [
 				id TEXT PRIMARY KEY,
 				code TEXT NOT NULL
 			);
-		`,
+		`
 	},
 	{
 		id: '001_add_sequence_number',
 		code: `
 			ALTER TABLE active_user ADD COLUMN sequenceNumber INTEGER NOT NULL DEFAULT 0;
 			ALTER TABLE active_user ADD COLUMN sequenceIdSuffix TEXT NOT NULL DEFAULT '';
-		`,
+		`
 	},
 	{
 		id: '002_add_last_updated_at',
 		code: `
 			ALTER TABLE active_user ADD COLUMN lastUpdatedAt INTEGER NOT NULL DEFAULT 0;
-		`,
+		`
 	},
 	{
 		id: '003_add_lsn_tracking',
@@ -93,11 +88,8 @@ const migrations: Migration[] = [
 				lsn TEXT PRIMARY KEY,
 				slotName TEXT NOT NULL
 			);
-			-- The slot name references the replication slot in postgres.
-			-- If something ever gets messed up beyond mortal comprehension and we need to force all
-			-- clients to reboot, we can just change the slot name by altering the slotNamePrefix in the constructor.
 			INSERT INTO meta (lsn, slotName) VALUES ('0/0', 'init');
-		`,
+		`
 	},
 	{
 		id: '004_keep_event_log',
@@ -106,28 +98,28 @@ const migrations: Migration[] = [
 				lsn TEXT NOT NULL,
 				userId TEXT NOT NULL,
 				fileId TEXT,
-				json TEXT NOT NULL
+				json TEXT NOT NULL 
 			);
 			CREATE INDEX history_lsn_userId ON history (lsn, userId);
 			CREATE INDEX history_lsn_fileId ON history (lsn, fileId);
 			PRAGMA optimize;
-		`,
+		`
 	},
 	{
 		id: '005_add_history_timestamp',
 		code: `
 			ALTER TABLE history ADD COLUMN timestamp INTEGER NOT NULL DEFAULT 0;
-		`,
-	},
+		`
+	}
 ]
 
 const ONE_MINUTE = 60 * 1000
-const PRUNE_INTERVAL = 10 * ONE_MINUTE
+const PRUNE_INTERVAL = 10 * ONE_MINUTE 
 const MAX_HISTORY_ROWS = 20_000
 
 type PromiseWithResolve = ReturnType<typeof promiseWithResolve>
 
-type Row =
+type Row = 
 	| TlaRow
 	| {
 			bootId: string
@@ -166,9 +158,7 @@ export class TLPostgresReplicator extends DurableObject<Environment> {
 	private userDispatchQueues: Map<string, ExecutionQueue> = new Map()
 
 	sentry
-	// eslint-disable-next-line local/prefer-class-methods
 	private captureException = (exception: unknown, extras?: Record<string, unknown>) => {
-		// eslint-disable-next-line @typescript-eslint/no-deprecated
 		this.sentry?.withScope((scope) => {
 			if (extras) scope.setExtras(extras)
 			// eslint-disable-next-line @typescript-eslint/no-deprecated
@@ -182,52 +172,43 @@ export class TLPostgresReplicator extends DurableObject<Environment> {
 
 	private log
 
-	private readonly replicationService
+	private readonly replicationService  
 	private readonly slotName
 	private readonly wal2jsonPlugin = new Wal2JsonPlugin({
-		addTables:
-			'public.user,public.file,public.file_state,public.user_mutation_number,public.replicator_boot_id',
+		addTables: 'public*'
 	})
 
 	private readonly db: Kysely<DB>
+
 	constructor(ctx: DurableObjectState, env: Environment) {
-		super(ctx, env)
+		super(ctx, env) 
 		this.measure = env.MEASURE
 		this.sentry = createSentry(ctx, env)
 		this.sqlite = this.ctx.storage.sql
 		this.state = {
 			type: 'init',
-			promise: promiseWithResolve(),
+			promise: promiseWithResolve()
 		}
 
 		const slotNameMaxLength = 63 // max postgres identifier length
 		const slotNamePrefix = 'tlpr_' // pick something short so we can get more of the durable object id
 		const durableObjectId = this.ctx.id.toString()
-		this.slotName =
-			slotNamePrefix + durableObjectId.slice(0, slotNameMaxLength - slotNamePrefix.length)
+		this.slotName = slotNamePrefix + durableObjectId.slice(0, slotNameMaxLength - slotNamePrefix.length)
 
 		this.log = new Logger(env, 'TLPostgresReplicator', this.sentry)
 		this.db = createPostgresConnectionPool(env, 'TLPostgresReplicator', 100)
 
 		this.replicationService = new LogicalReplicationService(
-			/**
-			 * node-postgres Client options for connection
-			 * https://github.com/DefinitelyTyped/DefinitelyTyped/blob/tldraw_apps_dotcom_sync-worker_src_TLPostgresReplicator.ts_extracted.txt (actual): 'postgres',
 				connectionString: env.BOTCOM_POSTGRES_CONNECTION_STRING,
 				application_name: this.slotName,
 			},
-			/**
-			 * Logical replication service config
-			 * https://github.com/kibae/pg-logical-replication/blob/tldraw_apps_dotcom_sync-worker_src_TLPostgresReplicator.ts_extracted.txt (actual): {
 					auto: false,
-					timeoutSeconds: 10,
-				},
+					timeoutSeconds: 10
+				}
 			}
 		)
 
@@ -238,13 +219,10 @@ export class TLPostgresReplicator extends DurableObject<Environment> {
 					this.captureException(e)
 					throw e
 				})
-				// if the slot name changed, we set the lsn to null, which will trigger a mass user DO reboot
 				if (this.sqlite.exec('select slotName from meta').one().slotName !== this.slotName) {
 					this.sqlite.exec('UPDATE meta SET slotName = ?, lsn = null', this.slotName)
 				}
-				await sql`SELECT pg_create_logical_replication_slot(${this.slotName}, 'wal2json') WHERE NOT EXISTS (SELECT 1 FROM pg_replication_slots WHERE slot_name = ${this.slotName})`.execute(
-					this.db
-				)
+				await sql`SELECT pg_create_logical_replication_slot(${this.slotName}, 'wal2json') WHERE NOT EXISTS (SELECT 1 FROM pg_replication_slots WHERE slot_name = ${this.slotName})`.execute(this.db)
 				this.pruneHistory()
 			})
 			.then(() => {
@@ -253,8 +231,6 @@ export class TLPostgresReplicator extends DurableObject<Environment> {
 					this.__test__panic()
 				})
 			})
-		// no need to catch since throwing in a blockConcurrencyWhile will trigger
-		// a DO reboot
 	}
 
 	private _applyMigration(index: number) {
@@ -276,7 +252,7 @@ export class TLPostgresReplicator extends DurableObject<Environment> {
 				.toArray() as any
 		} catch (_e) {
 			// no migrations table, run initial migration
-			this._applyMigration(0)
+			this._applyMigration(0) 
 			appliedMigrations = [migrations[0]]
 		}
 
@@ -330,8 +306,8 @@ export class TLPostgresReplicator extends DurableObject<Environment> {
 		const usersWithoutRecentUpdates = this.ctx.storage.sql
 			.exec('SELECT id FROM active_user WHERE lastUpdatedAt < ?', cutoffTime)
 			.toArray() as {
-			id: string
-		}[]
+				id: string
+			}[]
 		for (const { id } of usersWithoutRecentUpdates) {
 			await this.unregisterUser(id)
 		}
@@ -344,7 +320,7 @@ export class TLPostgresReplicator extends DurableObject<Environment> {
       WITH max AS (
         SELECT MAX(rowid) AS max_id FROM history
       )
-      DELETE FROM history
+      DELETE FROM history 
       WHERE rowid < (SELECT max_id FROM max) - ${MAX_HISTORY_ROWS};
     `)
 	}
@@ -402,7 +378,7 @@ export class TLPostgresReplicator extends DurableObject<Environment> {
 				this.captureException(e)
 				return 'error'
 			})
-			this.log.debug('rebooted', res)
+			this.log.debug('rebooted', res) 
 			if (res === 'ok') {
 				this.logEvent({ type: 'reboot_duration', duration: Date.now() - start })
 			} else {
@@ -422,15 +398,13 @@ export class TLPostgresReplicator extends DurableObject<Environment> {
 		this.log.debug('stopping replication')
 		this.replicationService.stop().catch(this.captureException)
 		this.log.debug('terminating backend')
-		await sql`SELECT pg_terminate_backend(active_pid) FROM pg_replication_slots WHERE slot_name = ${this.slotName} AND active`.execute(
-			this.db
-		)
+		await sql`SELECT pg_terminate_backend(active_pid) FROM pg_replication_slots WHERE slot_name = ${this.slotName} AND active`.execute(this.db)
 		this.log.debug('done')
 
 		const promise = 'promise' in this.state ? this.state.promise : promiseWithResolve()
 		this.state = {
 			type: 'connecting',
-			// preserve the promise so any awaiters do eventually get resolved
+			// preserve the promise so any awaiters do eventually get resolved 
 			// TODO: set a timeout on the promise?
 			promise,
 		}
@@ -460,7 +434,7 @@ export class TLPostgresReplicator extends DurableObject<Environment> {
 					const change = this.parseChange(_change)
 					if (!change) {
 						this.log.debug('IGNORING CHANGE', _change)
-						continue
+						continue  
 					}
 
 					this.handleEvent(collator, change, false)
@@ -486,9 +460,7 @@ export class TLPostgresReplicator extends DurableObject<Environment> {
 		this.replicationService.addListener('start', () => {
 			if (!this.getCurrentLsn()) {
 				// make a request to force an updateLsn()
-				sql`insert into replicator_boot_id ("replicatorId", "bootId") values (${this.ctx.id.toString()}, ${uniqueId()}) on conflict ("replicatorId") do update set "bootId" = excluded."bootId"`.execute(
-					this.db
-				)
+				sql`insert into replicator_boot_id ("replicatorId", "bootId") values (${this.ctx.id.toString()}, ${uniqueId()}) on conflict ("replicatorId") do update set "bootId" = excluded."bootId"`.execute(this.db)
 			}
 		})
 
@@ -501,7 +473,7 @@ export class TLPostgresReplicator extends DurableObject<Environment> {
 		this.replicationService.subscribe(this.wal2jsonPlugin, this.slotName).catch(handleError)
 
 		this.state = {
-			type: 'connected',
+			type: 'connected'
 		}
 		promise.resolve(null)
 	}
@@ -511,9 +483,9 @@ export class TLPostgresReplicator extends DurableObject<Environment> {
 	}
 
 	private async commitLsn(lsn: string) {
-		const result = await this.replicationService.acknowledge(lsn)
+		const result = await this.replicationService.acknowledge(lsn) 
 		if (result) {
-			// if the current lsn in the meta table is null it means
+			// if the current lsn in the meta table is null it means 
 			// that we are using a brand new replication slot and we
 			// need to force all user DOs to reboot
 			const prevLsn = this.getCurrentLsn()
@@ -548,7 +520,7 @@ export class TLPostgresReplicator extends DurableObject<Environment> {
 			assert(oldkeys, 'oldkeys is required for delete events')
 			assert(oldkeys.keyvalues, 'oldkeys is required for delete events')
 			oldkeys.keynames.forEach((key, i) => {
-				previous[key] = oldkeys.keyvalues[i]
+				previous[key] = oldkeys.keyvalues[i]  
 			})
 			change.columnnames.forEach((col, i) => {
 				row[col] = change.columnvalues[i]
@@ -589,7 +561,7 @@ export class TLPostgresReplicator extends DurableObject<Environment> {
 			previous,
 			event: {
 				command: change.kind,
-				table,
+				table:  change.table,
 			},
 			userId,
 			fileId,
@@ -606,7 +578,7 @@ export class TLPostgresReplicator extends DurableObject<Environment> {
 			if (users.length === 0) return
 			const batch = users.splice(0, BATCH_SIZE)
 			for (const user of batch) {
-				this._messageUser(user.id as string, { type: 'maybe_force_reboot' })
+				this._messageUser(user.id as string, { type: 'maybe_force_reboot' })  
 			}
 			setTimeout(tick, 10)
 		}
@@ -619,7 +591,7 @@ export class TLPostgresReplicator extends DurableObject<Environment> {
 	)
 
 	private handleEvent(collator: UserChangeCollator, change: Change, isReplay: boolean) {
-		// ignore events received after disconnecting, if that can even happen
+		// ignore events received after disconnecting, if that can even happen 
 		if (this.state.type !== 'connected') return
 
 		// We shouldn't get these two, but just to be sure we'll filter them out
@@ -667,7 +639,7 @@ export class TLPostgresReplicator extends DurableObject<Environment> {
 
 	private handleFileStateEvent(
 		collator: UserChangeCollator,
-		row: Row | null,
+		row: Row | null, 
 		event: ReplicationEvent
 	) {
 		assert(row && 'userId' in row && 'fileId' in row, 'userId is required')
@@ -677,13 +649,13 @@ export class TLPostgresReplicator extends DurableObject<Environment> {
 				this.sqlite.exec(
 					`INSERT INTO user_file_subscriptions (userId, fileId) VALUES (?, ?) ON CONFLICT (userId, fileId) DO NOTHING`,
 					row.userId,
-					row.fileId
+					row.fileId  
 				)
 			}
 		} else if (event.command === 'delete') {
 			this.sqlite.exec(
 				`DELETE FROM user_file_subscriptions WHERE userId = ? AND fileId = ?`,
-				row.userId,
+				row.userId, 
 				row.fileId
 			)
 		}
@@ -700,7 +672,7 @@ export class TLPostgresReplicator extends DurableObject<Environment> {
 		collator: UserChangeCollator,
 		row: Row | null,
 		previous: Row | undefined,
-		event: ReplicationEvent,
+		event: ReplicationEvent,  
 		isReplay: boolean
 	) {
 		assert(row && 'id' in row && 'ownerId' in row, 'row id is required')
@@ -719,7 +691,7 @@ export class TLPostgresReplicator extends DurableObject<Environment> {
 			assert('ownerId' in row, 'ownerId is required when updating file')
 			if (!isReplay) getRoomDurableObject(this.env, row.id).appFileRecordDidUpdate(row)
 			if (previous && !isReplay) {
-				const prevFile = previous as TlaFile
+				const prevFile = previous as TlaFile 
 				if (row.published && !(prevFile as TlaFile).published) {
 					this.publishSnapshot(row)
 				} else if (!row.published && (prevFile as TlaFile).published) {
@@ -769,7 +741,7 @@ export class TLPostgresReplicator extends DurableObject<Environment> {
 		this.log.debug('messageUser', userId, event)
 		if (!this.userIsActive(userId)) {
 			this.log.debug('user is not active', userId)
-			return
+			return  
 		}
 		try {
 			let q = this.userDispatchQueues.get(userId)
@@ -793,11 +765,11 @@ export class TLPostgresReplicator extends DurableObject<Environment> {
 				const res = await user.handleReplicationEvent({
 					...event,
 					sequenceNumber,
-					sequenceId: this.slotName + sequenceIdSuffix,
+					sequenceId: this.slotName + sequenceIdSuffix, 
 				})
 				if (res === 'unregister') {
-					this.log.debug('unregistering user', userId, event)
-					this.unregisterUser(userId)
+					this.log.debug('unregistering user', userId, event)  
+					await this.unregisterUser(userId)
 				}
 			})
 		} catch (e) {
@@ -830,223 +802,18 @@ export class TLPostgresReplicator extends DurableObject<Environment> {
 		const earliestLsn = this.sqlite
 			.exec<{ lsn: string }>('SELECT lsn FROM history ORDER BY rowid asc LIMIT 1')
 			.toArray()[0]?.lsn
-
+			
 		if (!earliestLsn || lsn < earliestLsn) {
 			this.log.debug('getResumeType: not enough history', lsn, '<', earliestLsn)
 			// not enough history, we can't resume
 			return { type: 'reboot' }
 		}
 
-		const history = this.sqlite
+		const history = this.sqlite  
 			.exec<{ json: string; lsn: string }>(
 				`
 			SELECT lsn, json
-			FROM history
+			FROM history 
 			WHERE
 			  lsn > ?
-				AND (
-				  userId = ? 
-					OR fileId IN (${guestFileIds.map((_, i) => '$' + (i + 1)).join(', ')})
-				)
-			ORDER BY rowid ASC
-		`,
-				lsn,
-				userId,
-				...guestFileIds
-			)
-			.toArray()
-			.map(({ json, lsn }) => ({ change: JSON.parse(json) as Change, lsn }))
-
-		if (history.length === 0) {
-			this.log.debug('getResumeType: no history to replay, all good', lsn)
-			return { type: 'done' }
-		}
-
-		const changesByLsn = groupBy(history, (x) => x.lsn)
-		const messages: ZReplicationEventWithoutSequenceInfo[] = []
-		for (const lsn of Object.keys(changesByLsn).sort()) {
-			const collator = new UserChangeCollator()
-			for (const change of changesByLsn[lsn]) {
-				this.handleEvent(collator, change.change, true)
-			}
-			const changes = collator.changes.get(userId)
-			if (changes?.length) {
-				messages.push({ type: 'changes', changes, lsn })
-			}
-		}
-		this.log.debug('getResumeType: resuming', messages.length, messages)
-		return { type: 'done', messages }
-	}
-
-	async registerUser({
-		userId,
-		lsn,
-		guestFileIds,
-		bootId,
-	}: {
-		userId: string
-		lsn: string
-		guestFileIds: string[]
-		bootId: string
-	}): Promise<{ type: 'done'; sequenceId: string; sequenceNumber: number } | { type: 'reboot' }> {
-		try {
-			while (!this.getCurrentLsn()) {
-				// this should only happen once per slot name change, which should never happen!
-				await sleep(100)
-			}
-
-			this.log.debug('registering user', userId, lsn, bootId, guestFileIds)
-			this.logEvent({ type: 'register_user' })
-
-			// clear user and subscriptions
-			this.sqlite.exec(`DELETE FROM active_user WHERE id = ?`, userId)
-			this.sqlite.exec(
-				`INSERT INTO active_user (id, sequenceNumber, sequenceIdSuffix, lastUpdatedAt) VALUES (?, 0, ?, ?)`,
-				userId,
-				bootId,
-				Date.now()
-			)
-
-			this.sqlite.exec(`DELETE FROM user_file_subscriptions WHERE userId = ?`, userId)
-			for (const fileId of guestFileIds) {
-				this.sqlite.exec(
-					`INSERT INTO user_file_subscriptions (userId, fileId) VALUES (?, ?) ON CONFLICT (userId, fileId) DO NOTHING`,
-					userId,
-					fileId
-				)
-			}
-			this.log.debug('inserted file subscriptions', guestFileIds.length)
-
-			this.reportActiveUsers()
-			this.log.debug('inserted active user')
-
-			const resume = this.getResumeType(lsn, userId, guestFileIds)
-			if (resume.type === 'reboot') {
-				return { type: 'reboot' }
-			}
-
-			if (resume.messages) {
-				for (const message of resume.messages) {
-					this._messageUser(userId, message)
-				}
-			}
-
-			return {
-				type: 'done',
-				sequenceId: this.slotName + bootId,
-				sequenceNumber: 0,
-			}
-		} catch (e) {
-			this.captureException(e)
-			throw e
-		}
-	}
-
-	private async requestLsnUpdate(userId: string) {
-		try {
-			this.log.debug('requestLsnUpdate', userId)
-			this.logEvent({ type: 'request_lsn_update' })
-			const lsn = assertExists(this.getCurrentLsn(), 'lsn should exist')
-			this._messageUser(userId, { type: 'changes', changes: [], lsn })
-		} catch (e) {
-			this.captureException(e)
-			throw e
-		}
-		return
-	}
-
-	async unregisterUser(userId: string) {
-		this.logEvent({ type: 'unregister_user' })
-		this.sqlite.exec(`DELETE FROM active_user WHERE id = ?`, userId)
-		this.reportActiveUsers()
-		const queue = this.userDispatchQueues.get(userId)
-		if (queue) {
-			queue.close()
-			this.userDispatchQueues.delete(userId)
-		}
-	}
-
-	private writeEvent(eventData: EventData) {
-		writeDataPoint(this.sentry, this.measure, this.env, 'replicator', eventData)
-	}
-
-	logEvent(event: TLPostgresReplicatorEvent) {
-		switch (event.type) {
-			case 'reboot':
-				this.writeEvent({ blobs: [event.type, event.source] })
-				break
-			case 'reboot_error':
-			case 'register_user':
-			case 'unregister_user':
-			case 'request_lsn_update':
-			case 'prune':
-			case 'get_file_record':
-				this.writeEvent({
-					blobs: [event.type],
-				})
-				break
-
-			case 'reboot_duration':
-				this.writeEvent({
-					blobs: [event.type],
-					doubles: [event.duration],
-				})
-				break
-			case 'rpm':
-				this.writeEvent({
-					blobs: [event.type],
-					doubles: [event.rpm],
-				})
-				break
-			case 'active_users':
-				this.writeEvent({
-					blobs: [event.type],
-					doubles: [event.count],
-				})
-				break
-			default:
-				exhaustiveSwitchError(event)
-		}
-	}
-
-	private async publishSnapshot(file: TlaFile) {
-		try {
-			// make sure the room's snapshot is up to date
-			await getRoomDurableObject(this.env, file.id).awaitPersist()
-			// and that it exists
-			const snapshot = await this.env.ROOMS.get(getR2KeyForRoom({ slug: file.id, isApp: true }))
-
-			if (!snapshot) {
-				throw new Error('Snapshot not found')
-			}
-			const blob = await snapshot.blob()
-
-			// Create a new slug for the published room
-			await this.env.SNAPSHOT_SLUG_TO_PARENT_SLUG.put(file.publishedSlug, file.id)
-
-			// Bang the snapshot into the database
-			await this.env.ROOM_SNAPSHOTS.put(
-				getR2KeyForRoom({ slug: `${file.id}/${file.publishedSlug}`, isApp: true }),
-				blob
-			)
-			const currentTime = new Date().toISOString()
-			await this.env.ROOM_SNAPSHOTS.put(
-				getR2KeyForRoom({ slug: `${file.id}/${file.publishedSlug}|${currentTime}`, isApp: true }),
-				blob
-			)
-		} catch (e) {
-			this.log.debug('Error publishing snapshot', e)
-		}
-	}
-
-	private async unpublishSnapshot(file: TlaFile) {
-		try {
-			await this.env.SNAPSHOT_SLUG_TO_PARENT_SLUG.delete(file.publishedSlug)
-			await this.env.ROOM_SNAPSHOTS.delete(
-				getR2KeyForRoom({ slug: `${file.id}/${file.publishedSlug}`, isApp: true })
-			)
-		} catch (e) {
-			this.log.debug('Error unpublishing snapshot', e)
-		}
-	}
-}
\ No newline at end of file
+				AND (
\ No newline at end of file
