--- aider_benchmark_problem_stats.py_expectedoutput.txt (expected)+++ aider_benchmark_problem_stats.py_extracted.txt (actual)@@ -84,7 +84,9 @@             # Calculate pass rate for sorting when using custom dirs
             if dirs is not None:
                 pass_rate = sum(
-                    1 for r in results if r.get("tests_outcomes", []) and r["tests_outcomes"][-1]
+                    1
+                    for r in results
+                    if r.get("tests_outcomes", []) and r["tests_outcomes"][-1]
                 ) / len(results)
             else:
                 # Use existing pass rate from leaderboard
@@ -105,6 +107,9 @@     if topn:
         valid_entries = valid_entries[:topn]
 
+    # Unpack the filtered and sorted entries
+    leaderboard = [entry for entry, _, _ in valid_entries]
+
     # Get all exercise names from a complete run
     all_exercises = set()
     exercise_solutions = defaultdict(list)
@@ -117,7 +122,10 @@                 try:
                     all_exercises.add(result["testcase"] + "/" + result["language"])
                 except KeyError:
-                    print(f"Warning: Missing testcase in {dirname}", json.dumps(result, indent=4))
+                    print(
+                        f"Warning: Missing testcase in {dirname}",
+                        json.dumps(result, indent=4),
+                    )
 
     for (dirname, model), results, _ in valid_entries:
         if not results:
@@ -156,7 +164,7 @@ 
     for testcase in all_exercises:
         # Language is already in the testcase string
-        lang = testcase.split("/")[0]  # First part is the language
+        lang = testcase.split("/")[1]  # First part is the language
         models = exercise_solutions[testcase]
         num_solved = len(models)
         percent = (num_solved / total_models) * 100
