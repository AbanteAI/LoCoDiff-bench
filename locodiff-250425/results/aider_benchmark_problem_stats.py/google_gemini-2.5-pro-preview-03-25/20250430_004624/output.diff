
index 36481d11..0d99264f 100644
--- a/aider_benchmark_problem_stats.py_expectedoutput.txt (expected):tmp/tmp7fnm38f7_expected.txt	
+++ b/aider_benchmark_problem_stats.py_extracted.txt (actual):tmp/tmpohn_fya7_actual.txt	
@@ -11,6 +11,7 @@ import yaml
 from aider.dump import dump  # noqa
 
 HARD_SET_NUM = 3  # Number of models that defines the hard set threshold
+PARSE_ERROR_M = 4  # Threshold for number of parse errors to DQ an exercise
 
 
 def get_dirs_from_leaderboard():
@@ -60,8 +61,6 @@ def load_results(dirname):
 
 
 def analyze_exercise_solutions(dirs=None, topn=None, copy_hard_set=False):
-    PARSE_ERROR_M = 4  # Threshold for number of parse errors to DQ an exercise
-
     if dirs is None:
         # Use leaderboard data if no directories specified
         dir_entries = get_dirs_from_leaderboard()
@@ -105,12 +104,9 @@ def analyze_exercise_solutions(dirs=None, topn=None, copy_hard_set=False):
     if topn:
         valid_entries = valid_entries[:topn]
 
-    # Get all exercise names from a complete run
-    all_exercises = set()
-    exercise_solutions = defaultdict(list)
-
     # Get all unique exercise names from all results
     all_exercises = set()
+    exercise_solutions = defaultdict(list)
     for (dirname, model), results, _ in valid_entries:
         if results:
             for result in results:
@@ -156,10 +152,10 @@ def analyze_exercise_solutions(dirs=None, topn=None, copy_hard_set=False):
 
     for testcase in all_exercises:
         # Language is already in the testcase string
-        lang = testcase.split("/")[0]  # First part is the language
+        lang = testcase.split("/")[1]  # First part is the language
         models = exercise_solutions[testcase]
         num_solved = len(models)
-        percent = (num_solved / total_models) * 100
+        percent = (num_solved / total_models) * 100 if total_models else 0
         testcase = testcase.replace("exercises/", "")  # Remove the exercises/ prefix
         # Remove duplicate language prefix (e.g. javascript/javascript/ -> javascript/)
         if testcase.startswith(f"{lang}/{lang}/"):
@@ -172,7 +168,7 @@ def analyze_exercise_solutions(dirs=None, topn=None, copy_hard_set=False):
     )  # -x[2] for descending solve rate, x[1] for ascending exercise name
 
     # Calculate max lengths for alignment after cleaning up paths
-    max_name_len = max(len(f"{lang}/{testcase}") for lang, testcase, _, _ in exercise_stats)
+    max_name_len = max(len(f"{testcase}") for lang, testcase, _, _ in exercise_stats)
 
     # Print all exercises sorted by solve rate
     print("\nAll Exercises (sorted by solve rate):")
@@ -292,7 +288,7 @@ def analyze_exercise_solutions(dirs=None, topn=None, copy_hard_set=False):
                 if tests_outcomes and tests_outcomes[-1]:
                     solved_hard += 1
 
-        pct = (solved_hard / len(hard_set)) * 100
+        pct = (solved_hard / len(hard_set)) * 100 if hard_set else 0
         model_hard_stats.append((model, solved_hard, pct))
 
     # Sort by number solved
