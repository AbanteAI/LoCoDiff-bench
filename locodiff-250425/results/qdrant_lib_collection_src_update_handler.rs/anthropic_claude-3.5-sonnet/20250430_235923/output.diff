--- qdrant_lib_collection_src_update_handler.rs_expectedoutput.txt (expected)+++ qdrant_lib_collection_src_update_handler.rs_extracted.txt (actual)@@ -35,12 +35,12 @@ use crate::operations::types::{CollectionError, CollectionResult};
 use crate::save_on_disk::SaveOnDisk;
 use crate::shards::local_shard::LocalShardClocks;
-use crate::wal::WalError;
+use crate::wal::WalError; 
 use crate::wal_delta::LockedWal;
 
 /// Interval at which the optimizer worker cleans up old optimization handles
 ///
-/// The longer the duration, the longer it  takes for panicked tasks to be reported.
+/// The longer the duration, the longer it takes for panicked tasks to be reported.
 const OPTIMIZER_CLEANUP_INTERVAL: Duration = Duration::from_secs(5);
 
 pub type Optimizer = dyn SegmentOptimizer + Sync + Send;
@@ -48,7 +48,7 @@ /// Information, required to perform operation and notify regarding the result
 #[derive(Debug)]
 pub struct OperationData {
-    /// Sequential number of the operation
+    /// Sequential number of the operation  
     pub op_num: SeqNumberType,
     /// Operation
     pub operation: CollectionUpdateOperations,
@@ -60,11 +60,11 @@ }
 
 /// Signal, used to inform Updater process
-#[derive(Debug)]
+#[derive(Debug)] 
 pub enum UpdateSignal {
     /// Requested operation to perform
     Operation(OperationData),
-    /// Stop all optimizers and listening
+    /// Stop all optimizers and listening  
     Stop,
     /// Empty signal used to trigger optimizers
     Nop,
@@ -80,7 +80,7 @@     /// Stop all optimizers and listening
     Stop,
     /// Empty signal used to trigger optimizers
-    Nop,
+    Nop, 
 }
 
 /// Structure, which holds object, required for processing updates of the collection
@@ -100,7 +100,7 @@     /// This parameter depends on the optimizer config and should be updated accordingly.
     pub flush_interval_sec: u64,
     segments: LockedSegmentHolder,
-    /// Process, that listens updates signals and perform updates
+    /// Process, that listens updates signals and perform updates 
     update_worker: Option<JoinHandle<()>>,
     /// Process, that listens for post-update signals and performs optimization
     optimizer_worker: Option<JoinHandle<()>>,
@@ -162,14 +162,14 @@             flush_interval_sec,
             optimization_handles: Arc::new(TokioMutex::new(vec![])),
             max_optimization_threads,
-            clocks,
+            clocks, 
             shard_path,
             has_triggered_optimizers: Default::default(),
         }
     }
 
     pub fn run_workers(&mut self, update_receiver: Receiver<UpdateSignal>) {
-        let (tx, rx) = mpsc::channel(self.shared_storage_config.update_queue_size);
+        let (tx, rx) = mpsc::channel(UPDATE_QUEUE_SIZE);
         self.optimizer_worker = Some(self.runtime_handle.spawn(Self::optimization_worker_fn(
             self.optimizers.clone(),
             tx.clone(),
@@ -178,7 +178,7 @@             self.wal.clone(),
             self.optimization_handles.clone(),
             self.optimizers_log.clone(),
-            self.total_optimized_points.clone(),
+            self.total_optimized_points.clone(), 
             self.optimizer_resource_budget.clone(),
             self.max_optimization_threads,
             self.has_triggered_optimizers.clone(),
@@ -211,7 +211,7 @@         }
     }
 
-    /// Gracefully wait before all optimizations stop
+    /// Gracefully wait before all optimizations stop 
     /// If some optimization is in progress - it will be finished before shutdown.
     pub async fn wait_workers_stops(&mut self) -> CollectionResult<()> {
         let maybe_handle = self.update_worker.take();
@@ -242,7 +242,7 @@     }
 
     /// Checks if there are any failed operations.
-    /// If so - attempts to re-apply all failed operations.
+    /// If so - attempts to re-apply all failed operations. 
     async fn try_recover(segments: LockedSegmentHolder, wal: LockedWal) -> CollectionResult<usize> {
         // Try to re-apply everything starting from the first failed operation
         let first_failed_operation_option = segments.read().failed_operation.iter().cloned().min();
@@ -261,156 +261,6 @@             }
         };
         Ok(0)
-    }
-
-    /// Checks conditions for all optimizers until there is no suggested segment
-    /// Starts a task for each optimization
-    /// Returns handles for started tasks
-    pub(crate) fn launch_optimization<F>(
-        optimizers: Arc<Vec<Arc<Optimizer>>>,
-        optimizers_log: Arc<Mutex<TrackerLog>>,
-        total_optimized_points: Arc<AtomicUsize>,
-        optimizer_resource_budget: &ResourceBudget,
-        segments: LockedSegmentHolder,
-        callback: F,
-        limit: Option<usize>,
-    ) -> Vec<StoppableTaskHandle<bool>>
-    where
-        F: Fn(bool) + Send + Clone + Sync + 'static,
-    {
-        let mut scheduled_segment_ids = HashSet::<_>::default();
-        let mut handles = vec![];
-
-        'outer: for optimizer in optimizers.iter() {
-            loop {
-                // Return early if we reached the optimization job limit
-                if limit.map(|extra| handles.len() >= extra).unwrap_or(false) {
-                    log::trace!("Reached optimization job limit, postponing other optimizations");
-                    break 'outer;
-                }
-
-                let nonoptimal_segment_ids =
-                    optimizer.check_condition(segments.clone(), &scheduled_segment_ids);
-                if nonoptimal_segment_ids.is_empty() {
-                    break;
-                }
-
-                debug!("Optimizing segments: {:?}", &nonoptimal_segment_ids);
-
-                // Determine how many Resources we prefer for optimization task, acquire permit for it
-                // And use same amount of IO threads as CPUs
-                let max_indexing_threads = optimizer.hnsw_config().max_indexing_threads;
-                let desired_io = num_rayon_threads(max_indexing_threads);
-                let Some(mut permit) = optimizer_resource_budget.try_acquire(0, desired_io) else {
-                    // If there is no Resource budget, break outer loop and return early
-                    // If we have no handles (no optimizations) trigger callback so that we wake up
-                    // our optimization worker to try again later, otherwise it could get stuck
-                    log::trace!(
-                        "No available IO permit for {} optimizer, postponing",
-                        optimizer.name(),
-                    );
-                    if handles.is_empty() {
-                        callback(false);
-                    }
-                    break 'outer;
-                };
-                log::trace!(
-                    "Acquired {} IO permit for {} optimizer",
-                    permit.num_io,
-                    optimizer.name(),
-                );
-
-                let permit_callback = callback.clone();
-
-                permit.set_on_release(move || {
-                    // Notify scheduler that resource budget changed
-                    permit_callback(false);
-                });
-
-                let optimizer = optimizer.clone();
-                let optimizers_log = optimizers_log.clone();
-                let total_optimized_points = total_optimized_points.clone();
-                let segments = segments.clone();
-                let nsi = nonoptimal_segment_ids.clone();
-                scheduled_segment_ids.extend(&nsi);
-                let callback = callback.clone();
-
-                let handle = spawn_stoppable(
-                    // Stoppable task
-                    {
-                        let resource_budget = optimizer_resource_budget.clone();
-                        let segments = segments.clone();
-                        move |stopped| {
-                            // Track optimizer status
-                            let tracker = Tracker::start(optimizer.as_ref().name(), nsi.clone());
-                            let tracker_handle = tracker.handle();
-                            optimizers_log.lock().register(tracker);
-
-                            // Optimize and handle result
-                            match optimizer.as_ref().optimize(
-                                segments.clone(),
-                                nsi,
-                                permit,
-                                resource_budget,
-                                stopped,
-                            ) {
-                                // Perform some actions when optimization if finished
-                                Ok(optimized_points) => {
-                                    let is_optimized = optimized_points > 0;
-                                    total_optimized_points
-                                        .fetch_add(optimized_points, Ordering::Relaxed);
-                                    tracker_handle.update(TrackerStatus::Done);
-                                    callback(is_optimized);
-                                    is_optimized
-                                }
-                                // Handle and report errors
-                                Err(error) => match error {
-                                    CollectionError::Cancelled { description } => {
-                                        debug!("Optimization cancelled - {description}");
-                                        tracker_handle
-                                            .update(TrackerStatus::Cancelled(description));
-                                        false
-                                    }
-                                    _ => {
-                                        segments.write().report_optimizer_error(error.clone());
-
-                                        // Error of the optimization can not be handled by API user
-                                        // It is only possible to fix after full restart,
-                                        // so the best available action here is to stop whole
-                                        // optimization thread and log the error
-                                        log::error!("Optimization error: {error}");
-
-                                        tracker_handle
-                                            .update(TrackerStatus::Error(error.to_string()));
-
-                                        panic!("Optimization error: {error}");
-                                    }
-                                },
-                            }
-                        }
-                    },
-                    // Panic handler
-                    Some(Box::new(move |panic_payload| {
-                        let message = panic::downcast_str(&panic_payload).unwrap_or("");
-                        let separator = if !message.is_empty() { ": " } else { "" };
-
-                        warn!(
-                            "Optimization task panicked, collection may be in unstable state\
-                             {separator}{message}"
-                        );
-
-                        segments
-                            .write()
-                            .report_optimizer_error(CollectionError::service_error(format!(
-                                "Optimization task panicked{separator}{message}"
-                            )));
-                    })),
-                );
-                handles.push(handle);
-            }
-        }
-
-        handles
     }
 
     /// Ensure there is at least one appendable segment with enough capacity
@@ -462,7 +312,7 @@     ///
     /// This function returns a tuple of two booleans:
     /// - The first indicates if any optimizers have been triggered since startup.
-    /// - The second indicates if there are any pending/suboptimal optimizers.
+    /// - The second indicates if there are any pending/suboptimal optimizers. 
     pub(crate) fn check_optimizer_conditions(&self) -> (bool, bool) {
         // Check if Qdrant triggered any optimizations since starting at all
         let has_triggered_any_optimizers = self.has_triggered_optimizers.load(Ordering::Relaxed);
@@ -537,7 +387,7 @@             handle.join_and_handle_panic().await;
         }
 
-        finished_any
+        finished_any 
     }
 
     #[allow(clippy::too_many_arguments)]
@@ -567,18 +417,18 @@         loop {
             let result = timeout(OPTIMIZER_CLEANUP_INTERVAL, receiver.recv()).await;
 
-            let cleaned_any =
+            let cleaned_any = 
                 Self::cleanup_optimization_handles(optimization_handles.clone()).await;
 
             // Either continue below here with the worker, or reloop/break
             // Decision logic doing one of three things:
             // 1. run optimizers
-            // 2. reloop and wait for next signal
+            // 2. reloop and wait for next signal  
             // 3. break here and stop the optimization worker
             let ignore_max_handles = match result {
                 // Regular optimizer signal: run optimizers: do 1
                 Ok(Some(OptimizerSignal::Operation(_))) => false,
-                // Optimizer signal ignoring max handles: do 1
+                // Optimizer signal ignoring max handles: do 1  
                 Ok(Some(OptimizerSignal::Nop)) => true,
                 // Hit optimizer cleanup interval, did clean up a task: do 1
                 Err(Elapsed { .. }) if cleaned_any => {
@@ -634,7 +484,7 @@             // Continue if we have enough resource budget available to start an optimization
             // Otherwise skip now and start a task to trigger the optimizer again once resource
             // budget becomes available
-            let desired_cpus = 0;
+            let desired_cpus = 0; 
             let desired_io = num_rayon_threads(max_indexing_threads);
             if !optimizer_resource_budget.has_budget(desired_cpus, desired_io) {
                 let trigger_active = resource_available_trigger
@@ -651,7 +501,7 @@                 continue;
             }
 
-            // Determine optimization handle limit based on max handles we allow
+            // Determine optimization handle limit based on max handles we allow 
             // Not related to the CPU budget, but a different limit for the maximum number
             // of concurrent concrete optimizations per shard as configured by the user in
             // the Qdrant configuration.
@@ -678,7 +528,7 @@ 
     async fn update_worker_fn(
         mut receiver: Receiver<UpdateSignal>,
-        optimize_sender: Sender<OptimizerSignal>,
+        optimize_sender: Sender<OptimizerSignal>, 
         wal: LockedWal,
         segments: LockedSegmentHolder,
     ) {
@@ -824,7 +674,7 @@     }
 
     /// Returns confirmed version after flush of all segments
-    ///
+    /// 
     /// # Errors
     /// Returns an error on flush failure
     fn flush_segments(segments: LockedSegmentHolder) -> OperationResult<SeqNumberType> {
@@ -840,7 +690,7 @@ /// Trigger optimizers when CPU budget is available
 fn trigger_optimizers_on_resource_budget(
     optimizer_resource_budget: ResourceBudget,
-    desired_cpus: usize,
+    desired_cpus: usize, 
     desired_io: usize,
     sender: Sender<OptimizerSignal>,
 ) -> JoinHandle<()> {
