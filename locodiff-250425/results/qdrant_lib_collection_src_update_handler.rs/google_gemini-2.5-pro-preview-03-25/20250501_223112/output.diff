
index cb922e86..f8a3df82 100644
--- a/qdrant_lib_collection_src_update_handler.rs_expectedoutput.txt (expected):tmp/tmp7s6z6czp_expected.txt	
+++ b/qdrant_lib_collection_src_update_handler.rs_extracted.txt (actual):tmp/tmp8wgsns48_actual.txt	
@@ -93,8 +93,8 @@ pub struct UpdateHandler {
     optimizers_log: Arc<Mutex<TrackerLog>>,
     /// Total number of optimized points since last start
     total_optimized_points: Arc<AtomicUsize>,
-    /// Global CPU budget in number of cores for all optimization tasks.
-    /// Assigns CPU permits to tasks to limit overall resource utilization.
+    /// Global resource budget in number of cores/threads for all optimization tasks.
+    /// Assigns resource permits to tasks to limit overall resource utilization.
     optimizer_resource_budget: ResourceBudget,
     /// How frequent can we flush data
     /// This parameter depends on the optimizer config and should be updated accordingly.
@@ -143,8 +143,8 @@ impl UpdateHandler {
         max_optimization_threads: Option<usize>,
         clocks: LocalShardClocks,
         shard_path: PathBuf,
-    ) -> UpdateHandler {
-        UpdateHandler {
+    ) -> Self {
+        Self {
             shared_storage_config,
             payload_index_schema,
             optimizers,
@@ -266,6 +266,7 @@ impl UpdateHandler {
     /// Checks conditions for all optimizers until there is no suggested segment
     /// Starts a task for each optimization
     /// Returns handles for started tasks
+    #[allow(clippy::too_many_arguments)]
     pub(crate) fn launch_optimization<F>(
         optimizers: Arc<Vec<Arc<Optimizer>>>,
         optimizers_log: Arc<Mutex<TrackerLog>>,
@@ -284,7 +285,7 @@ impl UpdateHandler {
         'outer: for optimizer in optimizers.iter() {
             loop {
                 // Return early if we reached the optimization job limit
-                if limit.map(|extra| handles.len() >= extra).unwrap_or(false) {
+                if limit.is_some_and(|extra| handles.len() >= extra) {
                     log::trace!("Reached optimization job limit, postponing other optimizations");
                     break 'outer;
                 }
@@ -295,7 +296,7 @@ impl UpdateHandler {
                     break;
                 }
 
-                debug!("Optimizing segments: {:?}", &nonoptimal_segment_ids);
+                debug!("Optimizing segments: {nonoptimal_segment_ids:?}");
 
                 // Determine how many Resources we prefer for optimization task, acquire permit for it
                 // And use same amount of IO threads as CPUs
@@ -347,13 +348,13 @@ impl UpdateHandler {
                             optimizers_log.lock().register(tracker);
 
                             // Optimize and handle result
-                            match optimizer.as_ref().optimize(
+                            match unsafe { optimizer.as_ref().optimize(
                                 segments.clone(),
                                 nsi,
                                 permit,
                                 resource_budget,
                                 stopped,
-                            ) {
+                            ) } {
                                 // Perform some actions when optimization if finished
                                 Ok(optimized_points) => {
                                     let is_optimized = optimized_points > 0;
@@ -372,6 +373,8 @@ impl UpdateHandler {
                                         false
                                     }
                                     _ => {
+                                        // Save only the first error
+                                        // If is more likely to be the real cause of all further problems
                                         segments.write().report_optimizer_error(error.clone());
 
                                         // Error of the optimization can not be handled by API user
@@ -384,7 +387,7 @@ impl UpdateHandler {
                                             .update(TrackerStatus::Error(error.to_string()));
 
                                         panic!("Optimization error: {error}");
-                                    }
+                                    },
                                 },
                             }
                         }
@@ -561,7 +564,7 @@ impl UpdateHandler {
             .map(|optimizer| optimizer.hnsw_config().max_indexing_threads)
             .unwrap_or_default();
 
-        // Asynchronous task to trigger optimizers once CPU budget is available again
+        // Asynchronous task to trigger optimizers once resource budget is available again
         let mut resource_available_trigger: Option<JoinHandle<()>> = None;
 
         loop {
@@ -652,7 +655,7 @@ impl UpdateHandler {
             }
 
             // Determine optimization handle limit based on max handles we allow
-            // Not related to the CPU budget, but a different limit for the maximum number
+            // Not related to the resource budget, but a different limit for the maximum number
             // of concurrent concrete optimizations per shard as configured by the user in
             // the Qdrant configuration.
             // Skip if we reached limit, an ongoing optimization that finishes will trigger this loop again
@@ -721,7 +724,9 @@ impl UpdateHandler {
 
                     if let Some(feedback) = sender {
                         feedback.send(res).unwrap_or_else(|_| {
-                            debug!("Can't report operation {op_num} result. Assume already not required");
+                            debug!(
+                                "Can't report operation {op_num} result. Assume already not required",
+                            );
                         });
                     };
                 }
@@ -802,7 +807,7 @@ impl UpdateHandler {
             // This is to prevent truncating WAL entries that other bits of code still depend on
             // such as the queue proxy shard.
             // Default keep_from is `u64::MAX` to allow acknowledging all confirmed.
-            let keep_from = wal_keep_from.load(std::sync::atomic::Ordering::Relaxed);
+            let keep_from = wal_keep_from.load(Ordering::Relaxed);
 
             // If we should keep the first message, do not acknowledge at all
             if keep_from == 0 {
@@ -837,7 +842,7 @@ impl UpdateHandler {
     }
 }
 
-/// Trigger optimizers when CPU budget is available
+/// Trigger optimizers when resource budget is available
 fn trigger_optimizers_on_resource_budget(
     optimizer_resource_budget: ResourceBudget,
     desired_cpus: usize,
@@ -845,11 +850,11 @@ fn trigger_optimizers_on_resource_budget(
     sender: Sender<OptimizerSignal>,
 ) -> JoinHandle<()> {
     task::spawn(async move {
-        log::trace!("Skipping optimization checks, waiting for CPU budget to be available");
+        log::trace!("Skipping optimization checks, waiting for resource budget to be available");
         optimizer_resource_budget
             .notify_on_budget_available(desired_cpus, desired_io)
             .await;
-        log::trace!("Continue optimization checks, new CPU budget available");
+        log::trace!("Continue optimization checks, new resource budget available");
 
         // Trigger optimizers with Nop operation
         sender.send(OptimizerSignal::Nop).await.unwrap_or_else(|_| {
