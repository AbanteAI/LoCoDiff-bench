--- qdrant_lib_collection_src_update_handler.rs_expectedoutput.txt (expected)+++ qdrant_lib_collection_src_update_handler.rs_extracted.txt (actual)@@ -205,7 +205,7 @@ 
     pub fn stop_flush_worker(&mut self) {
         if let Some(flush_stop) = self.flush_stop.take() {
-            if let Err(()) = flush_stop.send(()) {
+            if flush_stop.send(()).is_err() {
                 warn!("Failed to stop flush worker as it is already stopped.");
             }
         }
@@ -213,6 +213,7 @@ 
     /// Gracefully wait before all optimizations stop
     /// If some optimization is in progress - it will be finished before shutdown.
+    /// Blocking function.
     pub async fn wait_workers_stops(&mut self) -> CollectionResult<()> {
         let maybe_handle = self.update_worker.take();
         if let Some(handle) = maybe_handle {
@@ -263,9 +264,25 @@         Ok(0)
     }
 
-    /// Checks conditions for all optimizers until there is no suggested segment
-    /// Starts a task for each optimization
-    /// Returns handles for started tasks
+    /// Checks the optimizer conditions.
+    ///
+    /// This function returns a tuple of two booleans:
+    /// - The first indicates if any optimizers have been triggered since startup.
+    /// - The second indicates if there are any pending/suboptimal optimizers.
+    pub(crate) fn check_optimizer_conditions(&self) -> (bool, bool) {
+        // Check if Qdrant triggered any optimizations since starting at all
+        let has_triggered_any_optimizers = self.has_triggered_optimizers.load(Ordering::Relaxed);
+
+        let excluded_ids = HashSet::<_>::default();
+        let has_suboptimal_optimizers = self.optimizers.iter().any(|optimizer| {
+            let nonoptimal_segment_ids =
+                optimizer.check_condition(self.segments.clone(), &excluded_ids);
+            !nonoptimal_segment_ids.is_empty()
+        });
+
+        (has_triggered_any_optimizers, has_suboptimal_optimizers)
+    }
+
     pub(crate) fn launch_optimization<F>(
         optimizers: Arc<Vec<Arc<Optimizer>>>,
         optimizers_log: Arc<Mutex<TrackerLog>>,
@@ -280,7 +297,6 @@     {
         let mut scheduled_segment_ids = HashSet::<_>::default();
         let mut handles = vec![];
-
         'outer: for optimizer in optimizers.iter() {
             loop {
                 // Return early if we reached the optimization job limit
@@ -366,12 +382,14 @@                                 // Handle and report errors
                                 Err(error) => match error {
                                     CollectionError::Cancelled { description } => {
-                                        debug!("Optimization cancelled - {description}");
+                                        log::debug!("Optimization cancelled - {description}");
                                         tracker_handle
                                             .update(TrackerStatus::Cancelled(description));
                                         false
                                     }
                                     _ => {
+                                        // Save only the first error
+                                        // If is more likely to be the real cause of all further problems
                                         segments.write().report_optimizer_error(error.clone());
 
                                         // Error of the optimization can not be handled by API user
@@ -409,7 +427,6 @@                 handles.push(handle);
             }
         }
-
         handles
     }
 
@@ -458,25 +475,6 @@         Ok(())
     }
 
-    /// Checks the optimizer conditions.
-    ///
-    /// This function returns a tuple of two booleans:
-    /// - The first indicates if any optimizers have been triggered since startup.
-    /// - The second indicates if there are any pending/suboptimal optimizers.
-    pub(crate) fn check_optimizer_conditions(&self) -> (bool, bool) {
-        // Check if Qdrant triggered any optimizations since starting at all
-        let has_triggered_any_optimizers = self.has_triggered_optimizers.load(Ordering::Relaxed);
-
-        let excluded_ids = HashSet::<_>::default();
-        let has_suboptimal_optimizers = self.optimizers.iter().any(|optimizer| {
-            let nonoptimal_segment_ids =
-                optimizer.check_condition(self.segments.clone(), &excluded_ids);
-            !nonoptimal_segment_ids.is_empty()
-        });
-
-        (has_triggered_any_optimizers, has_suboptimal_optimizers)
-    }
-
     #[allow(clippy::too_many_arguments)]
     pub(crate) async fn process_optimization(
         optimizers: Arc<Vec<Arc<Optimizer>>>,
@@ -505,6 +503,7 @@         );
         let mut handles = optimization_handles.lock().await;
         handles.append(&mut new_handles);
+        handles.retain(|h| !h.is_finished())
     }
 
     /// Cleanup finalized optimization task handles
@@ -823,7 +822,7 @@         }
     }
 
-    /// Returns confirmed version after flush of all segments
+    /// Returns confirmed version after flush of all segements
     ///
     /// # Errors
     /// Returns an error on flush failure
@@ -837,7 +836,6 @@     }
 }
 
-/// Trigger optimizers when CPU budget is available
 fn trigger_optimizers_on_resource_budget(
     optimizer_resource_budget: ResourceBudget,
     desired_cpus: usize,
