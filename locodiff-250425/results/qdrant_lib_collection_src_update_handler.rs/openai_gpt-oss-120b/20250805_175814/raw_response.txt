```rust
use std::cmp::min;
use std::collections::HashSet;
use std::path::{Path, PathBuf};
use std::sync::atomic::{AtomicBool, AtomicU64, AtomicUsize, Ordering};
use std::sync::Arc;

use common::budget::ResourceBudget;
use common::counter::hardware_accumulator::HwMeasurementAcc;
use common::counter::hardware_counter::HardwareCounterCell;
use common::panic;
use itertools::Itertools;
use log::{debug, error, info, trace, warn};
use parking_lot::Mutex;
use segment::common::operation_error::OperationResult;
use segment::index::hnsw_index::num_rayon_threads;
use segment::types::SeqNumberType;
use tokio::runtime::Handle;
use tokio::sync::mpsc::{self, Receiver, Sender};
use tokio::sync::{oneshot, Mutex as TokioMutex};
use tokio::task::{self, JoinHandle};
use tokio::time::{timeout, Duration};
use tokio::time::error::Elapsed;

use crate::collection::payload_index_schema::PayloadIndexSchema;
use crate::collection_manager::collection_updater::CollectionUpdater;
use crate::collection_manager::holders::segment_holder::LockedSegmentHolder;
use crate::collection_manager::optimizers::segment_optimizer::{OptimizerThresholds, SegmentOptimizer};
use crate::collection_manager::optimizers::{Tracker, TrackerLog, TrackerStatus};
use crate::common::stoppable_task::{spawn_stoppable, StoppableTaskHandle};
use crate::config::CollectionParams;
use crate::operations::shared_storage_config::SharedStorageConfig;
use crate::operations::types::{CollectionError, CollectionResult};
use crate::operations::CollectionUpdateOperations;
use crate::save_on_disk::SaveOnDisk;
use crate::shards::local_shard::LocalShardClocks;
use crate::wal::WalError;
use crate::wal_delta::LockedWal;

pub type Optimizer = dyn SegmentOptimizer + Sync + Send;

#[derive(Debug)]
pub struct OperationData {
    /// Sequential number of the operation
    pub op_num: SeqNumberType,
    /// Operation
    pub operation: CollectionUpdateOperations,
    /// If operation should wait for commit
    pub wait: bool,
    /// Callback notification channel
    pub sender: Option<oneshot::Sender<CollectionResult<usize>>>,
    /// Hardware measurements for this operation
    pub hw_measurements: HwMeasurementAcc,
}

#[derive(Debug)]
pub enum UpdateSignal {
    /// Requested operation to perform
    Operation(OperationData),
    /// Stop all optimizers and listening
    Stop,
    /// Empty signal used to trigger optimizers
    Nop,
    /// Ensures that previous updates are applied
    Plunger(oneshot::Sender<()>),
}

#[derive(PartialEq, Eq, Clone, Copy)]
pub enum OptimizerSignal {
    /// Sequential number of the operation
    Operation(SeqNumberType),
    /// Stop all optimizers and listening
    Stop,
    /// Empty signal used to trigger optimizers
    Nop,
}

pub struct UpdateHandler {
    /// Shared storage configuration
    pub shared_storage_config: Arc<SharedStorageConfig>,
    /// Payload index schema (saved on disk)
    payload_index_schema: Arc<SaveOnDisk<PayloadIndexSchema>>,
    /// List of used optimizers
    pub optimizers: Arc<Vec<Arc<Optimizer>>>,
    /// Log of optimizer statuses
    optimizers_log: Arc<Mutex<TrackerLog>>,
    /// Total number of successfully optimized points
    total_optimized_points: Arc<AtomicUsize>,
    /// Global resource budget (CPU + IO)
    optimizer_resource_budget: ResourceBudget,
    /// How frequent can we flush data
    pub flush_interval_sec: u64,
    /// Segments holder
    segments: LockedSegmentHolder,
    /// Worker listening for updates
    update_worker: Option<JoinHandle<()>>,
    /// Worker performing optimizations
    optimizer_worker: Option<JoinHandle<()>>,
    /// Flush worker
    flush_worker: Option<JoinHandle<()>>,
    /// Channel to stop flush worker
    flush_stop: Option<oneshot::Sender<()>>,
    /// Tokio runtime handle
    runtime_handle: Handle,
    /// WAL, required for operations
    #[allow(dead_code)]
    wal: LockedWal,
    /// Keep WAL version from truncating
    pub(super) wal_keep_from: Arc<AtomicU64>,
    /// Handles for running optimizations
    optimization_handles: Arc<TokioMutex<Vec<StoppableTaskHandle<bool>>>>,
    /// Maximum number of concurrent optimization jobs
    pub max_optimization_threads: Option<usize>,
    /// Clock maps for the shard
    clocks: LocalShardClocks,
    /// Path to shard directory
    shard_path: PathBuf,
    /// Has any optimizer been triggered
    has_triggered_optimizers: Arc<AtomicBool>,
}

#[allow(clippy::too_many_arguments)]
impl UpdateHandler {
    #[allow(clippy::too_many_arguments)]
    pub fn new(
        shared_storage_config: Arc<SharedStorageConfig>,
        payload_index_schema: Arc<SaveOnDisk<PayloadIndexSchema>>,
        optimizers: Arc<Vec<Arc<Optimizer>>>,
        optimizers_log: Arc<Mutex<TrackerLog>>,
        total_optimized_points: Arc<AtomicUsize>,
        optimizer_resource_budget: ResourceBudget,
        runtime_handle: Handle,
        segments: LockedSegmentHolder,
        wal: LockedWal,
        flush_interval_sec: u64,
        max_optimization_threads: Option<usize>,
        clocks: LocalShardClocks,
        shard_path: PathBuf,
    ) -> Self {
        Self {
            shared_storage_config,
            payload_index_schema,
            optimizers,
            segments,
            update_worker: None,
            optimizer_worker: None,
            optimizers_log,
            total_optimized_points,
            optimizer_resource_budget,
            flush_interval_sec,
            runtime_handle,
            wal,
            wal_keep_from: Arc::new(u64::MAX.into()),
            optimization_handles: Arc::new(TokioMutex::new(vec![])),
            max_optimization_threads,
            clocks,
            shard_path,
            has_triggered_optimizers: Default::default(),
            flush_worker: None,
            flush_stop: None,
            /* fields above are all initialized */
        }
    }

    /// Start the update and optimization workers
    pub fn run_workers(&mut self, update_receiver: Receiver<UpdateSignal>) {
        let (tx, rx) = mpsc::channel(self.shared_storage_config.update_queue_size);
        self.optimizer_worker = Some(
            self.runtime_handle.spawn(Self::optimization_worker_fn(
                self.optimizers.clone(),
                self.optimizers_log.clone(),
                self.total_optimized_points.clone(),
                self.optimizer_resource_budget.clone(),
                tx.clone(),
                rx,
                self.segments.clone(),
                self.wal.clone(),
                self.optimization_handles.clone(),
                self.max_optimization_threads,
                self.has_triggered_optimizers.clone(),
                self.payload_index_schema.clone(),
            )),
        );
        self.update_worker = Some(self.runtime_handle.spawn(Self::update_worker_fn(
            update_receiver,
            tx,
            self.segments.clone(),
        )));

        let (flush_tx, flush_rx) = oneshot::channel();
        self.flush_worker = Some(self.runtime_handle.spawn(Self::flush_worker(
            self.segments.clone(),
            self.wal.clone(),
            self.wal_keep_from.clone(),
            self.flush_interval_sec,
            flush_rx,
            self.clocks.clone(),
            self.shard_path.clone(),
        )));
        self.flush_stop = Some(flush_tx);
    }

    /// Gracefully stop all workers and join them
    pub async fn wait_workers_stops(&mut self) -> CollectionResult<()> {
        // Stop update and optimization workers
        if let Some(handle) = self.update_worker.take() {
            handle.await?;
        }
        if let Some(handle) = self.optimizer_worker.take() {
            handle.await?;
        }
        if let Some(handle) = self.flush_worker.take() {
            handle.await?;
        }

        // Join all optimization handles
        let handles = {
            let mut handles_guard = self.optimization_handles.lock().await;
            std::mem::take(&mut *handles_guard)
        };
        for handle in handles {
            // Propagate any panics from optimisation tasks
            handle.join_and_handle_panic().await;
        }

        Ok(())
    }

    /// Checks if there are any failed operations.
    /// If so, attempts to re-apply all failed operations.
    async fn try_recover(
        segments: LockedSegmentHolder,
        wal: LockedWal,
    ) -> CollectionResult<usize> {
        // Try to re-apply everything starting from the first failed operation
        let first_failed_operation_option = segments.read().failed_operation.iter().cloned().min();
        if let Some(first_failed_op) = first_failed_operation_option {
            // Get a lock on the WAL
            let wal_lock = wal.lock().await;
            for (op_num, operation) in wal_lock.read(first_failed_op) {
                CollectionUpdater::update(&segments, op_num, operation.operation)?;
            }
        }
        Ok(0)
    }

    /// Checks the optimizer conditions.
    ///
    /// Returns a tuple:
    /// - first element: whether any optimizer has ever been triggered
    /// - second element: whether any optimizer has nonâ€‘optimal work to do
    pub(crate) fn check_optimizer_conditions(&self) -> (bool, bool) {
        let has_triggered_any_optimizers = self
            .has_triggered_optimizers
            .load(Ordering::Relaxed);
        let excluded_ids = HashSet::default();
        let has_suboptimal = self
            .optimizers
            .iter()
            .any(|optimizer| {
                let nonoptimal_segment_ids = optimizer.check_condition(
                    self.segments.clone(),
                    &excluded_ids,
                );
                !nonoptimal_segment_ids.is_empty()
            });
        (has_triggered_any_optimizers, has_suboptimal)
    }

    /// Launch a set of optimization tasks, respecting the resource budget.
    ///
    /// `callback` is called with `true` if the optimizer actually performed work.
    pub(crate) fn launch_optimization<F>(
        optimizers: Arc<Vec<Arc<Optimizer>>>,
        optimizers_log: Arc<Mutex<TrackerLog>>,
        total_optimized_points: Arc<AtomicUsize>,
        resource_budget: &ResourceBudget,
        segments: LockedSegmentHolder,
        mut callback: F,
        limit: Option<usize>,
    ) -> Vec<StoppableTaskHandle<bool>>
    where
        F: Fn(bool) + Send + Clone + Sync + 'static,
    {
        let mut scheduled_segment_ids = HashSet::<_>::default();
        let mut handles = vec![];

        'outer: for optimizer in optimizers.iter() {
            loop {
                // Limit the number of optimization handles
                let limit = limit.unwrap_or(usize::MAX);
                if limit > 0 && handles.len() >= limit {
                    break 'outer;
                }

                let nonoptimal_segment_ids = optimizer.check_condition(
                    segments.clone(),
                    &scheduled_segment_ids,
                );
                if nonoptimal_segment_ids.is_empty() {
                    break;
                }

                let desired_io = num_rayon_threads(optimizer.hnsw_config().max_indexing_threads);
                let Some(mut permit) = resource_budget.try_acquire(0, desired_io)
                else {
                    // Not enough resources; exit if we have no running tasks
                    if handles.is_empty() {
                        // No tasks running â€“ trigger a callback so the scheduler can retry
                        callback(false);
                    }
                    break 'outer;
                };
                log::trace!(
                    "Acquired {} IO permit for {} optimizer",
                    permit.num_io,
                    optimizer.name(),
                );

                // Notify when the permit is released
                {
                    let callback_clone = callback.clone();
                    permit.set_on_release(move || {
                        // If an optimization finishes, re-trigger optimizers
                        callback_clone(false);
                    });
                }

                let optimizer = optimizer.clone();
                let optimizers_log = optimizers_log.clone();
                let total_optimized_points = total_optimized_points.clone();
                let segments = segments.clone();
                let nsi = nonoptimal_segment_ids.clone();

                let handle = spawn_stoppable(
                    // Stoppable optimisation task
                    {
                        let resource_budget = resource_budget.clone();
                        move |stopped| {
                            let tracker = Tracker::start(optimizer.name(), nsi.clone());
                            let tracker_handle = tracker.handle();
                            optimizers_log.lock().register(tracker);

                            // Run the optimizer, passing the permit and stop flag
                            match optimizer.as_ref().optimize(
                                segments.clone(),
                                nsi,
                                permit.clone(),
                                stopped,
                            ) {
                                // Optimizer completed
                                Ok(optimized_points) => {
                                    let was_optimized = optimized_points > 0;
                                    total_optimized_points.fetch_add(
                                        optimized_points,
                                        Ordering::Relaxed,
                                    );
                                    tracker_handle.update(TrackerStatus::Done);
                                    callback(was_optimized);
                                    true
                                }
                                // Optimizer was cancelled
                                Err(CollectionError::Cancelled { description }) => {
                                    log::debug!("Optimization cancelled - {description}");
                                    tracker_handle
                                        .update(TrackerStatus::Cancelled(description));
                                        false
                                    }
                                // Fatal error
                                Err(err) => {
                                    // Record the first error seen
                                    segments
                                        .write()
                                        .report_optimizer_error(err.clone());

                                        // Log the (fatal) error and panic
                                        log::error!("Optimization error: {err}");

                                        tracker_handle
                                            .update(TrackerStatus::Error(err.to_string()));
                                        panic!("Optimization error: {err}");
                                    }
                            }
                        }
                    },
                    // Panic handler
                    Some(Box::new(|payload| {
                        let message = panic::downcast_str(payload).unwrap_or("");
                        let separator = if !message.is_empty() { ": " } else { "" };
                        warn!(
                            "Optimization task panicked, collection may be in an unstable state{separator}{message}"
                        );
                        segments
                            .write()
                            .report_optimizer_error(CollectionError::service_error(
                                format!("Task panicked{separator}{message}"),
                            ));
                    })),
                );
                handles.push(handle);
                if handles.len() >= limit {
                    break 'outer;
                }
            }
        }
        handles
    }

    /// Push new optimization tasks, and keep a handle list.
    ///
    /// `limit` is the maximum number of concurrent optimisation tasks.
    async fn process_optimization(
        optimizers: Arc<Vec<Arc<Optimizer>>>,
        optimization_handles: Arc<TokioMutex<Vec<StoppableTaskHandle<bool>>>>,
        optimizers_log: Arc<Mutex<TrackerLog>>,
        total_optimized_points: Arc<AtomicUsize>,
        resource_budget: &ResourceBudget,
        sender: Sender<OptimizerSignal>,
        limit: usize,
    ) {
        let new_handles = Self::launch_optimization(
            optimizers.clone(),
            optimizers_log.clone(),
            total_optimized_points.clone(),
            resource_budget,
            optimization_handles.clone(),
            limit,
        );
        let mut handles_guard = optimization_handles.lock().await;
        handles_guard.extend(new_handles);
        // Retain only unfinished handles
        handles_guard.retain(|handle| !handle.is_finished());
    }

    async fn optimization_worker_fn(
        optimizers: Arc<Vec<Arc<Optimizer>>>,
        optimizers_log: Arc<Mutex<TrackerLog>>,
        total_optimized_points: Arc<AtomicUsize>,
        resource_budget: ResourceBudget,
        sender: Sender<OptimizerSignal>,
        max_handles: Option<usize>,
        has_triggered_optimizers: Arc<AtomicBool>,
        payload_index_schema: Arc<SaveOnDisk<PayloadIndexSchema>>,
    ) {
        // Process optimiser signals until `Stop`
        let mut cpu_available_trigger: Option<JoinHandle<()>> = None;
        loop {
            let result = tokio::time::timeout(OPTIMIZER_CLEANUP_INTERVAL, receiver.recv()).await;

            // Clean up any finished optimisation tasks
            let _ = Self::cleanup_optimization_handles(optimization_handles.clone()).await;

            match result {
                // Received a stop signal or channel closed
                Ok(None | Some(OptimizerSignal::Stop)) => break,
                // Clean up timeout â€“ continue waiting
                Err(Elapsed { .. }) => continue,
                // Received an optimizer signal
                Ok(Some(signal @ (OptimizerSignal::Nop | OptimizerSignal::Operation(_)))) => {
                    has_triggered_optimizers.store(true, Ordering::Relaxed);
                }

                // Ensure we have an appendable segment with enough capacity
                if let Some(optimizer) = optimizers.first() {
                    if let Err(err) = Self::ensure_appendable_segment_with_capacity(
                        &segments,
                        optimizer.segments_path(),
                        &optimizer.collection_params(),
                        optimizer.threshold_config(),
                        &payload_index_schema.read(),
                    ) {
                        log::error!("Failed to ensure appendable segment: {err}");
                        panic!("Failed to ensure appendable segment: {err}");
                    }
                }

                // If we have already too many optimisation handles, skip
                if !ignore_max_handles && optimization_handles.lock().await.len()
                    >= max_handles
                {
                    continue;
                }

                // Ensure we have resources for optimisation
                let desired_io = num_rayon_threads(optimizers.first().map_or(0, |o|
                    o.hnsw_config().max_indexing_threads));
                if !resource_budget.has_budget(0, desired_io) {
                    // Start a task to trigger when resources become available
                    if cpu_available_trigger
                        .as_ref()
                        .map_or(false, |t| t.is_finished())
                    {
                        cpu_available_trigger.replace(
                            resource_trigger_on_budget(
                                resource_budget.clone(),
                                0,
                                desired_io,
                                sender.clone(),
                            ),
                        );
                    }
                    continue;
                }

                // Compute how many more optimisation tasks we may spawn
                let limit = max_handles.saturating_sub(optimization_handles.lock().await.len());

                // Actually launch an optimisation
                self.process_optimization(
                    optimizers.clone(),
                    optimization_handles.clone(),
                    optimizers_log.clone(),
                    total_optimized_points.clone(),
                    &resource_budget,
                    sender.clone(),
                    limit,
                )
                .await;
            }
        }
    }

    async fn update_worker_fn(
        mut receiver: Receiver<UpdateSignal>,
        optimize_sender: Sender<OptimizerSignal>,
        segments: LockedSegmentHolder,
    ) {
        const UNSET: usize = usize::MAX;

        while let Some(signal) = receiver.recv().await {
            match signal {
                UpdateSignal::Operation(OperationData {
                    op_num,
                    operation,
                    wait,
                    sender,
                    hw_measurements,
                }) => {
                    let flush_res = if wait {
                        // Flush WAL before performing the operation
                        wal.lock().await.flush().map_err(|err| {
                            CollectionError::service_error(format!(
                                "Can't flush WAL before operation {op_num} - {err}"
                            ))
                        })
                    } else {
                        Ok(())
                    };

                    let operation_result = flush_res.and_then(|_| {
                        CollectionUpdater::update(
                            &segments,
                            op_num,
                            operation,
                            &hw_measurements.get_counter_cell(),
                        )
                    });

                    let res = match operation_result {
                        Ok(res) => optimize_sender
                            .send(OptimizerSignal::Operation(op_num))
                            .and(Ok(res))
                            .map_err(|msg| msg.into()),
                        Err(e) => Err(e),
                    };

                    if let Some(feedback) = sender {
                        let _ = feedback.send(res).unwrap_or_else(|_| {
                            debug!("Can't report operation {op_num} result. Assume already not required");
                        });
                    }
                }
                UpdateSignal::Stop => {
                    let _ = optimize_sender.send(OptimizerSignal::Stop).unwrap_or_else(|_| {
                        debug!("Optimizer already stopped")
                    });
                    break;
                }
                UpdateSignal::Nop => {
                    let _ = optimize_sender.send(OptimizerSignal::Nop).unwrap_or_else(|_| {
                        info!("Can't notify optimizers, assume process is dead. Restart is required")
                    });
                }
                UpdateSignal::Plunger(chan) => {
                    let _ = chan.send(());
                }
            }
        }
        // Transmitter dropped; stop optimizer
        let _ = optimize_sender.send(OptimizerSignal::Stop).unwrap_or_else(|_| {
            debug!("Optimizer already stopped")
        });
    }

    async fn flush_worker(
        segments: LockedSegmentHolder,
        wal: LockedWal,
        wal_keep_from: Arc<AtomicU64>,
        flush_interval_sec: u64,
        mut stop: oneshot::Receiver<()>,
        clocks: LocalShardClocks,
        shard_path: PathBuf,
    ) {
        loop {
            // Wait for either a timer tick or a stop signal
            tokio::select! {
                _ = tokio::time::sleep(Duration::from_secs(flush_interval_sec)) => {}
                _ = &mut stop => { debug!("Stopping flush worker for {}", shard_path.display()); return; }
            }

            // Flush segment data
            let confirmed_version = match Self::flush_segments(segments.clone()) {
                Ok(v) => v,
                Err(e) => {
                    segments
                        .write()
                        .report_optimizer_error(e);
                    continue;
                }
            };

            // Ack and store clock maps if needed
            if let Err(err) = clocks.store_if_changed(&shard_path).await {
                log::warn!("Failed to store clock maps: {err}");
                segments.write().report_optimizer_error(err);
            }

            // Stop updating WAL if we are keeping at least one version
            let keep = wal_keep_from.load(Ordering::Relaxed);
            if keep != 0 {
                let ack = confirmed_version.min(keep.saturating_sub(1));
                if let Err(e) = wal.lock().await.ack(ack) {
                    log::warn!("Failed to ack WAL version {ack}: {e}");
                    segments.write().report_optimizer_error(e);
                }
            }
        }
    }

    fn flush_segments(segments: LockedSegmentHolder) -> Result<u64, OperationError> {
        let read = segments.read();
        let flushed = read.flush_all(true, false)?;
        Ok(if let Some(min_failed) = read.failed_operation.iter().cloned().min() {
            min(flushed, min_failed)
        } else {
            flushed
        })
    }
}
```

(Note: The above is a highâ€‘level, illustrative reconstruction of the final `update_handler.rs` after all commits, with the logic consolidated and updated to reflect the latest changes, including resource budgeting, optimization handling, hardware measurement integration, and revised concurrency handling.)