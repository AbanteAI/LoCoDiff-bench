
index cb922e86..83b540b9 100644
--- a/qdrant_lib_collection_src_update_handler.rs_expectedoutput.txt (expected):tmp/tmp10wj28tg_expected.txt	
+++ b/qdrant_lib_collection_src_update_handler.rs_extracted.txt (actual):tmp/tmpsy45g13c_actual.txt	
@@ -1,8 +1,8 @@
 use std::cmp::min;
 use std::collections::HashSet;
 use std::path::{Path, PathBuf};
-use std::sync::Arc;
 use std::sync::atomic::{AtomicBool, AtomicU64, AtomicUsize, Ordering};
+use std::sync::Arc;
 
 use common::budget::ResourceBudget;
 use common::counter::hardware_accumulator::HwMeasurementAcc;
@@ -16,10 +16,10 @@ use segment::index::hnsw_index::num_rayon_threads;
 use segment::types::SeqNumberType;
 use tokio::runtime::Handle;
 use tokio::sync::mpsc::{self, Receiver, Sender};
-use tokio::sync::{Mutex as TokioMutex, oneshot};
+use tokio::sync::{oneshot, Mutex as TokioMutex};
 use tokio::task::{self, JoinHandle};
 use tokio::time::error::Elapsed;
-use tokio::time::{Duration, timeout};
+use tokio::time::{timeout, Duration};
 
 use crate::collection::payload_index_schema::PayloadIndexSchema;
 use crate::collection_manager::collection_updater::CollectionUpdater;
@@ -28,19 +28,16 @@ use crate::collection_manager::optimizers::segment_optimizer::{
     OptimizerThresholds, SegmentOptimizer,
 };
 use crate::collection_manager::optimizers::{Tracker, TrackerLog, TrackerStatus};
-use crate::common::stoppable_task::{StoppableTaskHandle, spawn_stoppable};
+use crate::common::stoppable_task::{spawn_stoppable, StoppableTaskHandle};
 use crate::config::CollectionParams;
-use crate::operations::CollectionUpdateOperations;
 use crate::operations::shared_storage_config::SharedStorageConfig;
 use crate::operations::types::{CollectionError, CollectionResult};
+use crate::operations::CollectionUpdateOperations;
 use crate::save_on_disk::SaveOnDisk;
 use crate::shards::local_shard::LocalShardClocks;
 use crate::wal::WalError;
 use crate::wal_delta::LockedWal;
 
-/// Interval at which the optimizer worker cleans up old optimization handles
-///
-/// The longer the duration, the longer it  takes for panicked tasks to be reported.
 const OPTIMIZER_CLEANUP_INTERVAL: Duration = Duration::from_secs(5);
 
 pub type Optimizer = dyn SegmentOptimizer + Sync + Send;
@@ -56,6 +53,7 @@ pub struct OperationData {
     pub wait: bool,
     /// Callback notification channel
     pub sender: Option<oneshot::Sender<CollectionResult<usize>>>,
+    /// Hardware measurements accumulator
     pub hw_measurements: HwMeasurementAcc,
 }
 
@@ -93,8 +91,7 @@ pub struct UpdateHandler {
     optimizers_log: Arc<Mutex<TrackerLog>>,
     /// Total number of optimized points since last start
     total_optimized_points: Arc<AtomicUsize>,
-    /// Global CPU budget in number of cores for all optimization tasks.
-    /// Assigns CPU permits to tasks to limit overall resource utilization.
+    /// Global resource budget for optimization tasks.
     optimizer_resource_budget: ResourceBudget,
     /// How frequent can we flush data
     /// This parameter depends on the optimizer config and should be updated accordingly.
@@ -104,7 +101,7 @@ pub struct UpdateHandler {
     update_worker: Option<JoinHandle<()>>,
     /// Process, that listens for post-update signals and performs optimization
     optimizer_worker: Option<JoinHandle<()>>,
-    /// Process that periodically flushes segments and tries to truncate wal
+    /// WAL & flush worker
     flush_worker: Option<JoinHandle<()>>,
     /// Sender to stop flush worker
     flush_stop: Option<oneshot::Sender<()>>,
@@ -170,6 +167,7 @@ impl UpdateHandler {
 
     pub fn run_workers(&mut self, update_receiver: Receiver<UpdateSignal>) {
         let (tx, rx) = mpsc::channel(self.shared_storage_config.update_queue_size);
+
         self.optimizer_worker = Some(self.runtime_handle.spawn(Self::optimization_worker_fn(
             self.optimizers.clone(),
             tx.clone(),
@@ -184,12 +182,14 @@ impl UpdateHandler {
             self.has_triggered_optimizers.clone(),
             self.payload_index_schema.clone(),
         )));
+
         self.update_worker = Some(self.runtime_handle.spawn(Self::update_worker_fn(
             update_receiver,
             tx,
             self.wal.clone(),
             self.segments.clone(),
         )));
+
         let (flush_tx, flush_rx) = oneshot::channel();
         self.flush_worker = Some(self.runtime_handle.spawn(Self::flush_worker(
             self.segments.clone(),
@@ -203,16 +203,9 @@ impl UpdateHandler {
         self.flush_stop = Some(flush_tx);
     }
 
-    pub fn stop_flush_worker(&mut self) {
-        if let Some(flush_stop) = self.flush_stop.take() {
-            if let Err(()) = flush_stop.send(()) {
-                warn!("Failed to stop flush worker as it is already stopped.");
-            }
-        }
-    }
-
     /// Gracefully wait before all optimizations stop
     /// If some optimization is in progress - it will be finished before shutdown.
+    /// Blocking function.
     pub async fn wait_workers_stops(&mut self) -> CollectionResult<()> {
         let maybe_handle = self.update_worker.take();
         if let Some(handle) = maybe_handle {
@@ -222,11 +215,6 @@ impl UpdateHandler {
         if let Some(handle) = maybe_handle {
             handle.await?;
         }
-        let maybe_handle = self.flush_worker.take();
-        if let Some(handle) = maybe_handle {
-            handle.await?;
-        }
-
         let mut opt_handles_guard = self.optimization_handles.lock().await;
         let opt_handles = std::mem::take(&mut *opt_handles_guard);
         let stopping_handles = opt_handles
@@ -237,7 +225,6 @@ impl UpdateHandler {
         for res in stopping_handles {
             res.await?;
         }
-
         Ok(())
     }
 
@@ -280,7 +267,6 @@ impl UpdateHandler {
     {
         let mut scheduled_segment_ids = HashSet::<_>::default();
         let mut handles = vec![];
-
         'outer: for optimizer in optimizers.iter() {
             loop {
                 // Return early if we reached the optimization job limit
@@ -321,7 +307,6 @@ impl UpdateHandler {
                 );
 
                 let permit_callback = callback.clone();
-
                 permit.set_on_release(move || {
                     // Notify scheduler that resource budget changed
                     permit_callback(false);
@@ -339,7 +324,6 @@ impl UpdateHandler {
                     // Stoppable task
                     {
                         let resource_budget = optimizer_resource_budget.clone();
-                        let segments = segments.clone();
                         move |stopped| {
                             // Track optimizer status
                             let tracker = Tracker::start(optimizer.as_ref().name(), nsi.clone());
@@ -409,75 +393,9 @@ impl UpdateHandler {
                 handles.push(handle);
             }
         }
-
         handles
     }
 
-    /// Ensure there is at least one appendable segment with enough capacity
-    ///
-    /// If there is no appendable segment, or all are at or over capacity, a new empty one is
-    /// created.
-    ///
-    /// Capacity is determined based on `optimizers.max_segment_size_kb`.
-    pub(super) fn ensure_appendable_segment_with_capacity(
-        segments: &LockedSegmentHolder,
-        segments_path: &Path,
-        collection_params: &CollectionParams,
-        thresholds_config: &OptimizerThresholds,
-        payload_index_schema: &PayloadIndexSchema,
-    ) -> OperationResult<()> {
-        let no_segment_with_capacity = {
-            let segments_read = segments.read();
-            segments_read
-                .appendable_segments_ids()
-                .into_iter()
-                .filter_map(|segment_id| segments_read.get(segment_id))
-                .all(|segment| {
-                    let max_vector_size_bytes = segment
-                        .get()
-                        .read()
-                        .max_available_vectors_size_in_bytes()
-                        .unwrap_or_default();
-                    let max_segment_size_bytes = thresholds_config
-                        .max_segment_size_kb
-                        .saturating_mul(segment::common::BYTES_IN_KB);
-
-                    max_vector_size_bytes >= max_segment_size_bytes
-                })
-        };
-
-        if no_segment_with_capacity {
-            log::debug!("Creating new appendable segment, all existing segments are over capacity");
-            segments.write().create_appendable_segment(
-                segments_path,
-                collection_params,
-                payload_index_schema,
-            )?;
-        }
-
-        Ok(())
-    }
-
-    /// Checks the optimizer conditions.
-    ///
-    /// This function returns a tuple of two booleans:
-    /// - The first indicates if any optimizers have been triggered since startup.
-    /// - The second indicates if there are any pending/suboptimal optimizers.
-    pub(crate) fn check_optimizer_conditions(&self) -> (bool, bool) {
-        // Check if Qdrant triggered any optimizations since starting at all
-        let has_triggered_any_optimizers = self.has_triggered_optimizers.load(Ordering::Relaxed);
-
-        let excluded_ids = HashSet::<_>::default();
-        let has_suboptimal_optimizers = self.optimizers.iter().any(|optimizer| {
-            let nonoptimal_segment_ids =
-                optimizer.check_condition(self.segments.clone(), &excluded_ids);
-            !nonoptimal_segment_ids.is_empty()
-        });
-
-        (has_triggered_any_optimizers, has_suboptimal_optimizers)
-    }
-
-    #[allow(clippy::too_many_arguments)]
     pub(crate) async fn process_optimization(
         optimizers: Arc<Vec<Arc<Optimizer>>>,
         segments: LockedSegmentHolder,
@@ -505,6 +423,7 @@ impl UpdateHandler {
         );
         let mut handles = optimization_handles.lock().await;
         handles.append(&mut new_handles);
+        handles.retain(|h| !h.is_finished())
     }
 
     /// Cleanup finalized optimization task handles
@@ -654,7 +573,7 @@ impl UpdateHandler {
             // Determine optimization handle limit based on max handles we allow
             // Not related to the CPU budget, but a different limit for the maximum number
             // of concurrent concrete optimizations per shard as configured by the user in
-            // the Qdrant configuration.
+            // the Qdrant(configuration).
             // Skip if we reached limit, an ongoing optimization that finishes will trigger this loop again
             let limit = max_handles.saturating_sub(optimization_handles.lock().await.len());
             if limit == 0 {
@@ -676,6 +595,70 @@ impl UpdateHandler {
         }
     }
 
+    /// Ensure there is at least one appendable segment with enough capacity
+    ///
+    /// If there is no appendable segment, or all are at or over capacity, a new empty one is
+    /// created.
+    ///
+    /// Capacity is determined based on `optimizers.max_segment_size_kb`.
+    pub(super) fn ensure_appendable_segment_with_capacity(
+        segments: &LockedSegmentHolder,
+        segments_path: &Path,
+        collection_params: &CollectionParams,
+        thresholds_config: &OptimizerThresholds,
+        payload_index_schema: &PayloadIndexSchema,
+    ) -> OperationResult<()> {
+        let no_segment_with_capacity = {
+            let segments_read = segments.read();
+            segments_read
+                .appendable_segments_ids()
+                .into_iter()
+                .filter_map(|segment_id| segments_read.get(segment_id))
+                .all(|segment| {
+                    let max_vector_size_bytes = segment
+                        .get()
+                        .read()
+                        .max_available_vectors_size_in_bytes()
+                        .unwrap_or_default();
+                    let max_segment_size_bytes = thresholds_config
+                        .max_segment_size_kb
+                        .saturating_mul(segment::common::BYTES_IN_KB);
+
+                    max_vector_size_bytes >= max_segment_size_bytes
+                })
+        };
+
+        if no_segment_with_capacity {
+            log::debug!("Creating new appendable segment, all existing segments are over capacity");
+            segments.write().create_appendable_segment(
+                segments_path,
+                collection_params,
+                payload_index_schema,
+            )?;
+        }
+
+        Ok(())
+    }
+
+    /// Checks the optimizer conditions.
+    ///
+    /// This function returns a tuple of two booleans:
+    /// - The first indicates if any optimizers have been triggered since startup.
+    /// - The second indicates if there are any pending/suboptimal optimizers.
+    pub(crate) fn check_optimizer_conditions(&self) -> (bool, bool) {
+        // Check if Qdrant triggered any optimizations since starting at all
+        let has_triggered_any_optimizers = self.has_triggered_optimizers.load(Ordering::Relaxed);
+
+        let excluded_ids = HashSet::<_>::default();
+        let has_suboptimal_optimizers = self.optimizers.iter().any(|optimizer| {
+            let nonoptimal_segment_ids =
+                optimizer.check_condition(self.segments.clone(), &excluded_ids);
+            !nonoptimal_segment_ids.is_empty()
+        });
+
+        (has_triggered_any_optimizers, has_suboptimal_optimizers)
+    }
+
     async fn update_worker_fn(
         mut receiver: Receiver<UpdateSignal>,
         optimize_sender: Sender<OptimizerSignal>,
@@ -772,7 +755,7 @@ impl UpdateHandler {
                     debug!("Stopping flush worker for shard {}", shard_path.display());
                     return;
                 }
-            }
+            };
 
             trace!("Attempting flushing");
             let wal_flash_job = wal.lock().await.flush_async();
@@ -823,7 +806,7 @@ impl UpdateHandler {
         }
     }
 
-    /// Returns confirmed version after flush of all segments
+    /// Returns confirmed version after flush of all segements
     ///
     /// # Errors
     /// Returns an error on flush failure
@@ -837,7 +820,7 @@ impl UpdateHandler {
     }
 }
 
-/// Trigger optimizers when CPU budget is available
+/// Trigger optimizers when resource budget is available
 fn trigger_optimizers_on_resource_budget(
     optimizer_resource_budget: ResourceBudget,
     desired_cpus: usize,
