--- qdrant_lib_collection_tests_integration_collection_test.rs_expectedoutput.txt (expected)+++ qdrant_lib_collection_tests_integration_collection_test.rs_extracted.txt (actual)@@ -343,7 +343,6 @@     let _read_obj2: CollectionUpdateOperations = rmp_serde::from_slice(&raw_bytes).unwrap();
 }
 
-// Request to find points sent to all shards but they might not have a particular id, so they will return an error
 #[tokio::test(flavor = "multi_thread")]
 async fn test_recommendation_api() {
     test_recommendation_api_with_shards(1).await;
@@ -760,148 +759,4 @@             .points
             .iter()
             .fold(HashMap::<PointIdType, usize, _>::new(), |mut acc, point| {
-                acc.entry(point.id)
-                    .and_modify(|x| {
-                        *x += 1;
-                    })
-                    .or_insert(1);
-                acc
-            })
-            .values()
-            .all(|&x| x == 2),
-    );
-}
-
-#[tokio::test(flavor = "multi_thread")]
-async fn test_collection_delete_points_by_filter() {
-    test_collection_delete_points_by_filter_with_shards(1).await;
-    test_collection_delete_points_by_filter_with_shards(N_SHARDS).await;
-}
-
-async fn test_collection_delete_points_by_filter_with_shards(shard_number: u32) {
-    let collection_dir = Builder::new().prefix("collection").tempdir().unwrap();
-
-    let collection = simple_collection_fixture(collection_dir.path(), shard_number).await;
-
-    let batch = BatchPersisted {
-        ids: vec![0, 1, 2, 3, 4]
-            .into_iter()
-            .map(|x| x.into())
-            .collect_vec(),
-        vectors: BatchVectorStructPersisted::Single(vec![
-            vec![1.0, 0.0, 1.0, 1.0],
-            vec![1.0, 0.0, 1.0, 0.0],
-            vec![1.0, 1.0, 1.0, 1.0],
-            vec![1.0, 1.0, 0.0, 1.0],
-            vec![1.0, 0.0, 0.0, 0.0],
-        ]),
-        payloads: None,
-    };
-
-    let insert_points = CollectionUpdateOperations::PointOperation(PointOperations::UpsertPoints(
-        PointInsertOperationsInternal::from(batch),
-    ));
-
-    let hw_counter = HwMeasurementAcc::new();
-    let insert_result = collection
-        .update_from_client_simple(
-            insert_points,
-            true,
-            WriteOrdering::default(),
-            hw_counter.clone(),
-        )
-        .await;
-
-    match insert_result {
-        Ok(res) => {
-            assert_eq!(res.status, UpdateStatus::Completed)
-        }
-        Err(err) => panic!("operation failed: {err:?}"),
-    }
-
-    // delete points with id (0, 3)
-    let to_be_deleted: AHashSet<PointIdType> = vec![0.into(), 3.into()].into_iter().collect();
-    let delete_filter =
-        segment::types::Filter::new_must(Condition::HasId(HasIdCondition::from(to_be_deleted)));
-
-    let delete_points = CollectionUpdateOperations::PointOperation(
-        PointOperations::DeletePointsByFilter(delete_filter),
-    );
-
-    let delete_result = collection
-        .update_from_client_simple(delete_points, true, WriteOrdering::default(), hw_counter)
-        .await;
-
-    match delete_result {
-        Ok(res) => {
-            assert_eq!(res.status, UpdateStatus::Completed)
-        }
-        Err(err) => panic!("operation failed: {err:?}"),
-    }
-
-    let result = collection
-        .scroll_by(
-            ScrollRequestInternal {
-                offset: None,
-                limit: Some(10),
-                filter: None,
-                with_payload: Some(WithPayloadInterface::Bool(false)),
-                with_vector: false.into(),
-                order_by: None,
-            },
-            None,
-            &ShardSelectorInternal::All,
-            None,
-            HwMeasurementAcc::new(),
-        )
-        .await
-        .unwrap();
-
-    // check if we only have 3 out of 5 points left and that the point id were really deleted
-    assert_eq!(result.points.len(), 3);
-    assert_eq!(result.points.first().unwrap().id, 1.into());
-    assert_eq!(result.points.get(1).unwrap().id, 2.into());
-    assert_eq!(result.points.get(2).unwrap().id, 4.into());
-}
-
-#[tokio::test(flavor = "multi_thread")]
-async fn test_collection_local_load_initializing_not_stuck() {
-    let collection_dir = Builder::new().prefix("collection").tempdir().unwrap();
-
-    // Create and unload collection
-    simple_collection_fixture(collection_dir.path(), 1).await;
-
-    // Modify replica state file on disk, set state to Initializing
-    // This is to simulate a situation where a collection was not fully created, we cannot create
-    // this situation through our collection interface
-    {
-        let replica_state_path = collection_dir.path().join("0/replica_state.json");
-        let replica_state_file = File::open(&replica_state_path).unwrap();
-        let mut replica_set_state: ReplicaSetState =
-            serde_json::from_reader(replica_state_file).unwrap();
-
-        for peer_id in replica_set_state.peers().into_keys() {
-            replica_set_state.set_peer_state(peer_id, ReplicaState::Initializing);
-        }
-
-        let replica_state_file = File::create(&replica_state_path).unwrap();
-        serde_json::to_writer(replica_state_file, &replica_set_state).unwrap();
-    }
-
-    // Reload collection
-    let collection_path = collection_dir.path();
-    let loaded_collection = load_local_collection(
-        "test".to_string(),
-        collection_path,
-        &collection_path.join("snapshots"),
-    )
-    .await;
-
-    // Local replica must be in Active state after loading (all replicas are local)
-    let loaded_state = loaded_collection.state().await;
-    for shard_info in loaded_state.shards.values() {
-        for replica_state in shard_info.replicas.values() {
-            assert_eq!(replica_state, &ReplicaState::Active);
-        }
-    }
-}+                acc.entry(