
index 7f71a6bd..f4ce2063 100644
--- a/qdrant_lib_collection_tests_integration_collection_test.rs_expectedoutput.txt (expected):tmp/tmp2_cadeg__expected.txt	
+++ b/qdrant_lib_collection_tests_integration_collection_test.rs_extracted.txt (actual):tmp/tmpps6ek8d2_actual.txt	
@@ -7,7 +7,7 @@ use collection::operations::CollectionUpdateOperations;
 use collection::operations::payload_ops::{PayloadOps, SetPayloadOp};
 use collection::operations::point_ops::{
     BatchPersisted, BatchVectorStructPersisted, PointInsertOperationsInternal, PointOperations,
-    PointStructPersisted, VectorStructPersisted, WriteOrdering,
+    PointStructPersisted, WriteOrdering,
 };
 use collection::operations::shard_selector_internal::ShardSelectorInternal;
 use collection::operations::types::{
@@ -55,9 +55,10 @@ async fn test_collection_updater_with_shards(shard_number: u32) {
         payloads: None,
     };
 
-    let insert_points = CollectionUpdateOperations::PointOperation(PointOperations::UpsertPoints(
-        PointInsertOperationsInternal::from(batch),
-    ));
+    let insert_points =
+        CollectionUpdateOperations::PointOperation(PointOperations::UpsertPoints(
+            PointInsertOperationsInternal::from(batch),
+        ));
 
     let hw_counter = HwMeasurementAcc::new();
     let insert_result = collection
@@ -84,13 +85,7 @@ async fn test_collection_updater_with_shards(shard_number: u32) {
 
     let hw_acc = HwMeasurementAcc::new();
     let search_res = collection
-        .search(
-            search_request.into(),
-            None,
-            &ShardSelectorInternal::All,
-            None,
-            hw_acc,
-        )
+        .search(search_request.into(), None, &ShardSelectorInternal::All, None, hw_acc)
         .await;
 
     match search_res {
@@ -126,9 +121,10 @@ async fn test_collection_search_with_payload_and_vector_with_shards(shard_number
         .unwrap(),
     };
 
-    let insert_points = CollectionUpdateOperations::PointOperation(PointOperations::UpsertPoints(
-        PointInsertOperationsInternal::from(batch),
-    ));
+    let insert_points =
+        CollectionUpdateOperations::PointOperation(PointOperations::UpsertPoints(
+            PointInsertOperationsInternal::from(batch),
+        ));
 
     let hw_counter = HwMeasurementAcc::new();
     let insert_result = collection
@@ -155,13 +151,7 @@ async fn test_collection_search_with_payload_and_vector_with_shards(shard_number
 
     let hw_acc = HwMeasurementAcc::new();
     let search_res = collection
-        .search(
-            search_request.into(),
-            None,
-            &ShardSelectorInternal::All,
-            None,
-            hw_acc,
-        )
+        .search(search_request.into(), None, &ShardSelectorInternal::All, None, hw_acc)
         .await;
 
     match search_res {
@@ -190,13 +180,7 @@ async fn test_collection_search_with_payload_and_vector_with_shards(shard_number
 
     let hw_acc = HwMeasurementAcc::new();
     let count_res = collection
-        .count(
-            count_request,
-            None,
-            &ShardSelectorInternal::All,
-            None,
-            hw_acc,
-        )
+        .count(count_request, None, &ShardSelectorInternal::All, None, hw_acc)
         .await
         .unwrap();
     assert_eq!(count_res.count, 1);
@@ -214,7 +198,6 @@ async fn test_collection_loading_with_shards(shard_number: u32) {
 
     {
         let collection = simple_collection_fixture(collection_dir.path(), shard_number).await;
-
         let batch = BatchPersisted {
             ids: vec![0, 1, 2, 3, 4]
                 .into_iter()
@@ -230,9 +213,10 @@ async fn test_collection_loading_with_shards(shard_number: u32) {
             payloads: None,
         };
 
-        let insert_points = CollectionUpdateOperations::PointOperation(
-            PointOperations::UpsertPoints(PointInsertOperationsInternal::from(batch)),
-        );
+        let insert_points =
+            CollectionUpdateOperations::PointOperation(PointOperations::UpsertPoints(
+                PointInsertOperationsInternal::from(batch),
+            ));
 
         let hw_counter = HwMeasurementAcc::new();
         collection
@@ -242,13 +226,14 @@ async fn test_collection_loading_with_shards(shard_number: u32) {
 
         let payload: Payload = serde_json::from_str(r#"{"color":"red"}"#).unwrap();
 
-        let assign_payload =
-            CollectionUpdateOperations::PayloadOperation(PayloadOps::SetPayload(SetPayloadOp {
+        let assign_payload = CollectionUpdateOperations::PayloadOperation(
+            PayloadOps::SetPayload(SetPayloadOp {
                 payload,
                 points: Some(vec![2.into(), 3.into()]),
                 filter: None,
                 key: None,
-            }));
+            }),
+        );
 
         let hw_counter = HwMeasurementAcc::new();
         collection
@@ -270,13 +255,7 @@ async fn test_collection_loading_with_shards(shard_number: u32) {
         with_vector: true.into(),
     };
     let retrieved = loaded_collection
-        .retrieve(
-            request,
-            None,
-            &ShardSelectorInternal::All,
-            None,
-            HwMeasurementAcc::new(),
-        )
+        .retrieve(request, None, &ShardSelectorInternal::All, None, HwMeasurementAcc::new())
         .await
         .unwrap();
 
@@ -303,9 +282,10 @@ fn test_deserialization() {
         payloads: None,
     };
 
-    let insert_points = CollectionUpdateOperations::PointOperation(PointOperations::UpsertPoints(
-        PointInsertOperationsInternal::from(batch),
-    ));
+    let insert_points =
+        CollectionUpdateOperations::PointOperation(PointOperations::UpsertPoints(
+            PointInsertOperationsInternal::from(batch),
+        ));
     let json_str = serde_json::to_string_pretty(&insert_points).unwrap();
 
     let _read_obj: CollectionUpdateOperations = serde_json::from_str(&json_str).unwrap();
@@ -330,9 +310,10 @@ fn test_deserialization2() {
         },
     ];
 
-    let insert_points = CollectionUpdateOperations::PointOperation(PointOperations::UpsertPoints(
-        PointInsertOperationsInternal::from(points),
-    ));
+    let insert_points =
+        CollectionUpdateOperations::PointOperation(PointOperations::UpsertPoints(
+            PointInsertOperationsInternal::from(points),
+        ));
 
     let json_str = serde_json::to_string_pretty(&insert_points).unwrap();
 
@@ -373,18 +354,14 @@ async fn test_recommendation_api_with_shards(shard_number: u32) {
         payloads: None,
     };
 
-    let insert_points = CollectionUpdateOperations::PointOperation(PointOperations::UpsertPoints(
-        PointInsertOperationsInternal::from(batch),
-    ));
+    let insert_points =
+        CollectionUpdateOperations::PointOperation(PointOperations::UpsertPoints(
+            PointInsertOperationsInternal::from(batch),
+        ));
 
     let hw_acc = HwMeasurementAcc::new();
     collection
-        .update_from_client_simple(
-            insert_points,
-            true,
-            WriteOrdering::default(),
-            hw_acc.clone(),
-        )
+        .update_from_client_simple(insert_points, true, WriteOrdering::default(), hw_acc.clone())
         .await
         .unwrap();
     let result = recommend_by(
@@ -438,9 +415,10 @@ async fn test_read_api_with_shards(shard_number: u32) {
         payloads: None,
     };
 
-    let insert_points = CollectionUpdateOperations::PointOperation(PointOperations::UpsertPoints(
-        PointInsertOperationsInternal::from(batch),
-    ));
+    let insert_points =
+        CollectionUpdateOperations::PointOperation(PointOperations::UpsertPoints(
+            PointInsertOperationsInternal::from(batch),
+        ));
 
     let hw_counter = HwMeasurementAcc::new();
     collection
@@ -470,6 +448,93 @@ async fn test_read_api_with_shards(shard_number: u32) {
     assert_eq!(result.points.len(), 2);
 }
 
+#[tokio::test(flavor = "multi_thread")]
+async fn test_collection_delete_points_by_filter() {
+    test_collection_delete_points_by_filter_with_shards(1).await;
+    test_collection_delete_points_by_filter_with_shards(N_SHARDS).await;
+}
+
+async fn test_collection_delete_points_by_filter_with_shards(shard_number: u32) {
+    let collection_dir = Builder::new().prefix("collection").tempdir().unwrap();
+
+    let collection = simple_collection_fixture(collection_dir.path(), shard_number).await;
+
+    let batch = BatchPersisted {
+        ids: vec![0, 1, 2, 3, 4]
+            .into_iter()
+            .map(|x| x.into())
+            .collect_vec(),
+        vectors: BatchVectorStructPersisted::Single(vec![
+            vec![1.0, 0.0, 1.0, 1.0],
+            vec![1.0, 0.0, 1.0, 0.0],
+            vec![1.0, 1.0, 1.0, 1.0],
+            vec![1.0, 1.0, 0.0, 1.0],
+            vec![1.0, 0.0, 0.0, 0.0],
+        ]),
+        payloads: None,
+    };
+
+    let insert_points =
+        CollectionUpdateOperations::PointOperation(PointOperations::UpsertPoints(
+            PointInsertOperationsInternal::from(batch),
+        ));
+
+    let hw_counter = HwMeasurementAcc::new();
+    let insert_result = collection
+        .update_from_client_simple(insert_points, true, WriteOrdering::default(), hw_counter.clone())
+        .await;
+
+    match insert_result {
+        Ok(res) => {
+            assert_eq!(res.status, UpdateStatus::Completed)
+        }
+        Err(err) => panic!("operation failed: {err:?}"),
+    }
+
+    // delete points with id (0, 3)
+    let to_be_deleted: AHashSet<PointIdType> = vec![0.into(), 3.into()].into_iter().collect();
+    let delete_filter =
+        segment::types::Filter::new_must(Condition::HasId(HasIdCondition::from(to_be_deleted)));
+
+    let delete_points =
+        CollectionUpdateOperations::PointOperation(PointOperations::DeletePointsByFilter(delete_filter));
+
+    let delete_result = collection
+        .update_from_client_simple(delete_points, true, WriteOrdering::default(), hw_counter)
+        .await;
+
+    match delete_result {
+        Ok(res) => {
+            assert_eq!(res.status, UpdateStatus::Completed)
+        }
+        Err(err) => panic!("operation failed: {err:?}"),
+    }
+
+    let result = collection
+        .scroll_by(
+            ScrollRequestInternal {
+                offset: None,
+                limit: Some(10),
+                filter: None,
+                with_payload: Some(WithPayloadInterface::Bool(false)),
+                with_vector: false.into(),
+                order_by: None,
+            },
+            None,
+            &ShardSelectorInternal::All,
+            None,
+            HwMeasurementAcc::new(),
+        )
+        .await
+        .unwrap();
+
+    // check if we only have 3 out of 5 points left and that the point id were really deleted
+    assert_eq!(result.points.len(), 3);
+    assert_eq!(result.points.first().unwrap().id, 1.into());
+    assert_eq!(result.points.get(1).unwrap().id, 2.into());
+    assert_eq!(result.points.get(2).unwrap().id, 4.into());
+}
+
 #[tokio::test(flavor = "multi_thread")]
 async fn test_ordered_read_api() {
     test_ordered_scroll_api_with_shards(1).await;
@@ -536,18 +601,14 @@ async fn test_ordered_scroll_api_with_shards(shard_number: u32) {
         payloads: Some(payloads),
     };
 
-    let insert_points = CollectionUpdateOperations::PointOperation(PointOperations::UpsertPoints(
-        PointInsertOperationsInternal::from(batch),
-    ));
+    let insert_points =
+        CollectionUpdateOperations::PointOperation(PointOperations::UpsertPoints(
+            PointInsertOperationsInternal::from(batch),
+        ));
 
     let hw_counter = HwMeasurementAcc::new();
     collection
-        .update_from_client_simple(
-            insert_points,
-            true,
-            WriteOrdering::default(),
-            hw_counter.clone(),
-        )
+        .update_from_client_simple(insert_points, true, WriteOrdering::default(), hw_counter.clone())
         .await
         .unwrap();
 
@@ -651,7 +712,8 @@ async fn test_ordered_scroll_api_with_shards(shard_number: u32) {
             result_desc.points
         );
 
-        let asc_already_seen: AHashSet<_> = result_asc.points.iter().map(|x| x.id).collect();
+        let asc_already_seen: AHashSet<_> =
+            result_asc.points.iter().map(|x| x.id).collect();
 
         dbg!(&asc_already_seen);
         let asc_second_page = collection
@@ -682,15 +744,16 @@ async fn test_ordered_scroll_api_with_shards(shard_number: u32) {
             .points
             .iter()
             .map(|x| x.id)
-            .collect::<HashSet<_>>();
+            .collect::<AHashSet<_>>();
         let valid_asc_second_page_points = [10, 9, 8, 7, 6]
             .into_iter()
             .map(|x| x.into())
-            .collect::<HashSet<ExtendedPointId>>();
+            .collect::<AHashSet<ExtendedPointId>>();
         assert_eq!(asc_second_page.points.len(), 5);
         assert!(asc_second_page_points.is_subset(&valid_asc_second_page_points));
 
-        let desc_already_seen: AHashSet<_> = result_desc.points.iter().map(|x| x.id).collect();
+        let desc_already_seen: AHashSet<_> =
+            result_desc.points.iter().map(|x| x.id).collect();
 
         dbg!(&desc_already_seen);
 
@@ -722,12 +785,12 @@ async fn test_ordered_scroll_api_with_shards(shard_number: u32) {
             .points
             .iter()
             .map(|x| x.id)
-            .collect::<HashSet<_>>();
+            .collect::<AHashSet<_>>();
 
         let valid_desc_second_page_points = [5, 6, 7, 8, 9]
             .into_iter()
             .map(|x| x.into())
-            .collect::<HashSet<ExtendedPointId>>();
+            .collect::<AHashSet<ExtendedPointId>>();
 
         assert_eq!(desc_second_page.points.len(), 4);
         assert!(
@@ -745,7 +808,9 @@ async fn test_ordered_scroll_api_with_shards(shard_number: u32) {
                 filter: None,
                 with_payload: Some(WithPayloadInterface::Bool(true)),
                 with_vector: false.into(),
-                order_by: Some(OrderByInterface::Key(MULTI_VALUE_KEY.parse().unwrap())),
+                order_by: Some(OrderByInterface::Key(
+                    MULTI_VALUE_KEY.parse().unwrap(),
+                )),
             },
             None,
             &ShardSelectorInternal::All,
@@ -770,138 +835,4 @@ async fn test_ordered_scroll_api_with_shards(shard_number: u32) {
             .values()
             .all(|&x| x == 2),
     );
-}
-
-#[tokio::test(flavor = "multi_thread")]
-async fn test_collection_delete_points_by_filter() {
-    test_collection_delete_points_by_filter_with_shards(1).await;
-    test_collection_delete_points_by_filter_with_shards(N_SHARDS).await;
-}
-
-async fn test_collection_delete_points_by_filter_with_shards(shard_number: u32) {
-    let collection_dir = Builder::new().prefix("collection").tempdir().unwrap();
-
-    let collection = simple_collection_fixture(collection_dir.path(), shard_number).await;
-
-    let batch = BatchPersisted {
-        ids: vec![0, 1, 2, 3, 4]
-            .into_iter()
-            .map(|x| x.into())
-            .collect_vec(),
-        vectors: BatchVectorStructPersisted::Single(vec![
-            vec![1.0, 0.0, 1.0, 1.0],
-            vec![1.0, 0.0, 1.0, 0.0],
-            vec![1.0, 1.0, 1.0, 1.0],
-            vec![1.0, 1.0, 0.0, 1.0],
-            vec![1.0, 0.0, 0.0, 0.0],
-        ]),
-        payloads: None,
-    };
-
-    let insert_points = CollectionUpdateOperations::PointOperation(PointOperations::UpsertPoints(
-        PointInsertOperationsInternal::from(batch),
-    ));
-
-    let hw_counter = HwMeasurementAcc::new();
-    let insert_result = collection
-        .update_from_client_simple(
-            insert_points,
-            true,
-            WriteOrdering::default(),
-            hw_counter.clone(),
-        )
-        .await;
-
-    match insert_result {
-        Ok(res) => {
-            assert_eq!(res.status, UpdateStatus::Completed)
-        }
-        Err(err) => panic!("operation failed: {err:?}"),
-    }
-
-    // delete points with id (0, 3)
-    let to_be_deleted: AHashSet<PointIdType> = vec![0.into(), 3.into()].into_iter().collect();
-    let delete_filter =
-        segment::types::Filter::new_must(Condition::HasId(HasIdCondition::from(to_be_deleted)));
-
-    let delete_points = CollectionUpdateOperations::PointOperation(
-        PointOperations::DeletePointsByFilter(delete_filter),
-    );
-
-    let delete_result = collection
-        .update_from_client_simple(delete_points, true, WriteOrdering::default(), hw_counter)
-        .await;
-
-    match delete_result {
-        Ok(res) => {
-            assert_eq!(res.status, UpdateStatus::Completed)
-        }
-        Err(err) => panic!("operation failed: {err:?}"),
-    }
-
-    let result = collection
-        .scroll_by(
-            ScrollRequestInternal {
-                offset: None,
-                limit: Some(10),
-                filter: None,
-                with_payload: Some(WithPayloadInterface::Bool(false)),
-                with_vector: false.into(),
-                order_by: None,
-            },
-            None,
-            &ShardSelectorInternal::All,
-            None,
-            HwMeasurementAcc::new(),
-        )
-        .await
-        .unwrap();
-
-    // check if we only have 3 out of 5 points left and that the point id were really deleted
-    assert_eq!(result.points.len(), 3);
-    assert_eq!(result.points.first().unwrap().id, 1.into());
-    assert_eq!(result.points.get(1).unwrap().id, 2.into());
-    assert_eq!(result.points.get(2).unwrap().id, 4.into());
-}
-
-#[tokio::test(flavor = "multi_thread")]
-async fn test_collection_local_load_initializing_not_stuck() {
-    let collection_dir = Builder::new().prefix("collection").tempdir().unwrap();
-
-    // Create and unload collection
-    simple_collection_fixture(collection_dir.path(), 1).await;
-
-    // Modify replica state file on disk, set state to Initializing
-    // This is to simulate a situation where a collection was not fully created, we cannot create
-    // this situation through our collection interface
-    {
-        let replica_state_path = collection_dir.path().join("0/replica_state.json");
-        let replica_state_file = File::open(&replica_state_path).unwrap();
-        let mut replica_set_state: ReplicaSetState =
-            serde_json::from_reader(replica_state_file).unwrap();
-
-        for peer_id in replica_set_state.peers().into_keys() {
-            replica_set_state.set_peer_state(peer_id, ReplicaState::Initializing);
-        }
-
-        let replica_state_file = File::create(&replica_state_path).unwrap();
-        serde_json::to_writer(replica_state_file, &replica_set_state).unwrap();
-    }
-
-    // Reload collection
-    let collection_path = collection_dir.path();
-    let loaded_collection = load_local_collection(
-        "test".to_string(),
-        collection_path,
-        &collection_path.join("snapshots"),
-    )
-    .await;
-
-    // Local replica must be in Active state after loading (all replicas are local)
-    let loaded_state = loaded_collection.state().await;
-    for shard_info in loaded_state.shards.values() {
-        for replica_state in shard_info.replicas.values() {
-            assert_eq!(replica_state, &ReplicaState::Active);
-        }
-    }
 }
\ No newline at end of file
