
index 7f71a6bd..81ca76e7 100644
--- a/qdrant_lib_collection_tests_integration_collection_test.rs_expectedoutput.txt (expected):tmp/tmp3ofj5i8i_expected.txt	
+++ b/qdrant_lib_collection_tests_integration_collection_test.rs_extracted.txt (actual):tmp/tmplxw7w030_actual.txt	
@@ -27,7 +27,7 @@ use segment::types::{
 use serde_json::Map;
 use tempfile::Builder;
 
-use crate::common::{N_SHARDS, load_local_collection, simple_collection_fixture};
+use crate::common::{load_local_collection, simple_collection_fixture, N_SHARDS};
 
 #[tokio::test(flavor = "multi_thread")]
 async fn test_collection_updater() {
@@ -188,14 +188,14 @@ async fn test_collection_search_with_payload_and_vector_with_shards(shard_number
         exact: true,
     };
 
-    let hw_acc = HwMeasurementAcc::new();
+    let hw_acc2 = HwMeasurementAcc::new();
     let count_res = collection
         .count(
             count_request,
             None,
             &ShardSelectorInternal::All,
             None,
-            hw_acc,
+            hw_acc2,
         )
         .await
         .unwrap();
@@ -234,9 +234,9 @@ async fn test_collection_loading_with_shards(shard_number: u32) {
             PointOperations::UpsertPoints(PointInsertOperationsInternal::from(batch)),
         );
 
-        let hw_counter = HwMeasurementAcc::new();
+        let hw_counter1 = HwMeasurementAcc::new();
         collection
-            .update_from_client_simple(insert_points, true, WriteOrdering::default(), hw_counter)
+            .update_from_client_simple(insert_points, true, WriteOrdering::default(), hw_counter1)
             .await
             .unwrap();
 
@@ -250,9 +250,9 @@ async fn test_collection_loading_with_shards(shard_number: u32) {
                 key: None,
             }));
 
-        let hw_counter = HwMeasurementAcc::new();
+        let hw_counter2 = HwMeasurementAcc::new();
         collection
-            .update_from_client_simple(assign_payload, true, WriteOrdering::default(), hw_counter)
+            .update_from_client_simple(assign_payload, true, WriteOrdering::default(), hw_counter2)
             .await
             .unwrap();
     }
@@ -302,7 +302,6 @@ fn test_deserialization() {
         ]),
         payloads: None,
     };
-
     let insert_points = CollectionUpdateOperations::PointOperation(PointOperations::UpsertPoints(
         PointInsertOperationsInternal::from(batch),
     ));
@@ -377,13 +376,13 @@ async fn test_recommendation_api_with_shards(shard_number: u32) {
         PointInsertOperationsInternal::from(batch),
     ));
 
-    let hw_acc = HwMeasurementAcc::new();
+    let hw_acc_update = HwMeasurementAcc::new();
     collection
         .update_from_client_simple(
             insert_points,
             true,
             WriteOrdering::default(),
-            hw_acc.clone(),
+            hw_acc_update.clone(),
         )
         .await
         .unwrap();
@@ -399,7 +398,7 @@ async fn test_recommendation_api_with_shards(shard_number: u32) {
         None,
         ShardSelectorInternal::All,
         None,
-        hw_acc,
+        hw_acc_update,
     )
     .await
     .unwrap();
@@ -678,11 +677,12 @@ async fn test_ordered_scroll_api_with_shards(shard_number: u32) {
             .await
             .unwrap();
 
-        let asc_second_page_points = asc_second_page
-            .points
-            .iter()
-            .map(|x| x.id)
-            .collect::<HashSet<_>>();
+        let asc_second_page_points =
+            asc_second_page
+                .points
+                .iter()
+                .map(|x| x.id)
+                .collect::<HashSet<_>>();
         let valid_asc_second_page_points = [10, 9, 8, 7, 6]
             .into_iter()
             .map(|x| x.into())
@@ -718,11 +718,12 @@ async fn test_ordered_scroll_api_with_shards(shard_number: u32) {
             .await
             .unwrap();
 
-        let desc_second_page_points = desc_second_page
-            .points
-            .iter()
-            .map(|x| x.id)
-            .collect::<HashSet<_>>();
+        let desc_second_page_points =
+            desc_second_page
+                .points
+                .iter()
+                .map(|x| x.id)
+                .collect::<HashSet<_>>();
 
         let valid_desc_second_page_points = [5, 6, 7, 8, 9]
             .into_iter()
@@ -732,7 +733,9 @@ async fn test_ordered_scroll_api_with_shards(shard_number: u32) {
         assert_eq!(desc_second_page.points.len(), 4);
         assert!(
             desc_second_page_points.is_subset(&valid_desc_second_page_points),
-            "expected: {valid_desc_second_page_points:?}, got: {desc_second_page_points:?}"
+            "expected: {:?}, got: {:?}",
+            valid_desc_second_page_points,
+            desc_second_page_points
         );
     }
 
@@ -820,13 +823,16 @@ async fn test_collection_delete_points_by_filter_with_shards(shard_number: u32)
     }
 
     // delete points with id (0, 3)
-    let to_be_deleted: AHashSet<PointIdType> = vec![0.into(), 3.into()].into_iter().collect();
+    let to_be_deleted: AHashSet<PointIdType> = vec![0.into(), 3.into()]
+        .into_iter()
+        .collect();
     let delete_filter =
         segment::types::Filter::new_must(Condition::HasId(HasIdCondition::from(to_be_deleted)));
 
-    let delete_points = CollectionUpdateOperations::PointOperation(
-        PointOperations::DeletePointsByFilter(delete_filter),
-    );
+    let delete_points =
+        CollectionUpdateOperations::PointOperation(PointOperations::DeletePointsByFilter(
+            delete_filter,
+        ));
 
     let delete_result = collection
         .update_from_client_simple(delete_points, true, WriteOrdering::default(), hw_counter)
@@ -862,46 +868,4 @@ async fn test_collection_delete_points_by_filter_with_shards(shard_number: u32)
     assert_eq!(result.points.first().unwrap().id, 1.into());
     assert_eq!(result.points.get(1).unwrap().id, 2.into());
     assert_eq!(result.points.get(2).unwrap().id, 4.into());
-}
-
-#[tokio::test(flavor = "multi_thread")]
-async fn test_collection_local_load_initializing_not_stuck() {
-    let collection_dir = Builder::new().prefix("collection").tempdir().unwrap();
-
-    // Create and unload collection
-    simple_collection_fixture(collection_dir.path(), 1).await;
-
-    // Modify replica state file on disk, set state to Initializing
-    // This is to simulate a situation where a collection was not fully created, we cannot create
-    // this situation through our collection interface
-    {
-        let replica_state_path = collection_dir.path().join("0/replica_state.json");
-        let replica_state_file = File::open(&replica_state_path).unwrap();
-        let mut replica_set_state: ReplicaSetState =
-            serde_json::from_reader(replica_state_file).unwrap();
-
-        for peer_id in replica_set_state.peers().into_keys() {
-            replica_set_state.set_peer_state(peer_id, ReplicaState::Initializing);
-        }
-
-        let replica_state_file = File::create(&replica_state_path).unwrap();
-        serde_json::to_writer(replica_state_file, &replica_set_state).unwrap();
-    }
-
-    // Reload collection
-    let collection_path = collection_dir.path();
-    let loaded_collection = load_local_collection(
-        "test".to_string(),
-        collection_path,
-        &collection_path.join("snapshots"),
-    )
-    .await;
-
-    // Local replica must be in Active state after loading (all replicas are local)
-    let loaded_state = loaded_collection.state().await;
-    for shard_info in loaded_state.shards.values() {
-        for replica_state in shard_info.replicas.values() {
-            assert_eq!(replica_state, &ReplicaState::Active);
-        }
-    }
 }
\ No newline at end of file
