
index 71e15f9b..c3c196dc 100644
--- a/qdrant_lib_collection_src_collection_mod.rs_expectedoutput.txt (expected):tmp/tmp5zu3r3kh_expected.txt	
+++ b/qdrant_lib_collection_src_collection_mod.rs_extracted.txt (actual):tmp/tmptoosdc3__actual.txt	
@@ -36,7 +36,9 @@ use crate::common::is_ready::IsReady;
 use crate::config::CollectionConfigInternal;
 use crate::operations::config_diff::{DiffConfig, OptimizersConfigDiff};
 use crate::operations::shared_storage_config::SharedStorageConfig;
-use crate::operations::types::{CollectionError, CollectionResult, NodeType, OptimizersStatus};
+use crate::operations::types::{
+    CollectionError, CollectionResult, NodeType, OptimizersStatus,
+};
 use crate::optimizers_builder::OptimizersConfig;
 use crate::save_on_disk::SaveOnDisk;
 use crate::shards::channel_service::ChannelService;
@@ -46,34 +48,39 @@ use crate::shards::replica_set::ReplicaState::{Active, Dead, Initializing, Liste
 use crate::shards::replica_set::{
     ChangePeerFromState, ChangePeerState, ReplicaState, ShardReplicaSet,
 };
+use crate::shards::resharding::ReshardKey;
 use crate::shards::shard::{PeerId, ShardId};
-use crate::shards::shard_holder::shard_mapping::ShardKeyMapping;
-use crate::shards::shard_holder::{LockedShardHolder, ShardHolder, shard_not_found_error};
+use crate::shards::shard_holder::{
+    shard_not_found_error,
+    shard_mapping::ShardKeyMapping,
+    LockedShardHolder,
+    ShardHolder,
+};
 use crate::shards::transfer::helpers::check_transfer_conflicts_strict;
 use crate::shards::transfer::transfer_tasks_pool::{TaskResult, TransferTasksPool};
 use crate::shards::transfer::{ShardTransfer, ShardTransferMethod};
-use crate::shards::{CollectionId, replica_set};
+use crate::shards::{replica_set, CollectionId};
 use crate::telemetry::{
     CollectionConfigTelemetry, CollectionTelemetry, CollectionsAggregatedTelemetry,
 };
 
 /// Collection's data is split into several shards.
 pub struct Collection {
-    pub(crate) id: CollectionId,
+    pub(crate) id:            CollectionId,
     pub(crate) shards_holder: Arc<LockedShardHolder>,
     pub(crate) collection_config: Arc<RwLock<CollectionConfigInternal>>,
     pub(crate) shared_storage_config: Arc<SharedStorageConfig>,
-    payload_index_schema: Arc<SaveOnDisk<PayloadIndexSchema>>,
-    optimizers_overwrite: Option<OptimizersConfigDiff>,
-    this_peer_id: PeerId,
-    path: PathBuf,
-    snapshots_path: PathBuf,
-    channel_service: ChannelService,
-    transfer_tasks: Mutex<TransferTasksPool>,
+    payload_index_schema:     Arc<SaveOnDisk<PayloadIndexSchema>>,
+    optimizers_overwrite:     Option<OptimizersConfigDiff>,
+    this_peer_id:             PeerId,
+    path:                     PathBuf,
+    snapshots_path:           PathBuf,
+    channel_service:          ChannelService,
+    transfer_tasks:           Mutex<TransferTasksPool>,
     request_shard_transfer_cb: RequestShardTransfer,
-    notify_peer_failure_cb: ChangePeerFromState,
-    abort_shard_transfer_cb: replica_set::AbortShardTransfer,
-    init_time: Duration,
+    notify_peer_failure_cb:   ChangePeerFromState,
+    abort_shard_transfer_cb:  replica_set::AbortShardTransfer,
+    init_time:                Duration,
     // One-way boolean flag that is set to true when the collection is fully initialized
     // i.e. all shards are activated for the first time.
     is_initialized: Arc<IsReady>,
@@ -128,7 +135,8 @@ impl Collection {
         for (shard_id, mut peers) in shard_distribution.shards {
             let is_local = peers.remove(&this_peer_id);
 
-            let mut effective_optimizers_config = collection_config.optimizer_config.clone();
+            let mut effective_optimizers_config =
+                collection_config.optimizer_config.clone();
             if let Some(optimizers_overwrite) = optimizers_overwrite.clone() {
                 effective_optimizers_config =
                     optimizers_overwrite.update(&effective_optimizers_config)?;
@@ -173,20 +181,20 @@ impl Collection {
         collection_config.save(path)?;
 
         Ok(Self {
-            id: name.clone(),
-            shards_holder: locked_shard_holder,
-            collection_config: shared_collection_config,
-            optimizers_overwrite,
-            payload_index_schema,
+            id:                    name.clone(),
+            shards_holder:         locked_shard_holder,
+            collection_config:     shared_collection_config,
             shared_storage_config,
+            payload_index_schema,
+            optimizers_overwrite,
             this_peer_id,
-            path: path.to_owned(),
-            snapshots_path: snapshots_path.to_owned(),
+            path:                  path.to_owned(),
+            snapshots_path:        snapshots_path.to_owned(),
             channel_service,
-            transfer_tasks: Mutex::new(TransferTasksPool::new(name.clone())),
+            transfer_tasks:        Mutex::new(TransferTasksPool::new(name.clone())),
             request_shard_transfer_cb: request_shard_transfer.clone(),
-            notify_peer_failure_cb: on_replica_failure.clone(),
-            abort_shard_transfer_cb: abort_shard_transfer,
+            notify_peer_failure_cb:    on_replica_failure.clone(),
+            abort_shard_transfer_cb:   abort_shard_transfer,
             init_time: start_time.elapsed(),
             is_initialized: Default::default(),
             updates_lock: Default::default(),
@@ -252,9 +260,10 @@ impl Collection {
         let mut effective_optimizers_config = collection_config.optimizer_config.clone();
 
         if let Some(optimizers_overwrite) = optimizers_overwrite.clone() {
-            effective_optimizers_config = optimizers_overwrite
-                .update(&effective_optimizers_config)
-                .expect("Can not apply optimizer overwrite");
+            effective_optimizers_config =
+                optimizers_overwrite
+                    .update(&effective_optimizers_config)
+                    .expect("Can not apply optimizer overwrite");
         }
 
         let shared_collection_config = Arc::new(RwLock::new(collection_config.clone()));
@@ -289,20 +298,20 @@ impl Collection {
         );
 
         Self {
-            id: collection_id.clone(),
-            shards_holder: locked_shard_holder,
-            collection_config: shared_collection_config,
-            optimizers_overwrite,
-            payload_index_schema,
+            id:                    collection_id.clone(),
+            shards_holder:         locked_shard_holder,
+            collection_config:     shared_collection_config,
             shared_storage_config,
+            payload_index_schema,
+            optimizers_overwrite,
             this_peer_id,
-            path: path.to_owned(),
-            snapshots_path: snapshots_path.to_owned(),
+            path:                  path.to_owned(),
+            snapshots_path:        snapshots_path.to_owned(),
             channel_service,
-            transfer_tasks: Mutex::new(TransferTasksPool::new(collection_id.clone())),
+            transfer_tasks:        Mutex::new(TransferTasksPool::new(collection_id.clone())),
             request_shard_transfer_cb: request_shard_transfer.clone(),
-            notify_peer_failure_cb: on_replica_failure,
-            abort_shard_transfer_cb: abort_shard_transfer,
+            notify_peer_failure_cb:    on_replica_failure,
+            abort_shard_transfer_cb:   abort_shard_transfer,
             init_time: start_time.elapsed(),
             is_initialized: Default::default(),
             updates_lock: Default::default(),
@@ -331,10 +340,7 @@ impl Collection {
         if stored.minor != app.minor {
             return false;
         }
-        if stored.patch + 1 < app.patch {
-            return false;
-        }
-        true
+        stored.patch + 1 >= app.patch
     }
 
     pub fn name(&self) -> String {
@@ -375,7 +381,7 @@ impl Collection {
         let shard = shard_holder_read.get_shard(shard_id);
         let Some(replica_set) = shard else {
             return Err(CollectionError::NotFound {
-                what: format!("Shard {shard_id}"),
+                what: "Shard {shard_id}".into(),
             });
         };
 
@@ -483,19 +489,22 @@ impl Collection {
             abort_resharding_result?;
         }
 
-        // If not initialized yet, we need to check if it was initialized by this call
         if !self.is_initialized.check_ready() {
             let state = self.state().await;
 
             let mut is_ready = true;
 
             for (_shard_id, shard_info) in state.shards {
-                let all_replicas_active = shard_info.replicas.into_iter().all(|(_, state)| {
-                    matches!(
-                        state,
-                        ReplicaState::Active | ReplicaState::ReshardingScaleDown
-                    )
-                });
+                let all_replicas_active =
+                    shard_info
+                        .replicas
+                        .into_iter()
+                        .all(|(_, state)| {
+                            matches!(
+                                state,
+                                ReplicaState::Active | ReplicaState::ReshardingScaleDown
+                            )
+                        });
 
                 if !all_replicas_active {
                     is_ready = false;
@@ -508,10 +517,34 @@ impl Collection {
             }
         }
 
+        // Try to request shard transfer if replicas on the current peer are dead
+        if new_state == ReplicaState::Dead && self.this_peer_id == peer_id {
+            let transfer_from = replica_set
+                .peers()
+                .into_iter()
+                .find(|(_, state)| state == &ReplicaState::Active)
+                .map(|(peer_id, _)| peer_id);
+            if let Some(transfer_from) = transfer_from {
+                self.request_shard_transfer(ShardTransfer {
+                    shard_id,
+                    from: transfer_from,
+                    to: self.this_peer_id,
+                    to_shard_id: None,
+                    sync: true,
+                    method: None,
+                })
+            } else {
+                log::warn!("No alive replicas to recover shard {shard_id}");
+            }
+        }
+
         Ok(())
     }
 
-    pub async fn shard_recovery_point(&self, shard_id: ShardId) -> CollectionResult<RecoveryPoint> {
+    pub async fn shard_recovery_point(
+        &self,
+        shard_id: ShardId,
+    ) -> CollectionResult<RecoveryPoint> {
         let shard_holder_read = self.shards_holder.read().await;
 
         let shard = shard_holder_read.get_shard(shard_id);
@@ -534,7 +567,7 @@ impl Collection {
         let shard = shard_holder_read.get_shard(shard_id);
         let Some(replica_set) = shard else {
             return Err(CollectionError::NotFound {
-                what: format!("Shard {shard_id}"),
+                what: "Shard {shard_id}".into(),
             });
         };
 
@@ -563,30 +596,6 @@ impl Collection {
         }
     }
 
-    pub async fn remove_shards_at_peer(&self, peer_id: PeerId) -> CollectionResult<()> {
-        // Abort resharding, if shards are removed from peer driving resharding
-        // (which *usually* means the *peer* is being removed from consensus)
-        let resharding_state = self
-            .resharding_state()
-            .await
-            .filter(|state| state.peer_id == peer_id);
-
-        if let Some(state) = resharding_state {
-            if let Err(err) = self.abort_resharding(state.key(), true).await {
-                log::error!(
-                    "Failed to abort resharding {} while removing peer {peer_id}: {err}",
-                    state.key(),
-                );
-            }
-        }
-
-        self.shards_holder
-            .read()
-            .await
-            .remove_shards_at_peer(peer_id)
-            .await
-    }
-
     pub async fn sync_local_state(
         &self,
         on_transfer_failure: OnTransferFailure,
@@ -664,7 +673,8 @@ impl Collection {
             if self.shared_storage_config.node_type == NodeType::Listener {
                 // We probably should not switch node type during resharding, so we only check for `Active`,
                 // but not `ReshardingScaleDown` replica state here...
-                let is_last_active = peers.values().filter(|&&state| state == Active).count() == 1;
+                let is_last_active =
+                    peers.values().filter(|&&state| state == Active).count() == 1;
 
                 if this_peer_state == Some(Active) && !is_last_active {
                     // Convert active node from active to listener
@@ -701,22 +711,6 @@ impl Collection {
                 continue;
             }
 
-            // Select shard transfer method, prefer user configured method or choose one now
-            // If all peers are 1.8+, we try WAL delta transfer, otherwise we use the default method
-            let shard_transfer_method = self
-                .shared_storage_config
-                .default_shard_transfer_method
-                .unwrap_or_else(|| {
-                    let all_support_wal_delta = self
-                        .channel_service
-                        .all_peers_at_version(&Version::new(1, 8, 0));
-                    if all_support_wal_delta {
-                        ShardTransferMethod::WalDelta
-                    } else {
-                        ShardTransferMethod::default()
-                    }
-                });
-
             // Try to find a replica to transfer from
             //
             // `active_remote_shards` includes `Active` and `ReshardingScaleDown` replicas!
@@ -728,7 +722,20 @@ impl Collection {
                     to_shard_id: None,
                     sync: true,
                     // For automatic shard transfers, always select some default method from this point on
-                    method: Some(shard_transfer_method),
+                    method: Some(
+                        self.shared_storage_config
+                            .default_shard_transfer_method
+                            .unwrap_or_else(|| {
+                                let all_support_wal_delta = self
+                                    .channel_service
+                                    .all_peers_at_version(&Version::new(1, 8, 0));
+                                if all_support_wal_delta {
+                                    ShardTransferMethod::WalDelta
+                                } else {
+                                    ShardTransferMethod::default()
+                                }
+                            }),
+                    ),
                 };
 
                 if check_transfer_conflicts_strict(&transfer, transfers.iter()).is_some() {
@@ -755,6 +762,7 @@ impl Collection {
                         self.id,
                         replica_set.shard_id,
                     );
+
                     continue;
                 }
 
@@ -784,7 +792,9 @@ impl Collection {
                 }
                 (
                     Some(shards_telemetry),
-                    Some(shards_holder.get_shard_transfer_info(&*self.transfer_tasks.lock().await)),
+                    Some(shards_holder.get_shard_transfer_info(
+                        &*self.transfer_tasks.lock().await,
+                    )),
                     Some(
                         shards_holder
                             .get_resharding_operations_info()
@@ -801,7 +811,9 @@ impl Collection {
         CollectionTelemetry {
             id: self.name(),
             init_time_ms: self.init_time.as_millis() as u64,
-            config: CollectionConfigTelemetry::from(self.collection_config.read().await.clone()),
+            config: CollectionConfigTelemetry::from(
+                self.collection_config.read().await.clone(),
+            ),
             shards: shards_telemetry,
             transfers,
             resharding,
@@ -816,10 +828,8 @@ impl Collection {
         let mut vectors = 0;
 
         for shard in shards_holder.all_shards() {
-            let shard_optimization_status = shard
-                .get_optimization_status()
-                .await
-                .unwrap_or(OptimizersStatus::Ok);
+            let shard_optimization_status =
+                shard.get_optimization_status().await.unwrap_or(OptimizersStatus::Ok);
 
             shard_optimization_statuses.push(shard_optimization_status);
 
@@ -838,16 +848,6 @@ impl Collection {
         }
     }
 
-    pub async fn effective_optimizers_config(&self) -> CollectionResult<OptimizersConfig> {
-        let config = self.collection_config.read().await;
-
-        if let Some(optimizers_overwrite) = self.optimizers_overwrite.clone() {
-            Ok(optimizers_overwrite.update(&config.optimizer_config)?)
-        } else {
-            Ok(config.optimizer_config.clone())
-        }
-    }
-
     pub async fn lock_updates(&self) -> RwLockWriteGuard<()> {
         self.updates_lock.write().await
     }
@@ -881,7 +881,9 @@ impl Collection {
 
     /// Returns estimations of collection sizes. This values are cached and might be not 100% up to date.
     /// The cache gets updated every 32 calls.
-    pub(crate) async fn estimated_collection_stats(&self) -> Option<&CollectionSizeAtomicStats> {
+    pub(crate) async fn estimated_collection_stats(
+        &self,
+    ) -> Option<&CollectionSizeAtomicStats> {
         self.collection_stats_cache
             .get_or_update_cache(|| Self::estimate_collection_size_stats(&self.shards_holder))
             .await
