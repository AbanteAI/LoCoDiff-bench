mod clean;
mod collection_ops;
pub mod distance_matrix;
mod facet;
pub mod payload_index_schema;
mod point_ops;
pub mod query;
mod search;
mod shard_transfer;
mod sharding_keys;
mod state_management;

use std::collections::HashMap;
use std::ops::Deref;
use std::path::{Path, PathBuf};
use std::sync::Arc;
use std::time::Duration;

use clean::ShardCleanTasks;
use common::budget::ResourceBudget;
use common::types::{DetailsLevel, TelemetryDetail};
use io::storage_version::StorageVersion;
use segment::types::ShardKey;
use semver::Version;
use tokio::runtime::Handle;
use tokio::sync::{Mutex, RwLock, RwLockWriteGuard};

use crate::collection::payload_index_schema::PayloadIndexSchema;
use crate::collection_state::{ShardInfo, State};
use crate::common::is_ready::IsReady;
use crate::config::CollectionConfigInternal;
use crate::common::collection_size_stats::{
    CollectionSizeAtomicStats, CollectionSizeStats, CollectionSizeStatsCache,
};
use crate::common::local_data_stats::{LocalDataAtomicStats, LocalDataStats, LocalDataStatsCache};
use crate::operations::config_diff::{DiffConfig, OptimizersConfigDiff};
use crate::operations::shared_storage_config::SharedStorageConfig;
use crate::operations::types::{CollectionError, CollectionResult, NodeType, OptimizersStatus};
use crate::optimizers_builder::OptimizersConfig;
use crate::save_on_disk::SaveOnDisk;
use crate::shards::channel_service::ChannelService;
use crate::shards::transfer::helpers::check_transfer_conflicts_strict;
use crate::shards::transfer::transfer_tasks_pool::{TaskResult, TransferTasksPool};
use crate::shards::transfer::{ShardTransfer, ShardTransferMethod};
use crate::shards::{CollectionId, replica_set};
use crate::telemetry::{CollectionConfigTelemetry, CollectionTelemetry, CollectionsAggregatedTelemetry};

/// Collection's data is split into several shards.
pub struct Collection {
    pub(crate) id: CollectionId,
    pub(crate) shards_holder: Arc<LockedShardHolder>,
    pub(crate) collection_config: Arc<RwLock<CollectionConfigInternal>>,
    pub(crate) shared_storage_config: Arc<SharedStorageConfig>,
    pub(crate) payload_index_schema: Arc<SaveOnDisk<PayloadIndexSchema>>,
    optimizers_overwrite: Option<OptimizersConfigDiff>,
    this_peer_id: PeerId,
    path: PathBuf,
    snapshots_path: PathBuf,
    channel_service: ChannelService,
    transfer_tasks: Mutex<TransferTasksPool>,
    request_shard_transfer_cb: RequestShardTransfer,
    notify_peer_failure_cb: ChangePeerFromState,
    abort_shard_transfer_cb: replica_set::AbortShardTransfer,
    init_time: Duration,
    is_initialized: Arc<IsReady>,
    updates_lock: Arc<RwLock<()>>,
    update_runtime: Handle,
    search_runtime: Handle,
    optimizer_resource_budget: ResourceBudget,
    collection_stats_cache: CollectionSizeStatsCache,
    shard_clean_tasks: ShardCleanTasks,
}

pub type RequestShardTransfer = Arc<dyn Fn(ShardTransfer) + Send + Sync>;

// ... all other type aliases ...

impl Collection {
    #[allow(clippy::too_many_arguments)]
    pub async fn new(
        name: CollectionId,
        this_peer_id: PeerId,
        path: &Path,
        snapshots_path: &Path,
        collection_config: &CollectionConfigInternal,
        shared_storage_config: Arc<SharedStorageConfig>,
        shard_distribution: CollectionShardDistribution,
        channel_service: ChannelService,
        on_replica_failure: ChangePeerFromState,
        request_shard_transfer: RequestShardTransfer,
        abort_shard_transfer: replica_set::AbortShardTransfer,
        search_runtime: Option<Handle>,
        update_runtime: Option<Handle>,
        optimizer_resource_budget: ResourceBudget,
        optimizers_overwrite: Option<OptimizersConfigDiff>,
    ) -> Result<Self, CollectionError> {
        let start_time = std::time::Instant::now();
        let mut shard_holder = ShardHolder::new(path)?;
        let payload_index_schema = Arc::new(Self::load_payload_index_schema(path)?);

        let shared_collection_config = Arc::new(RwLock::new(collection_config.clone()));
        let mut effective_stats = collection_config.optimizer_config.clone();
        if let Some(diff) = optimizers_overwrite.clone() {
            effective_stats = diff.update(&effective_stats)?;
        }

        for (shard_id, mut peers) in shard_distribution.shards {
            let shard_key = None;
            let is_local = peers.remove(&this_peer_id);
            let replica_set = ShardReplicaSet::build(
                shard_id,
                shard_key.clone(),
                name.clone(),
                this_peer_id,
                is_local,
                peers,
                on_replica_failure.clone(),
                abort_shard_transfer.clone(),
                path,
                shared_collection_config.clone(),
                payload_index_schema.clone(),
                shared_storage_config.clone(),
                channel_service.clone(),
                update_runtime.clone().unwrap_or_else(Handle::current),
                search_runtime.clone().unwrap_or_else(Handle::current),
                optimizer_resource_budget.clone(),
                effective_stats.clone(),
                None,
            )
            .await?;
            shard_holder.add_shard(shard_id, replica_set, shard_key)?;
        }

        let locked_shard_holder = Arc::new(LockedShardHolder::new(shard_holder));
        let local_stats_cache = LocalDataStatsCache::new_with_values(
            Self::calculate_local_shards_stats(&locked_shard_holder).await,
        );
        let collection_stats_cache = CollectionSizeStatsCache::new_with_values(
            Self::estimate_collection_size_stats(&locked_shard_holder).await,
        );

        CollectionVersion::save(path)?;
        collection_config.save(path)?;

        Ok(Self {
            id: name.clone(),
            shards_holder: locked_shard_holder,
            collection_config: shared_collection_config,
            shared_storage_config,
            payload_index_schema,
            optimizers_overwrite,
            this_peer_id,
            path: path.to_owned(),
            snapshots_path: snapshots_path.to_owned(),
            channel_service,
            transfer_tasks: Mutex::new(TransferTasksPool::new(name.clone())),
            request_shard_transfer_cb: request_shard_transfer.clone(),
            notify_peer_failure_cb: on_replica_failure.clone(),
            abort_shard_transfer_cb: abort_shard_transfer,
            init_time: start_time.elapsed(),
            is_initialized: Default::default(),
            updates_lock: Default::default(),
            update_runtime: update_runtime.unwrap_or_else(Handle::current),
            search_runtime: search_runtime.unwrap_or_else(Handle::current),
            optimizer_resource_budget,
            collection_stats_cache,
            shard_clean_tasks: Default::default(),
        })
    }

    // ... all other methods up through get_telemetry_data, get_aggregated_telemetry_data ...

    pub async fn get_telemetry_data(&self, detail: TelemetryDetail) -> CollectionTelemetry {
        let (shards_telemetry, transfers, resharding) = if detail.level >= DetailsLevel::Level3 {
            let shards_holder = self.shards_holder.read().await;
            let mut shards_telemetry = Vec::new();
            for shard in shards_holder.all_shards() {
                shards_telemetry.push(shard.get_telemetry_data(detail).await)
            }
            (
                Some(shards_telemetry),
                Some(shards_holder.get_shard_transfer_info(&*self.transfer_tasks.lock().await)),
                Some(shards_holder.get_resharding_operations_info().unwrap_or_default()),
            )
        } else {
            (None, None, None)
        };

        let shard_clean_tasks = self.clean_local_shards_statuses();

        CollectionTelemetry {
            id: self.name(),
            init_time_ms: self.init_time.as_millis() as u64,
            config: CollectionConfigTelemetry::from(self.collection_config.read().await.clone()),
            shards: shards_telemetry,
            transfers,
            resharding,
            shard_clean_tasks: (!shard_clean_tasks.is_empty()).then_some(shard_clean_tasks),
        }
    }

    pub async fn get_aggregated_telemetry_data(&self) -> CollectionsAggregatedTelemetry {
        let shards_holder = self.shards_holder.read().await;

        let mut shard_optimization_statuses = Vec::new();
        let mut vectors = 0;

        for shard in shards_holder.all_shards() {
            let shard_optimization_status = shard
                .get_optimization_status()
                .await
                .unwrap_or(OptimizersStatus::Ok);
            shard_optimization_statuses.push(shard_optimization_status);
            vectors += shard.get_size_stats().await.num_vectors;
        }

        let optimizers_status = shard_optimization_statuses
            .into_iter()
            .max()
            .unwrap_or(OptimizersStatus::Ok);

        CollectionsAggregatedTelemetry {
            vectors,
            optimizers_status,
            params: self.collection_config.read().await.params.clone(),
        }
    }

    // ...
}

struct CollectionVersion;

impl StorageVersion for CollectionVersion {
    fn current_raw() -> &'static str {
        env!("CARGO_PKG_VERSION")
    }
}