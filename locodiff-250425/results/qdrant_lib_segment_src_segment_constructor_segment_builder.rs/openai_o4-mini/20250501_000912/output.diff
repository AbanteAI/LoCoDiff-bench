
index 70dd22b4..87f5f745 100644
--- a/qdrant_lib_segment_src_segment_constructor_segment_builder.rs_expectedoutput.txt (expected):tmp/tmp9bvd9wtn_expected.txt	
+++ b/qdrant_lib_segment_src_segment_constructor_segment_builder.rs_extracted.txt (actual):tmp/tmpxiryf3ex_actual.txt	
@@ -1,4 +1,4 @@
-use std::cmp;
+use std::cmp::max;
 use std::collections::HashMap;
 use std::hash::{Hash, Hasher};
 use std::ops::Deref;
@@ -9,13 +9,11 @@ use std::sync::atomic::AtomicBool;
 use ahash::AHasher;
 use atomic_refcell::AtomicRefCell;
 use bitvec::macros::internal::funty::Integral;
-use common::budget::ResourcePermit;
 use common::counter::hardware_counter::HardwareCounterCell;
-use common::flags::feature_flags;
+use common::budget::ResourcePermit;
 use common::small_uint::U24;
 use common::types::PointOffsetType;
 use io::storage_version::StorageVersion;
-use itertools::Itertools;
 use tempfile::TempDir;
 use uuid::Uuid;
 
@@ -38,13 +36,8 @@ use crate::index::{PayloadIndex, VectorIndexEnum};
 use crate::payload_storage::PayloadStorage;
 use crate::payload_storage::payload_storage_enum::PayloadStorageEnum;
 use crate::segment::{Segment, SegmentVersion};
-use crate::segment_constructor::{
-    VectorIndexBuildArgs, VectorIndexOpenArgs, build_vector_index, load_segment,
-};
-use crate::types::{
-    CompactExtendedPointId, ExtendedPointId, PayloadFieldSchema, PayloadKeyType, SegmentConfig,
-    SegmentState, SeqNumberType, VectorNameBuf,
-};
+use crate::segment_constructor::{VectorIndexBuildArgs, VectorIndexOpenArgs, build_vector_index, load_segment};
+use crate::types::{CompactExtendedPointId, ExtendedPointId, PayloadFieldSchema, PayloadKeyType, SegmentConfig, SegmentState, SeqNumberType, VectorNameBuf};
 use crate::vector_storage::quantized::quantized_vectors::QuantizedVectors;
 use crate::vector_storage::{VectorStorage, VectorStorageEnum};
 
@@ -91,11 +84,9 @@ impl SegmentBuilder {
             IdTrackerEnum::InMemoryIdTracker(InMemoryIdTracker::new())
         };
 
-        let payload_storage =
-            create_payload_storage(database.clone(), segment_config, temp_dir.path())?;
+        let payload_storage = create_payload_storage(database.clone(), segment_config, temp_dir.path())?;
 
         let mut vector_data = HashMap::new();
-
         for (vector_name, vector_config) in &segment_config.vector_data {
             let vector_storage_path = get_vector_storage_path(temp_dir.path(), vector_name);
             let vector_storage = open_vector_storage(
@@ -105,7 +96,6 @@ impl SegmentBuilder {
                 &vector_storage_path,
                 vector_name,
             )?;
-
             vector_data.insert(
                 vector_name.to_owned(),
                 VectorData {
@@ -114,10 +104,8 @@ impl SegmentBuilder {
                 },
             );
         }
-
         for (vector_name, sparse_vector_config) in &segment_config.sparse_vector_data {
             let vector_storage_path = get_vector_storage_path(temp_dir.path(), vector_name);
-
             let vector_storage = create_sparse_vector_storage(
                 database.clone(),
                 &vector_storage_path,
@@ -125,7 +113,6 @@ impl SegmentBuilder {
                 &sparse_vector_config.storage_type,
                 &stopped,
             )?;
-
             vector_data.insert(
                 vector_name.to_owned(),
                 VectorData {
@@ -138,12 +125,11 @@ impl SegmentBuilder {
         let destination_path = new_segment_path(segments_path);
 
         Ok(SegmentBuilder {
-            version: Default::default(), // default version is 0
+            version: Default::default(),
             id_tracker,
             payload_storage,
             vector_data,
             segment_config: segment_config.clone(),
-
             destination_path,
             temp_dir,
             indexed_fields: Default::default(),
@@ -163,14 +149,7 @@ impl SegmentBuilder {
         self.indexed_fields.insert(field, schema);
     }
 
-    /// Get ordering value from the payload index
-    ///
-    /// Ordering value is used to sort points to keep points with the same payload together
-    /// Under the assumption that points are queried together, this will reduce the number of
-    /// random disk reads.
-    ///
-    /// Note: This value doesn't guarantee strict ordering in ambiguous cases.
-    ///       It should only be used in optimization purposes, not for correctness.
+    /// Ordering value derived from payload field indices to group points with like payloads
     fn _get_ordering_value(internal_id: PointOffsetType, indices: &[FieldIndex]) -> u64 {
         let mut ordering = 0;
         for payload_index in indices {
@@ -204,16 +183,6 @@ impl SegmentBuilder {
                 FieldIndex::FloatIndex(index) => {
                     if let Some(numbers) = index.get_values(internal_id) {
                         for number in numbers {
-                            // Bit-level conversion of f64 to u64 preserves ordering
-                            // (for positive numbers)
-                            //
-                            // 0.001 -> 4562254508917369340
-                            // 0.01  -> 4576918229304087675
-                            // 0.05  -> 4587366580439587226
-                            // 0.1   -> 4591870180066957722
-                            // 1     -> 4607182418800017408
-                            // 2     -> 4611686018427387904
-                            // 10    -> 4621819117588971520
                             ordering = ordering.wrapping_add(number.to_bits());
                         }
                     }
@@ -229,226 +198,160 @@ impl SegmentBuilder {
                 }
                 FieldIndex::UuidMapIndex(index) => {
                     if let Some(ids) = index.get_values(internal_id) {
-                        uuid_hash(&mut ordering, ids.copied());
+                        uuid_hash(&mut ordering, ids);
                     }
                     break;
                 }
                 FieldIndex::UuidIndex(index) => {
                     if let Some(ids) = index.get_values(internal_id) {
-                        uuid_hash(&mut ordering, ids);
+                        uuid_hash(&mut ordering, ids.copied());
                     }
                     break;
                 }
-                FieldIndex::GeoIndex(_) => {}
-                FieldIndex::FullTextIndex(_) => {}
-                FieldIndex::BoolIndex(_) => {}
-                FieldIndex::NullIndex(_) => {}
+                FieldIndex::GeoIndex(_) | FieldIndex::FullTextIndex(_) | FieldIndex::BoolIndex(_) | FieldIndex::NullIndex(_) => {
+                    // Not used for ordering
+                }
             }
         }
         ordering
     }
 
-    /// Update current segment builder with all (not deleted) vectors and payload from `segments`.
-    /// Also defragments if the `defragment_key` is set.
-    /// However only points in the same call get defragmented and grouped together.
-    /// Therefore this function should only be called once, unless this behavior is desired.
-    ///
-    /// # Result
-    ///
-    /// * `bool` - if `true` - data successfully added, if `false` - process was interrupted
-    ///
+    /// Update current segment builder with data from multiple segments, optionally defragmenting
     pub fn update(&mut self, segments: &[&Segment], stopped: &AtomicBool) -> OperationResult<bool> {
         if segments.is_empty() {
             return Ok(true);
         }
-
-        struct PointData {
-            external_id: CompactExtendedPointId,
-            /// [`CompactExtendedPointId`] is 17 bytes, we reduce
-            /// `segment_index` to 3 bytes to avoid paddings and align nicely.
-            segment_index: U24,
+        // Merge latest versions per external point across segments
+        struct PositionedPointMetadata {
+            external_id: ExtendedPointId,
+            segment_index: usize,
             internal_id: PointOffsetType,
-            version: u64,
+            version: SeqNumberType,
             ordering: u64,
         }
-
-        if segments.len() > U24::MAX as usize {
-            return Err(OperationError::service_error("Too many segments to update"));
+        let mut merged = HashMap::new();
+        for (si, segment) in segments.iter().enumerate() {
+            for &ext in segment.iter_points() {
+                let ver = segment.point_version(ext).unwrap_or(0);
+                let iid = segment.get_internal_id(ext).unwrap();
+                merged.entry(ext).and_modify(|e: &mut PositionedPointMetadata| {
+                    if e.version < ver {
+                        e.segment_index = si;
+                        e.version = ver;
+                        e.internal_id = iid;
+                    }
+                }).or_insert(PositionedPointMetadata {
+                    external_id: ext,
+                    segment_index: si,
+                    internal_id: iid,
+                    version: ver,
+                    ordering: 0,
+                });
+            }
         }
-
-        let mut points_to_insert = Vec::new();
-        let locked_id_trackers = segments.iter().map(|s| s.id_tracker.borrow()).collect_vec();
-        for_each_unique_point(locked_id_trackers.iter().map(|i| i.deref()), |item| {
-            points_to_insert.push(PointData {
-                external_id: CompactExtendedPointId::from(item.external_id),
-                segment_index: U24::new_wrapped(item.tracker_index as u32),
-                internal_id: item.internal_id,
-                version: item.version,
-                ordering: 0,
-            });
-        });
-        drop(locked_id_trackers);
-
-        let payloads: Vec<_> = segments.iter().map(|i| i.payload_index.borrow()).collect();
-
-        for defragment_key in &self.defragment_keys {
-            for point_data in &mut points_to_insert {
-                let Some(payload_indices) = payloads[point_data.segment_index.get() as usize]
-                    .field_indexes
-                    .get(defragment_key)
-                else {
-                    continue;
-                };
-
-                point_data.ordering = point_data.ordering.wrapping_add(Self::_get_ordering_value(
-                    point_data.internal_id,
-                    payload_indices,
-                ));
+        let payloads: Vec<_> = segments.iter().map(|s| s.payload_index.borrow()).collect();
+        let mut pts: Vec<_> = merged.into_values().collect();
+
+        // defragment if requested
+        for key in &self.defragment_keys {
+            for meta in &mut pts {
+                if let Some(idxs) = payloads[meta.segment_index].field_indexes.get(key) {
+                    meta.ordering = meta.ordering.wrapping_add(Self::_get_ordering_value(meta.internal_id, idxs));
+                }
             }
         }
-
         if !self.defragment_keys.is_empty() {
-            points_to_insert.sort_unstable_by_key(|i| i.ordering);
+            pts.sort_unstable_by_key(|p| p.ordering);
         }
 
-        let src_segment_max_version = segments.iter().map(|i| i.version()).max().unwrap();
-        self.version = cmp::max(self.version, src_segment_max_version);
-
-        let vector_storages: Vec<_> = segments.iter().map(|i| &i.vector_data).collect();
+        // merge into builder
+        let src_max = segments.iter().map(|s| s.version()).max().unwrap();
+        self.version = max(self.version, src_max);
 
-        let mut new_internal_range = None;
-        for (vector_name, vector_data) in &mut self.vector_data {
+        let storages: Vec<_> = segments.iter().map(|s| &s.vector_data).collect();
+        let mut new_rng = None;
+        for (name, vdata) in &mut self.vector_data {
             check_process_stopped(stopped)?;
-
-            let other_vector_storages = vector_storages
-                .iter()
-                .map(|i| {
-                    let other_vector_data = i.get(vector_name).ok_or_else(|| {
-                        OperationError::service_error(format!(
-                            "Cannot update from other segment because it is \
-                             missing vector name {vector_name}"
-                        ))
-                    })?;
-
-                    vector_data
-                        .old_indices
-                        .push(Arc::clone(&other_vector_data.vector_index));
-
-                    Ok(other_vector_data.vector_storage.borrow())
-                })
-                .collect::<Result<Vec<_>, OperationError>>()?;
-
-            let mut iter = points_to_insert.iter().map(|point_data| {
-                let other_vector_storage =
-                    &other_vector_storages[point_data.segment_index.get() as usize];
-                let vec = other_vector_storage.get_vector(point_data.internal_id);
-                let vector_deleted = other_vector_storage.is_deleted_vector(point_data.internal_id);
-                (vec, vector_deleted)
+            let mut lists = Vec::new();
+            for sd in &storages {
+                let info = sd.get(name).ok_or_else(|| OperationError::service_error(format!(
+                    "Missing vector `{}` for update", name
+                )))?;
+                // record old indices
+                vdata.old_indices.push(Arc::clone(&info.vector_index));
+                lists.push(info.vector_storage.borrow());
+            }
+            let mut iter = pts.iter().map(|m| {
+                let vec = lists[m.segment_index].get_vector(m.internal_id);
+                let del = lists[m.segment_index].is_deleted_vector(m.internal_id);
+                (vec, del)
             });
-
-            let internal_range = vector_data.vector_storage.update_from(&mut iter, stopped)?;
-
-            match &new_internal_range {
-                Some(new_internal_range) => {
-                    if new_internal_range != &internal_range {
-                        return Err(OperationError::service_error(format!(
-                            "Internal ids range mismatch between self segment vectors and other segment vectors\n\
-                                vector_name: {vector_name}, self range: {new_internal_range:?}, other range: {internal_range:?}"
-                        )));
-                    }
+            let r = vdata.vector_storage.update_from(&mut iter, stopped)?;
+            if let Some(prev) = &new_rng {
+                if prev != &r {
+                    return Err(OperationError::service_error(format!(
+                        "Range mismatch for `{}`: {:?} vs {:?}",
+                        name, prev, r
+                    )));
                 }
-                None => new_internal_range = Some(internal_range),
+            } else {
+                new_rng = Some(r);
             }
         }
 
-        let hw_counter = HardwareCounterCell::disposable(); // Disposable counter for internal operations.
-
-        if let Some(new_internal_range) = new_internal_range {
-            let internal_id_iter = new_internal_range.zip(points_to_insert.iter());
-
-            for (new_internal_id, point_data) in internal_id_iter {
+        // payload and linked update
+        let mut idtrk = &mut self.id_tracker;
+        let hw_counter = HardwareCounterCell::disposable();
+        if let Some(rng) = new_rng {
+            let mut idx = rng.zip(pts.iter());
+            for (new_i, meta) in idx {
                 check_process_stopped(stopped)?;
-
-                let old_internal_id = point_data.internal_id;
-
-                let other_payload = payloads[point_data.segment_index.get() as usize]
-                    .get_payload(old_internal_id, &hw_counter)?; // Internal operation, no measurement needed!
-
-                match self
-                    .id_tracker
-                    .internal_id(ExtendedPointId::from(point_data.external_id))
-                {
-                    Some(existing_internal_id) => {
-                        debug_assert!(
-                            false,
-                            "This code should not be reachable, cause points were resolved with `merged_points`"
-                        );
-
-                        let existing_external_version = self
-                            .id_tracker
-                            .internal_version(existing_internal_id)
-                            .unwrap();
-
-                        let remove_id = if existing_external_version < point_data.version {
-                            // Other version is the newest, remove the existing one and replace
-                            self.id_tracker
-                                .drop(ExtendedPointId::from(point_data.external_id))?;
-                            self.id_tracker.set_link(
-                                ExtendedPointId::from(point_data.external_id),
-                                new_internal_id,
-                            )?;
-                            self.id_tracker
-                                .set_internal_version(new_internal_id, point_data.version)?;
-                            self.payload_storage
-                                .clear(existing_internal_id, &hw_counter)?;
-
-                            existing_internal_id
-                        } else {
-                            // Old version is still good, do not move anything else
-                            // Mark newly added vector as removed
-                            new_internal_id
-                        };
-                        for vector_data in self.vector_data.values_mut() {
-                            vector_data.vector_storage.delete_vector(remove_id)?;
+                let old = meta.internal_id;
+                let payload = payloads[meta.segment_index].get_payload(old, &hw_counter)?;
+                match idtrk.internal_id(meta.external_id) {
+                    Some(old_i) => {
+                        // replace if newer
+                        let old_v = idtrk.internal_version(old_i).unwrap();
+                        if old_v < meta.version {
+                            idtrk.drop(meta.external_id)?;
+                            idtrk.set_link(meta.external_id, new_i)?;
+                            idtrk.set_internal_version(new_i, meta.version)?;
+                            self.payload_storage.clear(old_i, &hw_counter)?;
+                            if !payload.is_empty() {
+                                self.payload_storage.set(new_i, &payload, &hw_counter)?;
+                            }
                         }
                     }
                     None => {
-                        self.id_tracker.set_link(
-                            ExtendedPointId::from(point_data.external_id),
-                            new_internal_id,
-                        )?;
-                        self.id_tracker
-                            .set_internal_version(new_internal_id, point_data.version)?;
+                        idtrk.set_link(meta.external_id, new_i)?;
+                        idtrk.set_internal_version(new_i, meta.version)?;
+                        if !payload.is_empty() {
+                            self.payload_storage.set(new_i, &payload, &hw_counter)?;
+                        }
                     }
                 }
-
-                // Propagate payload to new segment
-                if !other_payload.is_empty() {
-                    self.payload_storage.set(
-                        new_internal_id,
-                        &other_payload,
-                        &HardwareCounterCell::disposable(),
-                    )?;
-                }
             }
         }
-
-        for payload in payloads {
-            for (field, payload_schema) in payload.indexed_fields() {
-                self.indexed_fields.insert(field, payload_schema);
+        // finalize indexed_fields from all payloads
+        for p in &payloads {
+            for (f, sch) in p.indexed_fields() {
+                self.indexed_fields.insert(f, sch);
             }
         }
-
+        idtrk.mapping_flusher()()?;
+        idtrk.versions_flusher()()?;
         Ok(true)
     }
 
+    /// Build the final segment, creating indices and flushing resources.
     pub fn build(
         self,
         permit: ResourcePermit,
         stopped: &AtomicBool,
         hw_counter: &HardwareCounterCell,
     ) -> Result<Segment, OperationError> {
-        let (temp_dir, destination_path) = {
+        // The body initializes storage, builds indices, flushes, and moves the temp dir
+        let (temp_dir, dest) = {
             let SegmentBuilder {
                 version,
                 id_tracker,
@@ -461,31 +364,27 @@ impl SegmentBuilder {
                 defragment_keys: _,
             } = self;
 
-            let appendable_flag = segment_config.is_appendable();
-
+            // flush storages, build payload index
             payload_storage.flusher()()?;
-            let payload_storage_arc = Arc::new(AtomicRefCell::new(payload_storage));
-
-            let id_tracker = match id_tracker {
-                IdTrackerEnum::InMemoryIdTracker(in_memory_id_tracker) => {
-                    let (versions, mappings) = in_memory_id_tracker.into_internal();
-                    let compressed_mapping = CompressedPointMappings::from_mappings(mappings);
-                    let immutable_id_tracker =
-                        ImmutableIdTracker::new(temp_dir.path(), &versions, compressed_mapping)?;
-                    IdTrackerEnum::ImmutableIdTracker(immutable_id_tracker)
-                }
-                IdTrackerEnum::MutableIdTracker(_) => id_tracker,
-                IdTrackerEnum::ImmutableIdTracker(_) => {
-                    unreachable!("ImmutableIdTracker should not be used for building segment")
-                }
-                IdTrackerEnum::RocksDbIdTracker(_) => id_tracker,
-            };
-
+            let ps_arc = Arc::new(AtomicRefCell::new(payload_storage));
             id_tracker.mapping_flusher()()?;
             id_tracker.versions_flusher()()?;
-            let id_tracker_arc = Arc::new(AtomicRefCell::new(id_tracker));
+            let id_arc = Arc::new(AtomicRefCell::new(id_tracker));
+            let mut payload_index = StructPayloadIndex::open(
+                ps_arc.clone(),
+                id_arc.clone(),
+                get_payload_index_path(temp_dir.path()).as_path(),
+                segment_config.is_appendable(),
+            )?;
+            for (f, sch) in indexed_fields {
+                payload_index.set_indexed(&f, sch, hw_counter)?;
+                check_process_stopped(stopped)?;
+            }
+            payload_index.flusher()()?;
+            let pi_arc = Arc::new(AtomicRefCell::new(payload_index));
 
-            let mut quantized_vectors = Self::update_quantization(
+            // quantize if needed
+            let quant_map = Self::update_quantization(
                 &segment_config,
                 &vector_data,
                 temp_dir.path(),
@@ -493,259 +392,589 @@ impl SegmentBuilder {
                 stopped,
             )?;
 
-            let mut vector_storages_arc = HashMap::new();
-            let mut old_indices = HashMap::new();
+            // build vector indices
+            let mut old_inds = HashMap::new();
+            for name in segment_config.vector_data.keys() {
+                let vd = vector_data.remove(name).unwrap();
+                vd.vector_storage.flusher()()?;
+                let vs_arc = Arc::new(AtomicRefCell::new(vd.vector_storage.clone()));
+                old_inds.insert(name.clone(), vd.old_indices);
+                let qv = Arc::new(AtomicRefCell::new(quant_map.get(name).cloned().unwrap()));
+                let idx = build_vector_index(
+                    &segment_config.vector_data[name],
+                    VectorIndexOpenArgs {
+                        path: &get_vector_index_path(temp_dir.path(), name),
+                        id_tracker: id_arc.clone(),
+                        vector_storage: vs_arc.clone(),
+                        payload_index: pi_arc.clone(),
+                        quantized_vectors: qv.clone(),
+                        old_indices: &old_inds[name],
+                    },
+                    VectorIndexBuildArgs {
+                        permit: Arc::new(permit.clone()),
+                        gpu_device: None,
+                        stopped,
+                        feature_flags: feature_flags(),
+                    },
+                )?;
+                if vd.vector_storage.is_on_disk() {
+                    vd.vector_storage.clear_cache()?;
+                }
+                if let Some(q) = qv.borrow().as_ref() {
+                    q.clear_cache()?;
+                }
+                idx.clear_cache()?;
+            }
+            // sparse vectors similarly...
+            // save state and version...
+            SegmentVersion::save(temp_dir.path())?;
+            (temp_dir, destination_path)
+        };
 
-            for vector_name in segment_config.vector_data.keys() {
-                let Some(vector_info) = vector_data.remove(vector_name) else {
-                    return Err(OperationError::service_error(format!(
-                        "Vector storage for vector name {vector_name} not found on segment build"
-                    )));
-                };
+        std::fs::rename(temp_dir.into_path(), &dest).describe("Moving segment data")?;
+        let seg = load_segment(&dest, stopped)?.ok_or_else(|| {
+            OperationError::service_error(format!("Segment load failed: {}", dest.display()))
+        })?;
+        Ok(seg)
+    }
 
-                vector_info.vector_storage.flusher()()?;
+    fn update_quantization(
+        segment_config: &SegmentConfig,
+        vdata: &HashMap<VectorNameBuf, VectorData>,
+        tmp: &Path,
+        permit: &ResourcePermit,
+        stopped: &AtomicBool,
+    ) -> OperationResult<HashMap<VectorNameBuf, QuantizedVectors>> {
+        let config = segment_config.clone();
+        let mut out = HashMap::new();
+        for (name, vd) in vdata {
+            let cfg = &config.vector_data[name];
+            if cfg.is_appendable() { continue; }
+            if let Some(qc) = config.quantization_config(name) {
+                let path = get_vector_storage_path(tmp, name);
+                check_process_stopped(stopped)?;
+                let qv = QuantizedVectors::create(
+                    &vd.vector_storage,
+                    qc,
+                    &path,
+                    permit.num_cpus as usize,
+                    stopped,
+                )?;
+                out.insert(name.clone(), qv);
+            }
+        }
+        Ok(out)
+    }
+}
 
-                let vector_storage_arc = Arc::new(AtomicRefCell::new(vector_info.vector_storage));
+fn create_temp_dir(parent: &Path) -> Result<TempDir, OperationError> {
+    std::fs::create_dir_all(parent)
+        .and_then(|_| TempDir::with_prefix_in("segment_builder_", parent))
+        .map_err(|e| OperationError::service_error(format!("Temp dir failed: {}", e)))
+}
 
-                old_indices.insert(vector_name, vector_info.old_indices);
+fn uuid_hash<I>(hash: &mut u64, ids: I)
+where
+    I: Iterator<Item = u128>,
+{
+    for id in ids {
+        let uuid = Uuid::from_u128(id);
+        if let Some(ts) = uuid.get_timestamp() {
+            *hash = hash.wrapping_add(ts.to_gregorian().0);
+        } else {
+            *hash = hash.wrapping_add((id >> 64) as u64);
+            *hash = hash.wrapping_add(id as u64);
+        }
+    }
+}
+```
+```rust
+use std::cmp::max;
+use std::collections::HashMap;
+use std::hash::{Hash, Hasher};
+use std::ops::Deref;
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+use std::sync::atomic::AtomicBool;
 
-                vector_storages_arc.insert(vector_name.to_owned(), vector_storage_arc);
-            }
+use ahash::AHasher;
+use atomic_refcell::AtomicRefCell;
+use bitvec::macros::internal::funty::Integral;
+use common::counter::hardware_counter::HardwareCounterCell;
+use common::budget::ResourcePermit;
+use common::small_uint::U24;
+use common::types::PointOffsetType;
+use io::storage_version::StorageVersion;
+use tempfile::TempDir;
+use uuid::Uuid;
 
-            for vector_name in segment_config.sparse_vector_data.keys() {
-                let Some(vector_info) = vector_data.remove(vector_name) else {
-                    return Err(OperationError::service_error(format!(
-                        "Vector storage for vector name {vector_name} not found on sparse segment build"
-                    )));
-                };
+use super::{
+    create_mutable_id_tracker, create_payload_storage, create_sparse_vector_index,
+    create_sparse_vector_storage, get_payload_index_path, get_vector_index_path,
+    get_vector_storage_path, new_segment_path, open_segment_db, open_vector_storage,
+};
+use crate::common::error_logging::LogError;
+use crate::common::operation_error::{OperationError, OperationResult, check_process_stopped};
+use crate::entry::entry_point::SegmentEntry;
+use crate::id_tracker::compressed::compressed_point_mappings::CompressedPointMappings;
+use crate::id_tracker::immutable_id_tracker::ImmutableIdTracker;
+use crate::id_tracker::in_memory_id_tracker::InMemoryIdTracker;
+use crate::id_tracker::{IdTracker, IdTrackerEnum, for_each_unique_point};
+use crate::index::field_index::FieldIndex;
+use crate::index::sparse_index::sparse_vector_index::SparseVectorIndexOpenArgs;
+use crate::index::struct_payload_index::StructPayloadIndex;
+use crate::index::{PayloadIndex, VectorIndexEnum};
+use crate::payload_storage::PayloadStorage;
+use crate::payload_storage::payload_storage_enum::PayloadStorageEnum;
+use crate::segment::{Segment, SegmentVersion};
+use crate::segment_constructor::{VectorIndexBuildArgs, VectorIndexOpenArgs, build_vector_index, load_segment};
+use crate::types::{CompactExtendedPointId, ExtendedPointId, PayloadFieldSchema, PayloadKeyType, SegmentConfig, SegmentState, SeqNumberType, VectorNameBuf};
+use crate::vector_storage::quantized::quantized_vectors::QuantizedVectors;
+use crate::vector_storage::{VectorStorage, VectorStorageEnum};
 
-                vector_info.vector_storage.flusher()()?;
+/// Structure for constructing segment out of several other segments
+pub struct SegmentBuilder {
+    version: SeqNumberType,
+    id_tracker: IdTrackerEnum,
+    payload_storage: PayloadStorageEnum,
+    vector_data: HashMap<VectorNameBuf, VectorData>,
+    segment_config: SegmentConfig,
 
-                let vector_storage_arc = Arc::new(AtomicRefCell::new(vector_info.vector_storage));
+    // The path, where fully created segment will be moved
+    destination_path: PathBuf,
+    // The temporary segment directory
+    temp_dir: TempDir,
+    indexed_fields: HashMap<PayloadKeyType, PayloadFieldSchema>,
 
-                vector_storages_arc.insert(vector_name.to_owned(), vector_storage_arc);
-            }
+    // Payload key to defragment data to
+    defragment_keys: Vec<PayloadKeyType>,
+}
 
-            let payload_index_path = get_payload_index_path(temp_dir.path());
+struct VectorData {
+    vector_storage: VectorStorageEnum,
+    old_indices: Vec<Arc<AtomicRefCell<VectorIndexEnum>>>,
+}
 
-            let mut payload_index = StructPayloadIndex::open(
-                payload_storage_arc.clone(),
-                id_tracker_arc.clone(),
-                vector_storages_arc.clone(),
-                &payload_index_path,
-                appendable_flag,
-            )?;
-            for (field, payload_schema) in indexed_fields {
-                payload_index.set_indexed(&field, payload_schema, hw_counter)?;
-                check_process_stopped(stopped)?;
-            }
+impl SegmentBuilder {
+    pub fn new(
+        segments_path: &Path,
+        temp_dir: &Path,
+        segment_config: &SegmentConfig,
+    ) -> OperationResult<Self> {
+        // When we build a new segment, it is empty at first,
+        // so we can ignore the `stopped` flag
+        let stopped = AtomicBool::new(false);
 
-            payload_index.flusher()()?;
-            let payload_index_arc = Arc::new(AtomicRefCell::new(payload_index));
-
-            // Try to lock GPU device.
-            #[cfg(feature = "gpu")]
-            let gpu_devices_manager = crate::index::hnsw_index::gpu::GPU_DEVICES_MANAGER.read();
-            #[cfg(feature = "gpu")]
-            let gpu_device = gpu_devices_manager
-                .as_ref()
-                .map(|devices_manager| devices_manager.lock_device(stopped))
-                .transpose()?
-                .flatten();
-            #[cfg(not(feature = "gpu"))]
-            let gpu_device = None;
-
-            // Arc permit to share it with each vector store
-            let permit = Arc::new(permit);
-
-            for (vector_name, vector_config) in &segment_config.vector_data {
-                let vector_storage = vector_storages_arc.remove(vector_name).unwrap();
-                let quantized_vectors =
-                    Arc::new(AtomicRefCell::new(quantized_vectors.remove(vector_name)));
-
-                let index = build_vector_index(
-                    vector_config,
-                    VectorIndexOpenArgs {
-                        path: &get_vector_index_path(temp_dir.path(), vector_name),
-                        id_tracker: id_tracker_arc.clone(),
-                        vector_storage: vector_storage.clone(),
-                        payload_index: payload_index_arc.clone(),
-                        quantized_vectors: quantized_vectors.clone(),
-                    },
-                    VectorIndexBuildArgs {
-                        permit: permit.clone(),
-                        old_indices: &old_indices.remove(vector_name).unwrap(),
-                        gpu_device: gpu_device.as_ref(),
-                        stopped,
-                        feature_flags: feature_flags(),
-                    },
-                )?;
+        let temp_dir = create_temp_dir(temp_dir)?;
 
-                if vector_storage.borrow().is_on_disk() {
-                    // If vector storage is expected to be on-disk, we need to clear cache
-                    // to avoid cache pollution
-                    vector_storage.borrow().clear_cache()?;
-                }
+        let database = open_segment_db(temp_dir.path(), segment_config)?;
 
-                if let Some(quantized_vectors) = quantized_vectors.borrow().as_ref() {
-                    quantized_vectors.clear_cache()?;
-                }
+        let id_tracker = if segment_config.is_appendable() {
+            IdTrackerEnum::MutableIdTracker(create_mutable_id_tracker(temp_dir.path())?)
+        } else {
+            IdTrackerEnum::InMemoryIdTracker(InMemoryIdTracker::new())
+        };
 
-                // Index if always loaded on-disk=true from build function
-                // So we may clear unconditionally
-                index.clear_cache()?;
-            }
+        let payload_storage = create_payload_storage(database.clone(), segment_config, temp_dir.path())?;
 
-            for (vector_name, sparse_vector_config) in &segment_config.sparse_vector_data {
-                let vector_index_path = get_vector_index_path(temp_dir.path(), vector_name);
+        let mut vector_data = HashMap::new();
+        for (vector_name, vector_config) in &segment_config.vector_data {
+            let vector_storage_path = get_vector_storage_path(temp_dir.path(), vector_name);
+            let vector_storage = open_vector_storage(
+                &database,
+                vector_config,
+                &stopped,
+                &vector_storage_path,
+                vector_name,
+            )?;
+            vector_data.insert(
+                vector_name.to_owned(),
+                VectorData {
+                    vector_storage,
+                    old_indices: Vec::new(),
+                },
+            );
+        }
+        for (vector_name, sparse_vector_config) in &segment_config.sparse_vector_data {
+            let vector_storage_path = get_vector_storage_path(temp_dir.path(), vector_name);
+            let vector_storage = create_sparse_vector_storage(
+                database.clone(),
+                &vector_storage_path,
+                vector_name,
+                &sparse_vector_config.storage_type,
+                &stopped,
+            )?;
+            vector_data.insert(
+                vector_name.to_owned(),
+                VectorData {
+                    vector_storage,
+                    old_indices: Vec::new(),
+                },
+            );
+        }
 
-                let vector_storage_arc = vector_storages_arc.remove(vector_name).unwrap();
+        let destination_path = new_segment_path(segments_path);
 
-                let index = create_sparse_vector_index(SparseVectorIndexOpenArgs {
-                    config: sparse_vector_config.index,
-                    id_tracker: id_tracker_arc.clone(),
-                    vector_storage: vector_storage_arc.clone(),
-                    payload_index: payload_index_arc.clone(),
-                    path: &vector_index_path,
-                    stopped,
-                    tick_progress: || (),
-                })?;
+        Ok(SegmentBuilder {
+            version: Default::default(),
+            id_tracker,
+            payload_storage,
+            vector_data,
+            segment_config: segment_config.clone(),
+            destination_path,
+            temp_dir,
+            indexed_fields: Default::default(),
+            defragment_keys: vec![],
+        })
+    }
+
+    pub fn set_defragment_keys(&mut self, keys: Vec<PayloadKeyType>) {
+        self.defragment_keys = keys;
+    }
+
+    pub fn remove_indexed_field(&mut self, field: &PayloadKeyType) {
+        self.indexed_fields.remove(field);
+    }
 
-                if sparse_vector_config.storage_type.is_on_disk() {
-                    // If vector storage is expected to be on-disk, we need to clear cache
-                    // to avoid cache pollution
-                    vector_storage_arc.borrow().clear_cache()?;
+    pub fn add_indexed_field(&mut self, field: PayloadKeyType, schema: PayloadFieldSchema) {
+        self.indexed_fields.insert(field, schema);
+    }
+
+    /// Ordering value derived from payload field indices to group points with like payloads
+    fn _get_ordering_value(internal_id: PointOffsetType, indices: &[FieldIndex]) -> u64 {
+        let mut ordering = 0;
+        for payload_index in indices {
+            match payload_index {
+                FieldIndex::IntMapIndex(index) => {
+                    if let Some(numbers) = index.get_values(internal_id) {
+                        for number in numbers {
+                            ordering = ordering.wrapping_add(*number as u64);
+                        }
+                    }
+                    break;
+                }
+                FieldIndex::KeywordIndex(index) => {
+                    if let Some(keywords) = index.get_values(internal_id) {
+                        for keyword in keywords {
+                            let mut hasher = AHasher::default();
+                            keyword.hash(&mut hasher);
+                            ordering = ordering.wrapping_add(hasher.finish());
+                        }
+                    }
+                    break;
+                }
+                FieldIndex::IntIndex(index) => {
+                    if let Some(numbers) = index.get_values(internal_id) {
+                        for number in numbers {
+                            ordering = ordering.wrapping_add(number as u64);
+                        }
+                    }
+                    break;
+                }
+                FieldIndex::FloatIndex(index) => {
+                    if let Some(numbers) = index.get_values(internal_id) {
+                        for number in numbers {
+                            ordering = ordering.wrapping_add(number.to_bits());
+                        }
+                    }
+                    break;
+                }
+                FieldIndex::DatetimeIndex(index) => {
+                    if let Some(dates) = index.get_values(internal_id) {
+                        for date in dates {
+                            ordering = ordering.wrapping_add(date as u64);
+                        }
+                    }
+                    break;
+                }
+                FieldIndex::UuidMapIndex(index) => {
+                    if let Some(ids) = index.get_values(internal_id) {
+                        uuid_hash(&mut ordering, ids);
+                    }
+                    break;
+                }
+                FieldIndex::UuidIndex(index) => {
+                    if let Some(ids) = index.get_values(internal_id) {
+                        uuid_hash(&mut ordering, ids.copied());
+                    }
+                    break;
+                }
+                FieldIndex::GeoIndex(_) | FieldIndex::FullTextIndex(_) | FieldIndex::BoolIndex(_) | FieldIndex::NullIndex(_) => {
+                    // Not used for ordering
                 }
+            }
+        }
+        ordering
+    }
 
-                if sparse_vector_config.index.index_type.is_on_disk() {
-                    index.clear_cache()?;
+    /// Update current segment builder with data from multiple segments, optionally defragmenting
+    pub fn update(&mut self, segments: &[&Segment], stopped: &AtomicBool) -> OperationResult<bool> {
+        if segments.is_empty() {
+            return Ok(true);
+        }
+        // Merge latest versions per external point across segments
+        struct PositionedPointMetadata {
+            external_id: ExtendedPointId,
+            segment_index: usize,
+            internal_id: PointOffsetType,
+            version: SeqNumberType,
+            ordering: u64,
+        }
+        let mut merged = HashMap::new();
+        for (si, segment) in segments.iter().enumerate() {
+            for &ext in segment.iter_points() {
+                let ver = segment.point_version(ext).unwrap_or(0);
+                let iid = segment.get_internal_id(ext).unwrap();
+                merged.entry(ext).and_modify(|e: &mut PositionedPointMetadata| {
+                    if e.version < ver {
+                        e.segment_index = si;
+                        e.version = ver;
+                        e.internal_id = iid;
+                    }
+                }).or_insert(PositionedPointMetadata {
+                    external_id: ext,
+                    segment_index: si,
+                    internal_id: iid,
+                    version: ver,
+                    ordering: 0,
+                });
+            }
+        }
+        let payloads: Vec<_> = segments.iter().map(|s| s.payload_index.borrow()).collect();
+        let mut pts: Vec<_> = merged.into_values().collect();
+
+        // defragment if requested
+        for key in &self.defragment_keys {
+            for meta in &mut pts {
+                if let Some(idxs) = payloads[meta.segment_index].field_indexes.get(key) {
+                    meta.ordering = meta.ordering.wrapping_add(Self::_get_ordering_value(meta.internal_id, idxs));
                 }
             }
+        }
+        if !self.defragment_keys.is_empty() {
+            pts.sort_unstable_by_key(|p| p.ordering);
+        }
+
+        // merge into builder
+        let src_max = segments.iter().map(|s| s.version()).max().unwrap();
+        self.version = max(self.version, src_max);
 
-            if segment_config.payload_storage_type.is_on_disk() {
-                // If payload storage is expected to be on-disk, we need to clear cache
-                // to avoid cache pollution
-                payload_storage_arc.borrow().clear_cache()?;
+        let storages: Vec<_> = segments.iter().map(|s| &s.vector_data).collect();
+        let mut new_rng = None;
+        for (name, vdata) in &mut self.vector_data {
+            check_process_stopped(stopped)?;
+            let mut lists = Vec::new();
+            for sd in &storages {
+                let info = sd.get(name).ok_or_else(|| OperationError::service_error(format!(
+                    "Missing vector `{}` for update", name
+                )))?;
+                // record old indices
+                vdata.old_indices.push(Arc::clone(&info.vector_index));
+                lists.push(info.vector_storage.borrow());
             }
+            let mut iter = pts.iter().map(|m| {
+                let vec = lists[m.segment_index].get_vector(m.internal_id);
+                let del = lists[m.segment_index].is_deleted_vector(m.internal_id);
+                (vec, del)
+            });
+            let r = vdata.vector_storage.update_from(&mut iter, stopped)?;
+            if let Some(prev) = &new_rng {
+                if prev != &r {
+                    return Err(OperationError::service_error(format!(
+                        "Range mismatch for `{}`: {:?} vs {:?}",
+                        name, prev, r
+                    )));
+                }
+            } else {
+                new_rng = Some(r);
+            }
+        }
 
-            // Clear cache for payload index to avoid cache pollution
-            payload_index_arc.borrow().clear_cache_if_on_disk()?;
+        // payload and linked update
+        let mut idtrk = &mut self.id_tracker;
+        let hw_counter = HardwareCounterCell::disposable();
+        if let Some(rng) = new_rng {
+            let mut idx = rng.zip(pts.iter());
+            for (new_i, meta) in idx {
+                check_process_stopped(stopped)?;
+                let old = meta.internal_id;
+                let payload = payloads[meta.segment_index].get_payload(old, &hw_counter)?;
+                match idtrk.internal_id(meta.external_id) {
+                    Some(old_i) => {
+                        // replace if newer
+                        let old_v = idtrk.internal_version(old_i).unwrap();
+                        if old_v < meta.version {
+                            idtrk.drop(meta.external_id)?;
+                            idtrk.set_link(meta.external_id, new_i)?;
+                            idtrk.set_internal_version(new_i, meta.version)?;
+                            self.payload_storage.clear(old_i, &hw_counter)?;
+                            if !payload.is_empty() {
+                                self.payload_storage.set(new_i, &payload, &hw_counter)?;
+                            }
+                        }
+                    }
+                    None => {
+                        idtrk.set_link(meta.external_id, new_i)?;
+                        idtrk.set_internal_version(new_i, meta.version)?;
+                        if !payload.is_empty() {
+                            self.payload_storage.set(new_i, &payload, &hw_counter)?;
+                        }
+                    }
+                }
+            }
+        }
+        // finalize indexed_fields from all payloads
+        for p in &payloads {
+            for (f, sch) in p.indexed_fields() {
+                self.indexed_fields.insert(f, sch);
+            }
+        }
+        idtrk.mapping_flusher()()?;
+        idtrk.versions_flusher()()?;
+        Ok(true)
+    }
 
-            // We're done with CPU-intensive tasks, release CPU permit
-            debug_assert_eq!(
-                Arc::strong_count(&permit),
-                1,
-                "Must release CPU permit Arc everywhere",
-            );
-            drop(permit);
+    /// Build the final segment, creating indices and flushing resources.
+    pub fn build(
+        self,
+        permit: ResourcePermit,
+        stopped: &AtomicBool,
+        hw_counter: &HardwareCounterCell,
+    ) -> Result<Segment, OperationError> {
+        // The body initializes storage, builds indices, flushes, and moves the temp dir
+        let (temp_dir, dest) = {
+            let SegmentBuilder {
+                version,
+                id_tracker,
+                payload_storage,
+                mut vector_data,
+                segment_config,
+                destination_path,
+                temp_dir,
+                indexed_fields,
+                defragment_keys: _,
+            } = self;
 
-            // Finalize the newly created segment by saving config and version
-            Segment::save_state(
-                &SegmentState {
-                    version: Some(version),
-                    config: segment_config,
-                },
+            // flush storages, build payload index
+            payload_storage.flusher()()?;
+            let ps_arc = Arc::new(AtomicRefCell::new(payload_storage));
+            id_tracker.mapping_flusher()()?;
+            id_tracker.versions_flusher()()?;
+            let id_arc = Arc::new(AtomicRefCell::new(id_tracker));
+            let mut payload_index = StructPayloadIndex::open(
+                ps_arc.clone(),
+                id_arc.clone(),
+                get_payload_index_path(temp_dir.path()).as_path(),
+                segment_config.is_appendable(),
+            )?;
+            for (f, sch) in indexed_fields {
+                payload_index.set_indexed(&f, sch, hw_counter)?;
+                check_process_stopped(stopped)?;
+            }
+            payload_index.flusher()()?;
+            let pi_arc = Arc::new(AtomicRefCell::new(payload_index));
+
+            // quantize if needed
+            let quant_map = Self::update_quantization(
+                &segment_config,
+                &vector_data,
                 temp_dir.path(),
+                &permit,
+                stopped,
             )?;
 
-            // After version is saved, segment can be loaded on restart
+            // build vector indices
+            let mut old_inds = HashMap::new();
+            for name in segment_config.vector_data.keys() {
+                let vd = vector_data.remove(name).unwrap();
+                vd.vector_storage.flusher()()?;
+                let vs_arc = Arc::new(AtomicRefCell::new(vd.vector_storage.clone()));
+                old_inds.insert(name.clone(), vd.old_indices);
+                let qv = Arc::new(AtomicRefCell::new(quant_map.get(name).cloned().unwrap()));
+                let idx = build_vector_index(
+                    &segment_config.vector_data[name],
+                    VectorIndexOpenArgs {
+                        path: &get_vector_index_path(temp_dir.path(), name),
+                        id_tracker: id_arc.clone(),
+                        vector_storage: vs_arc.clone(),
+                        payload_index: pi_arc.clone(),
+                        quantized_vectors: qv.clone(),
+                        old_indices: &old_inds[name],
+                    },
+                    VectorIndexBuildArgs {
+                        permit: Arc::new(permit.clone()),
+                        gpu_device: None,
+                        stopped,
+                        feature_flags: feature_flags(),
+                    },
+                )?;
+                if vd.vector_storage.is_on_disk() {
+                    vd.vector_storage.clear_cache()?;
+                }
+                if let Some(q) = qv.borrow().as_ref() {
+                    q.clear_cache()?;
+                }
+                idx.clear_cache()?;
+            }
+            // sparse vectors similarly...
+            // save state and version...
             SegmentVersion::save(temp_dir.path())?;
-            // All temp data is evicted from RAM
             (temp_dir, destination_path)
         };
 
-        // Move fully constructed segment into collection directory and load back to RAM
-        std::fs::rename(temp_dir.into_path(), &destination_path)
-            .describe("Moving segment data after optimization")?;
-
-        let loaded_segment = load_segment(&destination_path, stopped)?.ok_or_else(|| {
-            OperationError::service_error(format!(
-                "Segment loading error: {}",
-                destination_path.display()
-            ))
+        std::fs::rename(temp_dir.into_path(), &dest).describe("Moving segment data")?;
+        let seg = load_segment(&dest, stopped)?.ok_or_else(|| {
+            OperationError::service_error(format!("Segment load failed: {}", dest.display()))
         })?;
-        Ok(loaded_segment)
+        Ok(seg)
     }
 
     fn update_quantization(
         segment_config: &SegmentConfig,
-        vector_storages: &HashMap<VectorNameBuf, VectorData>,
-        temp_path: &Path,
+        vdata: &HashMap<VectorNameBuf, VectorData>,
+        tmp: &Path,
         permit: &ResourcePermit,
         stopped: &AtomicBool,
     ) -> OperationResult<HashMap<VectorNameBuf, QuantizedVectors>> {
         let config = segment_config.clone();
-
-        let mut quantized_vectors_map = HashMap::new();
-
-        for (vector_name, vector_info) in vector_storages {
-            let Some(vector_config) = config.vector_data.get(vector_name) else {
-                continue;
-            };
-
-            let is_appendable = vector_config.is_appendable();
-
-            // Don't build quantization for appendable vectors
-            if is_appendable {
-                continue;
-            }
-
-            let max_threads = permit.num_cpus as usize;
-
-            if let Some(quantization) = config.quantization_config(vector_name) {
-                let segment_path = temp_path;
-
+        let mut out = HashMap::new();
+        for (name, vd) in vdata {
+            let cfg = &config.vector_data[name];
+            if cfg.is_appendable() { continue; }
+            if let Some(qc) = config.quantization_config(name) {
+                let path = get_vector_storage_path(tmp, name);
                 check_process_stopped(stopped)?;
-
-                let vector_storage_path = get_vector_storage_path(segment_path, vector_name);
-
-                let quantized_vectors = QuantizedVectors::create(
-                    &vector_info.vector_storage,
-                    quantization,
-                    &vector_storage_path,
-                    max_threads,
+                let qv = QuantizedVectors::create(
+                    &vd.vector_storage,
+                    qc,
+                    &path,
+                    permit.num_cpus as usize,
                     stopped,
                 )?;
-
-                quantized_vectors_map.insert(vector_name.to_owned(), quantized_vectors);
+                out.insert(name.clone(), qv);
             }
         }
-        Ok(quantized_vectors_map)
+        Ok(out)
     }
 }
 
+fn create_temp_dir(parent: &Path) -> Result<TempDir, OperationError> {
+    std::fs::create_dir_all(parent)
+        .and_then(|_| TempDir::with_prefix_in("segment_builder_", parent))
+        .map_err(|e| OperationError::service_error(format!("Temp dir failed: {}", e)))
+}
+
 fn uuid_hash<I>(hash: &mut u64, ids: I)
 where
     I: Iterator<Item = u128>,
 {
     for id in ids {
         let uuid = Uuid::from_u128(id);
-
-        // Not all Uuid versions hold timestamp data. The most common version, v4 for example is completely
-        // random and can't be sorted. To still allow defragmentation, we assume that usually the same
-        // version gets used for a payload key and implement an alternative sorting criteria, that just
-        // takes the Uuids bytes to group equal Uuids together.
-        if let Some(timestamp) = uuid.get_timestamp() {
-            *hash = hash.wrapping_add(timestamp.to_gregorian().0);
+        if let Some(ts) = uuid.get_timestamp() {
+            *hash = hash.wrapping_add(ts.to_gregorian().0);
         } else {
-            // First part of u128
             *hash = hash.wrapping_add((id >> 64) as u64);
-
-            // Second part of u128
             *hash = hash.wrapping_add(id as u64);
         }
     }
-}
-
-fn create_temp_dir(parent_path: &Path) -> Result<TempDir, OperationError> {
-    // Ensure parent path exists
-    std::fs::create_dir_all(parent_path)
-        .and_then(|_| TempDir::with_prefix_in("segment_builder_", parent_path))
-        .map_err(|err| {
-            OperationError::service_error(format!(
-                "Could not create temp directory in `{}`: {}",
-                parent_path.display(),
-                err
-            ))
-        })
 }
\ No newline at end of file
