--- qdrant_lib_segment_src_segment_constructor_segment_builder.rs_expectedoutput.txt (expected)+++ qdrant_lib_segment_src_segment_constructor_segment_builder.rs_extracted.txt (actual)@@ -1,17 +1,16 @@-use std::cmp;
+use core::cmp;
 use std::collections::HashMap;
 use std::hash::{Hash, Hasher};
 use std::ops::Deref;
 use std::path::{Path, PathBuf};
+use std::sync::atomic::AtomicBool;
 use std::sync::Arc;
-use std::sync::atomic::AtomicBool;
 
 use ahash::AHasher;
 use atomic_refcell::AtomicRefCell;
 use bitvec::macros::internal::funty::Integral;
 use common::budget::ResourcePermit;
 use common::counter::hardware_counter::HardwareCounterCell;
-use common::flags::feature_flags;
 use common::small_uint::U24;
 use common::types::PointOffsetType;
 use io::storage_version::StorageVersion;
@@ -25,21 +24,21 @@     get_vector_storage_path, new_segment_path, open_segment_db, open_vector_storage,
 };
 use crate::common::error_logging::LogError;
-use crate::common::operation_error::{OperationError, OperationResult, check_process_stopped};
+use crate::common::operation_error::{check_process_stopped, OperationError, OperationResult};
 use crate::entry::entry_point::SegmentEntry;
 use crate::id_tracker::compressed::compressed_point_mappings::CompressedPointMappings;
 use crate::id_tracker::immutable_id_tracker::ImmutableIdTracker;
 use crate::id_tracker::in_memory_id_tracker::InMemoryIdTracker;
-use crate::id_tracker::{IdTracker, IdTrackerEnum, for_each_unique_point};
+use crate::id_tracker::{for_each_unique_point, IdTracker, IdTrackerEnum};
 use crate::index::field_index::FieldIndex;
 use crate::index::sparse_index::sparse_vector_index::SparseVectorIndexOpenArgs;
 use crate::index::struct_payload_index::StructPayloadIndex;
 use crate::index::{PayloadIndex, VectorIndexEnum};
+use crate::payload_storage::payload_storage_enum::PayloadStorageEnum;
 use crate::payload_storage::PayloadStorage;
-use crate::payload_storage::payload_storage_enum::PayloadStorageEnum;
 use crate::segment::{Segment, SegmentVersion};
 use crate::segment_constructor::{
-    VectorIndexBuildArgs, VectorIndexOpenArgs, build_vector_index, load_segment,
+    build_vector_index, load_segment, VectorIndexBuildArgs, VectorIndexOpenArgs,
 };
 use crate::types::{
     CompactExtendedPointId, ExtendedPointId, PayloadFieldSchema, PayloadKeyType, SegmentConfig,
@@ -235,7 +234,7 @@                 }
                 FieldIndex::UuidIndex(index) => {
                     if let Some(ids) = index.get_values(internal_id) {
-                        uuid_hash(&mut ordering, ids);
+                        uuid_hash(&mut ordering, ids.copied());
                     }
                     break;
                 }
@@ -262,20 +261,6 @@             return Ok(true);
         }
 
-        struct PointData {
-            external_id: CompactExtendedPointId,
-            /// [`CompactExtendedPointId`] is 17 bytes, we reduce
-            /// `segment_index` to 3 bytes to avoid paddings and align nicely.
-            segment_index: U24,
-            internal_id: PointOffsetType,
-            version: u64,
-            ordering: u64,
-        }
-
-        if segments.len() > U24::MAX as usize {
-            return Err(OperationError::service_error("Too many segments to update"));
-        }
-
         let mut points_to_insert = Vec::new();
         let locked_id_trackers = segments.iter().map(|s| s.id_tracker.borrow()).collect_vec();
         for_each_unique_point(locked_id_trackers.iter().map(|i| i.deref()), |item| {
@@ -439,12 +424,15 @@             }
         }
 
+        self.id_tracker.mapping_flusher()()?;
+        self.id_tracker.versions_flusher()()?;
+
         Ok(true)
     }
 
     pub fn build(
         self,
-        permit: ResourcePermit,
+        mut permit: ResourcePermit,
         stopped: &AtomicBool,
         hw_counter: &HardwareCounterCell,
     ) -> Result<Segment, OperationError> {
@@ -485,64 +473,6 @@             id_tracker.versions_flusher()()?;
             let id_tracker_arc = Arc::new(AtomicRefCell::new(id_tracker));
 
-            let mut quantized_vectors = Self::update_quantization(
-                &segment_config,
-                &vector_data,
-                temp_dir.path(),
-                &permit,
-                stopped,
-            )?;
-
-            let mut vector_storages_arc = HashMap::new();
-            let mut old_indices = HashMap::new();
-
-            for vector_name in segment_config.vector_data.keys() {
-                let Some(vector_info) = vector_data.remove(vector_name) else {
-                    return Err(OperationError::service_error(format!(
-                        "Vector storage for vector name {vector_name} not found on segment build"
-                    )));
-                };
-
-                vector_info.vector_storage.flusher()()?;
-
-                let vector_storage_arc = Arc::new(AtomicRefCell::new(vector_info.vector_storage));
-
-                old_indices.insert(vector_name, vector_info.old_indices);
-
-                vector_storages_arc.insert(vector_name.to_owned(), vector_storage_arc);
-            }
-
-            for vector_name in segment_config.sparse_vector_data.keys() {
-                let Some(vector_info) = vector_data.remove(vector_name) else {
-                    return Err(OperationError::service_error(format!(
-                        "Vector storage for vector name {vector_name} not found on sparse segment build"
-                    )));
-                };
-
-                vector_info.vector_storage.flusher()()?;
-
-                let vector_storage_arc = Arc::new(AtomicRefCell::new(vector_info.vector_storage));
-
-                vector_storages_arc.insert(vector_name.to_owned(), vector_storage_arc);
-            }
-
-            let payload_index_path = get_payload_index_path(temp_dir.path());
-
-            let mut payload_index = StructPayloadIndex::open(
-                payload_storage_arc.clone(),
-                id_tracker_arc.clone(),
-                vector_storages_arc.clone(),
-                &payload_index_path,
-                appendable_flag,
-            )?;
-            for (field, payload_schema) in indexed_fields {
-                payload_index.set_indexed(&field, payload_schema, hw_counter)?;
-                check_process_stopped(stopped)?;
-            }
-
-            payload_index.flusher()()?;
-            let payload_index_arc = Arc::new(AtomicRefCell::new(payload_index));
-
             // Try to lock GPU device.
             #[cfg(feature = "gpu")]
             let gpu_devices_manager = crate::index::hnsw_index::gpu::GPU_DEVICES_MANAGER.read();
@@ -557,6 +487,65 @@ 
             // Arc permit to share it with each vector store
             let permit = Arc::new(permit);
+
+            let mut quantized_vectors = Self::update_quantization(
+                &segment_config,
+                &vector_data,
+                temp_dir.path(),
+                &permit,
+                stopped,
+            )?;
+
+            let mut vector_storages_arc = HashMap::new();
+            let mut old_indices = HashMap::new();
+
+            for vector_name in segment_config.vector_data.keys() {
+                let Some(vector_info) = vector_data.remove(vector_name) else {
+                    return Err(OperationError::service_error(format!(
+                        "Vector storage for vector name {vector_name} not found on segment build"
+                    )));
+                };
+
+                vector_info.vector_storage.flusher()()?;
+
+                let vector_storage_arc = Arc::new(AtomicRefCell::new(vector_info.vector_storage));
+
+                old_indices.insert(vector_name.to_owned(), vector_info.old_indices);
+
+                vector_storages_arc.insert(vector_name.to_owned(), vector_storage_arc);
+            }
+
+            for vector_name in segment_config.sparse_vector_data.keys() {
+                let Some(vector_info) = vector_data.remove(vector_name) else {
+                    return Err(OperationError::service_error(format!(
+                        "Vector storage for vector name {vector_name} not found on sparse segment build"
+                    )));
+                };
+
+                vector_info.vector_storage.flusher()()?;
+
+                let vector_storage_arc = Arc::new(AtomicRefCell::new(vector_info.vector_storage));
+
+                vector_storages_arc.insert(vector_name.to_owned(), vector_storage_arc);
+            }
+
+            let payload_index_path = get_payload_index_path(temp_dir.path());
+
+            let mut payload_index = StructPayloadIndex::open(
+                payload_storage_arc.clone(),
+                id_tracker_arc.clone(),
+                vector_storages_arc.clone(),
+                &payload_index_path,
+                appendable_flag,
+            )?;
+
+            for (field, payload_schema) in indexed_fields {
+                payload_index.set_indexed(&field, payload_schema, hw_counter)?;
+                check_process_stopped(stopped)?;
+            }
+
+            payload_index.flusher()()?;
+            let payload_index_arc = Arc::new(AtomicRefCell::new(payload_index));
 
             for (vector_name, vector_config) in &segment_config.vector_data {
                 let vector_storage = vector_storages_arc.remove(vector_name).unwrap();
@@ -584,22 +573,22 @@                 if vector_storage.borrow().is_on_disk() {
                     // If vector storage is expected to be on-disk, we need to clear cache
                     // to avoid cache pollution
-                    vector_storage.borrow().clear_cache()?;
+                    vector_storage.borrow().clear_cache(hw_counter)?;
                 }
 
                 if let Some(quantized_vectors) = quantized_vectors.borrow().as_ref() {
-                    quantized_vectors.clear_cache()?;
+                    quantized_vectors.clear_cache(hw_counter)?;
                 }
 
                 // Index if always loaded on-disk=true from build function
                 // So we may clear unconditionally
-                index.clear_cache()?;
+                index.clear_cache(hw_counter)?;
             }
 
             for (vector_name, sparse_vector_config) in &segment_config.sparse_vector_data {
                 let vector_index_path = get_vector_index_path(temp_dir.path(), vector_name);
 
-                let vector_storage_arc = vector_storages_arc.remove(vector_name).unwrap();
+                let vector_storage_arc = vector_storages_arc.remove(vector_name.as_str()).unwrap();
 
                 let index = create_sparse_vector_index(SparseVectorIndexOpenArgs {
                     config: sparse_vector_config.index,
@@ -614,22 +603,22 @@                 if sparse_vector_config.storage_type.is_on_disk() {
                     // If vector storage is expected to be on-disk, we need to clear cache
                     // to avoid cache pollution
-                    vector_storage_arc.borrow().clear_cache()?;
+                    vector_storage_arc.borrow().clear_cache(hw_counter)?;
                 }
 
                 if sparse_vector_config.index.index_type.is_on_disk() {
-                    index.clear_cache()?;
+                    index.clear_cache(hw_counter)?;
                 }
             }
 
             if segment_config.payload_storage_type.is_on_disk() {
                 // If payload storage is expected to be on-disk, we need to clear cache
                 // to avoid cache pollution
-                payload_storage_arc.borrow().clear_cache()?;
+                payload_storage_arc.borrow().clear_cache(hw_counter)?;
             }
 
             // Clear cache for payload index to avoid cache pollution
-            payload_index_arc.borrow().clear_cache_if_on_disk()?;
+            payload_index_arc.borrow().clear_cache_if_on_disk(hw_counter)?;
 
             // We're done with CPU-intensive tasks, release CPU permit
             debug_assert_eq!(
@@ -665,52 +654,6 @@             ))
         })?;
         Ok(loaded_segment)
-    }
-
-    fn update_quantization(
-        segment_config: &SegmentConfig,
-        vector_storages: &HashMap<VectorNameBuf, VectorData>,
-        temp_path: &Path,
-        permit: &ResourcePermit,
-        stopped: &AtomicBool,
-    ) -> OperationResult<HashMap<VectorNameBuf, QuantizedVectors>> {
-        let config = segment_config.clone();
-
-        let mut quantized_vectors_map = HashMap::new();
-
-        for (vector_name, vector_info) in vector_storages {
-            let Some(vector_config) = config.vector_data.get(vector_name) else {
-                continue;
-            };
-
-            let is_appendable = vector_config.is_appendable();
-
-            // Don't build quantization for appendable vectors
-            if is_appendable {
-                continue;
-            }
-
-            let max_threads = permit.num_cpus as usize;
-
-            if let Some(quantization) = config.quantization_config(vector_name) {
-                let segment_path = temp_path;
-
-                check_process_stopped(stopped)?;
-
-                let vector_storage_path = get_vector_storage_path(segment_path, vector_name);
-
-                let quantized_vectors = QuantizedVectors::create(
-                    &vector_info.vector_storage,
-                    quantization,
-                    &vector_storage_path,
-                    max_threads,
-                    stopped,
-                )?;
-
-                quantized_vectors_map.insert(vector_name.to_owned(), quantized_vectors);
-            }
-        }
-        Ok(quantized_vectors_map)
     }
 }
 
@@ -748,4 +691,14 @@                 err
             ))
         })
+}
+
+struct PointData {
+    external_id: CompactExtendedPointId,
+    /// [`CompactExtendedPointId`] is 17 bytes, we reduce
+    /// `segment_index` to 3 bytes to avoid paddings and align nicely.
+    segment_index: U24,
+    internal_id: PointOffsetType,
+    version: u64,
+    ordering: u64,
 }