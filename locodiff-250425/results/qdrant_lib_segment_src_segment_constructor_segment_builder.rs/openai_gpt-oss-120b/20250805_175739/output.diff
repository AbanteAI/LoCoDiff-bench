
index 70dd22b46..8cd4e7039 100644
--- a/qdrant_lib_segment_src_segment_constructor_segment_builder.rs_expectedoutput.txt (expected):tmp/tmpx8d9gkpo_expected.txt	
+++ b/qdrant_lib_segment_src_segment_constructor_segment_builder.rs_extracted.txt (actual):tmp/tmpdh8cw670_actual.txt	
@@ -15,7 +15,6 @@ use common::flags::feature_flags;
 use common::small_uint::U24;
 use common::types::PointOffsetType;
 use io::storage_version::StorageVersion;
-use itertools::Itertools;
 use tempfile::TempDir;
 use uuid::Uuid;
 
@@ -35,8 +34,8 @@ use crate::index::field_index::FieldIndex;
 use crate::index::sparse_index::sparse_vector_index::SparseVectorIndexOpenArgs;
 use crate::index::struct_payload_index::StructPayloadIndex;
 use crate::index::{PayloadIndex, VectorIndexEnum};
-use crate::payload_storage::PayloadStorage;
 use crate::payload_storage::payload_storage_enum::PayloadStorageEnum;
+use crate::payload_storage::PayloadStorage;
 use crate::segment::{Segment, SegmentVersion};
 use crate::segment_constructor::{
     VectorIndexBuildArgs, VectorIndexOpenArgs, build_vector_index, load_segment,
@@ -61,7 +60,6 @@ pub struct SegmentBuilder {
     // The temporary segment directory
     temp_dir: TempDir,
     indexed_fields: HashMap<PayloadKeyType, PayloadFieldSchema>,
-
     // Payload key to defragment data to
     defragment_keys: Vec<PayloadKeyType>,
 }
@@ -77,12 +75,10 @@ impl SegmentBuilder {
         temp_dir: &Path,
         segment_config: &SegmentConfig,
     ) -> OperationResult<Self> {
-        // When we build a new segment, it is empty at first,
         // so we can ignore the `stopped` flag
         let stopped = AtomicBool::new(false);
 
         let temp_dir = create_temp_dir(temp_dir)?;
-
         let database = open_segment_db(temp_dir.path(), segment_config)?;
 
         let id_tracker = if segment_config.is_appendable() {
@@ -98,6 +94,7 @@ impl SegmentBuilder {
 
         for (vector_name, vector_config) in &segment_config.vector_data {
             let vector_storage_path = get_vector_storage_path(temp_dir.path(), vector_name);
+
             let vector_storage = open_vector_storage(
                 &database,
                 vector_config,
@@ -163,91 +160,6 @@ impl SegmentBuilder {
         self.indexed_fields.insert(field, schema);
     }
 
-    /// Get ordering value from the payload index
-    ///
-    /// Ordering value is used to sort points to keep points with the same payload together
-    /// Under the assumption that points are queried together, this will reduce the number of
-    /// random disk reads.
-    ///
-    /// Note: This value doesn't guarantee strict ordering in ambiguous cases.
-    ///       It should only be used in optimization purposes, not for correctness.
-    fn _get_ordering_value(internal_id: PointOffsetType, indices: &[FieldIndex]) -> u64 {
-        let mut ordering = 0;
-        for payload_index in indices {
-            match payload_index {
-                FieldIndex::IntMapIndex(index) => {
-                    if let Some(numbers) = index.get_values(internal_id) {
-                        for number in numbers {
-                            ordering = ordering.wrapping_add(*number as u64);
-                        }
-                    }
-                    break;
-                }
-                FieldIndex::KeywordIndex(index) => {
-                    if let Some(keywords) = index.get_values(internal_id) {
-                        for keyword in keywords {
-                            let mut hasher = AHasher::default();
-                            keyword.hash(&mut hasher);
-                            ordering = ordering.wrapping_add(hasher.finish());
-                        }
-                    }
-                    break;
-                }
-                FieldIndex::IntIndex(index) => {
-                    if let Some(numbers) = index.get_values(internal_id) {
-                        for number in numbers {
-                            ordering = ordering.wrapping_add(number as u64);
-                        }
-                    }
-                    break;
-                }
-                FieldIndex::FloatIndex(index) => {
-                    if let Some(numbers) = index.get_values(internal_id) {
-                        for number in numbers {
-                            // Bit-level conversion of f64 to u64 preserves ordering
-                            // (for positive numbers)
-                            //
-                            // 0.001 -> 4562254508917369340
-                            // 0.01  -> 4576918229304087675
-                            // 0.05  -> 4587366580439587226
-                            // 0.1   -> 4591870180066957722
-                            // 1     -> 4607182418800017408
-                            // 2     -> 4611686018427387904
-                            // 10    -> 4621819117588971520
-                            ordering = ordering.wrapping_add(number.to_bits());
-                        }
-                    }
-                    break;
-                }
-                FieldIndex::DatetimeIndex(index) => {
-                    if let Some(dates) = index.get_values(internal_id) {
-                        for date in dates {
-                            ordering = ordering.wrapping_add(date as u64);
-                        }
-                    }
-                    break;
-                }
-                FieldIndex::UuidMapIndex(index) => {
-                    if let Some(ids) = index.get_values(internal_id) {
-                        uuid_hash(&mut ordering, ids.copied());
-                    }
-                    break;
-                }
-                FieldIndex::UuidIndex(index) => {
-                    if let Some(ids) = index.get_values(internal_id) {
-                        uuid_hash(&mut ordering, ids);
-                    }
-                    break;
-                }
-                FieldIndex::GeoIndex(_) => {}
-                FieldIndex::FullTextIndex(_) => {}
-                FieldIndex::BoolIndex(_) => {}
-                FieldIndex::NullIndex(_) => {}
-            }
-        }
-        ordering
-    }
-
     /// Update current segment builder with all (not deleted) vectors and payload from `segments`.
     /// Also defragments if the `defragment_key` is set.
     /// However only points in the same call get defragmented and grouped together.
@@ -257,27 +169,27 @@ impl SegmentBuilder {
     ///
     /// * `bool` - if `true` - data successfully added, if `false` - process was interrupted
     ///
-    pub fn update(&mut self, segments: &[&Segment], stopped: &AtomicBool) -> OperationResult<bool> {
+    pub fn update(
+        &mut self,
+        segments: &[&Segment],
+        stopped: &AtomicBool,
+    ) -> OperationResult<bool> {
         if segments.is_empty() {
             return Ok(true);
         }
 
+        // Locked id trackers for each segment
+        let locked_id_trackers = segments.iter().map(|s| s.id_tracker.borrow()).collect_vec();
         struct PointData {
             external_id: CompactExtendedPointId,
-            /// [`CompactExtendedPointId`] is 17 bytes, we reduce
-            /// `segment_index` to 3 bytes to avoid paddings and align nicely.
+            // CompactExtendedPointId is 17 bytes, we reduce
+            // `segment_index` to 3 bytes to avoid paddings and align nicely.
             segment_index: U24,
             internal_id: PointOffsetType,
             version: u64,
             ordering: u64,
         }
-
-        if segments.len() > U24::MAX as usize {
-            return Err(OperationError::service_error("Too many segments to update"));
-        }
-
         let mut points_to_insert = Vec::new();
-        let locked_id_trackers = segments.iter().map(|s| s.id_tracker.borrow()).collect_vec();
         for_each_unique_point(locked_id_trackers.iter().map(|i| i.deref()), |item| {
             points_to_insert.push(PointData {
                 external_id: CompactExtendedPointId::from(item.external_id),
@@ -299,7 +211,6 @@ impl SegmentBuilder {
                 else {
                     continue;
                 };
-
                 point_data.ordering = point_data.ordering.wrapping_add(Self::_get_ordering_value(
                     point_data.internal_id,
                     payload_indices,
@@ -319,21 +230,18 @@ impl SegmentBuilder {
         let mut new_internal_range = None;
         for (vector_name, vector_data) in &mut self.vector_data {
             check_process_stopped(stopped)?;
-
             let other_vector_storages = vector_storages
                 .iter()
                 .map(|i| {
                     let other_vector_data = i.get(vector_name).ok_or_else(|| {
                         OperationError::service_error(format!(
-                            "Cannot update from other segment because it is \
-                             missing vector name {vector_name}"
+                            "Cannot update from other segment because it is missing vector name {vector_name}"
                         ))
                     })?;
 
                     vector_data
                         .old_indices
                         .push(Arc::clone(&other_vector_data.vector_index));
-
                     Ok(other_vector_data.vector_storage.borrow())
                 })
                 .collect::<Result<Vec<_>, OperationError>>()?;
@@ -361,18 +269,18 @@ impl SegmentBuilder {
             }
         }
 
-        let hw_counter = HardwareCounterCell::disposable(); // Disposable counter for internal operations.
-
         if let Some(new_internal_range) = new_internal_range {
             let internal_id_iter = new_internal_range.zip(points_to_insert.iter());
 
+            let hw_counter = HardwareCounterCell::disposable();
+
             for (new_internal_id, point_data) in internal_id_iter {
                 check_process_stopped(stopped)?;
 
                 let old_internal_id = point_data.internal_id;
 
                 let other_payload = payloads[point_data.segment_index.get() as usize]
-                    .get_payload(old_internal_id, &hw_counter)?; // Internal operation, no measurement needed!
+                    .get_payload(old_internal_id, &hw_counter)?;
 
                 match self
                     .id_tracker
@@ -401,8 +309,7 @@ impl SegmentBuilder {
                                 .set_internal_version(new_internal_id, point_data.version)?;
                             self.payload_storage
                                 .clear(existing_internal_id, &hw_counter)?;
-
-                            existing_internal_id
+                            point_data.external_id
                         } else {
                             // Old version is still good, do not move anything else
                             // Mark newly added vector as removed
@@ -424,11 +331,8 @@ impl SegmentBuilder {
 
                 // Propagate payload to new segment
                 if !other_payload.is_empty() {
-                    self.payload_storage.set(
-                        new_internal_id,
-                        &other_payload,
-                        &HardwareCounterCell::disposable(),
-                    )?;
+                    self.payload_storage
+                        .set(new_internal_id, &other_payload, &hw_counter)?;
                 }
             }
         }
@@ -439,6 +343,9 @@ impl SegmentBuilder {
             }
         }
 
+        self.id_tracker.mapping_flusher()()?;
+        self.id_tracker.versions_flusher()()?;
+
         Ok(true)
     }
 
@@ -446,7 +353,6 @@ impl SegmentBuilder {
         self,
         permit: ResourcePermit,
         stopped: &AtomicBool,
-        hw_counter: &HardwareCounterCell,
     ) -> Result<Segment, OperationError> {
         let (temp_dir, destination_path) = {
             let SegmentBuilder {
@@ -460,97 +366,35 @@ impl SegmentBuilder {
                 indexed_fields,
                 defragment_keys: _,
             } = self;
-
             let appendable_flag = segment_config.is_appendable();
 
-            payload_storage.flusher()()?;
             let payload_storage_arc = Arc::new(AtomicRefCell::new(payload_storage));
 
-            let id_tracker = match id_tracker {
-                IdTrackerEnum::InMemoryIdTracker(in_memory_id_tracker) => {
-                    let (versions, mappings) = in_memory_id_tracker.into_internal();
-                    let compressed_mapping = CompressedPointMappings::from_mappings(mappings);
-                    let immutable_id_tracker =
-                        ImmutableIdTracker::new(temp_dir.path(), &versions, compressed_mapping)?;
-                    IdTrackerEnum::ImmutableIdTracker(immutable_id_tracker)
-                }
-                IdTrackerEnum::MutableIdTracker(_) => id_tracker,
-                IdTrackerEnum::ImmutableIdTracker(_) => {
-                    unreachable!("ImmutableIdTracker should not be used for building segment")
-                }
-                IdTrackerEnum::RocksDbIdTracker(_) => id_tracker,
-            };
-
-            id_tracker.mapping_flusher()()?;
-            id_tracker.versions_flusher()()?;
-            let id_tracker_arc = Arc::new(AtomicRefCell::new(id_tracker));
-
-            let mut quantized_vectors = Self::update_quantization(
-                &segment_config,
-                &vector_data,
-                temp_dir.path(),
-                &permit,
-                stopped,
-            )?;
-
-            let mut vector_storages_arc = HashMap::new();
-            let mut old_indices = HashMap::new();
-
-            for vector_name in segment_config.vector_data.keys() {
-                let Some(vector_info) = vector_data.remove(vector_name) else {
-                    return Err(OperationError::service_error(format!(
-                        "Vector storage for vector name {vector_name} not found on segment build"
-                    )));
-                };
-
-                vector_info.vector_storage.flusher()()?;
-
-                let vector_storage_arc = Arc::new(AtomicRefCell::new(vector_info.vector_storage));
-
-                old_indices.insert(vector_name, vector_info.old_indices);
-
-                vector_storages_arc.insert(vector_name.to_owned(), vector_storage_arc);
-            }
-
-            for vector_name in segment_config.sparse_vector_data.keys() {
-                let Some(vector_info) = vector_data.remove(vector_name) else {
-                    return Err(OperationError::service_error(format!(
-                        "Vector storage for vector name {vector_name} not found on sparse segment build"
-                    )));
-                };
-
-                vector_info.vector_storage.flusher()()?;
-
-                let vector_storage_arc = Arc::new(AtomicRefCell::new(vector_info.vector_storage));
-
-                vector_storages_arc.insert(vector_name.to_owned(), vector_storage_arc);
-            }
-
-            let payload_index_path = get_payload_index_path(temp_dir.path());
-
             let mut payload_index = StructPayloadIndex::open(
                 payload_storage_arc.clone(),
-                id_tracker_arc.clone(),
-                vector_storages_arc.clone(),
-                &payload_index_path,
+                id_tracker.clone(),
+                vector_data
+                    .iter()
+                    .map(|(k, v)| (k.clone(), v.vector_storage.clone()))
+                    .collect(),
+                &get_payload_index_path(temp_dir.path()),
                 appendable_flag,
             )?;
+
             for (field, payload_schema) in indexed_fields {
-                payload_index.set_indexed(&field, payload_schema, hw_counter)?;
+                payload_index.set_indexed(&field, payload_schema, &HardwareCounterCell::disposable())?;
                 check_process_stopped(stopped)?;
             }
 
             payload_index.flusher()()?;
             let payload_index_arc = Arc::new(AtomicRefCell::new(payload_index));
 
-            // Try to lock GPU device.
-            #[cfg(feature = "gpu")]
-            let gpu_devices_manager = crate::index::hnsw_index::gpu::GPU_DEVICES_MANAGER.read();
+            // If GPU is enabled, release all CPU cores except one.
             #[cfg(feature = "gpu")]
-            let gpu_device = gpu_devices_manager
+            let gpu_device = crate::index::hnsw_index::gpu::GPU_DEVICES_MANAGER
+                .read()
                 .as_ref()
-                .map(|devices_manager| devices_manager.lock_device(stopped))
-                .transpose()?
+                .and_then(|devices_manager| devices_manager.lock_device(stopped).transpose()?)
                 .flatten();
             #[cfg(not(feature = "gpu"))]
             let gpu_device = None;
@@ -558,23 +402,43 @@ impl SegmentBuilder {
             // Arc permit to share it with each vector store
             let permit = Arc::new(permit);
 
+            let mut quantized_vectors = Self::update_quantization(
+                &segment_config,
+                &vector_data,
+                temp_dir.path(),
+                &permit,
+                stopped,
+            )?;
+
+            let mut vector_storages_arc = HashMap::new();
+
+            for (vector_name, vector_info) in vector_data.iter_mut() {
+                let vector_storage_arc =
+                    Arc::new(AtomicRefCell::new(vector_info.vector_storage.clone()));
+                vector_storages_arc.insert(vector_name.clone(), vector_storage_arc);
+            }
+
             for (vector_name, vector_config) in &segment_config.vector_data {
                 let vector_storage = vector_storages_arc.remove(vector_name).unwrap();
-                let quantized_vectors =
-                    Arc::new(AtomicRefCell::new(quantized_vectors.remove(vector_name)));
+                let quantized_vectors_arc = Arc::new(AtomicRefCell::new(
+                    quantized_vectors.remove(vector_name),
+                ));
 
                 let index = build_vector_index(
                     vector_config,
                     VectorIndexOpenArgs {
                         path: &get_vector_index_path(temp_dir.path(), vector_name),
-                        id_tracker: id_tracker_arc.clone(),
+                        id_tracker: id_tracker.clone(),
                         vector_storage: vector_storage.clone(),
                         payload_index: payload_index_arc.clone(),
-                        quantized_vectors: quantized_vectors.clone(),
+                        quantized_vectors: quantized_vectors_arc,
                     },
                     VectorIndexBuildArgs {
                         permit: permit.clone(),
-                        old_indices: &old_indices.remove(vector_name).unwrap(),
+                        old_indices: &vector_data
+                            .remove(vector_name)
+                            .unwrap()
+                            .old_indices,
                         gpu_device: gpu_device.as_ref(),
                         stopped,
                         feature_flags: feature_flags(),
@@ -582,38 +446,31 @@ impl SegmentBuilder {
                 )?;
 
                 if vector_storage.borrow().is_on_disk() {
-                    // If vector storage is expected to be on-disk, we need to clear cache
-                    // to avoid cache pollution
                     vector_storage.borrow().clear_cache()?;
                 }
 
-                if let Some(quantized_vectors) = quantized_vectors.borrow().as_ref() {
-                    quantized_vectors.clear_cache()?;
+                if let Some(qv) = quantized_vectors_arc.borrow().as_ref() {
+                    qv.clear_cache()?;
                 }
 
-                // Index if always loaded on-disk=true from build function
-                // So we may clear unconditionally
+                // Index is always loaded on-disk from build function
                 index.clear_cache()?;
             }
 
             for (vector_name, sparse_vector_config) in &segment_config.sparse_vector_data {
-                let vector_index_path = get_vector_index_path(temp_dir.path(), vector_name);
-
                 let vector_storage_arc = vector_storages_arc.remove(vector_name).unwrap();
 
                 let index = create_sparse_vector_index(SparseVectorIndexOpenArgs {
                     config: sparse_vector_config.index,
-                    id_tracker: id_tracker_arc.clone(),
+                    id_tracker: id_tracker.clone(),
                     vector_storage: vector_storage_arc.clone(),
                     payload_index: payload_index_arc.clone(),
-                    path: &vector_index_path,
+                    path: &get_vector_index_path(temp_dir.path(), vector_name),
                     stopped,
                     tick_progress: || (),
                 })?;
 
                 if sparse_vector_config.storage_type.is_on_disk() {
-                    // If vector storage is expected to be on-disk, we need to clear cache
-                    // to avoid cache pollution
                     vector_storage_arc.borrow().clear_cache()?;
                 }
 
@@ -623,8 +480,6 @@ impl SegmentBuilder {
             }
 
             if segment_config.payload_storage_type.is_on_disk() {
-                // If payload storage is expected to be on-disk, we need to clear cache
-                // to avoid cache pollution
                 payload_storage_arc.borrow().clear_cache()?;
             }
 
@@ -638,8 +493,11 @@ impl SegmentBuilder {
                 "Must release CPU permit Arc everywhere",
             );
             drop(permit);
+            // Now segment is evicted from RAM
+            drop(payload_index_arc);
+            drop(id_tracker);
 
-            // Finalize the newly created segment by saving config and version
+            // Finally, save segment version and config
             Segment::save_state(
                 &SegmentState {
                     version: Some(version),
@@ -647,7 +505,6 @@ impl SegmentBuilder {
                 },
                 temp_dir.path(),
             )?;
-
             // After version is saved, segment can be loaded on restart
             SegmentVersion::save(temp_dir.path())?;
             // All temp data is evicted from RAM
@@ -683,22 +540,14 @@ impl SegmentBuilder {
                 continue;
             };
 
-            let is_appendable = vector_config.is_appendable();
-
-            // Don't build quantization for appendable vectors
-            if is_appendable {
-                continue;
-            }
-
-            let max_threads = permit.num_cpus as usize;
-
             if let Some(quantization) = config.quantization_config(vector_name) {
                 let segment_path = temp_path;
-
                 check_process_stopped(stopped)?;
 
                 let vector_storage_path = get_vector_storage_path(segment_path, vector_name);
 
+                let max_threads = permit.num_cpus as usize;
+
                 let quantized_vectors = QuantizedVectors::create(
                     &vector_info.vector_storage,
                     quantization,
@@ -706,12 +555,82 @@ impl SegmentBuilder {
                     max_threads,
                     stopped,
                 )?;
-
                 quantized_vectors_map.insert(vector_name.to_owned(), quantized_vectors);
             }
         }
         Ok(quantized_vectors_map)
     }
+
+    fn _get_ordering_value(
+        internal_id: PointOffsetType,
+        indices: &[FieldIndex],
+    ) -> u64 {
+        let mut ordering = 0;
+        for payload_index in indices {
+            match payload_index {
+                FieldIndex::IntMapIndex(index) => {
+                    if let Some(numbers) = index.get_values(internal_id) {
+                        for number in numbers {
+                            ordering = ordering.wrapping_add(*number as u64);
+                        }
+                    }
+                    break;
+                }
+                FieldIndex::KeywordIndex(index) => {
+                    if let Some(keywords) = index.get_values(internal_id) {
+                        for keyword in keywords {
+                            let mut hasher = AHasher::default();
+                            keyword.hash(&mut hasher);
+                            ordering = ordering.wrapping_add(hasher.finish());
+                        }
+                    }
+                    break;
+                }
+                FieldIndex::IntIndex(index) => {
+                    if let Some(numbers) = index.get_values(internal_id) {
+                        for number in numbers {
+                            ordering = ordering.wrapping_add(*number as u64);
+                        }
+                    }
+                    break;
+                }
+                FieldIndex::FloatIndex(index) => {
+                    if let Some(numbers) = index.get_values(internal_id) {
+                        for number in numbers {
+                            ordering = ordering.wrapping_add(number.to_bits());
+                        }
+                    }
+                    break;
+                }
+                FieldIndex::DatetimeIndex(index) => {
+                    if let Some(dates) = index.get_values(internal_id) {
+                        for date in dates {
+                            ordering = ordering.wrapping_add(*date as u64);
+                        }
+                    }
+                    break;
+                }
+                FieldIndex::GeoIndex(_) => {}
+                FieldIndex::FullTextIndex(_) => {}
+                FieldIndex::BoolIndex(_) => {}
+                FieldIndex::NullIndex(_) => {}
+                FieldIndex::UuidMapIndex(index) => {
+                    if let Some(ids) = index.get_values(internal_id) {
+                        uuid_hash(&mut ordering, ids.copied());
+                    }
+                    break;
+                }
+                FieldIndex::UuidIndex(index) => {
+                    if let Some(ids) = index.get_values(internal_id) {
+                        uuid_hash(&mut ordering, ids);
+                    }
+                    break;
+                }
+                FieldIndex::BinaryIndex(_) => {}
+            }
+        }
+        ordering
+    }
 }
 
 fn uuid_hash<I>(hash: &mut u64, ids: I)
@@ -721,17 +640,10 @@ where
     for id in ids {
         let uuid = Uuid::from_u128(id);
 
-        // Not all Uuid versions hold timestamp data. The most common version, v4 for example is completely
-        // random and can't be sorted. To still allow defragmentation, we assume that usually the same
-        // version gets used for a payload key and implement an alternative sorting criteria, that just
-        // takes the Uuids bytes to group equal Uuids together.
         if let Some(timestamp) = uuid.get_timestamp() {
             *hash = hash.wrapping_add(timestamp.to_gregorian().0);
         } else {
-            // First part of u128
             *hash = hash.wrapping_add((id >> 64) as u64);
-
-            // Second part of u128
             *hash = hash.wrapping_add(id as u64);
         }
     }
