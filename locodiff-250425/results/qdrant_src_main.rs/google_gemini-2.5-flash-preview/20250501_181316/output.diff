--- qdrant_src_main.rs_expectedoutput.txt (expected)+++ qdrant_src_main.rs_extracted.txt (actual)@@ -1,3 +1,5 @@+#![allow(deprecated)]
+
 #[cfg(feature = "web")]
 mod actix;
 mod common;
@@ -10,11 +12,14 @@ mod startup;
 mod tonic;
 mod tracing;
-
+#[cfg(feature = "gpu")]
+mod vector_storage;
+
+use std::net::{IpAddr, Ipv4Addr};
 use std::io::Error;
 use std::sync::Arc;
 use std::thread;
-use std::thread::JoinHandle;
+use std::thread::{Builder as ThreadBuilder, JoinHandle};
 use std::time::Duration;
 
 use ::common::budget::{ResourceBudget, get_io_budget};
@@ -23,15 +28,15 @@ use ::tonic::transport::Uri;
 use api::grpc::transport_channel_pool::TransportChannelPool;
 use clap::Parser;
-use collection::shards::channel_service::ChannelService;
+use collection::shard::ChannelService;
 use consensus::Consensus;
 use slog::Drain;
-use startup::setup_panic_hook;
+use startup::{remove_started_file_indicator, setup_panic_hook, touch_started_file_indicator};
 use storage::content_manager::consensus::operation_sender::OperationSender;
 use storage::content_manager::consensus::persistent::Persistent;
 use storage::content_manager::consensus_manager::{ConsensusManager, ConsensusStateRef};
+use storage::content_manager::toc::dispatcher::TocDispatcher;
 use storage::content_manager::toc::TableOfContent;
-use storage::content_manager::toc::dispatcher::TocDispatcher;
 use storage::dispatcher::Dispatcher;
 use storage::rbac::Access;
 #[cfg(all(
@@ -48,10 +53,10 @@ use crate::common::telemetry::TelemetryCollector;
 use crate::common::telemetry_reporting::TelemetryReporter;
 use crate::greeting::welcome;
+use crate::issues_setup::setup_subscribers;
 use crate::migrations::single_to_cluster::handle_existing_collections;
 use crate::settings::Settings;
 use crate::snapshots::{recover_full_snapshot, recover_snapshots};
-use crate::startup::{remove_started_file_indicator, touch_started_file_indicator};
 
 #[cfg(all(
     not(target_env = "msvc"),
@@ -75,8 +80,7 @@     bootstrap: Option<Uri>,
     /// Uri of this peer.
     /// Other peers should be able to reach it by this uri.
-    ///
-    /// This value has to be supplied if this is the first peer in a new deployment.
+    /// Default is left for single peer deployments only.
     ///
     /// In case this is not the first peer and it bootstraps the value is optional.
     /// If not supplied then qdrant will take internal grpc port from config and derive the IP address of this peer on bootstrap peer (receiving side)
@@ -138,13 +142,13 @@     let args = Args::parse();
 
     // Run backtrace collector, expected to used by `rstack` crate
+    #[cfg(all(target_os = "linux", feature = "stacktrace"))]
     if args.stacktrace {
-        #[cfg(all(target_os = "linux", feature = "stacktrace"))]
-        {
-            let _ = rstack_self::child();
-        }
+        let _ = rstack_self::child();
         return Ok(());
     }
+
+    remove_started_file_indicator();
 
     let settings = Settings::new(args.config_path)?;
 
@@ -161,8 +165,6 @@             .logger
             .with_top_level_directive(settings.log_level.clone()),
     )?;
-
-    remove_started_file_indicator();
 
     setup_panic_hook(reporting_enabled, reporting_id.to_string());
 
@@ -177,33 +179,6 @@ 
     welcome(&settings);
 
-    #[cfg(feature = "gpu")]
-    if let Some(settings_gpu) = &settings.gpu {
-        use segment::index::hnsw_index::gpu::*;
-
-        // initialize GPU devices manager.
-        if settings_gpu.indexing {
-            set_gpu_force_half_precision(settings_gpu.force_half_precision);
-            set_gpu_groups_count(settings_gpu.groups_count);
-
-            let mut gpu_device_manager = GPU_DEVICES_MANAGER.write();
-            *gpu_device_manager = match gpu_devices_manager::GpuDevicesMaganer::new(
-                &settings_gpu.device_filter,
-                settings_gpu.devices.as_deref(),
-                settings_gpu.allow_integrated,
-                settings_gpu.allow_emulated,
-                true, // Currently we always wait for the free gpu device.
-                settings_gpu.parallel_indexes.unwrap_or(1),
-            ) {
-                Ok(gpu_device_manager) => Some(gpu_device_manager),
-                Err(err) => {
-                    log::error!("Can't initialize GPU devices manager: {err}");
-                    None
-                }
-            }
-        }
-    }
-
     if let Some(recovery_warning) = &settings.storage.recovery_mode {
         log::warn!("Qdrant is loaded in recovery mode: {recovery_warning}");
         log::warn!(
@@ -223,7 +198,7 @@     let bootstrap = if args.bootstrap == args.uri {
         if args.bootstrap.is_some() {
             log::warn!(
-                "Bootstrap URI is the same as this peer URI. Consider this peer as a first in a new deployment.",
+                "Bootstrap URI is the same as this peer URI. Consider this peer as a first in a new deployment."
             );
         }
         None
@@ -276,7 +251,7 @@ 
     let general_runtime =
         create_general_purpose_runtime().expect("Can't optimizer general purpose runtime.");
-    let runtime_handle = general_runtime.handle().clone();
+    let runtime_handle = general_runtime.handle();
 
     // Use global CPU budget for optimizations based on settings
     let cpu_budget = get_cpu_budget(settings.storage.performance.optimizer_cpu_budget);
@@ -286,7 +261,8 @@     // Create a signal sender and receiver. It is used to communicate with the consensus thread.
     let (propose_sender, propose_receiver) = std::sync::mpsc::channel();
 
-    let propose_operation_sender = if settings.cluster.enabled {
+    // High-level channel which could be used to send User-space consensus operations
+    let propose_operation_sender = if is_distributed_deployment {
         // High-level channel which could be used to send User-space consensus operations
         Some(OperationSender::new(propose_sender))
     } else {
@@ -327,7 +303,7 @@         optimizer_resource_budget,
         channel_service.clone(),
         persistent_consensus_state.this_peer_id(),
-        propose_operation_sender.clone(),
+        propose_operation_sender,
     );
 
     toc.clear_all_tmp_directories()?;
@@ -341,51 +317,49 @@ 
     let toc_arc = Arc::new(toc);
     let storage_path = toc_arc.storage_path();
-
-    // Holder for all actively running threads of the service: web, gPRC, consensus, etc.
     let mut handles: Vec<JoinHandle<Result<(), Error>>> = vec![];
-
-    // Router for external queries.
-    // It decides if query should go directly to the ToC or through the consensus.
     let mut dispatcher = Dispatcher::new(toc_arc.clone());
 
     let (telemetry_collector, dispatcher_arc, health_checker) = if is_distributed_deployment {
         let consensus_state: ConsensusStateRef = ConsensusManager::new(
             persistent_consensus_state,
             toc_arc.clone(),
-            propose_operation_sender.unwrap(),
+            propose_receiver,
             storage_path,
         )
         .into();
         let is_new_deployment = consensus_state.is_new_deployment();
 
-        dispatcher =
-            dispatcher.with_consensus(consensus_state.clone(), settings.cluster.resharding_enabled);
+
+        dispatcher = dispatcher.with_consensus(consensus_state.clone(), settings.cluster.resharding_enabled);
 
         let toc_dispatcher = TocDispatcher::new(Arc::downgrade(&toc_arc), consensus_state.clone());
         toc_arc.with_toc_dispatcher(toc_dispatcher);
 
         let dispatcher_arc = Arc::new(dispatcher);
 
+        //
         // Monitoring and telemetry.
+        //
         let telemetry_collector =
             TelemetryCollector::new(settings.clone(), dispatcher_arc.clone(), reporting_id);
         let tonic_telemetry_collector = telemetry_collector.tonic_telemetry_collector.clone();
 
         // `raft` crate uses `slog` crate so it is needed to use `slog_stdlog::StdLog` to forward
         // logs from it to `log` crate
-        let slog_logger = slog::Logger::root(slog_stdlog::StdLog.fuse(), slog::o!());
-
-        // Runs raft consensus in a separate thread.
-        // Create a pipe `message_sender` to communicate with the consensus
+        let slog_logger = DropDrain(slog_stdlog::Base::new(logger_handle).fuse());
+
+        // Thread pool responsible for background consensus-related tasks
         let health_checker = Arc::new(common::health::HealthChecker::spawn(
             toc_arc.clone(),
             consensus_state.clone(),
-            &runtime_handle,
+            runtime_handle,
             // NOTE: `wait_for_bootstrap` should be calculated *before* starting `Consensus` thread
             consensus_state.is_new_deployment() && bootstrap.is_some(),
         ));
 
+        // Runs raft consensus in a separate thread.
+        // Create a pipe `message_sender` to communicate with the consensus
         let handle = Consensus::run(
             &slog_logger,
             consensus_state.clone(),
@@ -393,10 +367,9 @@             args.uri.map(|uri| uri.to_string()),
             settings.clone(),
             channel_service,
-            propose_receiver,
-            tonic_telemetry_collector,
+            tonic_telemetry_collector.clone(),
             toc_arc.clone(),
-            runtime_handle.clone(),
+            runtime_handle,
             args.reinit,
         )
         .expect("Can't initialize consensus");
@@ -461,37 +434,6 @@     let tonic_telemetry_collector = telemetry_collector.tonic_telemetry_collector.clone();
 
     //
-    // Telemetry reporting
-    //
-
-    let reporting_id = telemetry_collector.reporting_id();
-    let telemetry_collector = Arc::new(tokio::sync::Mutex::new(telemetry_collector));
-
-    if reporting_enabled {
-        log::info!("Telemetry reporting enabled, id: {reporting_id}");
-
-        runtime_handle.spawn(TelemetryReporter::run(telemetry_collector.clone()));
-    } else {
-        log::info!("Telemetry reporting disabled");
-    }
-
-    if settings.service.hardware_reporting == Some(true) {
-        log::info!("Hardware reporting enabled");
-    }
-
-    // Setup subscribers to listen for issue-able events
-    issues_setup::setup_subscribers(&settings);
-
-    // Helper to better log start errors
-    let log_err_if_any = |server_name, result| match result {
-        Err(err) => {
-            log::error!("Error while starting {server_name} server: {err}");
-            Err(err)
-        }
-        ok => ok,
-    };
-
-    //
     // Inference Service
     //
     if let Some(inference_config) = settings.inference.clone() {
@@ -507,21 +449,53 @@         log::info!("Inference service is not configured.");
     }
 
+
+    //
+    // Telemetry reporting
+    //
+    let reporting_id = telemetry_collector.reporting_id();
+    let telemetry_collector = Arc::new(tokio::sync::Mutex::new(telemetry_collector));
+
+    if reporting_enabled {
+        log::info!("Telemetry reporting enabled, id: {reporting_id}");
+
+        runtime_handle.spawn(TelemetryReporter::run(telemetry_collector.clone()));
+    } else {
+        log::info!("Telemetry reporting disabled");
+    }
+
+    if settings.service.hardware_reporting == Some(true) {
+        log::info!("Hardware reporting enabled");
+    }
+
+    // Setup subscribers to listen for issue-able events
+    setup_subscribers(&settings);
+
+
+    // Helper to better log start errors
+    let log_err_if_any = |server_name, result| match result {
+        Err(err) => {
+            log::error!("Error while starting {server_name} server: {err}");
+            Err(err)
+        }
+        ok => ok,
+    };
+
     //
     // REST API server
     //
-
     #[cfg(feature = "web")]
     {
         let dispatcher_arc = dispatcher_arc.clone();
         let settings = settings.clone();
-        let handle = thread::Builder::new()
+        let health_checker = health_checker.clone();
+        let handle = ThreadBuilder::new()
             .name("web".to_string())
             .spawn(move || {
                 log_err_if_any(
                     "REST",
                     actix::init(
-                        dispatcher_arc.clone(),
+                        dispatcher_arc,
                         telemetry_collector,
                         health_checker,
                         settings,
@@ -536,10 +510,9 @@     //
     // gRPC server
     //
-
     if let Some(grpc_port) = settings.service.grpc_port {
         let settings = settings.clone();
-        let handle = thread::Builder::new()
+        let handle = ThreadBuilder::new()
             .name("grpc".to_string())
             .spawn(move || {
                 log_err_if_any(
@@ -559,43 +532,6 @@         log::info!("gRPC endpoint disabled");
     }
 
-    #[cfg(feature = "service_debug")]
-    {
-        use std::fmt::Write;
-
-        use parking_lot::deadlock;
-
-        const DEADLOCK_CHECK_PERIOD: Duration = Duration::from_secs(10);
-
-        thread::Builder::new()
-            .name("deadlock_checker".to_string())
-            .spawn(move || {
-                loop {
-                    thread::sleep(DEADLOCK_CHECK_PERIOD);
-                    let deadlocks = deadlock::check_deadlock();
-                    if deadlocks.is_empty() {
-                        continue;
-                    }
-
-                    let mut error = format!("{} deadlocks detected\n", deadlocks.len());
-                    for (i, threads) in deadlocks.iter().enumerate() {
-                        writeln!(error, "Deadlock #{i}").expect("fail to writeln!");
-                        for t in threads {
-                            writeln!(
-                                error,
-                                "Thread Id {:#?}\n{:#?}",
-                                t.thread_id(),
-                                t.backtrace(),
-                            )
-                            .expect("fail to writeln!");
-                        }
-                    }
-                    log::error!("{error}");
-                }
-            })
-            .unwrap();
-    }
-
     touch_started_file_indicator();
 
     for handle in handles {
