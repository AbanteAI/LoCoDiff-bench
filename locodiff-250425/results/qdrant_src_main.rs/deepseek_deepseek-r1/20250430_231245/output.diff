--- qdrant_src_main.rs_expectedoutput.txt (expected)+++ qdrant_src_main.rs_extracted.txt (actual)@@ -17,7 +17,7 @@ use std::thread::JoinHandle;
 use std::time::Duration;
 
-use ::common::budget::{ResourceBudget, get_io_budget};
+use ::common::budget::{get_io_budget, ResourceBudget};
 use ::common::cpu::get_cpu_budget;
 use ::common::flags::{feature_flags, init_feature_flags};
 use ::tonic::transport::Uri;
@@ -25,13 +25,14 @@ use clap::Parser;
 use collection::shards::channel_service::ChannelService;
 use consensus::Consensus;
+use log::LevelFilter;
 use slog::Drain;
 use startup::setup_panic_hook;
 use storage::content_manager::consensus::operation_sender::OperationSender;
 use storage::content_manager::consensus::persistent::Persistent;
 use storage::content_manager::consensus_manager::{ConsensusManager, ConsensusStateRef};
+use storage::content_manager::toc::dispatcher::TocDispatcher;
 use storage::content_manager::toc::TableOfContent;
-use storage::content_manager::toc::dispatcher::TocDispatcher;
 use storage::dispatcher::Dispatcher;
 use storage::rbac::Access;
 #[cfg(all(
@@ -48,6 +49,7 @@ use crate::common::telemetry::TelemetryCollector;
 use crate::common::telemetry_reporting::TelemetryReporter;
 use crate::greeting::welcome;
+use crate::issues_setup::setup_subscribers;
 use crate::migrations::single_to_cluster::handle_existing_collections;
 use crate::settings::Settings;
 use crate::snapshots::{recover_full_snapshot, recover_snapshots};
@@ -229,6 +231,36 @@         None
     } else {
         args.bootstrap
+    };
+
+    // Create and own search runtime out of the scope of async context to ensure correct
+    // destruction of it
+    let search_runtime = create_search_runtime(settings.storage.performance.max_search_threads)
+        .expect("Can't search create runtime.");
+
+    let update_runtime =
+        create_update_runtime(settings.storage.performance.max_optimization_threads)
+            .expect("Can't optimizer create runtime.");
+
+    let general_runtime =
+        create_general_purpose_runtime().expect("Can't optimizer general purpose runtime.");
+    let runtime_handle = general_runtime.handle().clone();
+
+    // Use global CPU budget for optimizations based on settings
+    let cpu_budget = get_cpu_budget(settings.storage.performance.optimizer_cpu_budget);
+    let io_budget = get_io_budget(settings.storage.performance.optimizer_io_budget, cpu_budget);
+    let optimizer_resource_budget = ResourceBudget::new(cpu_budget, io_budget);
+
+    // Create a signal sender and receiver. It is used to communicate with the consensus thread.
+    let (propose_sender, propose_receiver) = std::sync::mpsc::channel();
+
+    #[allow(clippy::option_if_let_else)]
+    let propose_operation_sender = if settings.cluster.enabled {
+        // High-level channel which could be used to send User-space consensus operations
+        Some(OperationSender::new(propose_sender))
+    } else {
+        // We don't need sender for the single-node mode
+        None
     };
 
     // Saved state of the consensus.
@@ -265,35 +297,6 @@         vec![]
     };
 
-    // Create and own search runtime out of the scope of async context to ensure correct
-    // destruction of it
-    let search_runtime = create_search_runtime(settings.storage.performance.max_search_threads)
-        .expect("Can't search create runtime.");
-
-    let update_runtime =
-        create_update_runtime(settings.storage.performance.max_optimization_threads)
-            .expect("Can't optimizer create runtime.");
-
-    let general_runtime =
-        create_general_purpose_runtime().expect("Can't optimizer general purpose runtime.");
-    let runtime_handle = general_runtime.handle().clone();
-
-    // Use global CPU budget for optimizations based on settings
-    let cpu_budget = get_cpu_budget(settings.storage.performance.optimizer_cpu_budget);
-    let io_budget = get_io_budget(settings.storage.performance.optimizer_io_budget, cpu_budget);
-    let optimizer_resource_budget = ResourceBudget::new(cpu_budget, io_budget);
-
-    // Create a signal sender and receiver. It is used to communicate with the consensus thread.
-    let (propose_sender, propose_receiver) = std::sync::mpsc::channel();
-
-    let propose_operation_sender = if settings.cluster.enabled {
-        // High-level channel which could be used to send User-space consensus operations
-        Some(OperationSender::new(propose_sender))
-    } else {
-        // We don't need sender for the single-node mode
-        None
-    };
-
     // Channel service is used to manage connections between peers.
     // It allocates required number of channels and manages proper reconnection handling
     let mut channel_service =
@@ -359,8 +362,7 @@         .into();
         let is_new_deployment = consensus_state.is_new_deployment();
 
-        dispatcher =
-            dispatcher.with_consensus(consensus_state.clone(), settings.cluster.resharding_enabled);
+        dispatcher = dispatcher.with_consensus(consensus_state.clone(), settings.cluster.resharding_enabled);
 
         let toc_dispatcher = TocDispatcher::new(Arc::downgrade(&toc_arc), consensus_state.clone());
         toc_arc.with_toc_dispatcher(toc_dispatcher);
@@ -376,8 +378,6 @@         // logs from it to `log` crate
         let slog_logger = slog::Logger::root(slog_stdlog::StdLog.fuse(), slog::o!());
 
-        // Runs raft consensus in a separate thread.
-        // Create a pipe `message_sender` to communicate with the consensus
         let health_checker = Arc::new(common::health::HealthChecker::spawn(
             toc_arc.clone(),
             consensus_state.clone(),
@@ -480,7 +480,7 @@     }
 
     // Setup subscribers to listen for issue-able events
-    issues_setup::setup_subscribers(&settings);
+    setup_subscribers(&settings);
 
     // Helper to better log start errors
     let log_err_if_any = |server_name, result| match result {
@@ -490,22 +490,6 @@         }
         ok => ok,
     };
-
-    //
-    // Inference Service
-    //
-    if let Some(inference_config) = settings.inference.clone() {
-        match InferenceService::init_global(inference_config) {
-            Ok(_) => {
-                log::info!("Inference service is configured.");
-            }
-            Err(err) => {
-                log::error!("{err}");
-            }
-        }
-    } else {
-        log::info!("Inference service is not configured.");
-    }
 
     //
     // REST API server
@@ -534,6 +518,23 @@     }
 
     //
+    // Inference Service
+    //
+
+    if let Some(inference_config) = settings.inference.clone() {
+        match InferenceService::init_global(inference_config) {
+            Ok(_) => {
+                log::info!("Inference service is configured.");
+            }
+            Err(err) => {
+                log::error!("{err}");
+            }
+        }
+    } else {
+        log::info!("Inference service is not configured.");
+    }
+
+    //
     // gRPC server
     //
 
@@ -556,14 +557,13 @@             .unwrap();
         handles.push(handle);
     } else {
-        log::info!("gRPC endpoint disabled");
+        log::info!("gRPC endpoint disabled")
     }
 
     #[cfg(feature = "service_debug")]
     {
+        use parking_lot::deadlock;
         use std::fmt::Write;
-
-        use parking_lot::deadlock;
 
         const DEADLOCK_CHECK_PERIOD: Duration = Duration::from_secs(10);
 
