--- qdrant_src_main.rs_expectedoutput.txt (expected)+++ qdrant_src_main.rs_extracted.txt (actual)@@ -11,6 +11,8 @@ mod tonic;
 mod tracing;
 
+#[cfg(feature = "gpu")]
+use segment::index::hnsw_index::gpu::*;
 use std::io::Error;
 use std::sync::Arc;
 use std::thread;
@@ -25,13 +27,13 @@ use clap::Parser;
 use collection::shards::channel_service::ChannelService;
 use consensus::Consensus;
+use memory::madvise;
 use slog::Drain;
-use startup::setup_panic_hook;
 use storage::content_manager::consensus::operation_sender::OperationSender;
 use storage::content_manager::consensus::persistent::Persistent;
 use storage::content_manager::consensus_manager::{ConsensusManager, ConsensusStateRef};
+use storage::content_manager::toc::dispatcher::TocDispatcher;
 use storage::content_manager::toc::TableOfContent;
-use storage::content_manager::toc::dispatcher::TocDispatcher;
 use storage::dispatcher::Dispatcher;
 use storage::rbac::Access;
 #[cfg(all(
@@ -76,8 +78,6 @@     /// Uri of this peer.
     /// Other peers should be able to reach it by this uri.
     ///
-    /// This value has to be supplied if this is the first peer in a new deployment.
-    ///
     /// In case this is not the first peer and it bootstraps the value is optional.
     /// If not supplied then qdrant will take internal grpc port from config and derive the IP address of this peer on bootstrap peer (receiving side)
     #[arg(long, value_parser, value_name = "URI", env = "QDRANT_URI")]
@@ -104,19 +104,6 @@     /// Use `/collections/<collection-name>/snapshots/recover` API instead.
     #[arg(long, value_name = "PATH")]
     storage_snapshot: Option<String>,
-
-    /// Path to an alternative configuration file.
-    /// Format: <config_file_path>
-    ///
-    /// Default path: config/config.yaml
-    #[arg(long, value_name = "PATH")]
-    config_path: Option<String>,
-
-    /// Disable telemetry sending to developers
-    /// If provided - telemetry collection will be disabled.
-    /// Read more: <https://qdrant.tech/documentation/guides/telemetry>
-    #[arg(long, action, default_value_t = false)]
-    disable_telemetry: bool,
 
     /// Run stacktrace collector. Used for debugging.
     #[arg(long, action, default_value_t = false)]
@@ -140,7 +127,7 @@     // Run backtrace collector, expected to used by `rstack` crate
     if args.stacktrace {
         #[cfg(all(target_os = "linux", feature = "stacktrace"))]
-        {
+        unsafe {
             let _ = rstack_self::child();
         }
         return Ok(());
@@ -204,6 +191,7 @@         }
     }
 
+
     if let Some(recovery_warning) = &settings.storage.recovery_mode {
         log::warn!("Qdrant is loaded in recovery mode: {recovery_warning}");
         log::warn!(
@@ -211,14 +199,14 @@         );
     }
 
-    // Validate as soon as possible, but we must initialize logging first
-    settings.validate_and_warn();
-
     // Report feature flags that are enabled for easier debugging
     let flags = feature_flags();
     if !flags.is_default() {
         log::debug!("Feature flags: {flags:?}");
     }
+
+    // Validate as soon as possible, but we must initialize logging first
+    settings.validate_and_warn();
 
     let bootstrap = if args.bootstrap == args.uri {
         if args.bootstrap.is_some() {
@@ -240,14 +228,11 @@ 
     let is_distributed_deployment = settings.cluster.enabled;
 
-    let temp_path = settings.storage.temp_path.as_deref();
-
     let restored_collections = if let Some(full_snapshot) = args.storage_snapshot {
         recover_full_snapshot(
-            temp_path,
+            settings.storage.temp_path.as_deref(),
             &full_snapshot,
-            &settings.storage.storage_path,
-            args.force_snapshot,
+            settings.force_snapshot || args.force_snapshot, // Command line arguments override config
             persistent_consensus_state.this_peer_id(),
             is_distributed_deployment,
         )
@@ -255,8 +240,8 @@         // recover from snapshots
         recover_snapshots(
             &snapshots,
-            args.force_snapshot,
-            temp_path,
+            settings.force_snapshot || args.force_snapshot, // Command line arguments override config
+            settings.storage.temp_path.as_deref(),
             &settings.storage.storage_path,
             persistent_consensus_state.this_peer_id(),
             is_distributed_deployment,
@@ -286,8 +271,8 @@     // Create a signal sender and receiver. It is used to communicate with the consensus thread.
     let (propose_sender, propose_receiver) = std::sync::mpsc::channel();
 
-    let propose_operation_sender = if settings.cluster.enabled {
-        // High-level channel which could be used to send User-space consensus operations
+    // High-level channel which could be used to send User-space consensus operations
+    let propose_operation_sender = if is_distributed_deployment {
         Some(OperationSender::new(propose_sender))
     } else {
         // We don't need sender for the single-node mode
@@ -343,7 +328,7 @@     let storage_path = toc_arc.storage_path();
 
     // Holder for all actively running threads of the service: web, gPRC, consensus, etc.
-    let mut handles: Vec<JoinHandle<Result<(), Error>>> = vec![];
+    let mut handles: Vec<JoinHandle<anyhow::Result<()>>> = vec![];
 
     // Router for external queries.
     // It decides if query should go directly to the ToC or through the consensus.
@@ -353,7 +338,7 @@         let consensus_state: ConsensusStateRef = ConsensusManager::new(
             persistent_consensus_state,
             toc_arc.clone(),
-            propose_operation_sender.unwrap(),
+            propose_operation_sender.expect("propose_operation_sender is None in distributed mode"),
             storage_path,
         )
         .into();
@@ -370,14 +355,8 @@         // Monitoring and telemetry.
         let telemetry_collector =
             TelemetryCollector::new(settings.clone(), dispatcher_arc.clone(), reporting_id);
-        let tonic_telemetry_collector = telemetry_collector.tonic_telemetry_collector.clone();
-
-        // `raft` crate uses `slog` crate so it is needed to use `slog_stdlog::StdLog` to forward
-        // logs from it to `log` crate
-        let slog_logger = slog::Logger::root(slog_stdlog::StdLog.fuse(), slog::o!());
-
-        // Runs raft consensus in a separate thread.
-        // Create a pipe `message_sender` to communicate with the consensus
+
+        // Runs health checker in a separate thread.
         let health_checker = Arc::new(common::health::HealthChecker::spawn(
             toc_arc.clone(),
             consensus_state.clone(),
@@ -387,19 +366,18 @@         ));
 
         let handle = Consensus::run(
-            &slog_logger,
+            &slog::Logger::root(slog_term::term_full().fuse(), slog::o!()),
             consensus_state.clone(),
             bootstrap,
             args.uri.map(|uri| uri.to_string()),
             settings.clone(),
             channel_service,
             propose_receiver,
-            tonic_telemetry_collector,
+            telemetry_collector.tonic_telemetry_collector.clone(),
             toc_arc.clone(),
             runtime_handle.clone(),
             args.reinit,
-        )
-        .expect("Can't initialize consensus");
+        )?;
 
         handles.push(handle);
 
@@ -420,11 +398,11 @@             }
         });
 
-        // TODO(resharding): Remove resharding driver?
-        //
+        // TODO(resharding): remove this if it is not required anymore
         // runtime_handle.block_on(async {
         //     toc_arc.resume_resharding_tasks().await;
         // });
+
 
         let collections_to_recover_in_consensus = if is_new_deployment {
             let existing_collections =
@@ -438,7 +416,7 @@         };
 
         if !collections_to_recover_in_consensus.is_empty() {
-            runtime_handle.block_on(handle_existing_collections(
+            runtime_handle.block_on(handle_existing_collections( // TODO(resharding) spawn?
                 toc_arc.clone(),
                 consensus_state.clone(),
                 dispatcher_arc.clone(),
@@ -447,6 +425,7 @@             ));
         }
 
+
         (telemetry_collector, dispatcher_arc, Some(health_checker))
     } else {
         log::info!("Distributed mode disabled");
@@ -463,8 +442,6 @@     //
     // Telemetry reporting
     //
-
-    let reporting_id = telemetry_collector.reporting_id();
     let telemetry_collector = Arc::new(tokio::sync::Mutex::new(telemetry_collector));
 
     if reporting_enabled {
@@ -483,7 +460,7 @@     issues_setup::setup_subscribers(&settings);
 
     // Helper to better log start errors
-    let log_err_if_any = |server_name, result| match result {
+    let log_err_if_any = |server_name, result: anyhow::Result<()>| match result {
         Err(err) => {
             log::error!("Error while starting {server_name} server: {err}");
             Err(err)
@@ -507,10 +484,10 @@         log::info!("Inference service is not configured.");
     }
 
+
     //
     // REST API server
     //
-
     #[cfg(feature = "web")]
     {
         let dispatcher_arc = dispatcher_arc.clone();
@@ -528,15 +505,13 @@                         logger_handle,
                     ),
                 )
-            })
-            .unwrap();
+            })?;
         handles.push(handle);
     }
 
     //
     // gRPC server
     //
-
     if let Some(grpc_port) = settings.service.grpc_port {
         let settings = settings.clone();
         let handle = thread::Builder::new()
@@ -552,18 +527,20 @@                         runtime_handle,
                     ),
                 )
-            })
-            .unwrap();
+            })?;
         handles.push(handle);
     } else {
         log::info!("gRPC endpoint disabled");
     }
 
+
+    //
+    // Deadlock checker - only for debug builds
+    //
     #[cfg(feature = "service_debug")]
     {
+        use parking_lot::deadlock;
         use std::fmt::Write;
-
-        use parking_lot::deadlock;
 
         const DEADLOCK_CHECK_PERIOD: Duration = Duration::from_secs(10);
 
