--- aider_scripts_blame.py_expectedoutput.txt (expected)+++ aider_scripts_blame.py_extracted.txt (actual)@@ -1,22 +1,20 @@ #!/usr/bin/env python3
 
 import argparse
-import os
 import subprocess
 import sys
 from collections import defaultdict
 from datetime import datetime
 from operator import itemgetter
-
 import semver
 import yaml
 from tqdm import tqdm
 
 website_files = [
-    "aider/website/index.html",
     "aider/website/share/index.md",
     "aider/website/_includes/head_custom.html",
     "aider/website/_includes/home.css",
+    "aider/website/index.html",
     "aider/website/docs/leaderboards/index.md",
 ]
 
@@ -24,7 +22,6 @@     "aider/website/install.ps1",
     "aider/website/install.sh",
 ]
-
 
 def blame(start_tag, end_tag=None):
     commits = get_all_commit_hashes_between_tags(start_tag, end_tag)
@@ -40,9 +37,9 @@         for f in files
         if f.endswith((".js", ".py", ".scm", ".sh", "Dockerfile", "Gemfile"))
         or (f.startswith(".github/workflows/") and f.endswith(".yml"))
-        or (f.startswith("aider/resources/") and f.endswith(".yml"))
         or f in website_files
         or f in test_files
+        or (f.startswith("aider/resources/") and f.endswith(".yml"))
     ]
     files = [f for f in files if not f.endswith("prompts.py")]
     files = [f for f in files if not f.startswith("tests/fixtures/watch")]
@@ -80,13 +77,12 @@ 
 
 def run(cmd):
-    # Get all commit hashes since the specified tag
     result = subprocess.run(cmd, capture_output=True, text=True, check=True)
     return result.stdout
 
 
 def get_commit_authors(commits):
-    commit_to_author = dict()
+    commit_to_author = {}
     for commit in commits:
         author = run(["git", "show", "-s", "--format=%an", commit]).strip()
         commit_message = run(["git", "show", "-s", "--format=%s", commit]).strip()
@@ -106,9 +102,8 @@     results = []
     for i in tqdm(range(len(tags) - 1), desc="Processing tags"):
         start_tag, end_tag = tags[i], tags[i + 1]
-        all_file_counts, grand_total, total_lines, aider_total, aider_percentage, end_date = blame(
-            start_tag, end_tag
-        )
+        all_file_counts, grand_total, total_lines, aider_total, aider_percentage, end_date = \
+            blame(start_tag, end_tag)
         results.append(
             {
                 "start_tag": start_tag,
@@ -117,9 +112,7 @@                 "file_counts": all_file_counts,
                 "grand_total": {
                     author: count
-                    for author, count in sorted(
-                        grand_total.items(), key=itemgetter(1), reverse=True
-                    )
+                    for author, count in sorted(grand_total.items(), key=itemgetter(1), reverse=True)
                 },
                 "total_lines": total_lines,
                 "aider_total": aider_total,
@@ -145,8 +138,8 @@         "--all-since",
         action="store_true",
         help=(
-            "Find all tags since the specified tag and print aider percentage between each pair of"
-            " successive tags"
+            "Find all tags since the specified tag and print aider percentage between each pair of "
+            "successive tags"
         ),
     )
     parser.add_argument(
@@ -161,36 +154,11 @@             return
 
     if args.all_since:
-        new_results = process_all_tags_since(args.start_tag)
-
-        # If output file exists, read and update it
-        existing_results = []
-        if args.output and os.path.exists(args.output):
-            with open(args.output, "r") as f:
-                existing_results = yaml.safe_load(f) or []
-
-        # Create a map of start_tag->end_tag to result for existing entries
-        existing_map = {(r["start_tag"], r["end_tag"]): i for i, r in enumerate(existing_results)}
-
-        # Update or append new results
-        for new_result in new_results:
-            key = (new_result["start_tag"], new_result["end_tag"])
-            if key in existing_map:
-                # Replace existing entry
-                existing_results[existing_map[key]] = new_result
-            else:
-                # Append new entry
-                existing_results.append(new_result)
-
-        # Sort results by start_tag
-        existing_results.sort(key=lambda x: semver.Version.parse(x["start_tag"][1:]))
-
-        yaml_output = yaml.dump(existing_results, sort_keys=True)
+        results = process_all_tags_since(args.start_tag)
+        yaml_output = yaml.dump(results, sort_keys=True)
     else:
-        all_file_counts, grand_total, total_lines, aider_total, aider_percentage, end_date = blame(
-            args.start_tag, args.end_tag
-        )
-
+        all_file_counts, grand_total, total_lines, aider_total, aider_percentage, end_date = \
+            blame(args.start_tag, args.end_tag)
         result = {
             "start_tag": args.start_tag,
             "end_tag": args.end_tag or "HEAD",
@@ -204,7 +172,6 @@             "aider_total": aider_total,
             "aider_percentage": round(aider_percentage, 2),
         }
-
         yaml_output = yaml.dump(result, sort_keys=True)
 
     if args.output:
@@ -268,7 +235,7 @@         else:
             # Some other error occurred
             print(f"Warning: Unable to blame file {fname}. Error: {e}", file=sys.stderr)
-            return None
+        return None
 
 
 def get_all_tags_since(start_tag):
