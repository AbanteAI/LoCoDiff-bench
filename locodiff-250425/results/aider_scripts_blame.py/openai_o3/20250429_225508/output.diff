--- aider_scripts_blame.py_expectedoutput.txt (expected)+++ aider_scripts_blame.py_extracted.txt (actual)@@ -12,6 +12,7 @@ import yaml
 from tqdm import tqdm
 
+# Files that should always be included in the blame statistics
 website_files = [
     "aider/website/index.html",
     "aider/website/share/index.md",
@@ -20,21 +21,40 @@     "aider/website/docs/leaderboards/index.md",
 ]
 
+# Files that should always be excluded from the blame statistics
 exclude_files = [
     "aider/website/install.ps1",
     "aider/website/install.sh",
 ]
 
-
-def blame(start_tag, end_tag=None):
+hash_len = len("44e6fefc2")  # short commit-hash length used by git-blame
+
+
+def blame(start_tag: str, end_tag: str | None = None):
+    """
+    Return line-ownership statistics for the revision range start_tag..end_tag.
+
+    The result is a tuple containing:
+        - per-file line counts (dict)
+        - grand_total  (author ➜ lines)  (dict)
+        - total_lines  (int)
+        - aider_total  (int)
+        - aider_percentage (float)
+        - end_date (datetime)
+    """
     commits = get_all_commit_hashes_between_tags(start_tag, end_tag)
     commits = [commit[:hash_len] for commit in commits]
-
     authors = get_commit_authors(commits)
 
     revision = end_tag if end_tag else "HEAD"
     files = run(["git", "ls-tree", "-r", "--name-only", revision]).strip().split("\n")
-    test_files = [f for f in files if f.startswith("tests/fixtures/languages/") and "/test." in f]
+
+    # Special sets
+    test_files = [
+        f for f in files if f.startswith("tests/fixtures/languages/") and "/test." in f
+    ]
+
+    # Filter the files we care about
     files = [
         f
         for f in files
@@ -48,90 +68,102 @@     files = [f for f in files if not f.startswith("tests/fixtures/watch")]
     files = [f for f in files if f not in exclude_files]
 
-    all_file_counts = {}
-    grand_total = defaultdict(int)
+    all_file_counts: dict[str, dict[str, int]] = {}
+    grand_total: defaultdict[str, int] = defaultdict(int)
     aider_total = 0
-    for file in files:
-        file_counts = get_counts_for_file(start_tag, end_tag, authors, file)
-        if file_counts:
-            all_file_counts[file] = file_counts
-            for author, count in file_counts.items():
-                grand_total[author] += count
-                if "(aider)" in author.lower():
-                    aider_total += count
+
+    for fname in tqdm(files, desc="Blaming files", leave=False):
+        file_counts = get_counts_for_file(start_tag, end_tag, authors, fname)
+        if not file_counts:
+            continue
+        all_file_counts[fname] = file_counts
+        for author, count in file_counts.items():
+            grand_total[author] += count
+            if "(aider)" in author.lower():
+                aider_total += count
 
     total_lines = sum(grand_total.values())
-    aider_percentage = (aider_total / total_lines) * 100 if total_lines > 0 else 0
-
+    aider_percentage = (aider_total / total_lines) * 100 if total_lines else 0.0
     end_date = get_tag_date(end_tag if end_tag else "HEAD")
 
-    return all_file_counts, grand_total, total_lines, aider_total, aider_percentage, end_date
-
-
-def get_all_commit_hashes_between_tags(start_tag, end_tag=None):
-    if end_tag:
-        res = run(["git", "rev-list", f"{start_tag}..{end_tag}"])
-    else:
-        res = run(["git", "rev-list", f"{start_tag}..HEAD"])
-
-    if res:
-        commit_hashes = res.strip().split("\n")
-        return commit_hashes
-
-
-def run(cmd):
-    # Get all commit hashes since the specified tag
+    return (
+        all_file_counts,
+        grand_total,
+        total_lines,
+        aider_total,
+        aider_percentage,
+        end_date,
+    )
+
+
+def get_all_commit_hashes_between_tags(start_tag: str, end_tag: str | None):
+    """
+    Return all commit hashes between two tags (inclusive of HEAD when end_tag is None).
+    """
+    rev_range = f"{start_tag}..{end_tag}" if end_tag else f"{start_tag}..HEAD"
+    res = run(["git", "rev-list", rev_range])
+    return res.strip().split("\n") if res else []
+
+
+def run(cmd: list[str]) -> str:
+    """Run a git command and return stdout."""
     result = subprocess.run(cmd, capture_output=True, text=True, check=True)
     return result.stdout
 
 
-def get_commit_authors(commits):
-    commit_to_author = dict()
+def get_commit_authors(commits: list[str]):
+    """
+    Map short-hash ➜ author.
+    Commits with messages starting “aider:” get “ (aider)” appended to the author.
+    """
+    out: dict[str, str] = {}
     for commit in commits:
         author = run(["git", "show", "-s", "--format=%an", commit]).strip()
-        commit_message = run(["git", "show", "-s", "--format=%s", commit]).strip()
-        if commit_message.lower().startswith("aider:"):
+        message = run(["git", "show", "-s", "--format=%s", commit]).strip()
+        if message.lower().startswith("aider:"):
             author += " (aider)"
-        commit_to_author[commit] = author
-    return commit_to_author
-
-
-hash_len = len("44e6fefc2")
-
-
-def process_all_tags_since(start_tag):
+        out[commit] = author
+    return out
+
+
+def process_all_tags_since(start_tag: str):
     tags = get_all_tags_since(start_tag)
-    # tags += ['HEAD']
+    # tags[-1] will be HEAD added later if needed
+    if tags[-1] != "HEAD":
+        tags.append("HEAD")
 
     results = []
     for i in tqdm(range(len(tags) - 1), desc="Processing tags"):
-        start_tag, end_tag = tags[i], tags[i + 1]
-        all_file_counts, grand_total, total_lines, aider_total, aider_percentage, end_date = blame(
-            start_tag, end_tag
-        )
+        s_tag, e_tag = tags[i], tags[i + 1]
+        (
+            file_counts,
+            grand_total,
+            total_lines,
+            aider_total,
+            aider_pct,
+            end_date,
+        ) = blame(s_tag, e_tag)
+
         results.append(
             {
-                "start_tag": start_tag,
-                "end_tag": end_tag,
+                "start_tag": s_tag,
+                "end_tag": e_tag,
                 "end_date": end_date.strftime("%Y-%m-%d"),
-                "file_counts": all_file_counts,
+                "file_counts": file_counts,
                 "grand_total": {
-                    author: count
-                    for author, count in sorted(
-                        grand_total.items(), key=itemgetter(1), reverse=True
-                    )
+                    a: c for a, c in sorted(grand_total.items(), key=itemgetter(1), reverse=True)
                 },
                 "total_lines": total_lines,
                 "aider_total": aider_total,
-                "aider_percentage": round(aider_percentage, 2),
+                "aider_percentage": round(aider_pct, 2),
             }
         )
     return results
 
 
 def get_latest_version_tag():
-    all_tags = run(["git", "tag", "--sort=-v:refname"]).strip().split("\n")
-    for tag in all_tags:
+    """Return the latest vX.Y.0 tag in the repo (by semantic version)."""
+    for tag in run(["git", "tag", "--sort=-v:refname"]).strip().split("\n"):
         if semver.Version.is_valid(tag[1:]) and tag.endswith(".0"):
             return tag
     return None
@@ -140,149 +172,127 @@ def main():
     parser = argparse.ArgumentParser(description="Get aider/non-aider blame stats")
     parser.add_argument("start_tag", nargs="?", help="The tag to start from (optional)")
-    parser.add_argument("--end-tag", help="The tag to end at (default: HEAD)", default=None)
+    parser.add_argument("--end-tag", help="The tag to end at (default: HEAD)")
     parser.add_argument(
         "--all-since",
         action="store_true",
-        help=(
-            "Find all tags since the specified tag and print aider percentage between each pair of"
-            " successive tags"
-        ),
+        help="Calculate stats for all successive tag pairs starting from start_tag",
     )
-    parser.add_argument(
-        "--output", help="Output file to save the YAML results", type=str, default=None
-    )
+    parser.add_argument("--output", type=str, help="Write YAML results to this file")
     args = parser.parse_args()
 
     if not args.start_tag:
         args.start_tag = get_latest_version_tag()
         if not args.start_tag:
-            print("Error: No valid vX.Y.0 tag found.")
-            return
+            print("Error: Could not find a suitable vX.Y.0 tag to start from.", file=sys.stderr)
+            sys.exit(1)
 
     if args.all_since:
         new_results = process_all_tags_since(args.start_tag)
 
-        # If output file exists, read and update it
-        existing_results = []
+        # Merge with existing YAML (if any)
+        combined = new_results
         if args.output and os.path.exists(args.output):
-            with open(args.output, "r") as f:
-                existing_results = yaml.safe_load(f) or []
-
-        # Create a map of start_tag->end_tag to result for existing entries
-        existing_map = {(r["start_tag"], r["end_tag"]): i for i, r in enumerate(existing_results)}
-
-        # Update or append new results
-        for new_result in new_results:
-            key = (new_result["start_tag"], new_result["end_tag"])
-            if key in existing_map:
-                # Replace existing entry
-                existing_results[existing_map[key]] = new_result
-            else:
-                # Append new entry
-                existing_results.append(new_result)
-
-        # Sort results by start_tag
-        existing_results.sort(key=lambda x: semver.Version.parse(x["start_tag"][1:]))
-
-        yaml_output = yaml.dump(existing_results, sort_keys=True)
+            with open(args.output) as f:
+                existing = yaml.safe_load(f) or []
+            key = lambda r: (r["start_tag"], r["end_tag"])
+            existing_map = {key(r): i for i, r in enumerate(existing)}
+            for res in new_results:
+                k = key(res)
+                if k in existing_map:
+                    existing[existing_map[k]] = res
+                else:
+                    existing.append(res)
+            existing.sort(key=lambda r: semver.Version.parse(r["start_tag"][1:]))
+            combined = existing
+        yaml_output = yaml.dump(combined, sort_keys=True)
     else:
-        all_file_counts, grand_total, total_lines, aider_total, aider_percentage, end_date = blame(
-            args.start_tag, args.end_tag
-        )
+        (
+            file_counts,
+            grand_total,
+            total_lines,
+            aider_total,
+            aider_pct,
+            end_date,
+        ) = blame(args.start_tag, args.end_tag)
 
         result = {
             "start_tag": args.start_tag,
             "end_tag": args.end_tag or "HEAD",
             "end_date": end_date.strftime("%Y-%m-%d"),
-            "file_counts": all_file_counts,
+            "file_counts": file_counts,
             "grand_total": {
-                author: count
-                for author, count in sorted(grand_total.items(), key=itemgetter(1), reverse=True)
+                a: c for a, c in sorted(grand_total.items(), key=itemgetter(1), reverse=True)
             },
             "total_lines": total_lines,
             "aider_total": aider_total,
-            "aider_percentage": round(aider_percentage, 2),
+            "aider_percentage": round(aider_pct, 2),
         }
-
         yaml_output = yaml.dump(result, sort_keys=True)
 
+    # Output YAML
     if args.output:
-        with open(args.output, "w") as f:
-            f.write(yaml_output)
+        with open(args.output, "w") as fh:
+            fh.write(yaml_output)
     else:
         print(yaml_output)
 
     if not args.all_since:
-        print(f"- Aider wrote {round(aider_percentage)}% of the code in this release.")
-
-
-def get_counts_for_file(start_tag, end_tag, authors, fname):
+        print(f"- Aider wrote {round(aider_pct)}% of the code in this release.")
+
+
+def get_counts_for_file(start_tag: str, end_tag: str | None, authors: dict, fname: str):
+    """
+    Blame a single file in the given revision range and return per-author line counts.
+    """
     try:
-        if end_tag:
-            text = run(
-                [
-                    "git",
-                    "blame",
-                    "-M100",  # Detect moved lines within a file with 100% similarity
-                    "-C100",  # Detect moves across files with 100% similarity
-                    "-C",  # Increase detection effort
-                    "-C",  # Increase detection effort even more
-                    "--abbrev=9",
-                    f"{start_tag}..{end_tag}",
-                    "--",
-                    fname,
-                ]
-            )
-        else:
-            text = run(
-                [
-                    "git",
-                    "blame",
-                    "-M100",  # Detect moved lines within a file with 100% similarity
-                    "-C100",  # Detect moves across files with 100% similarity
-                    "-C",  # Increase detection effort
-                    "-C",  # Increase detection effort even more
-                    "--abbrev=9",
-                    f"{start_tag}..HEAD",
-                    "--",
-                    fname,
-                ]
-            )
+        blame_cmd = [
+            "git",
+            "blame",
+            "-M100",  # detect moved lines within a file (100 % similarity)
+            "-C100",  # detect moved/copied lines across files (100 % similarity)
+            "-C",  # extra copy-detection effort
+            "-C",  # even more effort
+            "--abbrev=9",
+            f"{start_tag}..{end_tag or 'HEAD'}",
+            "--",
+            fname,
+        ]
+        text = run(blame_cmd)
         if not text:
             return None
-        text = text.splitlines()
-        line_counts = defaultdict(int)
-        for line in text:
-            if line.startswith("^"):
+
+        counts: defaultdict[str, int] = defaultdict(int)
+        for line in text.splitlines():
+            if line.startswith("^"):  # uncommitted or boundary lines
                 continue
-            hsh = line[:hash_len]
-            author = authors.get(hsh, "Unknown")
-            line_counts[author] += 1
-
-        return dict(line_counts)
-    except subprocess.CalledProcessError as e:
-        if "no such path" in str(e).lower():
-            # File doesn't exist in this revision range, which is okay
+            commit_hash = line[:hash_len]
+            author = authors.get(commit_hash, "Unknown")
+            counts[author] += 1
+        return dict(counts)
+
+    except subprocess.CalledProcessError as err:
+        # Ignore files missing in part of the range; warn on other errors.
+        if "no such path" in str(err).lower():
             return None
-        else:
-            # Some other error occurred
-            print(f"Warning: Unable to blame file {fname}. Error: {e}", file=sys.stderr)
-            return None
-
-
-def get_all_tags_since(start_tag):
-    all_tags = run(["git", "tag", "--sort=v:refname"]).strip().split("\n")
-    start_version = semver.Version.parse(start_tag[1:])  # Remove 'v' prefix
-    filtered_tags = [
-        tag
-        for tag in all_tags
-        if semver.Version.is_valid(tag[1:]) and semver.Version.parse(tag[1:]) >= start_version
+        print(f"Warning: Unable to blame {fname}: {err}", file=sys.stderr)
+        return None
+
+
+def get_all_tags_since(start_tag: str):
+    """
+    Return all vX.Y.0 tags >= start_tag, ordered ascending.
+    """
+    tags = run(["git", "tag", "--sort=v:refname"]).strip().split("\n")
+    start_version = semver.Version.parse(start_tag[1:])  # drop leading 'v'
+    return [
+        t
+        for t in tags
+        if t.endswith(".0") and semver.Version.is_valid(t[1:]) and semver.Version.parse(t[1:]) >= start_version
     ]
-    return [tag for tag in filtered_tags if tag.endswith(".0")]
-
-
-def get_tag_date(tag):
+
+
+def get_tag_date(tag: str):
     date_str = run(["git", "log", "-1", "--format=%ai", tag]).strip()
     return datetime.strptime(date_str, "%Y-%m-%d %H:%M:%S %z")
 
