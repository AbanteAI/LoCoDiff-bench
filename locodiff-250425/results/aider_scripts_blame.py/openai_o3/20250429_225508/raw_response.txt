```python
#!/usr/bin/env python3

import argparse
import os
import subprocess
import sys
from collections import defaultdict
from datetime import datetime
from operator import itemgetter

import semver
import yaml
from tqdm import tqdm

# Files that should always be included in the blame statistics
website_files = [
    "aider/website/index.html",
    "aider/website/share/index.md",
    "aider/website/_includes/head_custom.html",
    "aider/website/_includes/home.css",
    "aider/website/docs/leaderboards/index.md",
]

# Files that should always be excluded from the blame statistics
exclude_files = [
    "aider/website/install.ps1",
    "aider/website/install.sh",
]

hash_len = len("44e6fefc2")  # short commit-hash length used by git-blame


def blame(start_tag: str, end_tag: str | None = None):
    """
    Return line-ownership statistics for the revision range start_tag..end_tag.

    The result is a tuple containing:
        - per-file line counts (dict)
        - grand_total  (author ➜ lines)  (dict)
        - total_lines  (int)
        - aider_total  (int)
        - aider_percentage (float)
        - end_date (datetime)
    """
    commits = get_all_commit_hashes_between_tags(start_tag, end_tag)
    commits = [commit[:hash_len] for commit in commits]
    authors = get_commit_authors(commits)

    revision = end_tag if end_tag else "HEAD"
    files = run(["git", "ls-tree", "-r", "--name-only", revision]).strip().split("\n")

    # Special sets
    test_files = [
        f for f in files if f.startswith("tests/fixtures/languages/") and "/test." in f
    ]

    # Filter the files we care about
    files = [
        f
        for f in files
        if f.endswith((".js", ".py", ".scm", ".sh", "Dockerfile", "Gemfile"))
        or (f.startswith(".github/workflows/") and f.endswith(".yml"))
        or (f.startswith("aider/resources/") and f.endswith(".yml"))
        or f in website_files
        or f in test_files
    ]
    files = [f for f in files if not f.endswith("prompts.py")]
    files = [f for f in files if not f.startswith("tests/fixtures/watch")]
    files = [f for f in files if f not in exclude_files]

    all_file_counts: dict[str, dict[str, int]] = {}
    grand_total: defaultdict[str, int] = defaultdict(int)
    aider_total = 0

    for fname in tqdm(files, desc="Blaming files", leave=False):
        file_counts = get_counts_for_file(start_tag, end_tag, authors, fname)
        if not file_counts:
            continue
        all_file_counts[fname] = file_counts
        for author, count in file_counts.items():
            grand_total[author] += count
            if "(aider)" in author.lower():
                aider_total += count

    total_lines = sum(grand_total.values())
    aider_percentage = (aider_total / total_lines) * 100 if total_lines else 0.0
    end_date = get_tag_date(end_tag if end_tag else "HEAD")

    return (
        all_file_counts,
        grand_total,
        total_lines,
        aider_total,
        aider_percentage,
        end_date,
    )


def get_all_commit_hashes_between_tags(start_tag: str, end_tag: str | None):
    """
    Return all commit hashes between two tags (inclusive of HEAD when end_tag is None).
    """
    rev_range = f"{start_tag}..{end_tag}" if end_tag else f"{start_tag}..HEAD"
    res = run(["git", "rev-list", rev_range])
    return res.strip().split("\n") if res else []


def run(cmd: list[str]) -> str:
    """Run a git command and return stdout."""
    result = subprocess.run(cmd, capture_output=True, text=True, check=True)
    return result.stdout


def get_commit_authors(commits: list[str]):
    """
    Map short-hash ➜ author.
    Commits with messages starting “aider:” get “ (aider)” appended to the author.
    """
    out: dict[str, str] = {}
    for commit in commits:
        author = run(["git", "show", "-s", "--format=%an", commit]).strip()
        message = run(["git", "show", "-s", "--format=%s", commit]).strip()
        if message.lower().startswith("aider:"):
            author += " (aider)"
        out[commit] = author
    return out


def process_all_tags_since(start_tag: str):
    tags = get_all_tags_since(start_tag)
    # tags[-1] will be HEAD added later if needed
    if tags[-1] != "HEAD":
        tags.append("HEAD")

    results = []
    for i in tqdm(range(len(tags) - 1), desc="Processing tags"):
        s_tag, e_tag = tags[i], tags[i + 1]
        (
            file_counts,
            grand_total,
            total_lines,
            aider_total,
            aider_pct,
            end_date,
        ) = blame(s_tag, e_tag)

        results.append(
            {
                "start_tag": s_tag,
                "end_tag": e_tag,
                "end_date": end_date.strftime("%Y-%m-%d"),
                "file_counts": file_counts,
                "grand_total": {
                    a: c for a, c in sorted(grand_total.items(), key=itemgetter(1), reverse=True)
                },
                "total_lines": total_lines,
                "aider_total": aider_total,
                "aider_percentage": round(aider_pct, 2),
            }
        )
    return results


def get_latest_version_tag():
    """Return the latest vX.Y.0 tag in the repo (by semantic version)."""
    for tag in run(["git", "tag", "--sort=-v:refname"]).strip().split("\n"):
        if semver.Version.is_valid(tag[1:]) and tag.endswith(".0"):
            return tag
    return None


def main():
    parser = argparse.ArgumentParser(description="Get aider/non-aider blame stats")
    parser.add_argument("start_tag", nargs="?", help="The tag to start from (optional)")
    parser.add_argument("--end-tag", help="The tag to end at (default: HEAD)")
    parser.add_argument(
        "--all-since",
        action="store_true",
        help="Calculate stats for all successive tag pairs starting from start_tag",
    )
    parser.add_argument("--output", type=str, help="Write YAML results to this file")
    args = parser.parse_args()

    if not args.start_tag:
        args.start_tag = get_latest_version_tag()
        if not args.start_tag:
            print("Error: Could not find a suitable vX.Y.0 tag to start from.", file=sys.stderr)
            sys.exit(1)

    if args.all_since:
        new_results = process_all_tags_since(args.start_tag)

        # Merge with existing YAML (if any)
        combined = new_results
        if args.output and os.path.exists(args.output):
            with open(args.output) as f:
                existing = yaml.safe_load(f) or []
            key = lambda r: (r["start_tag"], r["end_tag"])
            existing_map = {key(r): i for i, r in enumerate(existing)}
            for res in new_results:
                k = key(res)
                if k in existing_map:
                    existing[existing_map[k]] = res
                else:
                    existing.append(res)
            existing.sort(key=lambda r: semver.Version.parse(r["start_tag"][1:]))
            combined = existing
        yaml_output = yaml.dump(combined, sort_keys=True)
    else:
        (
            file_counts,
            grand_total,
            total_lines,
            aider_total,
            aider_pct,
            end_date,
        ) = blame(args.start_tag, args.end_tag)

        result = {
            "start_tag": args.start_tag,
            "end_tag": args.end_tag or "HEAD",
            "end_date": end_date.strftime("%Y-%m-%d"),
            "file_counts": file_counts,
            "grand_total": {
                a: c for a, c in sorted(grand_total.items(), key=itemgetter(1), reverse=True)
            },
            "total_lines": total_lines,
            "aider_total": aider_total,
            "aider_percentage": round(aider_pct, 2),
        }
        yaml_output = yaml.dump(result, sort_keys=True)

    # Output YAML
    if args.output:
        with open(args.output, "w") as fh:
            fh.write(yaml_output)
    else:
        print(yaml_output)

    if not args.all_since:
        print(f"- Aider wrote {round(aider_pct)}% of the code in this release.")


def get_counts_for_file(start_tag: str, end_tag: str | None, authors: dict, fname: str):
    """
    Blame a single file in the given revision range and return per-author line counts.
    """
    try:
        blame_cmd = [
            "git",
            "blame",
            "-M100",  # detect moved lines within a file (100 % similarity)
            "-C100",  # detect moved/copied lines across files (100 % similarity)
            "-C",  # extra copy-detection effort
            "-C",  # even more effort
            "--abbrev=9",
            f"{start_tag}..{end_tag or 'HEAD'}",
            "--",
            fname,
        ]
        text = run(blame_cmd)
        if not text:
            return None

        counts: defaultdict[str, int] = defaultdict(int)
        for line in text.splitlines():
            if line.startswith("^"):  # uncommitted or boundary lines
                continue
            commit_hash = line[:hash_len]
            author = authors.get(commit_hash, "Unknown")
            counts[author] += 1
        return dict(counts)

    except subprocess.CalledProcessError as err:
        # Ignore files missing in part of the range; warn on other errors.
        if "no such path" in str(err).lower():
            return None
        print(f"Warning: Unable to blame {fname}: {err}", file=sys.stderr)
        return None


def get_all_tags_since(start_tag: str):
    """
    Return all vX.Y.0 tags >= start_tag, ordered ascending.
    """
    tags = run(["git", "tag", "--sort=v:refname"]).strip().split("\n")
    start_version = semver.Version.parse(start_tag[1:])  # drop leading 'v'
    return [
        t
        for t in tags
        if t.endswith(".0") and semver.Version.is_valid(t[1:]) and semver.Version.parse(t[1:]) >= start_version
    ]


def get_tag_date(tag: str):
    date_str = run(["git", "log", "-1", "--format=%ai", tag]).strip()
    return datetime.strptime(date_str, "%Y-%m-%d %H:%M:%S %z")


if __name__ == "__main__":
    main()
```