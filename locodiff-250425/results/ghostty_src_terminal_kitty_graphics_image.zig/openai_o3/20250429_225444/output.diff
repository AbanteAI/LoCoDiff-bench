
index 6abe1ca7..de8a3a0e 100644
--- a/ghostty_src_terminal_kitty_graphics_image.zig_expectedoutput.txt (expected):tmp/tmpw2lf6lop_expected.txt	
+++ b/ghostty_src_terminal_kitty_graphics_image.zig_extracted.txt (actual):tmp/tmp59b1d9go_actual.txt	
@@ -40,7 +40,7 @@ pub const LoadingImage = struct {
     /// used if q isn't set on subsequent chunks.
     quiet: command.Command.Quiet,
 
-    /// Initialize a chunked immage from the first image transmission.
+    /// Initialize a chunked image from the first image transmission.
     /// If this is a multi-chunk image, this should only be the FIRST
     /// chunk.
     pub fn init(alloc: Allocator, cmd: *const command.Command) !LoadingImage {
@@ -48,6 +48,7 @@ pub const LoadingImage = struct {
         // These can be overwritten by the data loading process. For example,
         // PNG loading sets the width/height from the data.
         const t = cmd.transmission().?;
+
         var result: LoadingImage = .{
             .image = .{
                 .id = t.image_id,
@@ -69,7 +70,6 @@ pub const LoadingImage = struct {
         }
 
         // Otherwise, the payload data is guaranteed to be a path.
-
         if (comptime builtin.os.tag != .windows) {
             if (std.mem.indexOfScalar(u8, cmd.data, 0) != null) {
                 // posix.realpath *asserts* that the path does not have
@@ -100,6 +100,135 @@ pub const LoadingImage = struct {
         return result;
     }
 
+    pub fn deinit(self: *LoadingImage, alloc: Allocator) void {
+        self.image.deinit(alloc);
+        self.data.deinit(alloc);
+    }
+
+    pub fn destroy(self: *LoadingImage, alloc: Allocator) void {
+        self.deinit(alloc);
+        alloc.destroy(self);
+    }
+
+    /// Adds a chunk of data to the image. Use this if the image
+    /// is coming in chunks (the "m" parameter in the protocol).
+    pub fn addData(self: *LoadingImage, alloc: Allocator, data: []const u8) !void {
+        // If no data, skip
+        if (data.len == 0) return;
+
+        // If our data would get too big, return an error
+        if (self.data.items.len + data.len > max_size) {
+            log.warn("image data too large max_size={}", .{max_size});
+            return error.InvalidData;
+        }
+
+        // Ensure we have enough room to add the data
+        try self.data.ensureUnusedCapacity(alloc, data.len);
+
+        const start_i = self.data.items.len;
+        self.data.items.len = start_i + data.len;
+        fastmem.copy(u8, self.data.items[start_i..], data);
+    }
+
+    /// Complete the chunked image, returning a completed image.
+    pub fn complete(self: *LoadingImage, alloc: Allocator) !Image {
+        const img = &self.image;
+
+        // Decompress the data if it is compressed.
+        try self.decompress(alloc);
+
+        // Decode the png if we have to
+        if (img.format == .png) try self.decodePng(alloc);
+
+        // Validate our dimensions.
+        if (img.width == 0 or img.height == 0) return error.DimensionsRequired;
+        if (img.width > max_dimension or img.height > max_dimension) return error.DimensionsTooLarge;
+
+        // Data length must be what we expect
+        const bpp = img.format.bpp();
+        const expected_len: usize = img.width * img.height * bpp;
+        const actual_len: usize = self.data.items.len;
+        if (actual_len != expected_len) {
+            log.warn(
+                "unexpected length image id={} width={} height={} bpp={} expected_len={} actual_len={}",
+                .{ img.id, img.width, img.height, bpp, expected_len, actual_len },
+            );
+            return error.InvalidData;
+        }
+
+        // Set our time
+        self.image.transmit_time = std.time.Instant.now() catch |err| {
+            log.warn("failed to get time: {}", .{err});
+            return error.InternalError;
+        };
+
+        // Everything looks good, copy the image data over.
+        var result = self.image;
+        result.data = try self.data.toOwnedSlice(alloc);
+        errdefer result.deinit(alloc);
+        self.image = .{};
+        return result;
+    }
+
+    /// Decompress the data in-place.
+    fn decompress(self: *LoadingImage, alloc: Allocator) !void {
+        return switch (self.image.compression) {
+            .none => {},
+            .zlib_deflate => self.decompressZlib(alloc),
+        };
+    }
+
+    fn decompressZlib(self: *LoadingImage, alloc: Allocator) !void {
+        // Open our zlib stream
+        var fbs = std.io.fixedBufferStream(self.data.items);
+        var stream = std.compress.zlib.decompressor(fbs.reader());
+
+        // Write it to an array list
+        var list = std.ArrayList(u8).init(alloc);
+        errdefer list.deinit();
+        stream.reader().readAllArrayList(&list, max_size) catch |err| {
+            log.warn("failed to read decompressed data: {}", .{err});
+            return error.DecompressionFailed;
+        };
+
+        // Empty our current data list, take ownership over managed array list
+        self.data.deinit(alloc);
+        self.data = .{ .items = list.items, .capacity = list.capacity };
+
+        // Make sure we note that our image is no longer compressed
+        self.image.compression = .none;
+    }
+
+    /// Decode the data as PNG. This will also update the image dimensions.
+    fn decodePng(self: *LoadingImage, alloc: Allocator) !void {
+        assert(self.image.format == .png);
+
+        const result = wuffs.png.decode(
+            alloc,
+            self.data.items,
+        ) catch |err| switch (err) {
+            error.WuffsError => return error.InvalidData,
+            error.OutOfMemory => return error.OutOfMemory,
+        };
+        defer alloc.free(result.data);
+
+        if (result.data.len > max_size) {
+            log.warn("png image too large size={} max_size={}", .{ result.data.len, max_size });
+            return error.InvalidData;
+        }
+
+        // Replace our data
+        self.data.deinit(alloc);
+        self.data = .{};
+        try self.data.ensureUnusedCapacity(alloc, result.data.len);
+        try self.data.appendSlice(alloc, result.data);
+
+        // Store updated image dimensions
+        self.image.width = result.width;
+        self.image.height = result.height;
+        self.image.format = .rgba;
+    }
+
     /// Reads the data from a shared memory segment.
     fn readSharedMemory(
         self: *LoadingImage,
@@ -136,20 +265,16 @@ pub const LoadingImage = struct {
         // The size from stat on may be larger than our expected size because
         // shared memory has to be a multiple of the page size.
         const stat_size: usize = stat: {
-            const stat = std.posix.fstat(fd) catch |err| {
+            const st = std.posix.fstat(fd) catch |err| {
                 log.warn("unable to fstat shared memory {s}: {}", .{ path, err });
                 return error.InvalidData;
             };
-            if (stat.size <= 0) return error.InvalidData;
-            break :stat @intCast(stat.size);
+            if (st.size <= 0) return error.InvalidData;
+            break :stat @intCast(st.size);
         };
 
         const expected_size: usize = switch (self.image.format) {
-            // Png we decode the full data size because later decoding will
-            // get the proper dimensions and assert validity.
             .png => stat_size,
-
-            // For these formats we have a size we must have.
             .gray, .gray_alpha, .rgb, .rgba => |f| size: {
                 const bpp = f.bpp();
                 break :size self.image.width * self.image.height * bpp;
@@ -182,10 +307,10 @@ pub const LoadingImage = struct {
         // Our end size always uses the expected size so we cut off the
         // padding for mmap alignment.
         const start: usize = @intCast(t.offset);
-        const end: usize = if (t.size > 0) @min(
-            @as(usize, @intCast(t.offset)) + @as(usize, @intCast(t.size)),
-            expected_size,
-        ) else expected_size;
+        const end: usize = if (t.size > 0)
+            @min(@as(usize, @intCast(t.offset)) + @as(usize, @intCast(t.size)), expected_size)
+        else
+            expected_size;
 
         assert(self.data.items.len == 0);
         try self.data.appendSlice(alloc, map[start..end]);
@@ -231,7 +356,7 @@ pub const LoadingImage = struct {
         };
 
         var file = std.fs.cwd().openFile(path, .{}) catch |err| {
-            log.warn("failed to open temporary file: {}", .{err});
+            log.warn("failed to open file: {}", .{err});
             return error.InvalidData;
         };
         defer file.close();
@@ -262,7 +387,7 @@ pub const LoadingImage = struct {
         errdefer managed.deinit();
         const size: usize = if (t.size > 0) @min(t.size, max_size) else max_size;
         reader.readAllArrayList(&managed, size) catch |err| {
-            log.warn("failed to read temporary file: {}", .{err});
+            log.warn("failed to read file: {}", .{err});
             return error.InvalidData;
         };
 
@@ -290,161 +415,6 @@ pub const LoadingImage = struct {
 
         return false;
     }
-
-    pub fn deinit(self: *LoadingImage, alloc: Allocator) void {
-        self.image.deinit(alloc);
-        self.data.deinit(alloc);
-    }
-
-    pub fn destroy(self: *LoadingImage, alloc: Allocator) void {
-        self.deinit(alloc);
-        alloc.destroy(self);
-    }
-
-    /// Adds a chunk of data to the image. Use this if the image
-    /// is coming in chunks (the "m" parameter in the protocol).
-    pub fn addData(self: *LoadingImage, alloc: Allocator, data: []const u8) !void {
-        // If no data, skip
-        if (data.len == 0) return;
-
-        // If our data would get too big, return an error
-        if (self.data.items.len + data.len > max_size) {
-            log.warn("image data too large max_size={}", .{max_size});
-            return error.InvalidData;
-        }
-
-        // Ensure we have enough room to add the data
-        // to the end of the ArrayList before doing so.
-        try self.data.ensureUnusedCapacity(alloc, data.len);
-
-        const start_i = self.data.items.len;
-        self.data.items.len = start_i + data.len;
-        fastmem.copy(u8, self.data.items[start_i..], data);
-    }
-
-    /// Complete the chunked image, returning a completed image.
-    pub fn complete(self: *LoadingImage, alloc: Allocator) !Image {
-        const img = &self.image;
-
-        // Decompress the data if it is compressed.
-        try self.decompress(alloc);
-
-        // Decode the png if we have to
-        if (img.format == .png) try self.decodePng(alloc);
-
-        // Validate our dimensions.
-        if (img.width == 0 or img.height == 0) return error.DimensionsRequired;
-        if (img.width > max_dimension or img.height > max_dimension) return error.DimensionsTooLarge;
-
-        // Data length must be what we expect
-        const bpp = img.format.bpp();
-        const expected_len = img.width * img.height * bpp;
-        const actual_len = self.data.items.len;
-        if (actual_len != expected_len) {
-            std.log.warn(
-                "unexpected length image id={} width={} height={} bpp={} expected_len={} actual_len={}",
-                .{ img.id, img.width, img.height, bpp, expected_len, actual_len },
-            );
-            return error.InvalidData;
-        }
-
-        // Set our time
-        self.image.transmit_time = std.time.Instant.now() catch |err| {
-            log.warn("failed to get time: {}", .{err});
-            return error.InternalError;
-        };
-
-        // Everything looks good, copy the image data over.
-        var result = self.image;
-        result.data = try self.data.toOwnedSlice(alloc);
-        errdefer result.deinit(alloc);
-        self.image = .{};
-        return result;
-    }
-
-    /// Debug function to write the data to a file. This is useful for
-    /// capturing some test data for unit tests.
-    pub fn debugDump(self: LoadingImage) !void {
-        if (comptime builtin.mode != .Debug) @compileError("debugDump in non-debug");
-
-        var buf: [1024]u8 = undefined;
-        const filename = try std.fmt.bufPrint(
-            &buf,
-            "image-{s}-{s}-{d}x{d}-{}.data",
-            .{
-                @tagName(self.image.format),
-                @tagName(self.image.compression),
-                self.image.width,
-                self.image.height,
-                self.image.id,
-            },
-        );
-        const cwd = std.fs.cwd();
-        const f = try cwd.createFile(filename, .{});
-        defer f.close();
-
-        const writer = f.writer();
-        try writer.writeAll(self.data.items);
-    }
-
-    /// Decompress the data in-place.
-    fn decompress(self: *LoadingImage, alloc: Allocator) !void {
-        return switch (self.image.compression) {
-            .none => {},
-            .zlib_deflate => self.decompressZlib(alloc),
-        };
-    }
-
-    fn decompressZlib(self: *LoadingImage, alloc: Allocator) !void {
-        // Open our zlib stream
-        var fbs = std.io.fixedBufferStream(self.data.items);
-        var stream = std.compress.zlib.decompressor(fbs.reader());
-
-        // Write it to an array list
-        var list = std.ArrayList(u8).init(alloc);
-        errdefer list.deinit();
-        stream.reader().readAllArrayList(&list, max_size) catch |err| {
-            log.warn("failed to read decompressed data: {}", .{err});
-            return error.DecompressionFailed;
-        };
-
-        // Empty our current data list, take ownership over managed array list
-        self.data.deinit(alloc);
-        self.data = .{ .items = list.items, .capacity = list.capacity };
-
-        // Make sure we note that our image is no longer compressed
-        self.image.compression = .none;
-    }
-
-    /// Decode the data as PNG. This will also updated the image dimensions.
-    fn decodePng(self: *LoadingImage, alloc: Allocator) !void {
-        assert(self.image.format == .png);
-
-        const result = wuffs.png.decode(
-            alloc,
-            self.data.items,
-        ) catch |err| switch (err) {
-            error.WuffsError => return error.InvalidData,
-            error.OutOfMemory => return error.OutOfMemory,
-        };
-        defer alloc.free(result.data);
-
-        if (result.data.len > max_size) {
-            log.warn("png image too large size={} max_size={}", .{ result.data.len, max_size });
-            return error.InvalidData;
-        }
-
-        // Replace our data
-        self.data.deinit(alloc);
-        self.data = .{};
-        try self.data.ensureUnusedCapacity(alloc, result.data.len);
-        try self.data.appendSlice(alloc, result.data[0..result.data.len]);
-
-        // Store updated image dimensions
-        self.image.width = result.width;
-        self.image.height = result.height;
-        self.image.format = .rgba;
-    }
 };
 
 /// Image represents a single fully loaded image.
@@ -498,16 +468,17 @@ pub const Rect = struct {
     bottom_right: PageList.Pin,
 };
 
-// This specifically tests we ALLOW invalid RGB data because Kitty
-// documents that this should work.
+// ------------------------------- Tests -----------------------------------
+
 test "image load with invalid RGB data" {
     const testing = std.testing;
     const alloc = testing.allocator;
 
-    // <ESC>_Gi=31,s=1,v=1,a=q,t=d,f=24;AAAA<ESC>\
     var cmd: command.Command = .{
         .control = .{ .transmit = .{
             .format = .rgb,
+            .medium = .direct,
+            .compression = .none,
             .width = 1,
             .height = 1,
             .image_id = 31,
@@ -526,6 +497,8 @@ test "image load with image too wide" {
     var cmd: command.Command = .{
         .control = .{ .transmit = .{
             .format = .rgb,
+            .medium = .direct,
+            .compression = .none,
             .width = max_dimension + 1,
             .height = 1,
             .image_id = 31,
@@ -545,6 +518,8 @@ test "image load with image too tall" {
     var cmd: command.Command = .{
         .control = .{ .transmit = .{
             .format = .rgb,
+            .medium = .direct,
+            .compression = .none,
             .height = max_dimension + 1,
             .width = 1,
             .image_id = 31,
