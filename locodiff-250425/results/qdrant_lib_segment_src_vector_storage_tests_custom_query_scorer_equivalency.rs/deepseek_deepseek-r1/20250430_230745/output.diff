--- qdrant_lib_segment_src_vector_storage_tests_custom_query_scorer_equivalency.rs_expectedoutput.txt (expected)+++ qdrant_lib_segment_src_vector_storage_tests_custom_query_scorer_equivalency.rs_extracted.txt (actual)@@ -27,7 +27,7 @@ use crate::vector_storage::quantized::quantized_vectors::QuantizedVectors;
 use crate::vector_storage::tests::utils::score;
 use crate::vector_storage::vector_storage_base::VectorStorage;
-use crate::vector_storage::{VectorStorageEnum, new_raw_scorer_for_test};
+use crate::vector_storage::{new_raw_scorer_for_test, VectorStorageEnum};
 
 const DIMS: usize = 128;
 const NUM_POINTS: usize = 600;
@@ -39,9 +39,7 @@ type Error = Box<dyn error::Error>;
 
 type Sampler<'a> = Box<dyn Iterator<Item = VectorElementType> + 'a>;
-
 type SamplerGenerator = Box<dyn for<'a> Fn(&'a mut StdRng) -> Sampler<'a>>;
-
 type WithQuantization = (QuantizationConfig, SamplerGenerator);
 
 fn random_query<R: Rng + ?Sized>(
@@ -212,18 +210,12 @@         let raw_scores = score(&*raw_scorer, &points);
         let other_scores = score(&*other_scorer, &points);
 
-        // Compare scores
         if quantized_vectors.is_none() {
-            // both calculations are done on raw vectors, so score should be exactly the same
             assert_eq!(
                 raw_scores, other_scores,
                 "Scorer results are not equal, attempt: {i}, query: {query:?}"
             );
         } else {
-            // Quantization is used for the other storage, so score should be similar
-            // but not necessarily the exact same. Recommend query has a step function,
-            // so small differences in similarities can lead to very different scores
-
             let top = SAMPLE_SIZE / 10;
 
             let raw_top: HashSet<_> = raw_scores
@@ -244,7 +236,7 @@             let intersection = raw_top.intersection(&other_top).count();
 
             assert!(
-                (intersection as f32 / top as f32) >= 0.7, // at least 70% of top 10% results should be shared
+                (intersection as f32 / top as f32) >= 0.7,
                 "Top results from scorers are not similar, attempt {i}:
                 top raw: {raw_top:?},
                 top other: {other_top:?}
