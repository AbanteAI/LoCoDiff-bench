--- qdrant_lib_segment_src_vector_storage_tests_custom_query_scorer_equivalency.rs_expectedoutput.txt (expected)+++ qdrant_lib_segment_src_vector_storage_tests_custom_query_scorer_equivalency.rs_extracted.txt (actual)@@ -21,7 +21,6 @@     BinaryQuantizationConfig, Distance, ProductQuantizationConfig, QuantizationConfig,
     ScalarQuantizationConfig,
 };
-#[cfg(target_os = "linux")]
 use crate::vector_storage::dense::memmap_dense_vector_storage::open_memmap_vector_storage_with_async_io;
 use crate::vector_storage::dense::simple_dense_vector_storage::open_simple_dense_vector_storage;
 use crate::vector_storage::quantized::quantized_vectors::QuantizedVectors;
@@ -39,9 +38,7 @@ type Error = Box<dyn error::Error>;
 
 type Sampler<'a> = Box<dyn Iterator<Item = VectorElementType> + 'a>;
-
 type SamplerGenerator = Box<dyn for<'a> Fn(&'a mut StdRng) -> Sampler<'a>>;
-
 type WithQuantization = (QuantizationConfig, SamplerGenerator);
 
 fn random_query<R: Rng + ?Sized>(
@@ -63,11 +60,6 @@         &AtomicBool::new(false),
     )
     .unwrap()
-}
-
-#[cfg(target_os = "linux")]
-fn async_memmap_storage(dir: &std::path::Path) -> VectorStorageEnum {
-    open_memmap_vector_storage_with_async_io(dir, DIMS, DISTANCE, true).unwrap()
 }
 
 fn scalar_u8() -> WithQuantization {
@@ -177,6 +169,7 @@     } else {
         None
     };
+    let quantized_vectors = quantized_vectors.as_ref().map(|q| q.borrow());
 
     let attempts = 50;
     for i in 0..attempts {
@@ -212,18 +205,12 @@         let raw_scores = score(&*raw_scorer, &points);
         let other_scores = score(&*other_scorer, &points);
 
-        // Compare scores
         if quantized_vectors.is_none() {
-            // both calculations are done on raw vectors, so score should be exactly the same
             assert_eq!(
                 raw_scores, other_scores,
                 "Scorer results are not equal, attempt: {i}, query: {query:?}"
             );
         } else {
-            // Quantization is used for the other storage, so score should be similar
-            // but not necessarily the exact same. Recommend query has a step function,
-            // so small differences in similarities can lead to very different scores
-
             let top = SAMPLE_SIZE / 10;
 
             let raw_top: HashSet<_> = raw_scores
@@ -244,7 +231,7 @@             let intersection = raw_top.intersection(&other_top).count();
 
             assert!(
-                (intersection as f32 / top as f32) >= 0.7, // at least 70% of top 10% results should be shared
+                (intersection as f32 / top as f32) >= 0.7,
                 "Top results from scorers are not similar, attempt {i}:
                 top raw: {raw_top:?},
                 top other: {other_top:?}
@@ -272,7 +259,6 @@     scoring_equivalency(query_variant, other_storage, quantization_config)
 }
 
-#[cfg(target_os = "linux")]
 #[rstest]
 fn async_compare_scoring_equivalency(
     #[values(
