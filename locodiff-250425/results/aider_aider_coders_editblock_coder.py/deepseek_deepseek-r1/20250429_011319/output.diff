--- aider_aider_coders_editblock_coder.py_expectedoutput.txt (expected)+++ aider_aider_coders_editblock_coder.py_extracted.txt (actual)@@ -4,8 +4,6 @@ import sys
 from difflib import SequenceMatcher
 from pathlib import Path
-
-from aider import utils
 
 from ..dump import dump  # noqa: F401
 from .base_coder import Coder
@@ -105,11 +103,6 @@ 
 """
 
-            if updated in content and updated:
-                res += f"""Are you sure you need this SEARCH/REPLACE block?
-The REPLACE lines are already in {path}!
-
-"""
         res += (
             "The SEARCH section must exactly match an existing block of lines including all white"
             " space, comments, indentation, docstrings, etc\n"
@@ -180,7 +173,6 @@     except ValueError:
         pass
 
-    return
     # Try fuzzy matching
     res = replace_closest_edit_distance(whole_lines, part, part_lines, replace_lines)
     if res:
@@ -300,6 +292,9 @@     most_similar_chunk_start = -1
     most_similar_chunk_end = -1
 
+    whole_lines = [line.rstrip("\n") for line in whole_lines]
+    part_lines = [line.rstrip("\n") for line in part_lines]
+
     scale = 0.1
     min_len = math.floor(len(part_lines) * (1 - scale))
     max_len = math.ceil(len(part_lines) * (1 + scale))
@@ -307,7 +302,7 @@     for length in range(min_len, max_len):
         for i in range(len(whole_lines) - length + 1):
             chunk = whole_lines[i : i + length]
-            chunk = "".join(chunk)
+            chunk = "\n".join(chunk)
 
             similarity = SequenceMatcher(None, chunk, part).ratio()
 
@@ -319,17 +314,17 @@     if max_similarity < similarity_thresh:
         return
 
+    replace_lines = [line.rstrip("\n") for line in replace_lines]
+
     modified_whole = (
-        whole_lines[:most_similar_chunk_start]
-        + replace_lines
-        + whole_lines[most_similar_chunk_end:]
+        whole_lines[:most_similar_chunk_start] + replace_lines + whole_lines[most_similar_chunk_end:]
     )
-    modified_whole = "".join(modified_whole)
+    modified_whole = "\n".join(modified_whole) + "\n"
 
     return modified_whole
 
 
-DEFAULT_FENCE = ("`" * 3, "`" * 3)
+DEFAULT_FENCE = ("```", "```")
 
 
 def strip_quoted_wrapping(res, fname=None, fence=DEFAULT_FENCE):
@@ -346,15 +341,12 @@     if not res:
         return res
 
-    res = res.splitlines()
-
-    if fname and res[0].strip().endswith(Path(fname).name):
-        res = res[1:]
-
-    if res[0].startswith(fence[0]) and res[-1].startswith(fence[1]):
-        res = res[1:-1]
-
-    res = "\n".join(res)
+    if fname and Path(fname).name in res.split("\n", 1)[0]:
+        res = res.split("\n", 1)[1]
+
+    if res.startswith(fence[0]) and res.endswith(fence[1] + "\n"):
+        res = res[len(fence[0]) : -len(fence[1]) - 1]
+
     if res and res[-1] != "\n":
         res += "\n"
 
@@ -379,6 +371,8 @@         new_content = content + after_text
     else:
         new_content = replace_most_similar_chunk(content, before_text, after_text)
+        if not new_content:
+            return
 
     return new_content
 
@@ -427,11 +421,6 @@     filename = filename.rstrip(":")
     filename = filename.lstrip("#")
     filename = filename.strip()
-    filename = filename.strip("`")
-    filename = filename.strip("*")
-
-    # https://github.com/Aider-AI/aider/issues/1158
-    # filename = filename.replace("\\_", "_")
 
     return filename
 
@@ -448,7 +437,7 @@     while i < len(lines):
         line = lines[i]
 
-        # Check for shell code blocks
+        # Check for various shell code blocks
         shell_starts = [
             "```bash",
             "```sh",
@@ -549,7 +538,6 @@ 
     This is a more flexible search back for filenames.
     """
-
     if valid_fnames is None:
         valid_fnames = []
 
@@ -571,8 +559,6 @@     if not filenames:
         return
 
-    # pick the *best* filename found
-
     # Check for exact match first
     for fname in filenames:
         if fname in valid_fnames:
@@ -605,6 +591,7 @@ 
     best_ratio = 0
     best_match = None
+    best_match_i = -1
 
     for i in range(len(content_lines) - len(search_lines) + 1):
         chunk = content_lines[i : i + len(search_lines)]
