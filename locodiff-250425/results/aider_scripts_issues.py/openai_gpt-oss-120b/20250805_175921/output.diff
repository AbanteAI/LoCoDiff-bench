
index 1f6f3a94e..5d9b9a333 100644
--- a/aider_scripts_issues.py_expectedoutput.txt (expected):tmp/tmp3h6nuwa2_expected.txt	
+++ b/aider_scripts_issues.py_extracted.txt (actual):tmp/tmphyvlmw91_actual.txt	
@@ -1,87 +1,87 @@
 #!/usr/bin/env python3
 
-import argparse
 import os
 import re
+import argparse
 from collections import defaultdict
 from datetime import datetime
-
 import requests
 from dotenv import load_dotenv
 from tqdm import tqdm
 
-
-def has_been_reopened(issue_number):
-    timeline_url = f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue_number}/timeline"
-    response = requests.get(timeline_url, headers=headers)
-    response.raise_for_status()
-    events = response.json()
-    return any(event["event"] == "reopened" for event in events if "event" in event)
-
-
 # Load environment variables from .env file
 load_dotenv()
 
-BOT_SUFFIX = """
-
+BOT_SUFFIX = """ 
 Note: [A bot script](https://github.com/Aider-AI/aider/blob/aider_scripts_issues.py_extracted.txt (actual)://api.github.com"
 REPO_OWNER = "Aider-AI"
 REPO_NAME = "aider"
 TOKEN = os.getenv("GITHUB_TOKEN")
-
 headers = {"Authorization": f"token {TOKEN}", "Accept": "application/vnd.github.v3+json"}
 
 
+def has_been_reopened(issue_number):
+    timeline_url = f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue_number}/timeline"
+    response = requests.get(timeline_url, headers=headers)
+    response.raise_for_status()
+    events = response.json()
+    return any(event["event"] == "reopened" for event in events if "event" in event)
+
+
 def get_issues(state="open"):
     issues = []
     page = 1
     per_page = 100
 
-    # First, get the total count of issues
+    # Determine total number of pages
     response = requests.get(
         f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues",
         headers=headers,
         params={"state": state, "per_page": 1},
     )
     response.raise_for_status()
-    total_count = int(response.headers.get("Link", "").split("page=")[-1].split(">")[0])
+    total_count = int(
+        response.headers.get("Link", "").split("page=")[-1].split(">")[0]
+    )
     total_pages = (total_count + per_page - 1) // per_page
 
     with tqdm(total=total_pages, desc="Collecting issues", unit="page") as pbar:
@@ -105,7 +105,9 @@ def group_issues_by_subject(issues):
     grouped_issues = defaultdict(list)
     pattern = r"Uncaught .+ in .+ line \d+"
     for issue in issues:
-        if re.search(pattern, issue["title"]) and not has_been_reopened(issue["number"]):
+        if re.search(pattern, issue["title"]) and not has_been_reopened(
+            issue["number"]
+        ):
             subject = issue["title"]
             grouped_issues[subject].append(issue)
     return grouped_issues
@@ -114,14 +116,17 @@ def group_issues_by_subject(issues):
 def find_oldest_issue(subject, all_issues):
     oldest_issue = None
     oldest_date = datetime.now()
-
     for issue in all_issues:
-        if issue["title"] == subject and not has_been_reopened(issue["number"]):
-            created_at = datetime.strptime(issue["created_at"], "%Y-%m-%dT%H:%M:%SZ")
+        if (
+            issue["title"] == subject
+            and not has_been_reopened(issue["number"])
+        ):
+            created_at = datetime.strptime(
+                issue["created_at"], "%Y-%m-%dT%H:%M:%SZ"
+            )
             if created_at < oldest_date:
                 oldest_date = created_at
                 oldest_issue = issue
-
     return oldest_issue
 
 
@@ -132,69 +137,76 @@ def comment_and_close_duplicate(issue, oldest_issue):
         return
 
     comment_url = (
-        f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue['number']}/comments"
+        f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}"
+        f"/issues/{issue['number']}/comments"
     )
     close_url = f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue['number']}"
 
-    comment_body = DUPLICATE_COMMENT.format(oldest_issue_number=oldest_issue["number"])
+    comment_body = DUPLICATE_COMMENT.format(
+        oldest_issue_number=oldest_issue["number"]
+    )
 
     # Post comment
-    response = requests.post(comment_url, headers=headers, json={"body": comment_body})
+    response = requests.post(
+        comment_url, headers=headers, json={"body": comment_body}
+    )
     response.raise_for_status()
 
     # Close issue
-    response = requests.patch(close_url, headers=headers, json={"state": "closed"})
+    response = requests.patch(
+        close_url, headers=headers, json={"state": "closed"}
+    )
     response.raise_for_status()
 
     print(f"  - Commented and closed issue #{issue['number']}")
 
 
 def find_unlabeled_with_paul_comments(issues):
-    unlabeled_issues = []
+    unlabeled = []
     for issue in issues:
         # Skip pull requests
         if "pull_request" in issue:
             continue
-
         if not issue["labels"] and issue["state"] == "open":
-            # Get comments for this issue
             comments_url = (
-                f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue['number']}/comments"
+                f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}"
+                f"/issues/{issue['number']}/comments"
             )
             response = requests.get(comments_url, headers=headers)
             response.raise_for_status()
             comments = response.json()
-
-            # Check if paul-gauthier has commented
-            if any(comment["user"]["login"] == "paul-gauthier" for comment in comments):
-                unlabeled_issues.append(issue)
-    return unlabeled_issues
+            if any(
+                comment["user"]["login"] == "paul-gauthier"
+                for comment in comments
+            ):
+                unlabeled.append(issue)
+    return unlabeled
 
 
 def handle_unlabeled_issues(all_issues, auto_yes):
     print("\nFinding unlabeled issues with paul-gauthier comments...")
-    unlabeled_issues = [
+    unlabeled = [
         issue
         for issue in find_unlabeled_with_paul_comments(all_issues)
         if "priority" not in [label["name"] for label in issue["labels"]]
     ]
 
-    if not unlabeled_issues:
+    if not unlabeled:
         print("No unlabeled issues with paul-gauthier comments found.")
         return
 
-    print(f"\nFound {len(unlabeled_issues)} unlabeled issues with paul-gauthier comments:")
-    for issue in unlabeled_issues:
+    print(f"\nFound {len(unlabeled)} unlabeled issues with paul-gauthier comments:")
+    for issue in unlabeled:
         print(f"  - #{issue['number']}: {issue['title']} {issue['html_url']}")
 
     if not auto_yes:
-        confirm = input("\nDo you want to add the 'question' label to these issues? (y/n): ")
-        if confirm.lower() != "y":
+        conf = input("\nAdd 'question' label to these issues? (y/n): ")
+        if conf.lower() != "y":
             print("Skipping labeling.")
             return
 
     print("\nAdding 'question' label to issues...")
-    for issue in unlabeled_issues:
+    for issue in unlabeled:
         url = f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue['number']}"
         response = requests.patch(url, headers=headers, json={"labels": ["question"]})
         response.raise_for_status()
@@ -203,9 +215,7 @@ def handle_unlabeled_issues(all_issues, auto_yes):
 
 def handle_stale_issues(all_issues, auto_yes):
     print("\nChecking for stale question issues...")
-
     for issue in all_issues:
-        # Skip if not open, not a question, already stale, or has been reopened
         labels = [label["name"] for label in issue["labels"]]
         if (
             issue["state"] != "open"
@@ -216,117 +226,115 @@ def handle_stale_issues(all_issues, auto_yes):
         ):
             continue
 
-        # Get latest activity timestamp from issue or its comments
         latest_activity = datetime.strptime(issue["updated_at"], "%Y-%m-%dT%H:%M:%SZ")
-
-        # Check if issue is stale (no activity for 14 days)
         days_inactive = (datetime.now() - latest_activity).days
         if days_inactive >= 14:
-            print(f"\nStale issue found: #{issue['number']}: {issue['title']}\n{issue['html_url']}")
+            print(f"\nStale issue found: #{issue['number']}: {issue['title']}")
             print(f"  No activity for {days_inactive} days")
-
             if not auto_yes:
                 confirm = input("Add stale label and comment? (y/n): ")
                 if confirm.lower() != "y":
-                    print("Skipping this issue.")
+                    print("Skipping.")
                     continue
-
             # Add comment
             comment_url = (
-                f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue['number']}/comments"
+                f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}"
+                f"/issues/{issue['number']}/comments"
+            )
+            response = requests.post(
+                comment_url, headers=headers, json={"body": STALE_COMMENT}
             )
-            response = requests.post(comment_url, headers=headers, json={"body": STALE_COMMENT})
             response.raise_for_status()
-
             # Add stale label
             url = f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue['number']}"
-            response = requests.patch(url, headers=headers, json={"labels": ["question", "stale"]})
+            response = requests.patch(
+                url, headers=headers, json={"labels": ["question", "stale"]}
+            )
             response.raise_for_status()
-
             print(f"  Added stale label and comment to #{issue['number']}")
 
 
 def handle_stale_closing(all_issues, auto_yes):
-    print("\nChecking for issues to close or unstale...")
-
+    print("\nChecking for issues to close or un-stale...")
     for issue in all_issues:
-        # Skip if not open, not stale, or is priority
         labels = [label["name"] for label in issue["labels"]]
         if issue["state"] != "open" or "stale" not in labels or "priority" in labels:
             continue
 
-        # Get the timeline to find when the stale label was last added
+            # Get timeline to find latest stale label
         timeline_url = (
-            f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue['number']}/timeline"
+            f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}"
+            f"/issues/{issue['number']}/timeline"
         )
         response = requests.get(timeline_url, headers=headers)
         response.raise_for_status()
         events = response.json()
-
-        # Find the most recent stale label addition
         stale_events = [
-            event
-            for event in events
-            if event.get("event") == "labeled" and event.get("label", {}).get("name") == "stale"
+            e
+            for e in events
+            if e.get("event") == "labeled"
+            and e.get("label", {}).get("name") == "stale"
         ]
-
         if not stale_events:
             continue
-
-        latest_stale = datetime.strptime(stale_events[-1]["created_at"], "%Y-%m-%dT%H:%M:%SZ")
-
-        # Get comments since the stale label
+        latest_stale = datetime.strptime(
+            stale_events[-1]["created_at"], "%Y-%m-%dT%H:%M:%SZ"
+        )
+        # Check for comments after stale label
         comments_url = (
-            f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue['number']}/comments"
+            f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}"
+            f"/issues/{issue['number']}/comments"
         )
         response = requests.get(comments_url, headers=headers)
         response.raise_for_status()
         comments = response.json()
-
-        # Check for comments newer than the stale label
         new_comments = [
-            comment
-            for comment in comments
-            if datetime.strptime(comment["created_at"], "%Y-%m-%dT%H:%M:%SZ") > latest_stale
+            c
+            for c in comments
+            if datetime.strptime(c["created_at"], "%Y-%m-%dT%H:%M:%SZ") > latest_stale
         ]
-
         if new_comments:
-            print(f"\nFound new activity on stale issue #{issue['number']}: {issue['title']}")
-            print(f"  {len(new_comments)} new comments since stale label")
-
+            print(f"\nNew activity on stale issue #{issue['number']}: {issue['title']}")
+            print(f"  {len(new_comments)} new comments since stale")
             if not auto_yes:
-                confirm = input("Remove stale label? (y/n): ")
-                if confirm.lower() != "y":
-                    print("Skipping this issue.")
+                conf = input("Remove stale label? (y/n): ")
+                if conf.lower() != "y":
+                    print("Skipping.")
                     continue
-
-            # Remove stale label but keep question label
-            url = f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue['number']}"
-            response = requests.patch(url, headers=headers, json={"labels": ["question"]})
+            # Remove stale label but keep question
+            url = (
+                f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}"
+                f"/issues/{issue['number']}"
+            )
+            response = requests.patch(
+                url, headers=headers, json={"labels": ["question"]}
+            )
             response.raise_for_status()
             print(f"  Removed stale label from #{issue['number']}")
         else:
-            # Check if it's been 7 days since stale label
             days_stale = (datetime.now() - latest_stale).days
             if days_stale >= 7:
-                print(f"\nStale issue ready for closing #{issue['number']}: {issue['title']}")
-                print(f"  No activity for {days_stale} days since stale label")
-
+                print(f"\nStale issue ready to close #{issue['number']}: {issue['title']}")
                 if not auto_yes:
-                    confirm = input("Close this issue? (y/n): ")
-                    if confirm.lower() != "y":
-                        print("Skipping this issue.")
+                    conf = input("Close issue? (y/n): ")
+                    if conf.lower() != "y":
+                        print("Skipping.")
                         continue
-
                 # Add closing comment
-                comment_url = f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue['number']}/comments"  # noqa
+                comment_url = (
+                    f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}"
+                    f"/issues/{issue['number']}/comments"
+                )
                 response = requests.post(
-                    comment_url, headers=headers, json={"body": CLOSE_STALE_COMMENT}
+                    comment_url,
+                    headers=headers,
+                    json={"body": CLOSE_STALE_COMMENT},
                 )
                 response.raise_for_status()
-
-                # Close the issue
-                url = f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue['number']}"
+                # Close issue
+                url = (
+                    f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue['number']}"
+                )
                 response = requests.patch(url, headers=headers, json={"state": "closed"})
                 response.raise_for_status()
                 print(f"  Closed issue #{issue['number']}")
@@ -334,59 +342,67 @@ def handle_stale_closing(all_issues, auto_yes):
 
 def handle_fixed_issues(all_issues, auto_yes):
     print("\nChecking for fixed enhancement and bug issues to close...")
-
     for issue in all_issues:
-        # Skip if not open, doesn't have fixed label, or is priority
         labels = [label["name"] for label in issue["labels"]]
-        if issue["state"] != "open" or "fixed" not in labels or "priority" in labels:
+        if (
+            issue["state"] != "open"
+            or "fixed" not in labels
+            or "priority" in labels
+        ):
             continue
 
-        # Check if it's an enhancement or bug
+            # Determine issue type
         is_enhancement = "enhancement" in labels
         is_bug = "bug" in labels
         if not (is_enhancement or is_bug):
             continue
 
-        # Find when the fixed label was added
+        # Get timeline for fixed label
         timeline_url = (
-            f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue['number']}/timeline"
+            f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}"
+            f"/issues/{issue['number']}/timeline"
         )
         response = requests.get(timeline_url, headers=headers)
         response.raise_for_status()
         events = response.json()
-
-        # Find the most recent fixed label addition
         fixed_events = [
-            event
-            for event in events
-            if event.get("event") == "labeled" and event.get("label", {}).get("name") == "fixed"
+            e
+            for e in events
+            if e.get("event") == "labeled"
+            and e.get("label", {}).get("name") == "fixed"
         ]
-
         if not fixed_events:
             continue
-
-        latest_fixed = datetime.strptime(fixed_events[-1]["created_at"], "%Y-%m-%dT%H:%M:%SZ")
+        latest_fixed = datetime.strptime(
+            fixed_events[-1]["created_at"], "%Y-%m-%dT%H:%M:%SZ"
+        )
         days_fixed = (datetime.now() - latest_fixed).days
 
         if days_fixed >= 21:
             issue_type = "enhancement" if is_enhancement else "bug"
-            print(f"\nFixed {issue_type} ready for closing #{issue['number']}: {issue['title']}")
-            print(f"  Has been marked fixed for {days_fixed} days")
-
+            print(
+                f"\nFixed {issue_type} ready for closing #{issue['number']}: {issue['title']}"
+            )
+            print(f"  Marked fixed for {days_fixed} days")
             if not auto_yes:
-                confirm = input("Close this issue? (y/n): ")
-                if confirm.lower() != "y":
-                    print("Skipping this issue.")
+                conf = input("Close this issue? (y/n): ")
+                if conf.lower() != "y":
+                    print("Skipping.")
                     continue
-
+            comment = (
+                CLOSE_FIXED_ENHANCEMENT_COMMENT
+                if is_enhancement
+                else CLOSE_FIXED_BUG_COMMENT
+            )
             # Add closing comment
             comment_url = (
-                f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue['number']}/comments"
+                f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}"
+                f"/issues/{issue['number']}/comments"
+            )
+            response = requests.post(
+                comment_url, headers=headers, json={"body": comment}
             )
-            comment = CLOSE_FIXED_ENHANCEMENT_COMMENT if is_enhancement else CLOSE_FIXED_BUG_COMMENT
-            response = requests.post(comment_url, headers=headers, json={"body": comment})
             response.raise_for_status()
-
             # Close the issue
             url = f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue['number']}"
             response = requests.patch(url, headers=headers, json={"state": "closed"})
@@ -395,58 +411,54 @@ def handle_fixed_issues(all_issues, auto_yes):
 
 
 def handle_duplicate_issues(all_issues, auto_yes):
-    open_issues = [issue for issue in all_issues if issue["state"] == "open"]
-    grouped_open_issues = group_issues_by_subject(open_issues)
+    open_issues = [i for i in all_issues if i["state"] == "open"]
+    grouped = group_issues_by_subject(open_issues)
 
     print("Looking for duplicate issues (skipping reopened issues)...")
-    for subject, issues in grouped_open_issues.items():
-        oldest_issue = find_oldest_issue(subject, all_issues)
-        if not oldest_issue:
-            continue
-
-        related_issues = set(issue["number"] for issue in issues)
-        related_issues.add(oldest_issue["number"])
-        if len(related_issues) <= 1:
+    for subject, issues for grouped.items():
+        oldest = find_oldest_issue(subject, all_issues)
+        if not oldest:
             continue
 
         print(f"\nIssue: {subject}")
         print(f"Open issues: {len(issues)}")
-        sorted_issues = sorted(issues, key=lambda x: x["number"], reverse=True)
-        for issue in sorted_issues:
-            print(f"  - #{issue['number']}: {issue['comments']} comments {issue['html_url']}")
+        for issue in sorted(issues, key=lambda x: x["number"], reverse=True):
+            print(f"  - #{issue['number']}: {issue['html_url']} ({issue['comments']} comments)")
 
-        print(
-            f"Oldest issue: #{oldest_issue['number']}: {oldest_issue['comments']} comments"
-            f" {oldest_issue['html_url']} ({oldest_issue['state']})"
-        )
+        print(f"Oldest issue: #{oldest['number']}: {oldest['html_url']} ({oldest['state']})")
 
         if not auto_yes:
-            confirm = input("Do you want to comment and close duplicate issues? (y/n): ")
-            if confirm.lower() != "y":
-                print("Skipping this group of issues.")
+            conf = input(
+                "Do you want to comment and close duplicate issues? (y/n): "
+            )
+            if conf.lower() != "y":
+                print("Skipping this group.")
                 continue
 
         for issue in issues:
-            if issue["number"] != oldest_issue["number"]:
-                comment_and_close_duplicate(issue, oldest_issue)
+            if issue["number"] != oldest["number"]:
+                comment_and_close_duplicate(issue, oldest)
 
-        if oldest_issue["state"] == "open":
-            print(f"Oldest issue #{oldest_issue['number']} left open")
+        if oldest["state"] == "open":
+            print(f"Oldest issue #{oldest['number']} left open")
 
 
 def main():
-    parser = argparse.ArgumentParser(description="Handle duplicate GitHub issues")
+    parser = argparse.ArgumentParser(
+        description="Handle duplicate GitHub issues"
+    )
     parser.add_argument(
         "--yes", action="store_true", help="Automatically close duplicates without prompting"
     )
     args = parser.parse_args()
 
     if not TOKEN:
-        print("Error: Missing GITHUB_TOKEN environment variable. Please check your .env file.")
+        print(
+            "Error: Missing GITHUB_TOKEN environment variable. Please check your .env file."
+        )
         return
 
     all_issues = get_issues("all")
-
     handle_unlabeled_issues(all_issues, args.yes)
     handle_stale_issues(all_issues, args.yes)
     handle_stale_closing(all_issues, args.yes)
