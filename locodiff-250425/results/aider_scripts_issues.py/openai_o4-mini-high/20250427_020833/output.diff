
index 1f6f3a94..bd066aed 100644
--- a/aider_scripts_issues.py_expectedoutput.txt (expected):tmp/tmpea1erlm8_expected.txt	
+++ b/aider_scripts_issues.py_extracted.txt (actual):tmp/tmpnb15g1zn_actual.txt	
@@ -10,20 +10,10 @@ import requests
 from dotenv import load_dotenv
 from tqdm import tqdm
 
-
-def has_been_reopened(issue_number):
-    timeline_url = f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue_number}/timeline"
-    response = requests.get(timeline_url, headers=headers)
-    response.raise_for_status()
-    events = response.json()
-    return any(event["event"] == "reopened" for event in events if "event" in event)
-
-
 # Load environment variables from .env file
 load_dotenv()
 
 BOT_SUFFIX = """
-
 Note: [A bot script](https://github.com/Aider-AI/aider/blob/aider_scripts_issues.py_extracted.txt (actual):
     return issues
 
 
+def has_been_reopened(issue_number):
+    timeline_url = f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue_number}/timeline"
+    response = requests.get(timeline_url, headers=headers)
+    response.raise_for_status()
+    events = response.json()
+    return any(event["event"] == "reopened" for event in events if "event" in event)
+
+
 def group_issues_by_subject(issues):
     grouped_issues = defaultdict(list)
     pattern = r"Uncaught .+ in .+ line \d+"
@@ -130,10 +128,7 @@ def comment_and_close_duplicate(issue, oldest_issue):
     if "priority" in [label["name"] for label in issue["labels"]]:
         print(f"  - Skipping priority issue #{issue['number']}")
         return
-
-    comment_url = (
-        f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue['number']}/comments"
-    )
+    comment_url = f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue['number']}/comments"
     close_url = f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue['number']}"
 
     comment_body = DUPLICATE_COMMENT.format(oldest_issue_number=oldest_issue["number"])
@@ -157,10 +152,7 @@ def find_unlabeled_with_paul_comments(issues):
             continue
 
         if not issue["labels"] and issue["state"] == "open":
-            # Get comments for this issue
-            comments_url = (
-                f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue['number']}/comments"
-            )
+            comments_url = f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue['number']}/comments"
             response = requests.get(comments_url, headers=headers)
             response.raise_for_status()
             comments = response.json()
@@ -203,7 +195,6 @@ def handle_unlabeled_issues(all_issues, auto_yes):
 
 def handle_stale_issues(all_issues, auto_yes):
     print("\nChecking for stale question issues...")
-
     for issue in all_issues:
         # Skip if not open, not a question, already stale, or has been reopened
         labels = [label["name"] for label in issue["labels"]]
@@ -232,9 +223,7 @@ def handle_stale_issues(all_issues, auto_yes):
                     continue
 
             # Add comment
-            comment_url = (
-                f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue['number']}/comments"
-            )
+            comment_url = f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue['number']}/comments"
             response = requests.post(comment_url, headers=headers, json={"body": STALE_COMMENT})
             response.raise_for_status()
 
@@ -248,7 +237,6 @@ def handle_stale_issues(all_issues, auto_yes):
 
 def handle_stale_closing(all_issues, auto_yes):
     print("\nChecking for issues to close or unstale...")
-
     for issue in all_issues:
         # Skip if not open, not stale, or is priority
         labels = [label["name"] for label in issue["labels"]]
@@ -256,9 +244,7 @@ def handle_stale_closing(all_issues, auto_yes):
             continue
 
         # Get the timeline to find when the stale label was last added
-        timeline_url = (
-            f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue['number']}/timeline"
-        )
+        timeline_url = f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue['number']}/timeline"
         response = requests.get(timeline_url, headers=headers)
         response.raise_for_status()
         events = response.json()
@@ -276,9 +262,7 @@ def handle_stale_closing(all_issues, auto_yes):
         latest_stale = datetime.strptime(stale_events[-1]["created_at"], "%Y-%m-%dT%H:%M:%SZ")
 
         # Get comments since the stale label
-        comments_url = (
-            f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue['number']}/comments"
-        )
+        comments_url = f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue['number']}/comments"
         response = requests.get(comments_url, headers=headers)
         response.raise_for_status()
         comments = response.json()
@@ -319,7 +303,7 @@ def handle_stale_closing(all_issues, auto_yes):
                         continue
 
                 # Add closing comment
-                comment_url = f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue['number']}/comments"  # noqa
+                comment_url = f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue['number']}/comments"
                 response = requests.post(
                     comment_url, headers=headers, json={"body": CLOSE_STALE_COMMENT}
                 )
@@ -334,7 +318,6 @@ def handle_stale_closing(all_issues, auto_yes):
 
 def handle_fixed_issues(all_issues, auto_yes):
     print("\nChecking for fixed enhancement and bug issues to close...")
-
     for issue in all_issues:
         # Skip if not open, doesn't have fixed label, or is priority
         labels = [label["name"] for label in issue["labels"]]
@@ -348,9 +331,7 @@ def handle_fixed_issues(all_issues, auto_yes):
             continue
 
         # Find when the fixed label was added
-        timeline_url = (
-            f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue['number']}/timeline"
-        )
+        timeline_url = f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue['number']}/timeline"
         response = requests.get(timeline_url, headers=headers)
         response.raise_for_status()
         events = response.json()
@@ -380,9 +361,7 @@ def handle_fixed_issues(all_issues, auto_yes):
                     continue
 
             # Add closing comment
-            comment_url = (
-                f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue['number']}/comments"
-            )
+            comment_url = f"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue['number']}/comments"
             comment = CLOSE_FIXED_ENHANCEMENT_COMMENT if is_enhancement else CLOSE_FIXED_BUG_COMMENT
             response = requests.post(comment_url, headers=headers, json={"body": comment})
             response.raise_for_status()
@@ -417,7 +396,7 @@ def handle_duplicate_issues(all_issues, auto_yes):
 
         print(
             f"Oldest issue: #{oldest_issue['number']}: {oldest_issue['comments']} comments"
-            f" {oldest_issue['html_url']} ({oldest_issue['state']})"
+            f" {oldest_issue['html_url']} (created on {oldest_issue['created_at']})"
         )
 
         if not auto_yes:
@@ -426,6 +405,7 @@ def handle_duplicate_issues(all_issues, auto_yes):
                 print("Skipping this group of issues.")
                 continue
 
+        # Comment and close duplicate issues
         for issue in issues:
             if issue["number"] != oldest_issue["number"]:
                 comment_and_close_duplicate(issue, oldest_issue)
@@ -450,8 +430,8 @@ def main():
     handle_unlabeled_issues(all_issues, args.yes)
     handle_stale_issues(all_issues, args.yes)
     handle_stale_closing(all_issues, args.yes)
-    handle_duplicate_issues(all_issues, args.yes)
     handle_fixed_issues(all_issues, args.yes)
+    handle_duplicate_issues(all_issues, args.yes)
 
 
 if __name__ == "__main__":
