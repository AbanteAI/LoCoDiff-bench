
index 80b840774..681c59308 100644
--- a/aider_tests_basic_test_reasoning.py_expectedoutput.txt (expected):tmp/tmpyze7fvmz_expected.txt	
+++ b/aider_tests_basic_test_reasoning.py_extracted.txt (actual):tmp/tmplp1n7qng_actual.txt	
@@ -138,10 +138,7 @@ class TestReasoning(unittest.TestCase):
         mock_hash.hexdigest.return_value = "mock_hash_digest"
 
         # Mock the model's send_completion to return the hash and completion
-        with (
-            patch.object(model, "send_completion", return_value=(mock_hash, chunks)),
-            patch.object(model, "token_count", return_value=10),
-        ):  # Mock token count to avoid serialization issues
+        with patch.object(model, "send_completion", return_value=(mock_hash, chunks)):
             # Set mdstream directly on the coder object
             coder.mdstream = mock_mdstream
 
@@ -183,7 +180,6 @@ class TestReasoning(unittest.TestCase):
             )
 
             # Verify that partial_response_content only contains the main content
-            coder.remove_reasoning_content()
             expected_content = "Final answer after reasoning"
             self.assertEqual(coder.partial_response_content.strip(), expected_content)
 
@@ -323,7 +319,10 @@ class TestReasoning(unittest.TestCase):
         mock_hash.hexdigest.return_value = "mock_hash_digest"
 
         # Mock the model's send_completion to return the hash and completion
-        with patch.object(model, "send_completion", return_value=(mock_hash, chunks)):
+        with (
+            patch.object(model, "send_completion", return_value=(mock_hash, chunks)),
+            patch.object(model, "token_count", return_value=10),
+        ):  # Mock token count to avoid serialization issues
             # Set mdstream directly on the coder object
             coder.mdstream = mock_mdstream
 
