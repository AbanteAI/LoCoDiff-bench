
index 80b84077..380a43c2 100644
--- a/aider_tests_basic_test_reasoning.py_expectedoutput.txt (expected):tmp/tmpzr862azp_expected.txt	
+++ b/aider_tests_basic_test_reasoning.py_extracted.txt (actual):tmp/tmp4tb6pxsi_actual.txt	
@@ -138,10 +138,7 @@ class TestReasoning(unittest.TestCase):
         mock_hash.hexdigest.return_value = "mock_hash_digest"
 
         # Mock the model's send_completion to return the hash and completion
-        with (
-            patch.object(model, "send_completion", return_value=(mock_hash, chunks)),
-            patch.object(model, "token_count", return_value=10),
-        ):  # Mock token count to avoid serialization issues
+        with patch.object(model, "send_completion", return_value=(mock_hash, chunks)):
             # Set mdstream directly on the coder object
             coder.mdstream = mock_mdstream
 
@@ -184,42 +181,37 @@ class TestReasoning(unittest.TestCase):
 
             # Verify that partial_response_content only contains the main content
             coder.remove_reasoning_content()
-            expected_content = "Final answer after reasoning"
-            self.assertEqual(coder.partial_response_content.strip(), expected_content)
+            self.assertEqual(coder.partial_response_content.strip(), "Final answer after reasoning")
 
-    def test_send_with_think_tags(self):
-        """Test that <think> tags are properly processed and formatted."""
+    def test_send_with_reasoning(self):
+        """Test that reasoning content from the 'reasoning' attribute is properly formatted
+        and output."""
         # Setup IO with no pretty
         io = InputOutput(pretty=False)
         io.assistant_output = MagicMock()
 
         # Setup model and coder
         model = Model("gpt-3.5-turbo")
-        model.reasoning_tag = "think"  # Set to remove <think> tags
         coder = Coder.create(model, None, io=io, stream=False)
 
         # Test data
         reasoning_content = "My step-by-step reasoning process"
         main_content = "Final answer after reasoning"
 
-        # Create content with think tags
-        combined_content = f"""<think>
-{reasoning_content}
-</think>
-
-{main_content}"""
-
-        # Mock completion response with think tags in content
+        # Mock completion response with reasoning content
         class MockCompletion:
-            def __init__(self, content):
+            def __init__(self, content, reasoning):
                 self.content = content
                 # Add required attributes expected by show_send_output
                 self.choices = [MagicMock()]
                 self.choices[0].message.content = content
-                self.choices[0].message.reasoning_content = None  # No separate reasoning_content
+                self.choices[0].message.reasoning = (
+                    reasoning  # Using reasoning instead of reasoning_content
+                )
+                delattr(self.choices[0].message, "reasoning_content")
                 self.finish_reason = "stop"
 
-        mock_completion = MockCompletion(combined_content)
+        mock_completion = MockCompletion(main_content, reasoning_content)
 
         # Create a mock hash object
         mock_hash = MagicMock()
@@ -245,6 +237,10 @@ class TestReasoning(unittest.TestCase):
             self.assertIn(reasoning_content, output)
             self.assertIn(main_content, output)
 
+            # Verify that partial_response_content only contains the main content
+            coder.remove_reasoning_content()
+            self.assertEqual(coder.partial_response_content.strip(), main_content.strip())
+
             # Ensure proper order: reasoning first, then main content
             reasoning_pos = output.find(reasoning_content)
             main_pos = output.find(main_content)
@@ -252,12 +248,9 @@ class TestReasoning(unittest.TestCase):
                 reasoning_pos, main_pos, "Reasoning content should appear before main content"
             )
 
-            # Verify that partial_response_content only contains the main content
-            coder.remove_reasoning_content()
-            self.assertEqual(coder.partial_response_content.strip(), main_content.strip())
-
-    def test_send_with_think_tags_stream(self):
-        """Test that streaming with <think> tags is properly processed and formatted."""
+    def test_send_with_reasoning_stream(self):
+        """Test that streaming reasoning content from the 'reasoning' attribute is properly
+        formatted and output."""
         # Setup IO with pretty output for streaming
         io = InputOutput(pretty=True)
         mock_mdstream = MagicMock()
@@ -265,7 +258,6 @@ class TestReasoning(unittest.TestCase):
 
         # Setup model and coder
         model = Model("gpt-3.5-turbo")
-        model.reasoning_tag = "think"  # Set to remove <think> tags
         coder = Coder.create(model, None, io=io, stream=True)
 
         # Ensure the coder shows pretty output
@@ -301,19 +293,18 @@ class TestReasoning(unittest.TestCase):
                     # Need to handle attribute access that would raise AttributeError
                     delattr(self.choices[0].delta, "reasoning")
 
-        # Create chunks to simulate streaming with think tags
+        # Create chunks to simulate streaming - using reasoning attribute instead of
+        # reasoning_content
         chunks = [
-            # Start with open think tag
-            MockStreamingChunk(content="<think>\n", reasoning_content=None),
-            # Reasoning content inside think tags
-            MockStreamingChunk(content="My step-by-step ", reasoning_content=None),
-            MockStreamingChunk(content="reasoning process\n", reasoning_content=None),
-            # Close think tag
-            MockStreamingChunk(content="</think>\n\n", reasoning_content=None),
-            # Main content
-            MockStreamingChunk(content="Final ", reasoning_content=None),
-            MockStreamingChunk(content="answer ", reasoning_content=None),
-            MockStreamingChunk(content="after reasoning", reasoning_content=None),
+            # First chunk with reasoning content starts the tag
+            MockStreamingChunk(reasoning="My step-by-step "),
+            # Additional reasoning content
+            MockStreamingChunk(reasoning="reasoning process"),
+            # Switch to main content - this will automatically end the reasoning tag
+            MockStreamingChunk(content="Final "),
+            # More main content
+            MockStreamingChunk(content="answer "),
+            MockStreamingChunk(content="after reasoning"),
             # End the response
             MockStreamingChunk(finish_reason="stop"),
         ]
@@ -323,7 +314,10 @@ class TestReasoning(unittest.TestCase):
         mock_hash.hexdigest.return_value = "mock_hash_digest"
 
         # Mock the model's send_completion to return the hash and completion
-        with patch.object(model, "send_completion", return_value=(mock_hash, chunks)):
+        with (
+            patch.object(model, "send_completion", return_value=(mock_hash, chunks)),
+            patch.object(model, "token_count", return_value=10),
+        ):  # Mock token count to avoid serialization issues
             # Set mdstream directly on the coder object
             coder.mdstream = mock_mdstream
 
@@ -364,6 +358,36 @@ class TestReasoning(unittest.TestCase):
                 reasoning_pos, main_pos, "Reasoning content should appear before main content"
             )
 
+            # Verify that partial_response_content only contains the main content
+            coder.remove_reasoning_content()
+            expected_content = "Final answer after reasoning"
+            self.assertEqual(coder.partial_response_content.strip(), expected_content)
+
+    @patch("aider.models.litellm.completion")
+    def test_simple_send_with_retries_removes_reasoning(self, mock_completion):
+        """Test that simple_send_with_retries correctly removes reasoning content."""
+        model = Model("deepseek-r1")  # This model has reasoning_tag="think"
+
+        # Mock the completion response
+        mock_response = MagicMock()
+        mock_response.choices = [MagicMock(message=MagicMock(content="""Here is some text
+<think>
+This reasoning should be removed
+</think>
+And this text should remain"""))]
+        mock_completion.return_value = mock_response
+
+        messages = [{"role": "user", "content": "test"}]
+        result = model.simple_send_with_retries(messages)
+
+        expected = """Here is some text
+
+And this text should remain"""
+        self.assertEqual(result, expected)
+
+        # Verify the completion was called
+        mock_completion.assert_called_once()
+
     def test_remove_reasoning_content(self):
         """Test the remove_reasoning_content function from reasoning_tags module."""
         # Test with no removal configured
@@ -399,35 +423,39 @@ End"""
         text = "Just regular text"
         self.assertEqual(remove_reasoning_content(text, "think"), text)
 
-    def test_send_with_reasoning(self):
-        """Test that reasoning content from the 'reasoning' attribute is properly formatted
-        and output."""
+    def test_send_with_think_tags(self):
+        """Test that <think> tags are properly processed and formatted."""
         # Setup IO with no pretty
         io = InputOutput(pretty=False)
         io.assistant_output = MagicMock()
 
         # Setup model and coder
         model = Model("gpt-3.5-turbo")
+        model.reasoning_tag = "think"  # Set to remove <think> tags
         coder = Coder.create(model, None, io=io, stream=False)
 
         # Test data
         reasoning_content = "My step-by-step reasoning process"
         main_content = "Final answer after reasoning"
 
-        # Mock completion response with reasoning content
+        # Create content with think tags
+        combined_content = f"""<think>
+{reasoning_content}
+</think>
+
+{main_content}"""
+
+        # Mock completion response with think tags in content
         class MockCompletion:
-            def __init__(self, content, reasoning):
-                self.content = content
+            def __init__(self, content):
+                self.content = combined_content
                 # Add required attributes expected by show_send_output
                 self.choices = [MagicMock()]
                 self.choices[0].message.content = content
-                self.choices[0].message.reasoning = (
-                    reasoning  # Using reasoning instead of reasoning_content
-                )
-                delattr(self.choices[0].message, "reasoning_content")
+                self.choices[0].message.reasoning = None  # No separate reasoning content
                 self.finish_reason = "stop"
 
-        mock_completion = MockCompletion(main_content, reasoning_content)
+        mock_completion = MockCompletion(combined_content)
 
         # Create a mock hash object
         mock_hash = MagicMock()
@@ -464,9 +492,8 @@ End"""
                 reasoning_pos, main_pos, "Reasoning content should appear before main content"
             )
 
-    def test_send_with_reasoning_stream(self):
-        """Test that streaming reasoning content from the 'reasoning' attribute is properly
-        formatted and output."""
+    def test_send_with_think_tags_stream(self):
+        """Test that streaming with <think> tags is properly processed and formatted."""
         # Setup IO with pretty output for streaming
         io = InputOutput(pretty=True)
         mock_mdstream = MagicMock()
@@ -474,6 +501,7 @@ End"""
 
         # Setup model and coder
         model = Model("gpt-3.5-turbo")
+        model.reasoning_tag = "think"  # Set to remove <think> tags
         coder = Coder.create(model, None, io=io, stream=True)
 
         # Ensure the coder shows pretty output
@@ -509,16 +537,17 @@ End"""
                     # Need to handle attribute access that would raise AttributeError
                     delattr(self.choices[0].delta, "reasoning")
 
-        # Create chunks to simulate streaming - using reasoning attribute instead of
-        # reasoning_content
+        # Create chunks to simulate streaming with think tags
         chunks = [
-            # First chunk with reasoning content starts the tag
-            MockStreamingChunk(reasoning="My step-by-step "),
-            # Additional reasoning content
-            MockStreamingChunk(reasoning="reasoning process"),
-            # Switch to main content - this will automatically end the reasoning tag
+            # Start with open think tag
+            MockStreamingChunk(content="<think>\n"),
+            # Reasoning content inside think tags
+            MockStreamingChunk(content="My step-by-step "),
+            MockStreamingChunk(content="reasoning process\n"),
+            # Close think tag
+            MockStreamingChunk(content="</think>\n\n"),
+            # Main content
             MockStreamingChunk(content="Final "),
-            # More main content
             MockStreamingChunk(content="answer "),
             MockStreamingChunk(content="after reasoning"),
             # End the response
@@ -576,33 +605,7 @@ End"""
 
             # Verify that partial_response_content only contains the main content
             coder.remove_reasoning_content()
-            expected_content = "Final answer after reasoning"
-            self.assertEqual(coder.partial_response_content.strip(), expected_content)
-
-    @patch("aider.models.litellm.completion")
-    def test_simple_send_with_retries_removes_reasoning(self, mock_completion):
-        """Test that simple_send_with_retries correctly removes reasoning content."""
-        model = Model("deepseek-r1")  # This model has reasoning_tag="think"
-
-        # Mock the completion response
-        mock_response = MagicMock()
-        mock_response.choices = [MagicMock(message=MagicMock(content="""Here is some text
-<think>
-This reasoning should be removed
-</think>
-And this text should remain"""))]
-        mock_completion.return_value = mock_response
-
-        messages = [{"role": "user", "content": "test"}]
-        result = model.simple_send_with_retries(messages)
-
-        expected = """Here is some text
-
-And this text should remain"""
-        self.assertEqual(result, expected)
-
-        # Verify the completion was called
-        mock_completion.assert_called_once()
+            self.assertEqual(coder.partial_response_content.strip(), "Final answer after reasoning")
 
 
 if __name__ == "__main__":
