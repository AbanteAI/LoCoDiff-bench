
index a2b4b430..75f69f9b 100644
--- a/qdrant_lib_segment_src_index_field_index_full_text_index_inverted_index.rs_expectedoutput.txt (expected):tmp/tmpp8kyhe1t_expected.txt	
+++ b/qdrant_lib_segment_src_index_field_index_full_text_index_inverted_index.rs_extracted.txt (actual):tmp/tmptnwkqpls_actual.txt	
@@ -1,4 +1,5 @@
 use std::collections::{BTreeSet, HashMap};
+use std::mem::size_of;
 
 use common::counter::hardware_counter::HardwareCounterCell;
 use common::types::PointOffsetType;
@@ -48,7 +49,6 @@ impl ParsedQuery {
         if self.tokens.contains(&None) {
             return false;
         }
-
         // Check that all tokens are in document
         self.tokens
             .iter()
@@ -75,7 +75,6 @@ pub trait InvertedIndex {
             };
             document_tokens.push(vocab_idx);
         }
-
         Document::new(document_tokens)
     }
 
@@ -213,8 +212,6 @@ mod tests {
 
     fn generate_word() -> String {
         let mut rng = rand::rng();
-
-        // Each word is 1 to 3 characters long
         let len = rng.random_range(1..=3);
         rng.sample_iter(rand::distr::Alphanumeric)
             .take(len)
@@ -238,38 +235,32 @@ mod tests {
 
     fn mutable_inverted_index(indexed_count: u32, deleted_count: u32) -> MutableInvertedIndex {
         let mut index = MutableInvertedIndex::default();
-
         let hw_counter = HardwareCounterCell::new();
 
         for idx in 0..indexed_count {
-            // Generate 10 tot 30-word documents
             let doc_len = rand::rng().random_range(10..=30);
             let tokens: BTreeSet<String> = (0..doc_len).map(|_| generate_word()).collect();
             let document = index.document_from_tokens(&tokens);
             index.index_document(idx, document, &hw_counter).unwrap();
         }
 
-        // Remove some points
         let mut points_to_delete = (0..indexed_count).collect::<Vec<_>>();
         points_to_delete.shuffle(&mut rand::rng());
         for idx in &points_to_delete[..deleted_count as usize] {
             index.remove_document(*idx);
         }
-
         index
     }
 
     #[test]
     fn test_mutable_to_immutable() {
         let mutable = mutable_inverted_index(2000, 400);
-
         let immutable = ImmutableInvertedIndex::from(mutable.clone());
 
         assert!(immutable.vocab.len() < mutable.vocab.len());
         assert!(immutable.postings.len() < mutable.postings.len());
         assert!(!immutable.vocab.is_empty());
 
-        // Check that new vocabulary token ids leads to the same posting lists
         assert!({
             immutable.vocab.iter().all(|(key, new_token)| {
                 let new_posting = immutable
@@ -315,9 +306,7 @@ mod tests {
         let path = tempfile::tempdir().unwrap().into_path();
 
         MmapInvertedIndex::create(path.clone(), immutable.clone()).unwrap();
-
         let hw_counter = HardwareCounterCell::new();
-
         let mmap = MmapInvertedIndex::open(path, false).unwrap();
 
         // Check same vocabulary
@@ -335,21 +324,16 @@ mod tests {
         }
 
         for (point_id, count) in immutable.point_to_tokens_count.iter().enumerate() {
-            // Check same deleted points
             assert_eq!(
                 mmap.deleted_points.get(point_id).unwrap(),
                 count.is_none(),
                 "point_id: {point_id}"
             );
-
-            // Check same count
             assert_eq!(
                 *mmap.point_to_tokens_count.get(point_id).unwrap(),
                 count.unwrap_or(0)
             );
         }
-
-        // Check same points count
         assert_eq!(mmap.active_points_count, immutable.points_count);
     }
 
@@ -368,6 +352,7 @@ mod tests {
         let mut mmap_index = MmapInvertedIndex::open(path, false).unwrap();
 
         let queries: Vec<_> = (0..100).map(|_| generate_query()).collect();
+        let hw_counter = HardwareCounterCell::new();
 
         let mut_parsed_queries: Vec<_> = queries
             .clone()
@@ -375,8 +360,6 @@ mod tests {
             .map(|query| to_parsed_query(query, |token| mutable.vocab.get(&token).copied()))
             .collect();
 
-        let hw_counter = HardwareCounterCell::new();
-
         let imm_parsed_queries: Vec<_> = queries
             .into_iter()
             .map(|query| {
@@ -397,8 +380,6 @@ mod tests {
             assert_eq!(mut_filtered, imm_filtered);
         }
 
-        // Delete random documents from both indexes
-
         let points_to_delete: Vec<_> = (0..deleted_count)
             .map(|_| rand::rng().random_range(0..indexed_count))
             .collect();
@@ -408,8 +389,6 @@ mod tests {
             mmap_index.remove_document(*point_id);
         }
 
-        // Check congruence after deletion
-
         for (mut_query, imm_query) in mut_parsed_queries
             .iter()
             .cloned()
