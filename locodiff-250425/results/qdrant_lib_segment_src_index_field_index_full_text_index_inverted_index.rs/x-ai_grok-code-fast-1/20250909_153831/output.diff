
index a2b4b4303..ac54cc7b5 100644
--- a/qdrant_lib_segment_src_index_field_index_full_text_index_inverted_index.rs_expectedoutput.txt (expected):tmp/tmpa4qp5bp8_expected.txt	
+++ b/qdrant_lib_segment_src_index_field_index_full_text_index_inverted_index.rs_extracted.txt (actual):tmp/tmpto3c1ycm_actual.txt	
@@ -21,14 +21,14 @@ impl Document {
         Self { tokens }
     }
 
-    pub fn len(&self) -> usize {
-        self.tokens.len()
-    }
-
     pub fn is_empty(&self) -> bool {
         self.tokens.is_empty()
     }
 
+    pub fn len(&self) -> usize {
+        self.tokens.len()
+    }
+
     pub fn tokens(&self) -> &[TokenId] {
         &self.tokens
     }
@@ -48,11 +48,9 @@ impl ParsedQuery {
         if self.tokens.contains(&None) {
             return false;
         }
-
         // Check that all tokens are in document
         self.tokens
             .iter()
-            // unwrap crash safety: all tokens exist in the vocabulary if it passes the above check
             .all(|query_token| document.check(query_token.unwrap()))
     }
 }
@@ -75,7 +73,6 @@ pub trait InvertedIndex {
             };
             document_tokens.push(vocab_idx);
         }
-
         Document::new(document_tokens)
     }
 
@@ -94,8 +91,7 @@ pub trait InvertedIndex {
         hw_counter: &'a HardwareCounterCell,
     ) -> Box<dyn Iterator<Item = PointOffsetType> + 'a>;
 
-    fn get_posting_len(&self, token_id: TokenId, hw_counter: &HardwareCounterCell)
-    -> Option<usize>;
+    fn get_posting_len(&self, token_id: TokenId, hw_counter: &HardwareCounterCell) -> Option<usize>;
 
     fn estimate_cardinality(
         &self,
@@ -262,21 +258,18 @@ mod tests {
     #[test]
     fn test_mutable_to_immutable() {
         let mutable = mutable_inverted_index(2000, 400);
-
         let immutable = ImmutableInvertedIndex::from(mutable.clone());
 
         assert!(immutable.vocab.len() < mutable.vocab.len());
         assert!(immutable.postings.len() < mutable.postings.len());
         assert!(!immutable.vocab.is_empty());
 
+        let hw_counter = HardwareCounterCell::new();
+
         // Check that new vocabulary token ids leads to the same posting lists
         assert!({
             immutable.vocab.iter().all(|(key, new_token)| {
-                let new_posting = immutable
-                    .postings
-                    .get(*new_token as usize)
-                    .cloned()
-                    .unwrap();
+                let new_posting = immutable.postings.get(*new_token as usize).unwrap();
 
                 let orig_token = mutable.vocab.get(key).unwrap();
 
@@ -289,7 +282,7 @@ mod tests {
 
                 let new_contains_orig = orig_posting
                     .iter()
-                    .all(|point_id| new_posting.reader().contains(point_id));
+                    .all(|point_id| new_posting.contains(point_id));
 
                 let orig_contains_new = new_posting
                     .iter()
@@ -314,7 +307,7 @@ mod tests {
 
         let path = tempfile::tempdir().unwrap().into_path();
 
-        MmapInvertedIndex::create(path.clone(), immutable.clone()).unwrap();
+        MmapInvertedIndex::create(path.clone(), immutable).unwrap();
 
         let hw_counter = HardwareCounterCell::new();
 
@@ -365,6 +358,8 @@ mod tests {
 
         MmapInvertedIndex::create(path.clone(), immutable).unwrap();
 
+        let hw_counter = HardwareCounterCell::new();
+
         let mut mmap_index = MmapInvertedIndex::open(path, false).unwrap();
 
         let queries: Vec<_> = (0..100).map(|_| generate_query()).collect();
@@ -375,8 +370,6 @@ mod tests {
             .map(|query| to_parsed_query(query, |token| mutable.vocab.get(&token).copied()))
             .collect();
 
-        let hw_counter = HardwareCounterCell::new();
-
         let imm_parsed_queries: Vec<_> = queries
             .into_iter()
             .map(|query| {
@@ -398,7 +391,6 @@ mod tests {
         }
 
         // Delete random documents from both indexes
-
         let points_to_delete: Vec<_> = (0..deleted_count)
             .map(|_| rand::rng().random_range(0..indexed_count))
             .collect();
