
index ce6172c9..6659efb8 100644
--- a/aider_aider_history.py_expectedoutput.txt (expected):tmp/tmpp8s5igy3_expected.txt	
+++ b/aider_aider_history.py_extracted.txt (actual):tmp/tmpx60e6tnh_actual.txt	
@@ -47,7 +47,6 @@ class ChatSummary:
         split_index = len(messages)
         half_max_tokens = self.max_tokens // 2
 
-        # Iterate over the messages in reverse order
         for i in range(len(sized) - 1, -1, -1):
             tokens, _msg = sized[i]
             if tail_tokens + tokens < half_max_tokens:
@@ -56,8 +55,7 @@ class ChatSummary:
             else:
                 break
 
-        # Ensure the head ends with an assistant message
-        while messages[split_index - 1]["role"] != "assistant" and split_index > 1:
+        while split_index > 1 and messages[split_index - 1]["role"] != "assistant":
             split_index -= 1
 
         if split_index <= min_split:
@@ -72,7 +70,6 @@ class ChatSummary:
         keep = []
         total = 0
 
-        # These sometimes come set with value = None
         model_max_input_tokens = self.models[0].info.get("max_input_tokens") or 4096
         model_max_input_tokens -= 512
 
@@ -128,16 +125,15 @@ def main():
     parser.add_argument("filename", help="Markdown file to parse")
     args = parser.parse_args()
 
-    model_names = ["gpt-3.5-turbo", "gpt-4"]  # Add more model names as needed
+    model_names = ["gpt-3.5-turbo", "gpt-4"]
     model_list = [models.Model(name) for name in model_names]
     summarizer = ChatSummary(model_list)
 
     with open(args.filename, "r") as f:
         text = f.read()
 
-    summary = summarizer.summarize_chat_history_markdown(text)
+    summary = summarizer.summarize(messages[-40:])
     dump(summary)
 
-
 if __name__ == "__main__":
     main()
\ No newline at end of file
