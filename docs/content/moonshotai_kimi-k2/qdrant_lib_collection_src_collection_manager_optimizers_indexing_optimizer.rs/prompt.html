<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Prompt: lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs - Kimi K2</title>
    <link rel="stylesheet" href="../../../../styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/default.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
</head>
<body>
    <header>
        <h1>Prompt: lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs</h1>
        <h2>Model: Kimi K2</h2>
        <p><a href="../../../cases/moonshotai_kimi-k2/qdrant_lib_collection_src_collection_manager_optimizers_indexing_optimizer.rs.html">Back to Case</a> | <a href="../../../cases.html">All Cases</a> | <a href="../../../index.html">Home</a></p>
    </header>
    <main>
        <section>
            <h2>Prompt Content</h2>
            <pre><code class="language-plaintext"># Instructions

You are being benchmarked. You will see the output of a git log command, and from that must infer the current state of a file. Think carefully, as you must output the exact state of the file to earn full marks.

**Important:** Your goal is to reproduce the file's content *exactly* as it exists at the final commit, even if the code appears broken, buggy, or contains obvious errors. Do **not** try to "fix" the code. Attempting to correct issues will result in a poor score, as this benchmark evaluates your ability to reproduce the precise state of the file based on its history.

# Required Response Format

Wrap the content of the file in triple backticks (```). Any text outside the final closing backticks will be ignored. End your response after outputting the closing backticks.

# Example Response

```python
#!/usr/bin/env python
print('Hello, world!')
```

# File History

> git log -p --cc --topo-order --reverse -- lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs

commit 446d0c29f70f1154025e644b154adbd270007290
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Sun Aug 15 23:26:01 2021 +0200

    Deadlock fix (#91)
    
    * refactor: segment managers -> collection managers
    
    * fix segments holder deadlock
    
    * apply cargo fmt
    
    * fix cargo clippy
    
    * replace sequential segment locking with multiple try_lock attempts to prevent deadlocks

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
new file mode 100644
index 000000000..b0043510c
--- /dev/null
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -0,0 +1,340 @@
+use crate::collection_manager::holders::segment_holder::{
+    LockedSegment, LockedSegmentHolder, SegmentId,
+};
+use crate::collection_manager::optimizers::segment_optimizer::{
+    OptimizerThresholds, SegmentOptimizer,
+};
+use crate::config::CollectionParams;
+use segment::types::{HnswConfig, Indexes, PayloadIndexType, SegmentType, StorageType};
+use std::path::{Path, PathBuf};
+
+pub struct IndexingOptimizer {
+    thresholds_config: OptimizerThresholds,
+    segments_path: PathBuf,
+    collection_temp_dir: PathBuf,
+    collection_params: CollectionParams,
+    hnsw_config: HnswConfig,
+}
+
+impl IndexingOptimizer {
+    pub fn new(
+        thresholds_config: OptimizerThresholds,
+        segments_path: PathBuf,
+        collection_temp_dir: PathBuf,
+        collection_params: CollectionParams,
+        hnsw_config: HnswConfig,
+    ) -> Self {
+        IndexingOptimizer {
+            thresholds_config,
+            segments_path,
+            collection_temp_dir,
+            collection_params,
+            hnsw_config,
+        }
+    }
+
+    fn worst_segment(&self, segments: LockedSegmentHolder) -> Option<(SegmentId, LockedSegment)> {
+        segments
+            .read()
+            .iter()
+            .filter_map(|(idx, segment)| {
+                let segment_entry = segment.get();
+                let read_segment = segment_entry.read();
+                let vector_count = read_segment.vectors_count();
+
+                let segment_config = read_segment.config();
+
+                if read_segment.segment_type() == SegmentType::Special {
+                    return None; // Never optimize already optimized segment
+                }
+
+                // Apply indexing to plain segments which have grown too big
+                let is_vector_indexed = match segment_config.index {
+                    Indexes::Plain { .. } => false,
+                    Indexes::Hnsw(_) => true,
+                };
+
+                let is_payload_indexed = match segment_config.payload_index.unwrap_or_default() {
+                    PayloadIndexType::Plain => false,
+                    PayloadIndexType::Struct => true,
+                };
+
+                let is_memmaped = match segment_config.storage_type {
+                    StorageType::InMemory => false,
+                    StorageType::Mmap => true,
+                };
+
+                let big_for_mmap = vector_count >= self.thresholds_config.memmap_threshold;
+                let big_for_index = vector_count >= self.thresholds_config.indexing_threshold;
+                let big_for_payload_index =
+                    vector_count >= self.thresholds_config.payload_indexing_threshold;
+
+                let has_payload = !read_segment.get_indexed_fields().is_empty();
+
+                let require_indexing = (big_for_mmap && !is_memmaped)
+                    || (big_for_index && !is_vector_indexed)
+                    || (has_payload && big_for_payload_index && !is_payload_indexed);
+
+                match require_indexing {
+                    true => Some((*idx, vector_count)),
+                    false => None,
+                }
+            })
+            .max_by_key(|(_, num_vectors)| *num_vectors)
+            .map(|(idx, _)| (idx, segments.read().get(idx).unwrap().clone()))
+    }
+}
+
+impl SegmentOptimizer for IndexingOptimizer {
+    fn collection_path(&self) -> &Path {
+        self.segments_path.as_path()
+    }
+
+    fn temp_path(&self) -> &Path {
+        self.collection_temp_dir.as_path()
+    }
+
+    fn collection_params(&self) -> CollectionParams {
+        self.collection_params.clone()
+    }
+
+    fn hnsw_config(&self) -> HnswConfig {
+        self.hnsw_config
+    }
+
+    fn threshold_config(&self) -> &OptimizerThresholds {
+        &self.thresholds_config
+    }
+
+    fn check_condition(&self, segments: LockedSegmentHolder) -> Vec<SegmentId> {
+        match self.worst_segment(segments) {
+            None => vec![],
+            Some((segment_id, _segment)) => vec![segment_id],
+        }
+    }
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use crate::collection_manager::fixtures::random_segment;
+    use crate::collection_manager::holders::segment_holder::SegmentHolder;
+    use crate::collection_manager::simple_collection_updater::SimpleCollectionUpdater;
+    use crate::operations::point_ops::{PointInsertOperations, PointOperations};
+    use crate::operations::FieldIndexOperations;
+    use itertools::Itertools;
+    use parking_lot::lock_api::RwLock;
+    use segment::types::StorageType;
+    use std::sync::Arc;
+    use tempdir::TempDir;
+
+    fn init() {
+        let _ = env_logger::builder().is_test(true).try_init();
+    }
+
+    #[test]
+    fn test_indexing_optimizer() {
+        init();
+
+        let mut holder = SegmentHolder::default();
+
+        let payload_field = "number".to_owned();
+
+        let dim = 4;
+
+        let segments_dir = TempDir::new("segments_dir").unwrap();
+        let segments_temp_dir = TempDir::new("segments_temp_dir").unwrap();
+        let mut opnum = 101..1000000;
+
+        let small_segment = random_segment(segments_dir.path(), opnum.next().unwrap(), 25, dim);
+        let middle_segment = random_segment(segments_dir.path(), opnum.next().unwrap(), 100, dim);
+        let large_segment = random_segment(segments_dir.path(), opnum.next().unwrap(), 200, dim);
+
+        let segment_config = small_segment.segment_config.clone();
+
+        let small_segment_id = holder.add(small_segment);
+        let middle_segment_id = holder.add(middle_segment);
+        let large_segment_id = holder.add(large_segment);
+
+        let mut index_optimizer = IndexingOptimizer::new(
+            OptimizerThresholds {
+                memmap_threshold: 1000,
+                indexing_threshold: 1000,
+                payload_indexing_threshold: 50,
+            },
+            segments_dir.path().to_owned(),
+            segments_temp_dir.path().to_owned(),
+            CollectionParams {
+                vector_size: segment_config.vector_size,
+                distance: segment_config.distance,
+            },
+            Default::default(),
+        );
+
+        let locked_holder = Arc::new(RwLock::new(holder));
+
+        // ---- check condition for MMap optimization
+        let suggested_to_optimize = index_optimizer.check_condition(locked_holder.clone());
+        assert!(suggested_to_optimize.is_empty());
+
+        index_optimizer.thresholds_config.memmap_threshold = 150;
+        index_optimizer.thresholds_config.indexing_threshold = 50;
+
+        let suggested_to_optimize = index_optimizer.check_condition(locked_holder.clone());
+        assert!(suggested_to_optimize.contains(&large_segment_id));
+
+        // ----- CREATE AN INDEXED FIELD ------
+        let updater = SimpleCollectionUpdater::new(locked_holder.clone());
+        updater
+            .process_field_index_operation(
+                opnum.next().unwrap(),
+                &FieldIndexOperations::CreateIndex(payload_field.clone()),
+            )
+            .unwrap();
+
+        // ------ Plain -> Mmap & Indexed payload
+        let suggested_to_optimize = index_optimizer.check_condition(locked_holder.clone());
+        assert!(suggested_to_optimize.contains(&large_segment_id));
+        eprintln!("suggested_to_optimize = {:#?}", suggested_to_optimize);
+        index_optimizer
+            .optimize(locked_holder.clone(), suggested_to_optimize)
+            .unwrap();
+        eprintln!("Done");
+
+        // ------ Plain -> Indexed payload
+        let suggested_to_optimize = index_optimizer.check_condition(locked_holder.clone());
+        assert!(suggested_to_optimize.contains(&middle_segment_id));
+        index_optimizer
+            .optimize(locked_holder.clone(), suggested_to_optimize)
+            .unwrap();
+
+        // ------- Keep smallest segment without changes
+        let suggested_to_optimize = index_optimizer.check_condition(locked_holder.clone());
+        assert!(suggested_to_optimize.is_empty());
+
+        assert_eq!(
+            locked_holder.read().len(),
+            3,
+            "Testing no new segments were created"
+        );
+
+        let infos = locked_holder
+            .read()
+            .iter()
+            .map(|(_sid, segment)| segment.get().read().info())
+            .collect_vec();
+        let configs = locked_holder
+            .read()
+            .iter()
+            .map(|(_sid, segment)| segment.get().read().config())
+            .collect_vec();
+
+        let indexed_count = infos
+            .iter()
+            .filter(|info| info.segment_type == SegmentType::Indexed)
+            .count();
+        assert_eq!(
+            indexed_count, 2,
+            "Testing that 2 segments are actually indexed"
+        );
+
+        let mmap_count = configs
+            .iter()
+            .filter(|config| config.storage_type == StorageType::Mmap)
+            .count();
+        assert_eq!(
+            mmap_count, 1,
+            "Testing that only largest segment is not Mmap"
+        );
+
+        let segment_dirs = segments_dir.path().read_dir().unwrap().collect_vec();
+        assert_eq!(
+            segment_dirs.len(),
+            locked_holder.read().len(),
+            "Testing that new segments are persisted and old data is removed"
+        );
+
+        for info in infos.iter() {
+            assert!(
+                info.schema.contains_key(&payload_field),
+                "Testing that payload is not lost"
+            );
+            assert!(
+                info.schema[&payload_field].indexed,
+                "Testing that payload index is not lost"
+            );
+        }
+
+        let insert_point_ops = PointOperations::UpsertPoints(PointInsertOperations::BatchPoints {
+            ids: vec![501, 502, 503],
+            vectors: vec![
+                vec![1.0, 0.0, 0.5, 0.0],
+                vec![1.0, 0.0, 0.5, 0.5],
+                vec![1.0, 0.0, 0.5, 1.0],
+            ],
+            payloads: None,
+        });
+
+        let smallest_size = infos
+            .iter()
+            .min_by_key(|info| info.num_vectors)
+            .unwrap()
+            .num_vectors;
+
+        updater
+            .process_point_operation(opnum.next().unwrap(), insert_point_ops)
+            .unwrap();
+
+        let new_infos = locked_holder
+            .read()
+            .iter()
+            .map(|(_sid, segment)| segment.get().read().info())
+            .collect_vec();
+        let new_smallest_size = new_infos
+            .iter()
+            .min_by_key(|info| info.num_vectors)
+            .unwrap()
+            .num_vectors;
+
+        assert_eq!(
+            new_smallest_size,
+            smallest_size + 3,
+            "Testing that new data is added to an appendable segment only"
+        );
+
+        // ---- New appendable segment should be created if none left
+
+        // Index even the smallest segment
+        index_optimizer.thresholds_config.payload_indexing_threshold = 20;
+        let suggested_to_optimize = index_optimizer.check_condition(locked_holder.clone());
+        assert!(suggested_to_optimize.contains(&small_segment_id));
+        index_optimizer
+            .optimize(locked_holder.clone(), suggested_to_optimize)
+            .unwrap();
+
+        let new_infos2 = locked_holder
+            .read()
+            .iter()
+            .map(|(_sid, segment)| segment.get().read().info())
+            .collect_vec();
+
+        assert!(
+            new_infos2.len() > new_infos.len(),
+            "Check that new appendable segment was created"
+        );
+
+        let insert_point_ops = PointOperations::UpsertPoints(PointInsertOperations::BatchPoints {
+            ids: vec![601, 602, 603],
+            vectors: vec![
+                vec![0.0, 1.0, 0.5, 0.0],
+                vec![0.0, 1.0, 0.5, 0.5],
+                vec![0.0, 1.0, 0.5, 1.0],
+            ],
+            payloads: None,
+        });
+
+        updater
+            .process_point_operation(opnum.next().unwrap(), insert_point_ops)
+            .unwrap();
+    }
+}

commit 2cbe1d4f6b86ae6fc8b77da5f9c68ae4444d09e6
Author: Alexander Galibey <48586936+galibey@users.noreply.github.com>
Date:   Sun Aug 22 23:11:00 2021 +0300

    Decouple searcher and updater from collection (#93)

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index b0043510c..d2e157261 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -116,18 +116,25 @@ impl SegmentOptimizer for IndexingOptimizer {
 
 #[cfg(test)]
 mod tests {
-    use super::*;
-    use crate::collection_manager::fixtures::random_segment;
-    use crate::collection_manager::holders::segment_holder::SegmentHolder;
-    use crate::collection_manager::simple_collection_updater::SimpleCollectionUpdater;
-    use crate::operations::point_ops::{PointInsertOperations, PointOperations};
-    use crate::operations::FieldIndexOperations;
+    use std::ops::Deref;
+    use std::sync::Arc;
+
     use itertools::Itertools;
     use parking_lot::lock_api::RwLock;
-    use segment::types::StorageType;
-    use std::sync::Arc;
     use tempdir::TempDir;
 
+    use segment::types::StorageType;
+
+    use crate::operations::point_ops::{PointInsertOperations, PointOperations};
+    use crate::operations::FieldIndexOperations;
+
+    use super::*;
+    use crate::collection_manager::fixtures::random_segment;
+    use crate::collection_manager::holders::segment_holder::SegmentHolder;
+    use crate::collection_manager::segments_updater::{
+        process_field_index_operation, process_point_operation,
+    };
+
     fn init() {
         let _ = env_logger::builder().is_test(true).try_init();
     }
@@ -184,13 +191,12 @@ mod tests {
         assert!(suggested_to_optimize.contains(&large_segment_id));
 
         // ----- CREATE AN INDEXED FIELD ------
-        let updater = SimpleCollectionUpdater::new(locked_holder.clone());
-        updater
-            .process_field_index_operation(
-                opnum.next().unwrap(),
-                &FieldIndexOperations::CreateIndex(payload_field.clone()),
-            )
-            .unwrap();
+        process_field_index_operation(
+            locked_holder.deref(),
+            opnum.next().unwrap(),
+            &FieldIndexOperations::CreateIndex(payload_field.clone()),
+        )
+        .unwrap();
 
         // ------ Plain -> Mmap & Indexed payload
         let suggested_to_optimize = index_optimizer.check_condition(locked_holder.clone());
@@ -281,9 +287,12 @@ mod tests {
             .unwrap()
             .num_vectors;
 
-        updater
-            .process_point_operation(opnum.next().unwrap(), insert_point_ops)
-            .unwrap();
+        process_point_operation(
+            locked_holder.deref(),
+            opnum.next().unwrap(),
+            insert_point_ops,
+        )
+        .unwrap();
 
         let new_infos = locked_holder
             .read()
@@ -333,8 +342,11 @@ mod tests {
             payloads: None,
         });
 
-        updater
-            .process_point_operation(opnum.next().unwrap(), insert_point_ops)
-            .unwrap();
+        process_point_operation(
+            locked_holder.deref(),
+            opnum.next().unwrap(),
+            insert_point_ops,
+        )
+        .unwrap();
     }
 }

commit c603f0075e9b546afee57522cdbd8ad28c0da27f
Author: Marcin Puc <5671049+tranzystorek-io@users.noreply.github.com>
Date:   Wed Nov 10 21:32:25 2021 +0100

    Add various refactorings (#118)

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index d2e157261..74fa41a52 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -260,7 +260,7 @@ mod tests {
             "Testing that new segments are persisted and old data is removed"
         );
 
-        for info in infos.iter() {
+        for info in &infos {
             assert!(
                 info.schema.contains_key(&payload_field),
                 "Testing that payload is not lost"

commit 97b227048513143e555353d346a7f4560db9854e
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Mon Nov 29 09:39:22 2021 +0100

    Rustdoc and README for internal entities and processes (#123)
    
    * extend comments for strorage crate
    
    * update comments and readme for collection crate
    
    * apply cargo fmt
    
    * fix tests
    
    * apply fmt

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 74fa41a52..ef89ce052 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -8,6 +8,10 @@ use crate::config::CollectionParams;
 use segment::types::{HnswConfig, Indexes, PayloadIndexType, SegmentType, StorageType};
 use std::path::{Path, PathBuf};
 
+/// Looks for the segments, which require to be indexed.
+/// If segment is too large, but still does not have indexes - it is time to create some indexes.
+/// The process of index creation is slow and CPU-bounded, so it is convenient to perform
+/// index building in a same way as segment re-creation.
 pub struct IndexingOptimizer {
     thresholds_config: OptimizerThresholds,
     segments_path: PathBuf,

commit 0d18625ebd4a3e3c2c7ca7a19403ebfd5f979aef
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Mon Jan 17 17:48:59 2022 +0100

    Multiprocessing optimization fix (#155)
    
    * test to detect a problem
    
    * add checks for already scheduled and currently optimizing segments
    
    * fmt

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index ef89ce052..2b0f2363a 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -6,6 +6,7 @@ use crate::collection_manager::optimizers::segment_optimizer::{
 };
 use crate::config::CollectionParams;
 use segment::types::{HnswConfig, Indexes, PayloadIndexType, SegmentType, StorageType};
+use std::collections::HashSet;
 use std::path::{Path, PathBuf};
 
 /// Looks for the segments, which require to be indexed.
@@ -37,11 +38,20 @@ impl IndexingOptimizer {
         }
     }
 
-    fn worst_segment(&self, segments: LockedSegmentHolder) -> Option<(SegmentId, LockedSegment)> {
+    fn worst_segment(
+        &self,
+        segments: LockedSegmentHolder,
+        excluded_ids: &HashSet<SegmentId>,
+    ) -> Option<(SegmentId, LockedSegment)> {
         segments
             .read()
             .iter()
             .filter_map(|(idx, segment)| {
+                if excluded_ids.contains(idx) {
+                    // This segment is excluded externally. It might already be scheduled for optimization
+                    return None;
+                }
+
                 let segment_entry = segment.get();
                 let read_segment = segment_entry.read();
                 let vector_count = read_segment.vectors_count();
@@ -110,8 +120,12 @@ impl SegmentOptimizer for IndexingOptimizer {
         &self.thresholds_config
     }
 
-    fn check_condition(&self, segments: LockedSegmentHolder) -> Vec<SegmentId> {
-        match self.worst_segment(segments) {
+    fn check_condition(
+        &self,
+        segments: LockedSegmentHolder,
+        excluded_ids: &HashSet<SegmentId>,
+    ) -> Vec<SegmentId> {
+        match self.worst_segment(segments, excluded_ids) {
             None => vec![],
             Some((segment_id, _segment)) => vec![segment_id],
         }
@@ -184,14 +198,18 @@ mod tests {
 
         let locked_holder = Arc::new(RwLock::new(holder));
 
+        let excluded_ids = Default::default();
+
         // ---- check condition for MMap optimization
-        let suggested_to_optimize = index_optimizer.check_condition(locked_holder.clone());
+        let suggested_to_optimize =
+            index_optimizer.check_condition(locked_holder.clone(), &excluded_ids);
         assert!(suggested_to_optimize.is_empty());
 
         index_optimizer.thresholds_config.memmap_threshold = 150;
         index_optimizer.thresholds_config.indexing_threshold = 50;
 
-        let suggested_to_optimize = index_optimizer.check_condition(locked_holder.clone());
+        let suggested_to_optimize =
+            index_optimizer.check_condition(locked_holder.clone(), &excluded_ids);
         assert!(suggested_to_optimize.contains(&large_segment_id));
 
         // ----- CREATE AN INDEXED FIELD ------
@@ -203,7 +221,8 @@ mod tests {
         .unwrap();
 
         // ------ Plain -> Mmap & Indexed payload
-        let suggested_to_optimize = index_optimizer.check_condition(locked_holder.clone());
+        let suggested_to_optimize =
+            index_optimizer.check_condition(locked_holder.clone(), &excluded_ids);
         assert!(suggested_to_optimize.contains(&large_segment_id));
         eprintln!("suggested_to_optimize = {:#?}", suggested_to_optimize);
         index_optimizer
@@ -212,14 +231,16 @@ mod tests {
         eprintln!("Done");
 
         // ------ Plain -> Indexed payload
-        let suggested_to_optimize = index_optimizer.check_condition(locked_holder.clone());
+        let suggested_to_optimize =
+            index_optimizer.check_condition(locked_holder.clone(), &excluded_ids);
         assert!(suggested_to_optimize.contains(&middle_segment_id));
         index_optimizer
             .optimize(locked_holder.clone(), suggested_to_optimize)
             .unwrap();
 
         // ------- Keep smallest segment without changes
-        let suggested_to_optimize = index_optimizer.check_condition(locked_holder.clone());
+        let suggested_to_optimize =
+            index_optimizer.check_condition(locked_holder.clone(), &excluded_ids);
         assert!(suggested_to_optimize.is_empty());
 
         assert_eq!(
@@ -319,7 +340,8 @@ mod tests {
 
         // Index even the smallest segment
         index_optimizer.thresholds_config.payload_indexing_threshold = 20;
-        let suggested_to_optimize = index_optimizer.check_condition(locked_holder.clone());
+        let suggested_to_optimize =
+            index_optimizer.check_condition(locked_holder.clone(), &Default::default());
         assert!(suggested_to_optimize.contains(&small_segment_id));
         index_optimizer
             .optimize(locked_holder.clone(), suggested_to_optimize)

commit 0f91c9a5e29ef9065c79a20e0ace25be898beff8
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Tue Jan 18 15:06:42 2022 +0100

    [WIP] Force optimization stop #31 (#161)
    
    * implement checking stop-flag in the optimization routine
    
    * wip: optimization cancel test
    
    * force optimization stop during the construction of vector index
    
    * fix clippy

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 2b0f2363a..6dca340ba 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -135,6 +135,7 @@ impl SegmentOptimizer for IndexingOptimizer {
 #[cfg(test)]
 mod tests {
     use std::ops::Deref;
+    use std::sync::atomic::AtomicBool;
     use std::sync::Arc;
 
     use itertools::Itertools;
@@ -165,6 +166,7 @@ mod tests {
 
         let payload_field = "number".to_owned();
 
+        let stopped = AtomicBool::new(false);
         let dim = 4;
 
         let segments_dir = TempDir::new("segments_dir").unwrap();
@@ -226,7 +228,7 @@ mod tests {
         assert!(suggested_to_optimize.contains(&large_segment_id));
         eprintln!("suggested_to_optimize = {:#?}", suggested_to_optimize);
         index_optimizer
-            .optimize(locked_holder.clone(), suggested_to_optimize)
+            .optimize(locked_holder.clone(), suggested_to_optimize, &stopped)
             .unwrap();
         eprintln!("Done");
 
@@ -235,7 +237,7 @@ mod tests {
             index_optimizer.check_condition(locked_holder.clone(), &excluded_ids);
         assert!(suggested_to_optimize.contains(&middle_segment_id));
         index_optimizer
-            .optimize(locked_holder.clone(), suggested_to_optimize)
+            .optimize(locked_holder.clone(), suggested_to_optimize, &stopped)
             .unwrap();
 
         // ------- Keep smallest segment without changes
@@ -344,7 +346,7 @@ mod tests {
             index_optimizer.check_condition(locked_holder.clone(), &Default::default());
         assert!(suggested_to_optimize.contains(&small_segment_id));
         index_optimizer
-            .optimize(locked_holder.clone(), suggested_to_optimize)
+            .optimize(locked_holder.clone(), suggested_to_optimize, &stopped)
             .unwrap();
 
         let new_infos2 = locked_holder

commit d51a70fa931bc70443a369d08b3c55bceadfd015
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Mon Jan 24 17:33:57 2022 +0100

    add openapi validation during generation #208 (#248)
    
    * add openapi validation during generation #208
    
    * fix: POST -> PUT in point update api implementation and docs #208
    
    * fix: openapi structure exposure
    
    * fix: api usage in stress test

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 6dca340ba..04e760bcf 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -144,7 +144,9 @@ mod tests {
 
     use segment::types::StorageType;
 
-    use crate::operations::point_ops::{PointInsertOperations, PointOperations};
+    use crate::operations::point_ops::{
+        BatchInsertOperation, BatchPoints, PointInsertOperations, PointOperations,
+    };
     use crate::operations::FieldIndexOperations;
 
     use super::*;
@@ -298,15 +300,19 @@ mod tests {
             );
         }
 
-        let insert_point_ops = PointOperations::UpsertPoints(PointInsertOperations::BatchPoints {
-            ids: vec![501, 502, 503],
-            vectors: vec![
-                vec![1.0, 0.0, 0.5, 0.0],
-                vec![1.0, 0.0, 0.5, 0.5],
-                vec![1.0, 0.0, 0.5, 1.0],
-            ],
-            payloads: None,
-        });
+        let insert_point_ops = PointOperations::UpsertPoints(PointInsertOperations::BatchPoints(
+            BatchInsertOperation {
+                batch: BatchPoints {
+                    ids: vec![501, 502, 503],
+                    vectors: vec![
+                        vec![1.0, 0.0, 0.5, 0.0],
+                        vec![1.0, 0.0, 0.5, 0.5],
+                        vec![1.0, 0.0, 0.5, 1.0],
+                    ],
+                    payloads: None,
+                },
+            },
+        ));
 
         let smallest_size = infos
             .iter()
@@ -360,15 +366,19 @@ mod tests {
             "Check that new appendable segment was created"
         );
 
-        let insert_point_ops = PointOperations::UpsertPoints(PointInsertOperations::BatchPoints {
-            ids: vec![601, 602, 603],
-            vectors: vec![
-                vec![0.0, 1.0, 0.5, 0.0],
-                vec![0.0, 1.0, 0.5, 0.5],
-                vec![0.0, 1.0, 0.5, 1.0],
-            ],
-            payloads: None,
-        });
+        let insert_point_ops = PointOperations::UpsertPoints(PointInsertOperations::BatchPoints(
+            BatchInsertOperation {
+                batch: BatchPoints {
+                    ids: vec![601, 602, 603],
+                    vectors: vec![
+                        vec![0.0, 1.0, 0.5, 0.0],
+                        vec![0.0, 1.0, 0.5, 0.5],
+                        vec![0.0, 1.0, 0.5, 1.0],
+                    ],
+                    payloads: None,
+                },
+            },
+        ));
 
         process_point_operation(
             locked_holder.deref(),

commit 9440143af0a4e56162829a0dfa6c31705483bfe8
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Mon Jan 24 19:32:14 2022 +0100

    rename point update api structure #208 (#251)

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 04e760bcf..d98005908 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -145,7 +145,7 @@ mod tests {
     use segment::types::StorageType;
 
     use crate::operations::point_ops::{
-        BatchInsertOperation, BatchPoints, PointInsertOperations, PointOperations,
+        Batch, PointInsertOperations, PointOperations, PointsBatch,
     };
     use crate::operations::FieldIndexOperations;
 
@@ -300,9 +300,9 @@ mod tests {
             );
         }
 
-        let insert_point_ops = PointOperations::UpsertPoints(PointInsertOperations::BatchPoints(
-            BatchInsertOperation {
-                batch: BatchPoints {
+        let insert_point_ops =
+            PointOperations::UpsertPoints(PointInsertOperations::PointsBatch(PointsBatch {
+                batch: Batch {
                     ids: vec![501, 502, 503],
                     vectors: vec![
                         vec![1.0, 0.0, 0.5, 0.0],
@@ -311,8 +311,7 @@ mod tests {
                     ],
                     payloads: None,
                 },
-            },
-        ));
+            }));
 
         let smallest_size = infos
             .iter()
@@ -366,9 +365,9 @@ mod tests {
             "Check that new appendable segment was created"
         );
 
-        let insert_point_ops = PointOperations::UpsertPoints(PointInsertOperations::BatchPoints(
-            BatchInsertOperation {
-                batch: BatchPoints {
+        let insert_point_ops =
+            PointOperations::UpsertPoints(PointInsertOperations::PointsBatch(PointsBatch {
+                batch: Batch {
                     ids: vec![601, 602, 603],
                     vectors: vec![
                         vec![0.0, 1.0, 0.5, 0.0],
@@ -377,8 +376,7 @@ mod tests {
                     ],
                     payloads: None,
                 },
-            },
-        ));
+            }));
 
         process_point_operation(
             locked_holder.deref(),

commit 1fbe4093170a40bcbe9b29f5ed6eeda64b1cb32e
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Thu Jan 27 17:15:58 2022 +0100

    fix: remove double read locking of segment holder (#260)

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index d98005908..cd8dcd6c9 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -43,8 +43,8 @@ impl IndexingOptimizer {
         segments: LockedSegmentHolder,
         excluded_ids: &HashSet<SegmentId>,
     ) -> Option<(SegmentId, LockedSegment)> {
-        segments
-            .read()
+        let segments_read_guard = segments.read();
+        segments_read_guard
             .iter()
             .filter_map(|(idx, segment)| {
                 if excluded_ids.contains(idx) {
@@ -95,7 +95,7 @@ impl IndexingOptimizer {
                 }
             })
             .max_by_key(|(_, num_vectors)| *num_vectors)
-            .map(|(idx, _)| (idx, segments.read().get(idx).unwrap().clone()))
+            .map(|(idx, _)| (idx, segments_read_guard.get(idx).unwrap().clone()))
     }
 }
 

commit 65787f7f556b309ffbfc733c0e3e01433e87e92b
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Mon Jan 31 13:18:07 2022 +0100

    UUID as point id (#265)
    
    * wip: u64 -> u128 + serialization tests
    
    * breaking: use more flexible structure for saving point ids
    
    * replace u64 external id type with enum
    
    * update openapi definitions for uuid + fix retrieve point api + bash script tests

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index cd8dcd6c9..560392285 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -303,7 +303,7 @@ mod tests {
         let insert_point_ops =
             PointOperations::UpsertPoints(PointInsertOperations::PointsBatch(PointsBatch {
                 batch: Batch {
-                    ids: vec![501, 502, 503],
+                    ids: vec![501.into(), 502.into(), 503.into()],
                     vectors: vec![
                         vec![1.0, 0.0, 0.5, 0.0],
                         vec![1.0, 0.0, 0.5, 0.5],
@@ -368,7 +368,7 @@ mod tests {
         let insert_point_ops =
             PointOperations::UpsertPoints(PointInsertOperations::PointsBatch(PointsBatch {
                 batch: Batch {
-                    ids: vec![601, 602, 603],
+                    ids: vec![601.into(), 602.into(), 603.into()],
                     vectors: vec![
                         vec![0.0, 1.0, 0.5, 0.0],
                         vec![0.0, 1.0, 0.5, 0.5],

commit 4483ea0d60bb4cf97df1267de6299556674d83fa
Author: Gabriel Velo <gabriel.velo@gmail.com>
Date:   Wed Feb 9 11:46:01 2022 -0300

    fix: #101 Payload type consistency is not enforced.

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 560392285..db42686f7 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -1,3 +1,10 @@
+use std::collections::HashSet;
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use segment::payload_storage::schema_storage::SchemaStorage;
+use segment::types::{HnswConfig, Indexes, PayloadIndexType, SegmentType, StorageType};
+
 use crate::collection_manager::holders::segment_holder::{
     LockedSegment, LockedSegmentHolder, SegmentId,
 };
@@ -5,9 +12,6 @@ use crate::collection_manager::optimizers::segment_optimizer::{
     OptimizerThresholds, SegmentOptimizer,
 };
 use crate::config::CollectionParams;
-use segment::types::{HnswConfig, Indexes, PayloadIndexType, SegmentType, StorageType};
-use std::collections::HashSet;
-use std::path::{Path, PathBuf};
 
 /// Looks for the segments, which require to be indexed.
 /// If segment is too large, but still does not have indexes - it is time to create some indexes.
@@ -19,6 +23,7 @@ pub struct IndexingOptimizer {
     collection_temp_dir: PathBuf,
     collection_params: CollectionParams,
     hnsw_config: HnswConfig,
+    schema_store: Arc<SchemaStorage>,
 }
 
 impl IndexingOptimizer {
@@ -28,6 +33,7 @@ impl IndexingOptimizer {
         collection_temp_dir: PathBuf,
         collection_params: CollectionParams,
         hnsw_config: HnswConfig,
+        schema_store: Arc<SchemaStorage>,
     ) -> Self {
         IndexingOptimizer {
             thresholds_config,
@@ -35,6 +41,7 @@ impl IndexingOptimizer {
             collection_temp_dir,
             collection_params,
             hnsw_config,
+            schema_store,
         }
     }
 
@@ -130,6 +137,10 @@ impl SegmentOptimizer for IndexingOptimizer {
             Some((segment_id, _segment)) => vec![segment_id],
         }
     }
+
+    fn schema_store(&self) -> Arc<SchemaStorage> {
+        self.schema_store.clone()
+    }
 }
 
 #[cfg(test)]
@@ -144,17 +155,17 @@ mod tests {
 
     use segment::types::StorageType;
 
+    use crate::collection_manager::fixtures::random_segment;
+    use crate::collection_manager::holders::segment_holder::SegmentHolder;
+    use crate::collection_manager::segments_updater::{
+        process_field_index_operation, process_point_operation,
+    };
     use crate::operations::point_ops::{
         Batch, PointInsertOperations, PointOperations, PointsBatch,
     };
     use crate::operations::FieldIndexOperations;
 
     use super::*;
-    use crate::collection_manager::fixtures::random_segment;
-    use crate::collection_manager::holders::segment_holder::SegmentHolder;
-    use crate::collection_manager::segments_updater::{
-        process_field_index_operation, process_point_operation,
-    };
 
     fn init() {
         let _ = env_logger::builder().is_test(true).try_init();
@@ -198,6 +209,7 @@ mod tests {
                 distance: segment_config.distance,
             },
             Default::default(),
+            Arc::new(SchemaStorage::new()),
         );
 
         let locked_holder = Arc::new(RwLock::new(holder));

commit 2bb52abc71541401a07b3371e8bf4edafecc74f6
Author: Egor Ivkov <e.o.ivkov@gmail.com>
Date:   Mon Mar 7 16:22:47 2022 +0300

    Multiple shards in collection (#360)
    
    * Multiple shards in collection
    
    * Collection and Shard async drop
    
    * Generate APIs for shard_number param

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index db42686f7..1b2e9c051 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -207,6 +207,7 @@ mod tests {
             CollectionParams {
                 vector_size: segment_config.vector_size,
                 distance: segment_config.distance,
+                shard_number: 1,
             },
             Default::default(),
             Arc::new(SchemaStorage::new()),

commit 960937b58bd5fa23667f552b1a6368b537876aa8
Author: Egor Ivkov <e.o.ivkov@gmail.com>
Date:   Fri Mar 11 19:26:09 2022 +0300

    Sharding related collection API changes (#381)
    
    * NonZeroU32 shard number
    
    * Inconsistent Failure option
    
    * Generate docs and apis

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 1b2e9c051..bb1b407c8 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -145,6 +145,7 @@ impl SegmentOptimizer for IndexingOptimizer {
 
 #[cfg(test)]
 mod tests {
+    use std::num::NonZeroU32;
     use std::ops::Deref;
     use std::sync::atomic::AtomicBool;
     use std::sync::Arc;
@@ -207,7 +208,7 @@ mod tests {
             CollectionParams {
                 vector_size: segment_config.vector_size,
                 distance: segment_config.distance,
-                shard_number: 1,
+                shard_number: NonZeroU32::new(1).unwrap(),
             },
             Default::default(),
             Arc::new(SchemaStorage::new()),

commit f69a7b740fb57da8ed887f36afb173a3f3846c66
Author: Gabriel Velo <gabriel.velo@gmail.com>
Date:   Mon Mar 21 07:09:10 2022 -0300

    json as payload (#306)
    
    add json as payload
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index bb1b407c8..4163a9a76 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -1,8 +1,6 @@
 use std::collections::HashSet;
 use std::path::{Path, PathBuf};
-use std::sync::Arc;
 
-use segment::payload_storage::schema_storage::SchemaStorage;
 use segment::types::{HnswConfig, Indexes, PayloadIndexType, SegmentType, StorageType};
 
 use crate::collection_manager::holders::segment_holder::{
@@ -23,7 +21,6 @@ pub struct IndexingOptimizer {
     collection_temp_dir: PathBuf,
     collection_params: CollectionParams,
     hnsw_config: HnswConfig,
-    schema_store: Arc<SchemaStorage>,
 }
 
 impl IndexingOptimizer {
@@ -33,7 +30,6 @@ impl IndexingOptimizer {
         collection_temp_dir: PathBuf,
         collection_params: CollectionParams,
         hnsw_config: HnswConfig,
-        schema_store: Arc<SchemaStorage>,
     ) -> Self {
         IndexingOptimizer {
             thresholds_config,
@@ -41,7 +37,6 @@ impl IndexingOptimizer {
             collection_temp_dir,
             collection_params,
             hnsw_config,
-            schema_store,
         }
     }
 
@@ -137,10 +132,6 @@ impl SegmentOptimizer for IndexingOptimizer {
             Some((segment_id, _segment)) => vec![segment_id],
         }
     }
-
-    fn schema_store(&self) -> Arc<SchemaStorage> {
-        self.schema_store.clone()
-    }
 }
 
 #[cfg(test)]
@@ -152,9 +143,10 @@ mod tests {
 
     use itertools::Itertools;
     use parking_lot::lock_api::RwLock;
+    use serde_json::json;
     use tempdir::TempDir;
 
-    use segment::types::StorageType;
+    use segment::types::{Payload, PayloadSchemaType, StorageType};
 
     use crate::collection_manager::fixtures::random_segment;
     use crate::collection_manager::holders::segment_holder::SegmentHolder;
@@ -164,7 +156,7 @@ mod tests {
     use crate::operations::point_ops::{
         Batch, PointInsertOperations, PointOperations, PointsBatch,
     };
-    use crate::operations::FieldIndexOperations;
+    use crate::operations::{CreateIndex, FieldIndexOperations};
 
     use super::*;
 
@@ -211,7 +203,6 @@ mod tests {
                 shard_number: NonZeroU32::new(1).unwrap(),
             },
             Default::default(),
-            Arc::new(SchemaStorage::new()),
         );
 
         let locked_holder = Arc::new(RwLock::new(holder));
@@ -234,7 +225,10 @@ mod tests {
         process_field_index_operation(
             locked_holder.deref(),
             opnum.next().unwrap(),
-            &FieldIndexOperations::CreateIndex(payload_field.clone()),
+            &FieldIndexOperations::CreateIndex(CreateIndex {
+                field_name: payload_field.to_owned(),
+                field_type: Some(PayloadSchemaType::Integer),
+            }),
         )
         .unwrap();
 
@@ -305,15 +299,17 @@ mod tests {
 
         for info in &infos {
             assert!(
-                info.schema.contains_key(&payload_field),
+                info.index_schema.contains_key(&payload_field),
                 "Testing that payload is not lost"
             );
-            assert!(
-                info.schema[&payload_field].indexed,
-                "Testing that payload index is not lost"
+            assert_eq!(
+                info.index_schema[&payload_field].data_type,
+                PayloadSchemaType::Integer,
+                "Testing that payload type is not lost"
             );
         }
 
+        let point_payload: Payload = json!({"number":10000i64}).into();
         let insert_point_ops =
             PointOperations::UpsertPoints(PointInsertOperations::PointsBatch(PointsBatch {
                 batch: Batch {
@@ -323,7 +319,11 @@ mod tests {
                         vec![1.0, 0.0, 0.5, 0.5],
                         vec![1.0, 0.0, 0.5, 1.0],
                     ],
-                    payloads: None,
+                    payloads: Some(vec![
+                        Some(point_payload.clone()),
+                        Some(point_payload.clone()),
+                        Some(point_payload),
+                    ]),
                 },
             }));
 

commit 036c186e0dfffae10b1319c7621c20752f6e39e3
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Mon May 23 13:28:17 2022 +0200

    Better error reporting in enums (#587)
    
    * remove conflicting deprecated apis
    
    * implement custom JsonSchema for the PointInsertOperations
    
    * fmt
    
    * clippy
    
    * revert unnesessare changes

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 4163a9a76..2baf19428 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -153,9 +153,7 @@ mod tests {
     use crate::collection_manager::segments_updater::{
         process_field_index_operation, process_point_operation,
     };
-    use crate::operations::point_ops::{
-        Batch, PointInsertOperations, PointOperations, PointsBatch,
-    };
+    use crate::operations::point_ops::{Batch, PointInsertOperations, PointOperations};
     use crate::operations::{CreateIndex, FieldIndexOperations};
 
     use super::*;
@@ -205,7 +203,7 @@ mod tests {
             Default::default(),
         );
 
-        let locked_holder = Arc::new(RwLock::new(holder));
+        let locked_holder: Arc<RwLock<_, _>> = Arc::new(RwLock::new(holder));
 
         let excluded_ids = Default::default();
 
@@ -311,20 +309,18 @@ mod tests {
 
         let point_payload: Payload = json!({"number":10000i64}).into();
         let insert_point_ops =
-            PointOperations::UpsertPoints(PointInsertOperations::PointsBatch(PointsBatch {
-                batch: Batch {
-                    ids: vec![501.into(), 502.into(), 503.into()],
-                    vectors: vec![
-                        vec![1.0, 0.0, 0.5, 0.0],
-                        vec![1.0, 0.0, 0.5, 0.5],
-                        vec![1.0, 0.0, 0.5, 1.0],
-                    ],
-                    payloads: Some(vec![
-                        Some(point_payload.clone()),
-                        Some(point_payload.clone()),
-                        Some(point_payload),
-                    ]),
-                },
+            PointOperations::UpsertPoints(PointInsertOperations::PointsBatch(Batch {
+                ids: vec![501.into(), 502.into(), 503.into()],
+                vectors: vec![
+                    vec![1.0, 0.0, 0.5, 0.0],
+                    vec![1.0, 0.0, 0.5, 0.5],
+                    vec![1.0, 0.0, 0.5, 1.0],
+                ],
+                payloads: Some(vec![
+                    Some(point_payload.clone()),
+                    Some(point_payload.clone()),
+                    Some(point_payload),
+                ]),
             }));
 
         let smallest_size = infos
@@ -380,16 +376,14 @@ mod tests {
         );
 
         let insert_point_ops =
-            PointOperations::UpsertPoints(PointInsertOperations::PointsBatch(PointsBatch {
-                batch: Batch {
-                    ids: vec![601.into(), 602.into(), 603.into()],
-                    vectors: vec![
-                        vec![0.0, 1.0, 0.5, 0.0],
-                        vec![0.0, 1.0, 0.5, 0.5],
-                        vec![0.0, 1.0, 0.5, 1.0],
-                    ],
-                    payloads: None,
-                },
+            PointOperations::UpsertPoints(PointInsertOperations::PointsBatch(Batch {
+                ids: vec![601.into(), 602.into(), 603.into()],
+                vectors: vec![
+                    vec![0.0, 1.0, 0.5, 0.0],
+                    vec![0.0, 1.0, 0.5, 0.5],
+                    vec![0.0, 1.0, 0.5, 1.0],
+                ],
+                payloads: None,
             }));
 
         process_point_operation(

commit 1b458780eb196ebbbd7fb1f6c5d85ce3b15adb64
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Wed Jun 1 17:23:34 2022 +0200

    On disk payload storage (#634)
    
    * implement on-disk payload storage
    
    * fmt + clippy
    
    * config param for on-disk payload storage
    
    * upd openapi definitions
    
    * add integration test with on-disk payload
    
    * fix clippy
    
    * review fixes
    
    * fmt

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 2baf19428..d5b64cd03 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -199,6 +199,7 @@ mod tests {
                 vector_size: segment_config.vector_size,
                 distance: segment_config.distance,
                 shard_number: NonZeroU32::new(1).unwrap(),
+                on_disk_payload: false,
             },
             Default::default(),
         );

commit 2601c017de71bbb46bc61df256ea8263a8fe23b9
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Wed Jun 1 18:09:38 2022 +0200

    Smarter defaults (#637)
    
    * auto segments number
    
    * auto segments number
    
    * replace vector number limits with vector size limits
    
    * fmt

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index d5b64cd03..2dbb0f297 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -1,7 +1,9 @@
 use std::collections::HashSet;
 use std::path::{Path, PathBuf};
 
-use segment::types::{HnswConfig, Indexes, PayloadIndexType, SegmentType, StorageType};
+use segment::types::{
+    HnswConfig, Indexes, PayloadIndexType, SegmentType, StorageType, VECTOR_ELEMENT_SIZE,
+};
 
 use crate::collection_manager::holders::segment_holder::{
     LockedSegment, LockedSegmentHolder, SegmentId,
@@ -11,6 +13,8 @@ use crate::collection_manager::optimizers::segment_optimizer::{
 };
 use crate::config::CollectionParams;
 
+const BYTES_IN_KB: usize = 1024;
+
 /// Looks for the segments, which require to be indexed.
 /// If segment is too large, but still does not have indexes - it is time to create some indexes.
 /// The process of index creation is slow and CPU-bounded, so it is convenient to perform
@@ -57,6 +61,7 @@ impl IndexingOptimizer {
                 let segment_entry = segment.get();
                 let read_segment = segment_entry.read();
                 let vector_count = read_segment.vectors_count();
+                let vector_size = vector_count * read_segment.vector_dim() * VECTOR_ELEMENT_SIZE;
 
                 let segment_config = read_segment.config();
 
@@ -80,10 +85,14 @@ impl IndexingOptimizer {
                     StorageType::Mmap => true,
                 };
 
-                let big_for_mmap = vector_count >= self.thresholds_config.memmap_threshold;
-                let big_for_index = vector_count >= self.thresholds_config.indexing_threshold;
+                let big_for_mmap =
+                    vector_size >= self.thresholds_config.memmap_threshold * BYTES_IN_KB;
+                let big_for_index =
+                    vector_size >= self.thresholds_config.indexing_threshold * BYTES_IN_KB;
+
+                // ToDo: remove deprecated
                 let big_for_payload_index =
-                    vector_count >= self.thresholds_config.payload_indexing_threshold;
+                    vector_size >= self.thresholds_config.payload_indexing_threshold * BYTES_IN_KB;
 
                 let has_payload = !read_segment.get_indexed_fields().is_empty();
 
@@ -92,11 +101,11 @@ impl IndexingOptimizer {
                     || (has_payload && big_for_payload_index && !is_payload_indexed);
 
                 match require_indexing {
-                    true => Some((*idx, vector_count)),
+                    true => Some((*idx, vector_size)),
                     false => None,
                 }
             })
-            .max_by_key(|(_, num_vectors)| *num_vectors)
+            .max_by_key(|(_, vector_size)| *vector_size)
             .map(|(idx, _)| (idx, segments_read_guard.get(idx).unwrap().clone()))
     }
 }
@@ -143,6 +152,8 @@ mod tests {
 
     use itertools::Itertools;
     use parking_lot::lock_api::RwLock;
+    use rand::thread_rng;
+    use segment::fixtures::index_fixtures::random_vector;
     use serde_json::json;
     use tempdir::TempDir;
 
@@ -166,12 +177,13 @@ mod tests {
     fn test_indexing_optimizer() {
         init();
 
+        let mut rng = thread_rng();
         let mut holder = SegmentHolder::default();
 
         let payload_field = "number".to_owned();
 
         let stopped = AtomicBool::new(false);
-        let dim = 4;
+        let dim = 256;
 
         let segments_dir = TempDir::new("segments_dir").unwrap();
         let segments_temp_dir = TempDir::new("segments_temp_dir").unwrap();
@@ -313,9 +325,9 @@ mod tests {
             PointOperations::UpsertPoints(PointInsertOperations::PointsBatch(Batch {
                 ids: vec![501.into(), 502.into(), 503.into()],
                 vectors: vec![
-                    vec![1.0, 0.0, 0.5, 0.0],
-                    vec![1.0, 0.0, 0.5, 0.5],
-                    vec![1.0, 0.0, 0.5, 1.0],
+                    random_vector(&mut rng, dim),
+                    random_vector(&mut rng, dim),
+                    random_vector(&mut rng, dim),
                 ],
                 payloads: Some(vec![
                     Some(point_payload.clone()),
@@ -380,9 +392,9 @@ mod tests {
             PointOperations::UpsertPoints(PointInsertOperations::PointsBatch(Batch {
                 ids: vec![601.into(), 602.into(), 603.into()],
                 vectors: vec![
-                    vec![0.0, 1.0, 0.5, 0.0],
-                    vec![0.0, 1.0, 0.5, 0.5],
-                    vec![0.0, 1.0, 0.5, 1.0],
+                    random_vector(&mut rng, dim),
+                    random_vector(&mut rng, dim),
+                    random_vector(&mut rng, dim),
                 ],
                 payloads: None,
             }));

commit c15981092ac33c7dde9541ab4a2df558e6abe4e6
Author: Gabriel Velo <gabriel.velo@gmail.com>
Date:   Mon Jun 6 12:14:20 2022 -0300

    [WIP] [real-time index] Implement payloadstorage for structpayloadindex (#642)
    
    * [real-time index] Extend FieldIndex enum and StructPayloadIndex with method from PayloadStorage
    
    * [real-time index] add missing remove_point methods
    
    * [real-time index] add new index to FieldIndex enum
    
    * fix compile
    
    * are you happy fmt
    
    * merge load and remove
    
    * fix test generics
    
    * decrement points count
    
    * remove from histogram
    
    * simplify histogram usage
    
    * [real-time index] remove old tests and fix clippy warnings
    
    * histogram: method to derive range by size (#657)
    
    * [real-time index] add histogram based payload_blocks implementation.
    
    * payload blocks
    
    * fmt
    
    * clippy
    
    * [real-time index] refactor Segment to use PayloadIndex instead of PayloadStorage.
    
    * fix tests
    
    * fmt
    
    * clippy
    
    * rename indexes
    
    * remove redundent params
    
    * add struct payload deletion test + fix delete payload in map index
    
    * remove payload threshold
    
    Co-authored-by: Ivan Pleshkov <pleshkov.ivan@gmail.com>
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 2dbb0f297..e51a3ed07 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -1,9 +1,7 @@
 use std::collections::HashSet;
 use std::path::{Path, PathBuf};
 
-use segment::types::{
-    HnswConfig, Indexes, PayloadIndexType, SegmentType, StorageType, VECTOR_ELEMENT_SIZE,
-};
+use segment::types::{HnswConfig, Indexes, SegmentType, StorageType, VECTOR_ELEMENT_SIZE};
 
 use crate::collection_manager::holders::segment_holder::{
     LockedSegment, LockedSegmentHolder, SegmentId,
@@ -75,11 +73,6 @@ impl IndexingOptimizer {
                     Indexes::Hnsw(_) => true,
                 };
 
-                let is_payload_indexed = match segment_config.payload_index.unwrap_or_default() {
-                    PayloadIndexType::Plain => false,
-                    PayloadIndexType::Struct => true,
-                };
-
                 let is_memmaped = match segment_config.storage_type {
                     StorageType::InMemory => false,
                     StorageType::Mmap => true,
@@ -90,15 +83,8 @@ impl IndexingOptimizer {
                 let big_for_index =
                     vector_size >= self.thresholds_config.indexing_threshold * BYTES_IN_KB;
 
-                // ToDo: remove deprecated
-                let big_for_payload_index =
-                    vector_size >= self.thresholds_config.payload_indexing_threshold * BYTES_IN_KB;
-
-                let has_payload = !read_segment.get_indexed_fields().is_empty();
-
-                let require_indexing = (big_for_mmap && !is_memmaped)
-                    || (big_for_index && !is_vector_indexed)
-                    || (has_payload && big_for_payload_index && !is_payload_indexed);
+                let require_indexing =
+                    (big_for_mmap && !is_memmaped) || (big_for_index && !is_vector_indexed);
 
                 match require_indexing {
                     true => Some((*idx, vector_size)),
@@ -203,7 +189,6 @@ mod tests {
             OptimizerThresholds {
                 memmap_threshold: 1000,
                 indexing_threshold: 1000,
-                payload_indexing_threshold: 50,
             },
             segments_dir.path().to_owned(),
             segments_temp_dir.path().to_owned(),
@@ -369,7 +354,7 @@ mod tests {
         // ---- New appendable segment should be created if none left
 
         // Index even the smallest segment
-        index_optimizer.thresholds_config.payload_indexing_threshold = 20;
+        index_optimizer.thresholds_config.indexing_threshold = 20;
         let suggested_to_optimize =
             index_optimizer.check_condition(locked_holder.clone(), &Default::default());
         assert!(suggested_to_optimize.contains(&small_segment_id));

commit 0edbc9d1e5d1a9108f496cbb921b0d11b11ef619
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Wed Jun 8 00:42:48 2022 +0200

    bug fix: move local shard config save to collection level

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index e51a3ed07..9c1be11c6 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -210,13 +210,30 @@ mod tests {
             index_optimizer.check_condition(locked_holder.clone(), &excluded_ids);
         assert!(suggested_to_optimize.is_empty());
 
-        index_optimizer.thresholds_config.memmap_threshold = 150;
+        index_optimizer.thresholds_config.memmap_threshold = 1000;
         index_optimizer.thresholds_config.indexing_threshold = 50;
 
         let suggested_to_optimize =
             index_optimizer.check_condition(locked_holder.clone(), &excluded_ids);
         assert!(suggested_to_optimize.contains(&large_segment_id));
 
+        index_optimizer.thresholds_config.memmap_threshold = 1000;
+        index_optimizer.thresholds_config.indexing_threshold = 1000;
+
+        let suggested_to_optimize =
+            index_optimizer.check_condition(locked_holder.clone(), &excluded_ids);
+        assert!(suggested_to_optimize.is_empty());
+
+        index_optimizer.thresholds_config.memmap_threshold = 50;
+        index_optimizer.thresholds_config.indexing_threshold = 1000;
+
+        let suggested_to_optimize =
+            index_optimizer.check_condition(locked_holder.clone(), &excluded_ids);
+        assert!(suggested_to_optimize.contains(&large_segment_id));
+
+        index_optimizer.thresholds_config.memmap_threshold = 150;
+        index_optimizer.thresholds_config.indexing_threshold = 50;
+
         // ----- CREATE AN INDEXED FIELD ------
         process_field_index_operation(
             locked_holder.deref(),

commit 850e937c2a883e87622b43b3603be9ee1aaf02af
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Mon Jun 27 15:17:09 2022 +0200

    Storage points tracking refactoring (#750)
    
    * segment refactoring
    
    * rm points iterator
    
    * fmt

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 9c1be11c6..90c2add83 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -58,7 +58,7 @@ impl IndexingOptimizer {
 
                 let segment_entry = segment.get();
                 let read_segment = segment_entry.read();
-                let vector_count = read_segment.vectors_count();
+                let vector_count = read_segment.points_count();
                 let vector_size = vector_count * read_segment.vector_dim() * VECTOR_ELEMENT_SIZE;
 
                 let segment_config = read_segment.config();

commit e983b07a1521cd47771b63006defe54f74d181ce
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Sun Jul 3 01:14:05 2022 +0200

    Parallel hnsw building (#773)
    
    * parallel hnsw building
    
    * improve hnsw payload blocks condition
    
    * update indexing optimizer condition
    
    * fmt

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 90c2add83..30272c280 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -4,7 +4,7 @@ use std::path::{Path, PathBuf};
 use segment::types::{HnswConfig, Indexes, SegmentType, StorageType, VECTOR_ELEMENT_SIZE};
 
 use crate::collection_manager::holders::segment_holder::{
-    LockedSegment, LockedSegmentHolder, SegmentId,
+    LockedSegmentHolder, SegmentHolder, SegmentId,
 };
 use crate::collection_manager::optimizers::segment_optimizer::{
     OptimizerThresholds, SegmentOptimizer,
@@ -42,13 +42,57 @@ impl IndexingOptimizer {
         }
     }
 
+    fn smallest_indexed_segment(
+        &self,
+        segments: &SegmentHolder,
+        excluded_ids: &HashSet<SegmentId>,
+    ) -> Option<(SegmentId, usize)> {
+        segments
+            .iter()
+            .filter_map(|(idx, segment)| {
+                if excluded_ids.contains(idx) {
+                    // This segment is excluded externally. It might already be scheduled for optimization
+                    return None;
+                }
+
+                let segment_entry = segment.get();
+                let read_segment = segment_entry.read();
+                let vector_count = read_segment.points_count();
+                let vector_size = vector_count * read_segment.vector_dim() * VECTOR_ELEMENT_SIZE;
+
+                if read_segment.segment_type() == SegmentType::Special {
+                    return None; // Never optimize already optimized segment
+                }
+
+                let segment_config = read_segment.config();
+
+                let is_vector_indexed = match segment_config.index {
+                    Indexes::Plain { .. } => false,
+                    Indexes::Hnsw(_) => true,
+                };
+
+                let is_memmaped = match segment_config.storage_type {
+                    StorageType::InMemory => false,
+                    StorageType::Mmap => true,
+                };
+
+                if !(is_vector_indexed || is_memmaped) {
+                    return None;
+                }
+
+                Some((idx, vector_size))
+            })
+            .min_by_key(|(_, vector_size)| *vector_size)
+            .map(|(idx, size)| (*idx, size))
+    }
+
     fn worst_segment(
         &self,
         segments: LockedSegmentHolder,
         excluded_ids: &HashSet<SegmentId>,
-    ) -> Option<(SegmentId, LockedSegment)> {
+    ) -> Vec<SegmentId> {
         let segments_read_guard = segments.read();
-        segments_read_guard
+        let candidates: Vec<_> = segments_read_guard
             .iter()
             .filter_map(|(idx, segment)| {
                 if excluded_ids.contains(idx) {
@@ -91,8 +135,42 @@ impl IndexingOptimizer {
                     false => None,
                 }
             })
-            .max_by_key(|(_, vector_size)| *vector_size)
-            .map(|(idx, _)| (idx, segments_read_guard.get(idx).unwrap().clone()))
+            .collect();
+        let selected_segment = candidates
+            .iter()
+            .max_by_key(|(_, vector_size)| *vector_size);
+        if selected_segment.is_none() {
+            return vec![];
+        }
+        let (selected_segment_id, selected_segment_size) = *selected_segment.unwrap();
+        // It is better for scheduling if indexing optimizer optimizes 2 segments.
+        // Because result of the optimization is usually 2 segment - it should preserve
+        // overall count of segments.
+        let smallest_unindexed = candidates
+            .iter()
+            .min_by_key(|(_, vector_size)| *vector_size);
+
+        if let Some((idx, size)) = smallest_unindexed {
+            if *idx != selected_segment_id
+                && selected_segment_size + size
+                    < self.thresholds_config.max_segment_size * BYTES_IN_KB
+            {
+                return vec![selected_segment_id, *idx];
+            }
+        }
+
+        let smallest_indexed = self.smallest_indexed_segment(&segments_read_guard, excluded_ids);
+
+        if let Some((idx, size)) = smallest_indexed {
+            if idx != selected_segment_id
+                && selected_segment_size + size
+                    < self.thresholds_config.max_segment_size * BYTES_IN_KB
+            {
+                return vec![selected_segment_id, idx];
+            }
+        }
+
+        vec![selected_segment_id]
     }
 }
 
@@ -122,10 +200,7 @@ impl SegmentOptimizer for IndexingOptimizer {
         segments: LockedSegmentHolder,
         excluded_ids: &HashSet<SegmentId>,
     ) -> Vec<SegmentId> {
-        match self.worst_segment(segments, excluded_ids) {
-            None => vec![],
-            Some((segment_id, _segment)) => vec![segment_id],
-        }
+        self.worst_segment(segments, excluded_ids)
     }
 }
 
@@ -176,17 +251,21 @@ mod tests {
         let mut opnum = 101..1000000;
 
         let small_segment = random_segment(segments_dir.path(), opnum.next().unwrap(), 25, dim);
+        let middle_low_segment =
+            random_segment(segments_dir.path(), opnum.next().unwrap(), 90, dim);
         let middle_segment = random_segment(segments_dir.path(), opnum.next().unwrap(), 100, dim);
         let large_segment = random_segment(segments_dir.path(), opnum.next().unwrap(), 200, dim);
 
         let segment_config = small_segment.segment_config.clone();
 
         let small_segment_id = holder.add(small_segment);
+        let middle_low_segment_id = holder.add(middle_low_segment);
         let middle_segment_id = holder.add(middle_segment);
         let large_segment_id = holder.add(large_segment);
 
         let mut index_optimizer = IndexingOptimizer::new(
             OptimizerThresholds {
+                max_segment_size: 300,
                 memmap_threshold: 1000,
                 indexing_threshold: 1000,
             },
@@ -216,6 +295,7 @@ mod tests {
         let suggested_to_optimize =
             index_optimizer.check_condition(locked_holder.clone(), &excluded_ids);
         assert!(suggested_to_optimize.contains(&large_segment_id));
+        assert!(suggested_to_optimize.contains(&middle_low_segment_id));
 
         index_optimizer.thresholds_config.memmap_threshold = 1000;
         index_optimizer.thresholds_config.indexing_threshold = 1000;
@@ -385,9 +465,14 @@ mod tests {
             .map(|(_sid, segment)| segment.get().read().info())
             .collect_vec();
 
+        let mut has_empty = false;
+        for info in new_infos2 {
+            has_empty |= info.num_vectors == 0;
+        }
+
         assert!(
-            new_infos2.len() > new_infos.len(),
-            "Check that new appendable segment was created"
+            has_empty,
+            "Testing that new segment is created if none left"
         );
 
         let insert_point_ops =

commit 026bd040b001f1c66e16fc911322f1f182d1cf0f
Author: Egor Ivkov <e.o.ivkov@gmail.com>
Date:   Fri Jul 15 15:42:25 2022 +0300

    Add import formatting rules (#820)
    
    * Add import formatting rules
    
    * Review fix: update rusty hook

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 30272c280..b69088322 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -215,11 +215,11 @@ mod tests {
     use parking_lot::lock_api::RwLock;
     use rand::thread_rng;
     use segment::fixtures::index_fixtures::random_vector;
+    use segment::types::{Payload, PayloadSchemaType, StorageType};
     use serde_json::json;
     use tempdir::TempDir;
 
-    use segment::types::{Payload, PayloadSchemaType, StorageType};
-
+    use super::*;
     use crate::collection_manager::fixtures::random_segment;
     use crate::collection_manager::holders::segment_holder::SegmentHolder;
     use crate::collection_manager::segments_updater::{
@@ -228,8 +228,6 @@ mod tests {
     use crate::operations::point_ops::{Batch, PointInsertOperations, PointOperations};
     use crate::operations::{CreateIndex, FieldIndexOperations};
 
-    use super::*;
-
     fn init() {
         let _ = env_logger::builder().is_test(true).try_init();
     }

commit dc4cccde3d14e18cf6eac51b64909889f1c64dce
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Sun Jul 31 13:03:53 2022 +0200

    Prevent Vector size zero (#876)

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index b69088322..9dfa12321 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -206,7 +206,7 @@ impl SegmentOptimizer for IndexingOptimizer {
 
 #[cfg(test)]
 mod tests {
-    use std::num::NonZeroU32;
+    use std::num::{NonZeroU32, NonZeroU64};
     use std::ops::Deref;
     use std::sync::atomic::AtomicBool;
     use std::sync::Arc;
@@ -270,7 +270,7 @@ mod tests {
             segments_dir.path().to_owned(),
             segments_temp_dir.path().to_owned(),
             CollectionParams {
-                vector_size: segment_config.vector_size,
+                vector_size: NonZeroU64::new(segment_config.vector_size as u64).unwrap(),
                 distance: segment_config.distance,
                 shard_number: NonZeroU32::new(1).unwrap(),
                 on_disk_payload: false,

commit c53f19c0dd5110215bdcce57f07f1a2a6793907e
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Mon Aug 1 15:18:40 2022 +0200

    Disable mmap threshold (#877)
    
    * allow to disable mmap by not specifying mmap threshold
    
    * fmt
    
    * smart default max_segment_size
    
    * upd openapi for max_segment_size

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 9dfa12321..3d9becd5d 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -122,10 +122,16 @@ impl IndexingOptimizer {
                     StorageType::Mmap => true,
                 };
 
-                let big_for_mmap =
-                    vector_size >= self.thresholds_config.memmap_threshold * BYTES_IN_KB;
-                let big_for_index =
-                    vector_size >= self.thresholds_config.indexing_threshold * BYTES_IN_KB;
+                let big_for_mmap = vector_size
+                    >= self
+                        .thresholds_config
+                        .memmap_threshold
+                        .saturating_mul(BYTES_IN_KB);
+                let big_for_index = vector_size
+                    >= self
+                        .thresholds_config
+                        .indexing_threshold
+                        .saturating_mul(BYTES_IN_KB);
 
                 let require_indexing =
                     (big_for_mmap && !is_memmaped) || (big_for_index && !is_vector_indexed);
@@ -153,7 +159,10 @@ impl IndexingOptimizer {
         if let Some((idx, size)) = smallest_unindexed {
             if *idx != selected_segment_id
                 && selected_segment_size + size
-                    < self.thresholds_config.max_segment_size * BYTES_IN_KB
+                    < self
+                        .thresholds_config
+                        .max_segment_size
+                        .saturating_mul(BYTES_IN_KB)
             {
                 return vec![selected_segment_id, *idx];
             }
@@ -164,7 +173,10 @@ impl IndexingOptimizer {
         if let Some((idx, size)) = smallest_indexed {
             if idx != selected_segment_id
                 && selected_segment_size + size
-                    < self.thresholds_config.max_segment_size * BYTES_IN_KB
+                    < self
+                        .thresholds_config
+                        .max_segment_size
+                        .saturating_mul(BYTES_IN_KB)
             {
                 return vec![selected_segment_id, idx];
             }

commit 5728a0e670ed61fa0abbeec89d4ef735e2c34f03
Author: Ivan Pleshkov <pleshkov.ivan@gmail.com>
Date:   Tue Aug 2 13:30:31 2022 +0400

    optimizers and indices telemetry (#892)

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 3d9becd5d..57cdac4be 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -1,6 +1,9 @@
 use std::collections::HashSet;
 use std::path::{Path, PathBuf};
+use std::sync::Arc;
 
+use parking_lot::Mutex;
+use segment::telemetry::TelemetryOperationAggregator;
 use segment::types::{HnswConfig, Indexes, SegmentType, StorageType, VECTOR_ELEMENT_SIZE};
 
 use crate::collection_manager::holders::segment_holder::{
@@ -10,6 +13,7 @@ use crate::collection_manager::optimizers::segment_optimizer::{
     OptimizerThresholds, SegmentOptimizer,
 };
 use crate::config::CollectionParams;
+use crate::telemetry::OptimizerTelemetry;
 
 const BYTES_IN_KB: usize = 1024;
 
@@ -23,6 +27,7 @@ pub struct IndexingOptimizer {
     collection_temp_dir: PathBuf,
     collection_params: CollectionParams,
     hnsw_config: HnswConfig,
+    optimizations_telemetry_counter: Arc<Mutex<TelemetryOperationAggregator>>,
 }
 
 impl IndexingOptimizer {
@@ -39,6 +44,7 @@ impl IndexingOptimizer {
             collection_temp_dir,
             collection_params,
             hnsw_config,
+            optimizations_telemetry_counter: TelemetryOperationAggregator::new(),
         }
     }
 
@@ -214,6 +220,16 @@ impl SegmentOptimizer for IndexingOptimizer {
     ) -> Vec<SegmentId> {
         self.worst_segment(segments, excluded_ids)
     }
+
+    fn get_telemetry_data(&self) -> OptimizerTelemetry {
+        OptimizerTelemetry::Indexing {
+            optimizations: self.get_telemetry_counter().lock().get_statistics(),
+        }
+    }
+
+    fn get_telemetry_counter(&self) -> Arc<Mutex<TelemetryOperationAggregator>> {
+        self.optimizations_telemetry_counter.clone()
+    }
 }
 
 #[cfg(test)]

commit 8e1f2ca35322cc699232ec8d8177fe05baae3f98
Author: Russ Cam <russ.cam@forloop.co.uk>
Date:   Wed Aug 10 17:39:21 2022 +1000

    Use tempfile (#922)
    
    This commit replaces tempdir with tempfile.
    tempdir is archived.
    
    Closes #544

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 57cdac4be..c0a25dfd7 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -245,7 +245,7 @@ mod tests {
     use segment::fixtures::index_fixtures::random_vector;
     use segment::types::{Payload, PayloadSchemaType, StorageType};
     use serde_json::json;
-    use tempdir::TempDir;
+    use tempfile::Builder;
 
     use super::*;
     use crate::collection_manager::fixtures::random_segment;
@@ -272,8 +272,11 @@ mod tests {
         let stopped = AtomicBool::new(false);
         let dim = 256;
 
-        let segments_dir = TempDir::new("segments_dir").unwrap();
-        let segments_temp_dir = TempDir::new("segments_temp_dir").unwrap();
+        let segments_dir = Builder::new().prefix("segments_dir").tempdir().unwrap();
+        let segments_temp_dir = Builder::new()
+            .prefix("segments_temp_dir")
+            .tempdir()
+            .unwrap();
         let mut opnum = 101..1000000;
 
         let small_segment = random_segment(segments_dir.path(), opnum.next().unwrap(), 25, dim);

commit dc0314201edc69c04930cd8e6b752515b59ee74e
Author: Egor Ivkov <e.o.ivkov@gmail.com>
Date:   Wed Aug 31 11:26:52 2022 +0300

    Add replication factor (#966)
    
    * Add replication_factor config and ops to change it

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index c0a25dfd7..3eb27ae61 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -304,6 +304,7 @@ mod tests {
                 vector_size: NonZeroU64::new(segment_config.vector_size as u64).unwrap(),
                 distance: segment_config.distance,
                 shard_number: NonZeroU32::new(1).unwrap(),
+                replication_factor: NonZeroU32::new(1).unwrap(),
                 on_disk_payload: false,
             },
             Default::default(),

commit b9eee55a9fb6d53572622f62756a80e62484009e
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Thu Sep 1 12:50:12 2022 +0200

    Full text search (#963)
    
    * allow additional params for payload field index
    
    * fmt
    
    * wip: full text index building
    
    * fmt
    
    * text search request
    
    * text search request
    
    * full text index persitance and loading
    
    * fmt
    
    * enable fts index in mapping
    
    * clippy
    
    * fix tests + add integration test
    
    * review fixes: extend payload index test
    
    * revert incedental change

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 3eb27ae61..d923a0c41 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -350,7 +350,7 @@ mod tests {
             opnum.next().unwrap(),
             &FieldIndexOperations::CreateIndex(CreateIndex {
                 field_name: payload_field.to_owned(),
-                field_type: Some(PayloadSchemaType::Integer),
+                field_type: Some(PayloadSchemaType::Integer.into()),
             }),
         )
         .unwrap();

commit f6b21861939744e054a861d9771608b7e6b614e7
Author: Ivan Pleshkov <pleshkov.ivan@gmail.com>
Date:   Sun Sep 11 22:59:23 2022 +0400

    [WIP] Many named vectors per point (#958)
    
    * many named vectors per point (segment-level)
    
    * operation result for dim function
    
    * beautifulized vector name
    
    * fix naming bug
    
    * segment version migration
    
    * fmt
    
    * add segment tests
    
    * are you happy clippy
    
    * fix build
    
    * [WIP] many named vectors per point (collection-level) (#975)
    
    * config and search
    
    * fix placeholders for proxy segment move
    
    * remove VectorType from collection
    
    * are you happy fmt
    
    * vectors in grps messages
    
    * create collections with vectors
    
    * segment holder fixes
    
    * are you happy fmt
    
    * remove default vector name placeholders
    
    * are you happy fmt
    
    * are you happy clippy
    
    * fix build
    
    * fix web api
    
    * are you happy clippy
    
    * are you happy fmt
    
    * record vector&vectors
    
    * openapi update
    
    * fix openapi integration tests
    
    * segment builder fix todo
    
    * vector names for update from segment
    
    * remove unwrap
    
    * backward compatibility
    
    * upd openapi
    
    * backward compatible PointStruct
    
    * upd openapi
    
    * fix record back-comp
    
    * fmt
    
    * vector configuration backward compatibility
    
    * fix vetor storage size estimation
    
    * fmt
    
    * multi-vec segment test + index test
    
    * fmt
    
    * api integration tests
    
    * [WIP] Named vectors struct (#1002)
    
    * move to separate file
    
    * named vectors as struct
    
    * use cow
    
    * fix build
    
    * keys iterator
    
    * avoid copy in PointStruct -> get_vectors
    
    * avoid another copy
    
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>
    
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index d923a0c41..104b158e6 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -64,7 +64,14 @@ impl IndexingOptimizer {
                 let segment_entry = segment.get();
                 let read_segment = segment_entry.read();
                 let vector_count = read_segment.points_count();
-                let vector_size = vector_count * read_segment.vector_dim() * VECTOR_ELEMENT_SIZE;
+                let vector_size = vector_count
+                    * read_segment
+                        .vector_dims()
+                        .values()
+                        .max()
+                        .copied()
+                        .unwrap_or(0)
+                    * VECTOR_ELEMENT_SIZE;
 
                 if read_segment.segment_type() == SegmentType::Special {
                     return None; // Never optimize already optimized segment
@@ -109,7 +116,14 @@ impl IndexingOptimizer {
                 let segment_entry = segment.get();
                 let read_segment = segment_entry.read();
                 let vector_count = read_segment.points_count();
-                let vector_size = vector_count * read_segment.vector_dim() * VECTOR_ELEMENT_SIZE;
+                let vector_size = vector_count
+                    * read_segment
+                        .vector_dims()
+                        .values()
+                        .max()
+                        .copied()
+                        .unwrap_or(0)
+                    * VECTOR_ELEMENT_SIZE;
 
                 let segment_config = read_segment.config();
 
@@ -234,6 +248,7 @@ impl SegmentOptimizer for IndexingOptimizer {
 
 #[cfg(test)]
 mod tests {
+    use std::collections::BTreeMap;
     use std::num::{NonZeroU32, NonZeroU64};
     use std::ops::Deref;
     use std::sync::atomic::AtomicBool;
@@ -242,17 +257,19 @@ mod tests {
     use itertools::Itertools;
     use parking_lot::lock_api::RwLock;
     use rand::thread_rng;
+    use segment::data_types::vectors::DEFAULT_VECTOR_NAME;
     use segment::fixtures::index_fixtures::random_vector;
     use segment::types::{Payload, PayloadSchemaType, StorageType};
     use serde_json::json;
     use tempfile::Builder;
 
     use super::*;
-    use crate::collection_manager::fixtures::random_segment;
+    use crate::collection_manager::fixtures::{random_multi_vec_segment, random_segment};
     use crate::collection_manager::holders::segment_holder::SegmentHolder;
     use crate::collection_manager::segments_updater::{
         process_field_index_operation, process_point_operation,
     };
+    use crate::config::{VectorParams, VectorsConfig};
     use crate::operations::point_ops::{Batch, PointInsertOperations, PointOperations};
     use crate::operations::{CreateIndex, FieldIndexOperations};
 
@@ -260,6 +277,106 @@ mod tests {
         let _ = env_logger::builder().is_test(true).try_init();
     }
 
+    #[test]
+    fn test_multi_vector_optimization() {
+        init();
+        let mut holder = SegmentHolder::default();
+
+        let stopped = AtomicBool::new(false);
+        let dim1 = 128;
+        let dim2 = 256;
+
+        let segments_dir = Builder::new().prefix("segments_dir").tempdir().unwrap();
+        let segments_temp_dir = Builder::new()
+            .prefix("segments_temp_dir")
+            .tempdir()
+            .unwrap();
+        let mut opnum = 101..1000000;
+
+        let large_segment =
+            random_multi_vec_segment(segments_dir.path(), opnum.next().unwrap(), 200, dim1, dim2);
+
+        let segment_config = large_segment.segment_config.clone();
+
+        let large_segment_id = holder.add(large_segment);
+
+        let vectors_config: BTreeMap<String, VectorParams> = segment_config
+            .vector_data
+            .iter()
+            .map(|(name, params)| {
+                (
+                    name.to_string(),
+                    VectorParams {
+                        size: NonZeroU64::new(params.size as u64).unwrap(),
+                        distance: params.distance,
+                    },
+                )
+            })
+            .collect();
+
+        let mut index_optimizer = IndexingOptimizer::new(
+            OptimizerThresholds {
+                max_segment_size: 300,
+                memmap_threshold: 1000,
+                indexing_threshold: 1000,
+            },
+            segments_dir.path().to_owned(),
+            segments_temp_dir.path().to_owned(),
+            CollectionParams {
+                vectors: Some(VectorsConfig::Multi(vectors_config)),
+                vector_size: None,
+                distance: None,
+                shard_number: NonZeroU32::new(1).unwrap(),
+                replication_factor: NonZeroU32::new(1).unwrap(),
+                on_disk_payload: false,
+            },
+            Default::default(),
+        );
+        let locked_holder: Arc<RwLock<_, _>> = Arc::new(RwLock::new(holder));
+
+        let excluded_ids = Default::default();
+
+        let suggested_to_optimize =
+            index_optimizer.check_condition(locked_holder.clone(), &excluded_ids);
+        assert!(suggested_to_optimize.is_empty());
+
+        index_optimizer.thresholds_config.memmap_threshold = 1000;
+        index_optimizer.thresholds_config.indexing_threshold = 50;
+
+        let suggested_to_optimize =
+            index_optimizer.check_condition(locked_holder.clone(), &excluded_ids);
+        assert!(suggested_to_optimize.contains(&large_segment_id));
+
+        index_optimizer
+            .optimize(locked_holder.clone(), suggested_to_optimize, &stopped)
+            .unwrap();
+
+        let infos = locked_holder
+            .read()
+            .iter()
+            .map(|(_sid, segment)| segment.get().read().info())
+            .collect_vec();
+        let configs = locked_holder
+            .read()
+            .iter()
+            .map(|(_sid, segment)| segment.get().read().config())
+            .collect_vec();
+
+        assert_eq!(infos.len(), 2);
+        assert_eq!(configs.len(), 2);
+
+        let total_points: usize = infos.iter().map(|info| info.num_points).sum();
+        let total_vectors: usize = infos.iter().map(|info| info.num_vectors).sum();
+        assert_eq!(total_points, 200);
+        assert_eq!(total_vectors, 400);
+
+        for config in configs {
+            assert_eq!(config.vector_data.len(), 2);
+            assert_eq!(config.vector_data.get("vector1").unwrap().size, dim1);
+            assert_eq!(config.vector_data.get("vector2").unwrap().size, dim2);
+        }
+    }
+
     #[test]
     fn test_indexing_optimizer() {
         init();
@@ -301,8 +418,18 @@ mod tests {
             segments_dir.path().to_owned(),
             segments_temp_dir.path().to_owned(),
             CollectionParams {
-                vector_size: NonZeroU64::new(segment_config.vector_size as u64).unwrap(),
-                distance: segment_config.distance,
+                vectors: Some(VectorsConfig::Single(VectorParams {
+                    size: NonZeroU64::new(
+                        segment_config.vector_data[DEFAULT_VECTOR_NAME].size as u64,
+                    )
+                    .unwrap(),
+                    distance: segment_config.vector_data[DEFAULT_VECTOR_NAME].distance,
+                })),
+                vector_size: Some(
+                    NonZeroU64::new(segment_config.vector_data[DEFAULT_VECTOR_NAME].size as u64)
+                        .unwrap(),
+                ),
+                distance: Some(segment_config.vector_data[DEFAULT_VECTOR_NAME].distance),
                 shard_number: NonZeroU32::new(1).unwrap(),
                 replication_factor: NonZeroU32::new(1).unwrap(),
                 on_disk_payload: false,
@@ -440,7 +567,8 @@ mod tests {
                     random_vector(&mut rng, dim),
                     random_vector(&mut rng, dim),
                     random_vector(&mut rng, dim),
-                ],
+                ]
+                .into(),
                 payloads: Some(vec![
                     Some(point_payload.clone()),
                     Some(point_payload.clone()),
@@ -512,7 +640,8 @@ mod tests {
                     random_vector(&mut rng, dim),
                     random_vector(&mut rng, dim),
                     random_vector(&mut rng, dim),
-                ],
+                ]
+                .into(),
                 payloads: None,
             }));
 

commit dc07b01e1fea5cb9be3579b555be480e30aa3041
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Mon Sep 19 13:51:03 2022 +0200

    remove deprecated fields from API (#1030)
    
    * remove depricated fields from API
    
    * fmt
    
    * upd openapi and integration tests
    
    * fix grpc test
    
    * regenerate storage reference data
    
    * improve docs
    
    Co-authored-by: Arnaud Gourlay <arnaud.gourlay@gmail.com>

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 104b158e6..69826675a 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -323,9 +323,7 @@ mod tests {
             segments_dir.path().to_owned(),
             segments_temp_dir.path().to_owned(),
             CollectionParams {
-                vectors: Some(VectorsConfig::Multi(vectors_config)),
-                vector_size: None,
-                distance: None,
+                vectors: VectorsConfig::Multi(vectors_config),
                 shard_number: NonZeroU32::new(1).unwrap(),
                 replication_factor: NonZeroU32::new(1).unwrap(),
                 on_disk_payload: false,
@@ -418,18 +416,13 @@ mod tests {
             segments_dir.path().to_owned(),
             segments_temp_dir.path().to_owned(),
             CollectionParams {
-                vectors: Some(VectorsConfig::Single(VectorParams {
+                vectors: VectorsConfig::Single(VectorParams {
                     size: NonZeroU64::new(
                         segment_config.vector_data[DEFAULT_VECTOR_NAME].size as u64,
                     )
                     .unwrap(),
                     distance: segment_config.vector_data[DEFAULT_VECTOR_NAME].distance,
-                })),
-                vector_size: Some(
-                    NonZeroU64::new(segment_config.vector_data[DEFAULT_VECTOR_NAME].size as u64)
-                        .unwrap(),
-                ),
-                distance: Some(segment_config.vector_data[DEFAULT_VECTOR_NAME].distance),
+                }),
                 shard_number: NonZeroU32::new(1).unwrap(),
                 replication_factor: NonZeroU32::new(1).unwrap(),
                 on_disk_payload: false,
@@ -477,7 +470,7 @@ mod tests {
             opnum.next().unwrap(),
             &FieldIndexOperations::CreateIndex(CreateIndex {
                 field_name: payload_field.to_owned(),
-                field_type: Some(PayloadSchemaType::Integer.into()),
+                field_schema: Some(PayloadSchemaType::Integer.into()),
             }),
         )
         .unwrap();

commit 516dcd7020e2f54d91ecdda87e08333b17d85574
Author: Ivan Pleshkov <pleshkov.ivan@gmail.com>
Date:   Sun Oct 23 02:48:55 2022 +0400

    Telemetry level of detail (#1049)
    
    * telemetry level of detail
    
    * rename duration aggregator
    
    * are you happy fmt
    
    * move total searches sum
    
    * separate levels
    
    * optional bucket size
    
    * search telemetry improvements
    
    * separate web telemetry into methods
    
    * tonic telemetry methods
    
    * merge optimizations
    
    * are you happy fmt
    
    * better rounding
    
    * qdrant configs on level 1
    
    * provide collection params
    
    * add peers count
    
    * collection points count
    
    * update openapi
    
    * use pattern in actix telemetry
    
    * are you happy fmt
    
    * merge dev
    
    * are you happy fmt
    
    * fix merge conflicts
    
    * update openapi
    
    * fix build
    
    * are you happy fmt
    
    * add exact searches statistics
    
    * process replica set
    
    * update openapi
    
    * fix wrong name
    
    * fix naming
    
    * fix unwrap
    
    * review
    
    * fmt
    
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 69826675a..4b60540c7 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -3,7 +3,9 @@ use std::path::{Path, PathBuf};
 use std::sync::Arc;
 
 use parking_lot::Mutex;
-use segment::telemetry::TelemetryOperationAggregator;
+use segment::common::operation_time_statistics::{
+    OperationDurationStatistics, OperationDurationsAggregator,
+};
 use segment::types::{HnswConfig, Indexes, SegmentType, StorageType, VECTOR_ELEMENT_SIZE};
 
 use crate::collection_manager::holders::segment_holder::{
@@ -13,7 +15,6 @@ use crate::collection_manager::optimizers::segment_optimizer::{
     OptimizerThresholds, SegmentOptimizer,
 };
 use crate::config::CollectionParams;
-use crate::telemetry::OptimizerTelemetry;
 
 const BYTES_IN_KB: usize = 1024;
 
@@ -27,7 +28,7 @@ pub struct IndexingOptimizer {
     collection_temp_dir: PathBuf,
     collection_params: CollectionParams,
     hnsw_config: HnswConfig,
-    optimizations_telemetry_counter: Arc<Mutex<TelemetryOperationAggregator>>,
+    telemetry_durations_aggregator: Arc<Mutex<OperationDurationsAggregator>>,
 }
 
 impl IndexingOptimizer {
@@ -44,7 +45,7 @@ impl IndexingOptimizer {
             collection_temp_dir,
             collection_params,
             hnsw_config,
-            optimizations_telemetry_counter: TelemetryOperationAggregator::new(),
+            telemetry_durations_aggregator: OperationDurationsAggregator::new(),
         }
     }
 
@@ -235,14 +236,12 @@ impl SegmentOptimizer for IndexingOptimizer {
         self.worst_segment(segments, excluded_ids)
     }
 
-    fn get_telemetry_data(&self) -> OptimizerTelemetry {
-        OptimizerTelemetry::Indexing {
-            optimizations: self.get_telemetry_counter().lock().get_statistics(),
-        }
+    fn get_telemetry_data(&self) -> OperationDurationStatistics {
+        self.get_telemetry_counter().lock().get_statistics()
     }
 
-    fn get_telemetry_counter(&self) -> Arc<Mutex<TelemetryOperationAggregator>> {
-        self.optimizations_telemetry_counter.clone()
+    fn get_telemetry_counter(&self) -> Arc<Mutex<OperationDurationsAggregator>> {
+        self.telemetry_durations_aggregator.clone()
     }
 }
 

commit 664d9bd93be71532061ffbc2ff9c2b4c11f3d20f
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Tue Oct 25 17:37:15 2022 +0200

    implement concern-factor, forbig disabling the last node, improve tes… (#1168)
    
    * implement concern-factor, forbig disabling the last node, improve test stability
    
    * upd docs
    
    * improve test_recover_dead_node
    
    * rename to write_consistency_factor
    
    * Fix bug: applied index higher than commit on restart (#1172)
    
    * create collection with default status = dead + await for activation on create_collecton_op_submit
    
    * fmt
    
    * fix unit tests
    
    Co-authored-by: Egor Ivkov <e.o.ivkov@gmail.com>

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 4b60540c7..c054accc6 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -325,6 +325,7 @@ mod tests {
                 vectors: VectorsConfig::Multi(vectors_config),
                 shard_number: NonZeroU32::new(1).unwrap(),
                 replication_factor: NonZeroU32::new(1).unwrap(),
+                write_consistency_factor: NonZeroU32::new(1).unwrap(),
                 on_disk_payload: false,
             },
             Default::default(),
@@ -424,6 +425,7 @@ mod tests {
                 }),
                 shard_number: NonZeroU32::new(1).unwrap(),
                 replication_factor: NonZeroU32::new(1).unwrap(),
+                write_consistency_factor: NonZeroU32::new(1).unwrap(),
                 on_disk_payload: false,
             },
             Default::default(),

commit 63b59c1044b2da42e493b4592cfe56e7699e8a95
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Wed Nov 9 12:58:06 2022 +0100

    fix colletion params update (#1208)

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index c054accc6..520afdfc4 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -268,8 +268,8 @@ mod tests {
     use crate::collection_manager::segments_updater::{
         process_field_index_operation, process_point_operation,
     };
-    use crate::config::{VectorParams, VectorsConfig};
     use crate::operations::point_ops::{Batch, PointInsertOperations, PointOperations};
+    use crate::operations::types::{VectorParams, VectorsConfig};
     use crate::operations::{CreateIndex, FieldIndexOperations};
 
     fn init() {

commit 66aa2c99cedbdc31648feb0b28cb469d7021bef4
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Thu Jan 26 17:48:52 2023 +0100

    Clippy rust 1.67 (#1406)
    
    * inline format! args
    
    * inline format! args
    
    * explicit lifetime could be elided
    
    * fmt

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 520afdfc4..6f46c1783 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -480,7 +480,7 @@ mod tests {
         let suggested_to_optimize =
             index_optimizer.check_condition(locked_holder.clone(), &excluded_ids);
         assert!(suggested_to_optimize.contains(&large_segment_id));
-        eprintln!("suggested_to_optimize = {:#?}", suggested_to_optimize);
+        eprintln!("suggested_to_optimize = {suggested_to_optimize:#?}");
         index_optimizer
             .optimize(locked_holder.clone(), suggested_to_optimize, &stopped)
             .unwrap();

commit 128e49fcc3633e361df33818de6cca0aab95da10
Author: Ivan Pleshkov <pleshkov.ivan@gmail.com>
Date:   Fri Mar 3 20:46:17 2023 +0400

    integrate quantized data to storages (#1311)
    
    * integrate quantized data to storages
    
    * revert gitignore
    
    * are you happy clippy
    
    * quantize in optimizer
    
    * provide flag
    
    * fix segfault
    
    * skip quantization flag, update scores
    
    * use quantization flag
    
    * are you happy fmt
    
    * use quantization flag
    
    * quantized search test
    
    * are you happy fmt
    
    * refactor test, refactor scorer choosing
    
    * are you happy fmt
    
    * run quantization on segment builder
    
    * decrease testing parameters
    
    * simplify segment
    
    * update version
    
    * remove use_quantization flag
    
    * provide quantization config
    
    * quantization version up
    
    * euclid dist
    
    * add euclid test
    
    * saveload
    
    * fix initialization bugs
    
    * quantization lib version up
    
    * fix arm build
    
    * refactor scorer selecting
    
    * quant lib version up
    
    * are you happy fmt
    
    * are you happy fmt
    
    * are you happy clippy
    
    * add save/load test for simple storage
    
    * add comments
    
    * quantiles
    
    * quantization mmap
    
    * remove f32
    
    * mmap test
    
    * fix mmap slice
    
    * fix mmap test
    
    * use chunks for quantization storage
    
    * fix build
    
    * are you happy fmt
    
    * update quantization library
    
    * update quantization lib
    
    * update quantization lib
    
    * integrate api changes
    
    * are you happy fmt
    
    * change quantization api
    
    * additional checks in tests
    
    * update quantization version
    
    * fix unit tests
    
    * add quantization to storage config
    
    * use quantization for all cardinality search cases
    
    * Integrate quantization suggestions 2 (#1520)
    
    * review api
    
    * wip: refactor quantization integrations
    
    * wip: refactor quantization integrations
    
    * wip: fmt
    
    * include quantization into snapshot
    
    * fmt
    
    ---------
    
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 6f46c1783..63070202e 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -6,7 +6,9 @@ use parking_lot::Mutex;
 use segment::common::operation_time_statistics::{
     OperationDurationStatistics, OperationDurationsAggregator,
 };
-use segment::types::{HnswConfig, Indexes, SegmentType, StorageType, VECTOR_ELEMENT_SIZE};
+use segment::types::{
+    HnswConfig, Indexes, QuantizationConfig, SegmentType, StorageType, VECTOR_ELEMENT_SIZE,
+};
 
 use crate::collection_manager::holders::segment_holder::{
     LockedSegmentHolder, SegmentHolder, SegmentId,
@@ -28,6 +30,7 @@ pub struct IndexingOptimizer {
     collection_temp_dir: PathBuf,
     collection_params: CollectionParams,
     hnsw_config: HnswConfig,
+    quantization_config: Option<QuantizationConfig>,
     telemetry_durations_aggregator: Arc<Mutex<OperationDurationsAggregator>>,
 }
 
@@ -38,6 +41,7 @@ impl IndexingOptimizer {
         collection_temp_dir: PathBuf,
         collection_params: CollectionParams,
         hnsw_config: HnswConfig,
+        quantization_config: Option<QuantizationConfig>,
     ) -> Self {
         IndexingOptimizer {
             thresholds_config,
@@ -45,6 +49,7 @@ impl IndexingOptimizer {
             collection_temp_dir,
             collection_params,
             hnsw_config,
+            quantization_config,
             telemetry_durations_aggregator: OperationDurationsAggregator::new(),
         }
     }
@@ -224,6 +229,10 @@ impl SegmentOptimizer for IndexingOptimizer {
         self.hnsw_config
     }
 
+    fn quantization_config(&self) -> Option<QuantizationConfig> {
+        self.quantization_config.clone()
+    }
+
     fn threshold_config(&self) -> &OptimizerThresholds {
         &self.thresholds_config
     }
@@ -329,6 +338,7 @@ mod tests {
                 on_disk_payload: false,
             },
             Default::default(),
+            Default::default(),
         );
         let locked_holder: Arc<RwLock<_, _>> = Arc::new(RwLock::new(holder));
 
@@ -429,6 +439,7 @@ mod tests {
                 on_disk_payload: false,
             },
             Default::default(),
+            Default::default(),
         );
 
         let locked_holder: Arc<RwLock<_, _>> = Arc::new(RwLock::new(holder));

commit 66ba8f17af136554e5a5a707c31d8d1fd801b70c
Author: Tim Visée <tim+github@visee.me>
Date:   Mon Apr 10 17:16:56 2023 +0200

    Add vector specific HNSW configuration (#1675)
    
    * Validate VectorConfig/VectorParams, remove obsolete validation
    
    * Add HNSW config diff to vector parameters
    
    * Validate params in collection config
    
    * Add HNSW config to segment vector data config
    
    * Add VectorsConfig params iterator for more elegant conversions
    
    * Prefer vector HNSW config over collection config for building HNSW index
    
    * Base segment vector param HNSW config on collection config
    
    * General improvements
    
    * Rewrite HNSW ef_construct extract function to also consider vector configs
    
    * Update OpenAPI specification
    
    * Add test to check if vector specific HNSW config is persisted
    
    * review changes
    
    * review changes
    
    * Regenerate gRPC docs
    
    * Fix test on Windows
    
    * Regenerate OpenAPI specification
    
    ---------
    
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 63070202e..a1a027cee 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -86,7 +86,7 @@ impl IndexingOptimizer {
                 let segment_config = read_segment.config();
 
                 let is_vector_indexed = match segment_config.index {
-                    Indexes::Plain { .. } => false,
+                    Indexes::Plain {} => false,
                     Indexes::Hnsw(_) => true,
                 };
 
@@ -139,7 +139,7 @@ impl IndexingOptimizer {
 
                 // Apply indexing to plain segments which have grown too big
                 let is_vector_indexed = match segment_config.index {
-                    Indexes::Plain { .. } => false,
+                    Indexes::Plain {} => false,
                     Indexes::Hnsw(_) => true,
                 };
 
@@ -317,6 +317,7 @@ mod tests {
                     VectorParams {
                         size: NonZeroU64::new(params.size as u64).unwrap(),
                         distance: params.distance,
+                        hnsw_config: None,
                     },
                 )
             })
@@ -432,6 +433,7 @@ mod tests {
                     )
                     .unwrap(),
                     distance: segment_config.vector_data[DEFAULT_VECTOR_NAME].distance,
+                    hnsw_config: None,
                 }),
                 shard_number: NonZeroU32::new(1).unwrap(),
                 replication_factor: NonZeroU32::new(1).unwrap(),

commit 868626f409a7bcc4e2537dcf69b9b4bbe2c10208
Author: Tim Visée <tim+github@visee.me>
Date:   Mon Apr 10 21:39:43 2023 +0200

    Add vector specific quantization configuration (#1680)
    
    * Add QuantizationConfigDiff type
    
    * Add quantization config diff to vector parameters
    
    * Prefer vector config over collection config for quantization
    
    * Update OpenAPI specification
    
    * Validate quantization configuration quantile in 0.5-1.0 range
    
    As per https://github.com/qdrant/qdrant/pull/1681
    
    * Add test if check if vector specific quantization config is persisted
    
    * Alias quantization to quantization_config in vector parameters
    
    * Remove quantization config diff, use full vector specific config instead
    
    * Regenerate OpenAPI specification and gRPC docs
    
    * Fix compilation error
    
    * Add error handling to quantization config conversions
    
    * Fix quantization integration test, make HNSW test stricter

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index a1a027cee..e08bd12a5 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -318,6 +318,7 @@ mod tests {
                         size: NonZeroU64::new(params.size as u64).unwrap(),
                         distance: params.distance,
                         hnsw_config: None,
+                        quantization_config: None,
                     },
                 )
             })
@@ -434,6 +435,7 @@ mod tests {
                     .unwrap(),
                     distance: segment_config.vector_data[DEFAULT_VECTOR_NAME].distance,
                     hnsw_config: None,
+                    quantization_config: None,
                 }),
                 shard_number: NonZeroU32::new(1).unwrap(),
                 replication_factor: NonZeroU32::new(1).unwrap(),

commit 1c85c9b2359c81897da57ea7dd5e9f0bdbf67791
Author: Tim Visée <tim+github@visee.me>
Date:   Fri Apr 28 10:36:58 2023 +0200

    Add optimizer for many deleted points, make aware of deleted points and vectors (#1758)
    
    * Minor collection optimizer cleanup
    
    * Make optimizers better aware of available vs soft deleted points
    
    * Fix incorrect deleted state on proxy segment for double delete
    
    * Rename upsert_vector to upsert_point, because we work with points
    
    * Refactor point methods for more clear and consistent naming
    
    * Replace internal_size in IdTracker with total_point_count
    
    * Keep track of vector deletion count on storage creation
    
    * Add sparse index optimizer, to optimize indexes with high deletion count
    
    * Add minimum vector count threshold to sparse index optimizer
    
    * Add sparse index optimizer test
    
    * Use consistent naming, write vector in full everywhere
    
    * Simplify vacuum optimizer a bit
    
    * Merge sparse index optimizer into vacuum optimizer
    
    * Improve update_from in segment builder by returning early
    
    * More accurately count vectors in segment optimizer
    
    * Remove random from vacuum optimizer tests to make them more reliable
    
    * Don't expose the total points in segment info, use available points
    
    * Process review feedback
    
    * Compare available vectors against indexed ones in vacuum optimizer
    
    This is much better than using the number of soft-deleted vectors when
    the segment was created for calculations. Not to mention that value had
    other problems as well.
    
    * Remove create_deleted_vector_count field, update vacuum test parameters
    
    * Potentially solve out of bound panic when building index
    
    * Review fixes:
    
    - Propagate deleted flags into payload hnsw building
    - Use `total` number of points for building HNSW instead of number of
      available points
    - minor refactoring of `hnsw_config` copy -> clone
    - Better detection of `indexed_points` in HNSW
    
    * fix assert condition
    
    * Optional named vectors optimizer reveiw 2 (#1794)
    
    * review with Ivan
    
    * fmt
    
    * remove available_vector_count from segment entry
    
    * remove total_point_count from segment entry
    
    ---------
    
    Co-authored-by: Ivan Pleshkov <pleshkov.ivan@gmail.com>
    
    * rollback changes in deleted count in proxy segment
    
    * improve vector threshold detection logic in optimized_segment_builder
    
    * style changes
    
    * fix propagate deleted points to vectors
    
    * Fix typo in method name
    
    ---------
    
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>
    Co-authored-by: Ivan Pleshkov <pleshkov.ivan@gmail.com>

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index e08bd12a5..b82a35352 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -6,9 +6,7 @@ use parking_lot::Mutex;
 use segment::common::operation_time_statistics::{
     OperationDurationStatistics, OperationDurationsAggregator,
 };
-use segment::types::{
-    HnswConfig, Indexes, QuantizationConfig, SegmentType, StorageType, VECTOR_ELEMENT_SIZE,
-};
+use segment::types::{HnswConfig, QuantizationConfig, SegmentType, VECTOR_ELEMENT_SIZE};
 
 use crate::collection_manager::holders::segment_holder::{
     LockedSegmentHolder, SegmentHolder, SegmentId,
@@ -69,8 +67,8 @@ impl IndexingOptimizer {
 
                 let segment_entry = segment.get();
                 let read_segment = segment_entry.read();
-                let vector_count = read_segment.points_count();
-                let vector_size = vector_count
+                let point_count = read_segment.available_point_count();
+                let vector_size = point_count
                     * read_segment
                         .vector_dims()
                         .values()
@@ -84,16 +82,8 @@ impl IndexingOptimizer {
                 }
 
                 let segment_config = read_segment.config();
-
-                let is_vector_indexed = match segment_config.index {
-                    Indexes::Plain {} => false,
-                    Indexes::Hnsw(_) => true,
-                };
-
-                let is_memmaped = match segment_config.storage_type {
-                    StorageType::InMemory => false,
-                    StorageType::Mmap => true,
-                };
+                let is_vector_indexed = segment_config.is_vector_indexed();
+                let is_memmaped = segment_config.is_memmaped();
 
                 if !(is_vector_indexed || is_memmaped) {
                     return None;
@@ -121,8 +111,8 @@ impl IndexingOptimizer {
 
                 let segment_entry = segment.get();
                 let read_segment = segment_entry.read();
-                let vector_count = read_segment.points_count();
-                let vector_size = vector_count
+                let point_count = read_segment.available_point_count();
+                let vector_size = point_count
                     * read_segment
                         .vector_dims()
                         .values()
@@ -138,15 +128,8 @@ impl IndexingOptimizer {
                 }
 
                 // Apply indexing to plain segments which have grown too big
-                let is_vector_indexed = match segment_config.index {
-                    Indexes::Plain {} => false,
-                    Indexes::Hnsw(_) => true,
-                };
-
-                let is_memmaped = match segment_config.storage_type {
-                    StorageType::InMemory => false,
-                    StorageType::Mmap => true,
-                };
+                let is_vector_indexed = segment_config.is_vector_indexed();
+                let is_memmaped = segment_config.is_memmaped();
 
                 let big_for_mmap = vector_size
                     >= self
@@ -162,12 +145,11 @@ impl IndexingOptimizer {
                 let require_indexing =
                     (big_for_mmap && !is_memmaped) || (big_for_index && !is_vector_indexed);
 
-                match require_indexing {
-                    true => Some((*idx, vector_size)),
-                    false => None,
-                }
+                require_indexing.then_some((*idx, vector_size))
             })
             .collect();
+
+        // Select the largest unindexed segment, return if none
         let selected_segment = candidates
             .iter()
             .max_by_key(|(_, vector_size)| *vector_size);
@@ -175,13 +157,15 @@ impl IndexingOptimizer {
             return vec![];
         }
         let (selected_segment_id, selected_segment_size) = *selected_segment.unwrap();
+
         // It is better for scheduling if indexing optimizer optimizes 2 segments.
         // Because result of the optimization is usually 2 segment - it should preserve
         // overall count of segments.
+
+        // Find smallest unindexed to check if we can index together
         let smallest_unindexed = candidates
             .iter()
             .min_by_key(|(_, vector_size)| *vector_size);
-
         if let Some((idx, size)) = smallest_unindexed {
             if *idx != selected_segment_id
                 && selected_segment_size + size
@@ -194,8 +178,8 @@ impl IndexingOptimizer {
             }
         }
 
+        // Find smallest indexed to check if we can reindex together
         let smallest_indexed = self.smallest_indexed_segment(&segments_read_guard, excluded_ids);
-
         if let Some((idx, size)) = smallest_indexed {
             if idx != selected_segment_id
                 && selected_segment_size + size
@@ -225,8 +209,8 @@ impl SegmentOptimizer for IndexingOptimizer {
         self.collection_params.clone()
     }
 
-    fn hnsw_config(&self) -> HnswConfig {
-        self.hnsw_config
+    fn hnsw_config(&self) -> &HnswConfig {
+        &self.hnsw_config
     }
 
     fn quantization_config(&self) -> Option<QuantizationConfig> {

commit 45ae3e048b15f10e71b5825a9fc00ee7b7676390
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Tue May 9 18:01:01 2023 +0200

    Dynamic mmap vector storage (#1838)
    
    * wip: chunked mmap
    
    * Fix typo
    
    * insert and get methods
    
    * dynamic bitvec
    
    * clippy
    
    * wip: vector storage
    
    * wip: fmt
    
    * wip: mmap chunks
    
    * wip: mmap problems
    
    * Share transmuted mutable reference over mmap
    
    * option to enable appendable mmap vectors
    
    * fmt
    
    * rename storage status file
    
    * update tests
    
    * fix get deleted value range
    
    * add recovery to vector storage tests
    
    * add flush to tests
    
    * fix transmute from immutable to mutable
    
    * make transmuted pointer private
    
    * remove unused unsafe functions
    
    * force WAL flush if wait=true
    
    * move wal flush into updater thread
    
    * remove flush from update api
    
    * Minimize pub visibility for specialized/dangerous functions
    
    * Allocate vector with predefined capacity
    
    * Inline format parameters
    
    * Assert we have multiple chunks while testing, test is useless otherwise
    
    * Remove unnecessary scope
    
    * Remove unnecessary dereference
    
    * Random bool has 0.5 as standard distribution, use iter::repeat_with
    
    * Replace RemovableMmap::new with Default derive
    
    * Rename len to num_flags
    
    * Use Option replace as it is convention alongside take
    
    * Add FileId enum to replace error prone manual ID rotating
    
    * Use debug_assert_eq where applicable
    
    * Refactor drop and set to replace
    
    * Change default chunk size for chunked mmap vectors to 32MB
    
    This change is made as per GitHub review, because allocating a few
    storages with 128MB would take a significant amount of time and storage.
    
    See: https://github.com/qdrant/qdrant/pull/1838#discussion_r1187215475
    
    * Replace for-loops with iterators
    
    * Draft: add typed mmap to improve code safety (#1860)
    
    * Add typed mmap
    
    * Replace some crude mmap usages with typed mmap
    
    * Use typed mmap for deleted flags
    
    * Simplify dynamic mmap flags a lot with new typed mmap, remove flags option
    
    * Reformat
    
    * Remove old mmap functions that are now unused
    
    * Reimplement mmap locking for mmap_vectors
    
    * Add MmapBitSlice tests
    
    * Replace MmapChunk with new typed mmap
    
    * Update docs
    
    * Clean-up
    
    * Disable alignment assertions on Windows for now
    
    * Rename mmap lock to mlock to prevent confusion with lockable types
    
    * one more small test
    
    * Some review fixes
    
    * Add aliasing note
    
    * Add basic error handling in typed mmap constructors
    
    * Use typed mmap error handling throughout project
    
    * Move mmap type module to common
    
    * Fix transmute functions being unsound
    
    See https://github.com/qdrant/qdrant/pull/1860#discussion_r1188593854
    
    ---------
    
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>
    
    ---------
    
    Co-authored-by: timvisee <tim@visee.me>
    Co-authored-by: Tim Visée <tim+github@visee.me>

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index b82a35352..369e1ed4f 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -303,6 +303,7 @@ mod tests {
                         distance: params.distance,
                         hnsw_config: None,
                         quantization_config: None,
+                        on_disk: None,
                     },
                 )
             })
@@ -420,6 +421,7 @@ mod tests {
                     distance: segment_config.vector_data[DEFAULT_VECTOR_NAME].distance,
                     hnsw_config: None,
                     quantization_config: None,
+                    on_disk: None,
                 }),
                 shard_number: NonZeroU32::new(1).unwrap(),
                 replication_factor: NonZeroU32::new(1).unwrap(),

commit df711b7c2e64ec4baf9c086fab2ba68dcdf0966e
Author: Tim Visée <tim+github@visee.me>
Date:   Wed May 17 09:49:55 2023 +0200

    Refactor segment config (#1894)
    
    * Clone current segment config to deprecated type
    
    * Remove segment level quantization config from segment config
    
    * Also deprecate current VectorDataConfig
    
    * Update old segment migration to work with new refactoring
    
    * Move index into vector data config
    
    * Move vector data config migration logic into segment level
    
    * Remove hnsw_config from vector data config
    
    * Rename collection params to vector data conversions function
    
    * Move storage type into vector data config
    
    * Set appendable flag correctly
    
    * Clean up and reformat
    
    * Make segment on disk flag not optional
    
    * Add appendable flag to segment config to replace storage type
    
    * Remove storage type from segment config
    
    * Deprecate storage type enum
    
    * Use consistent variable naming
    
    * Cleanup
    
    * Add segment config migration for v0.5.0 to current
    
    * Bump segment to 0.6.0
    
    * Remove serde defaults for new storage and vector data config types
    
    These default value configurations are not needed anymore, because these
    structs are not used to deserialize old data. All current fields should
    always be available in these structs. When new fields are added in new
    functions, the serde default annotation must be set again.
    
    * Cleanup
    
    * Update OpenAPI specification
    
    This updates the returned data structure on telemetry endpoints, as a
    result of segment configuration refactoring.
    
    * Fix quantization configuration not falling back to collection config
    
    * Fix compiler warning when building in release mode
    
    * Move deprecated type structs into compat module
    
    * Update allow deprecated attributes
    
    * Assign quantization config only in segment optimizer
    
    * Remove unsued parameter
    
    * Add vector storage type enum to vector data config
    
    * Remove appendable and on_disk flags from segment and vector config
    
    * Update OpenAPI specification
    
    * add tests
    
    ---------
    
    Co-authored-by: Andrey Vasnetsov <andrey@vasnetsov.com>

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 369e1ed4f..ca6021412 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -82,10 +82,10 @@ impl IndexingOptimizer {
                 }
 
                 let segment_config = read_segment.config();
-                let is_vector_indexed = segment_config.is_vector_indexed();
-                let is_memmaped = segment_config.is_memmaped();
+                let is_any_vector_indexed = segment_config.is_any_vector_indexed();
+                let is_any_mmap = segment_config.is_any_mmap();
 
-                if !(is_vector_indexed || is_memmaped) {
+                if !(is_any_vector_indexed || is_any_mmap) {
                     return None;
                 }
 
@@ -128,8 +128,8 @@ impl IndexingOptimizer {
                 }
 
                 // Apply indexing to plain segments which have grown too big
-                let is_vector_indexed = segment_config.is_vector_indexed();
-                let is_memmaped = segment_config.is_memmaped();
+                let are_all_vectors_indexed = segment_config.are_all_vectors_indexed();
+                let is_any_mmap = segment_config.is_any_mmap();
 
                 let big_for_mmap = vector_size
                     >= self
@@ -143,7 +143,7 @@ impl IndexingOptimizer {
                         .saturating_mul(BYTES_IN_KB);
 
                 let require_indexing =
-                    (big_for_mmap && !is_memmaped) || (big_for_index && !is_vector_indexed);
+                    (big_for_mmap && !is_any_mmap) || (big_for_index && !are_all_vectors_indexed);
 
                 require_indexing.then_some((*idx, vector_size))
             })
@@ -251,7 +251,7 @@ mod tests {
     use rand::thread_rng;
     use segment::data_types::vectors::DEFAULT_VECTOR_NAME;
     use segment::fixtures::index_fixtures::random_vector;
-    use segment::types::{Payload, PayloadSchemaType, StorageType};
+    use segment::types::{Payload, PayloadSchemaType};
     use serde_json::json;
     use tempfile::Builder;
 
@@ -526,10 +526,7 @@ mod tests {
             "Testing that 2 segments are actually indexed"
         );
 
-        let mmap_count = configs
-            .iter()
-            .filter(|config| config.storage_type == StorageType::Mmap)
-            .count();
+        let mmap_count = configs.iter().filter(|config| config.is_any_mmap()).count();
         assert_eq!(
             mmap_count, 1,
             "Testing that only largest segment is not Mmap"

commit 7baa296d8ba5e3bf7d3cdcbdc127c60d0e3894a5
Author: Tim Visée <tim+github@visee.me>
Date:   Tue Jul 18 14:32:13 2023 +0200

    Update collection: HNSW config (#2083)
    
    * Add field to REST collection update to change HNSW config
    
    * Add field to gRPC collection update to change HNSW config
    
    * Update OpenAPI specification
    
    * Update gRPC docs
    
    * Improve optimizer filtering for excluded segment IDs
    
    * Add config mismatch optimizer detecting basic HNSW mismatches
    
    * Trigger optimizers when changing collection HNSW config
    
    * Make config mismatch optimizer aware of vector specific HNSW configs
    
    * Extract triggering optimizers after collection update into function
    
    * Add config mismatch optimizer test for changing HNSW config
    
    * Simplify config mismatch optimizer test
    
    * Add config mismatch optimizer test for vector specific HNSW change
    
    * Reformat
    
    * Update collection HNSW params in integration test
    
    * Validate HNSW config in collection update gRPC endpoint
    
    * Improve description of update collection request
    
    * Do not require to rebuild HNSW when on_disk flag changes
    
    Ref: https://github.com/qdrant/qdrant/pull/2083#discussion_r1231002072
    
    * Do rebuild segment with on_disk change
    
    * Trigger optimizers in parallel
    
    * Recreate optimizers only once on collection update
    
    * Reformat
    
    * Fix incorrect usage of self
    
    * Fix deadlock in collection state config update
    
    * Also rebuild index on full scan threshold change
    
    * decompose worst_segment condition check
    
    * review refactor
    
    * Update lib/storage/src/content_manager/collection_meta_ops.rs
    
    Co-authored-by: Luis Cossío <luis.cossio@qdrant.com>
    
    * Update lib/api/src/grpc/proto/collections.proto
    
    Co-authored-by: Luis Cossío <luis.cossio@qdrant.com>
    
    * upd grpc docs
    
    * upd grpc docs
    
    * update openapi
    
    ---------
    
    Co-authored-by: generall <andrey@vasnetsov.com>
    Co-authored-by: Luis Cossío <luis.cossio@qdrant.com>

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index ca6021412..b47dcc367 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -59,12 +59,9 @@ impl IndexingOptimizer {
     ) -> Option<(SegmentId, usize)> {
         segments
             .iter()
+            // Excluded externally, might already be scheduled for optimization
+            .filter(|(idx, _)| !excluded_ids.contains(idx))
             .filter_map(|(idx, segment)| {
-                if excluded_ids.contains(idx) {
-                    // This segment is excluded externally. It might already be scheduled for optimization
-                    return None;
-                }
-
                 let segment_entry = segment.get();
                 let read_segment = segment_entry.read();
                 let point_count = read_segment.available_point_count();
@@ -103,12 +100,9 @@ impl IndexingOptimizer {
         let segments_read_guard = segments.read();
         let candidates: Vec<_> = segments_read_guard
             .iter()
+            // Excluded externally, might already be scheduled for optimization
+            .filter(|(idx, _)| !excluded_ids.contains(idx))
             .filter_map(|(idx, segment)| {
-                if excluded_ids.contains(idx) {
-                    // This segment is excluded externally. It might already be scheduled for optimization
-                    return None;
-                }
-
                 let segment_entry = segment.get();
                 let read_segment = segment_entry.read();
                 let point_count = read_segment.available_point_count();

commit aae707c08f39107b9ac3a02480689a566be2bb98
Author: Tim Visée <tim+github@visee.me>
Date:   Mon Jul 31 11:43:39 2023 +0200

    update collection: on_disk parameters (#2097)
    
    * Add on_disk_payload field to collections params diff
    
    * Add on_disk flag to update collection vector params
    
    * Add on_disk parameters to collection update integration test
    
    * Update and extend unit tests
    
    * monitor on-disk params in optimizr
    
    * fmt
    
    * review fix
    
    * fmt
    
    ---------
    
    Co-authored-by: generall <andrey@vasnetsov.com>

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index b47dcc367..2b1ff7321 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -80,9 +80,9 @@ impl IndexingOptimizer {
 
                 let segment_config = read_segment.config();
                 let is_any_vector_indexed = segment_config.is_any_vector_indexed();
-                let is_any_mmap = segment_config.is_any_mmap();
+                let is_any_on_disk = segment_config.is_any_on_disk();
 
-                if !(is_any_vector_indexed || is_any_mmap) {
+                if !(is_any_vector_indexed || is_any_on_disk) {
                     return None;
                 }
 
@@ -123,7 +123,7 @@ impl IndexingOptimizer {
 
                 // Apply indexing to plain segments which have grown too big
                 let are_all_vectors_indexed = segment_config.are_all_vectors_indexed();
-                let is_any_mmap = segment_config.is_any_mmap();
+                let is_any_on_disk = segment_config.is_any_on_disk();
 
                 let big_for_mmap = vector_size
                     >= self
@@ -136,8 +136,8 @@ impl IndexingOptimizer {
                         .indexing_threshold
                         .saturating_mul(BYTES_IN_KB);
 
-                let require_indexing =
-                    (big_for_mmap && !is_any_mmap) || (big_for_index && !are_all_vectors_indexed);
+                let require_indexing = (big_for_mmap && !is_any_on_disk)
+                    || (big_for_index && !are_all_vectors_indexed);
 
                 require_indexing.then_some((*idx, vector_size))
             })
@@ -520,9 +520,12 @@ mod tests {
             "Testing that 2 segments are actually indexed"
         );
 
-        let mmap_count = configs.iter().filter(|config| config.is_any_mmap()).count();
+        let on_disk_count = configs
+            .iter()
+            .filter(|config| config.is_any_on_disk())
+            .count();
         assert_eq!(
-            mmap_count, 1,
+            on_disk_count, 1,
             "Testing that only largest segment is not Mmap"
         );
 

commit ecaff1023de967e0f2e3ea0facf98b80268ff87d
Author: Di Zhao <di.zhao@gmail.com>
Date:   Wed Aug 16 01:56:44 2023 -0700

    Add `indexed_only` to speed up search (#2431)
    
    * add ignore_plain_index to speed up search
    
    * remove unnecessary & for vectors_batch
    
    * format
    
    * add special handle for proxy segments where the wrapped segment is plain
    indexed
    
    * review refactoring
    
    * rollback changes in google.protobuf.rs
    
    ---------
    
    Co-authored-by: Di Zhao <diz@twitter.com>
    Co-authored-by: generall <andrey@vasnetsov.com>

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 2b1ff7321..6aab29f6e 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -348,7 +348,7 @@ mod tests {
         let configs = locked_holder
             .read()
             .iter()
-            .map(|(_sid, segment)| segment.get().read().config())
+            .map(|(_sid, segment)| segment.get().read().config().clone())
             .collect_vec();
 
         assert_eq!(infos.len(), 2);
@@ -508,7 +508,7 @@ mod tests {
         let configs = locked_holder
             .read()
             .iter()
-            .map(|(_sid, segment)| segment.get().read().config())
+            .map(|(_sid, segment)| segment.get().read().config().clone())
             .collect_vec();
 
         let indexed_count = infos

commit 34f654568bf2847ddc1485735b160cd3a7c77547
Author: Tim Visée <tim+github@visee.me>
Date:   Mon Aug 28 09:14:37 2023 +0200

    Report optimizer status and history in telemetry (#2475)
    
    * Add name to optimizers
    
    * Track optimizer status in update handler
    
    * Remove unused optimizer telemetry implementation
    
    * Report tracked optimizer status in local shard telemetry
    
    * Keep just the last 16 optimizer trackers and non successful ones
    
    * Also eventually truncate cancelled optimizer statuses
    
    * Fix codespell
    
    * Assert basic optimizer log state in unit test
    
    * Remove repetitive suffix from optimizer names
    
    * Loosen requirements for optimizer status test to prevent flakyness

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 6aab29f6e..78856b9b7 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -191,6 +191,10 @@ impl IndexingOptimizer {
 }
 
 impl SegmentOptimizer for IndexingOptimizer {
+    fn name(&self) -> &str {
+        "indexing"
+    }
+
     fn collection_path(&self) -> &Path {
         self.segments_path.as_path()
     }

commit 0df5ef470a0443be270a9f6c349cf835d3d5ec7b
Author: Roman Titov <ffuugoo@users.noreply.github.com>
Date:   Fri Sep 22 21:56:10 2023 +0200

    Fan out read operations if local shard is updated (#2642)
    
    * Fan-out read operations if local shard is being updated
    
    * Implement `is_update_in_progress` check for all shard types
    
    * fixup! Implement `is_update_in_progress` check for all shard types
    
    Reverse conditional 🤦‍♀️
    
    * WIP: Add `read_fan_out_factor` collection parameter...
    
    ...and refactor `execute_read_operation`/`execute_and_resolve_read_operation` to use it reasonably
    
    * WIP: Refactor `info` and `count` requests to utilize `read_fan_out_factor` properly
    
    * fixup! WIP: Refactor `info` and `count` requests to utilize `read_fan_out_factor` properly
    
    Fix typo
    
    * fixup! WIP: Add `read_fan_out_factor` collection parameter...
    
    Initialize `read_fan_out_factor` in tests
    
    * fixup! WIP: Add `read_fan_out_factor` collection parameter...
    
    Add `TODO` marker (:
    
    * fixup! WIP: Add `read_fan_out_factor` collection parameter...
    
    * fixup! fixup! WIP: Add `read_fan_out_factor` collection parameter...
    
    * fixup! fixup! fixup! WIP: Add `read_fan_out_factor` collection parameter...
    
    🤦‍♀️
    
    * Add `read_fan_out_factor` to required HTTP and gRPC APIs
    
    * WIP: Generate OpenAPI spec and gRPC docs
    
    * fixup! Add `read_fan_out_factor` to required HTTP and gRPC APIs
    
    * fixup! WIP: Add `read_fan_out_factor` collection parameter...
    
    Fix the comment
    
    * Add documentation
    
    * fixup! Add documentation
    
    Update OpenAPI spec and gRPC docs
    
    * optional param by default + comment
    
    * fmt
    
    * rollback test fixes
    
    * review changes
    
    * fmt
    
    * revert api changes
    
    * upd openapi
    
    * upd comment
    
    * fix info api
    
    * resolve merge conflicts
    
    ---------
    
    Co-authored-by: generall <andrey@vasnetsov.com>

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 78856b9b7..9e5c78e03 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -239,7 +239,7 @@ impl SegmentOptimizer for IndexingOptimizer {
 #[cfg(test)]
 mod tests {
     use std::collections::BTreeMap;
-    use std::num::{NonZeroU32, NonZeroU64};
+    use std::num::NonZeroU64;
     use std::ops::Deref;
     use std::sync::atomic::AtomicBool;
     use std::sync::Arc;
@@ -317,10 +317,7 @@ mod tests {
             segments_temp_dir.path().to_owned(),
             CollectionParams {
                 vectors: VectorsConfig::Multi(vectors_config),
-                shard_number: NonZeroU32::new(1).unwrap(),
-                replication_factor: NonZeroU32::new(1).unwrap(),
-                write_consistency_factor: NonZeroU32::new(1).unwrap(),
-                on_disk_payload: false,
+                ..CollectionParams::empty()
             },
             Default::default(),
             Default::default(),
@@ -421,10 +418,7 @@ mod tests {
                     quantization_config: None,
                     on_disk: None,
                 }),
-                shard_number: NonZeroU32::new(1).unwrap(),
-                replication_factor: NonZeroU32::new(1).unwrap(),
-                write_consistency_factor: NonZeroU32::new(1).unwrap(),
-                on_disk_payload: false,
+                ..CollectionParams::empty()
             },
             Default::default(),
             Default::default(),

commit 816b5a7448c7f1e0d81c99e5a31219d00ece6fe5
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Thu Nov 9 15:06:02 2023 +0100

    Shard key routing for update requests (#2909)
    
    * add shard_key into output data structures for points
    
    * fmt
    
    * add shard selector for point update operations
    
    * fix creating index without sharding
    
    * Merge serde attributes
    
    * Code review changes
    
    * review fixes
    
    * upd openapi
    
    ---------
    
    Co-authored-by: timvisee <tim@visee.me>

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 9e5c78e03..d162a7350 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -259,7 +259,7 @@ mod tests {
     use crate::collection_manager::segments_updater::{
         process_field_index_operation, process_point_operation,
     };
-    use crate::operations::point_ops::{Batch, PointInsertOperations, PointOperations};
+    use crate::operations::point_ops::{Batch, PointOperations};
     use crate::operations::types::{VectorParams, VectorsConfig};
     use crate::operations::{CreateIndex, FieldIndexOperations};
 
@@ -547,21 +547,21 @@ mod tests {
         }
 
         let point_payload: Payload = json!({"number":10000i64}).into();
-        let insert_point_ops =
-            PointOperations::UpsertPoints(PointInsertOperations::PointsBatch(Batch {
-                ids: vec![501.into(), 502.into(), 503.into()],
-                vectors: vec![
-                    random_vector(&mut rng, dim),
-                    random_vector(&mut rng, dim),
-                    random_vector(&mut rng, dim),
-                ]
-                .into(),
-                payloads: Some(vec![
-                    Some(point_payload.clone()),
-                    Some(point_payload.clone()),
-                    Some(point_payload),
-                ]),
-            }));
+        let insert_point_ops: PointOperations = Batch {
+            ids: vec![501.into(), 502.into(), 503.into()],
+            vectors: vec![
+                random_vector(&mut rng, dim),
+                random_vector(&mut rng, dim),
+                random_vector(&mut rng, dim),
+            ]
+            .into(),
+            payloads: Some(vec![
+                Some(point_payload.clone()),
+                Some(point_payload.clone()),
+                Some(point_payload),
+            ]),
+        }
+        .into();
 
         let smallest_size = infos
             .iter()
@@ -620,17 +620,17 @@ mod tests {
             "Testing that new segment is created if none left"
         );
 
-        let insert_point_ops =
-            PointOperations::UpsertPoints(PointInsertOperations::PointsBatch(Batch {
-                ids: vec![601.into(), 602.into(), 603.into()],
-                vectors: vec![
-                    random_vector(&mut rng, dim),
-                    random_vector(&mut rng, dim),
-                    random_vector(&mut rng, dim),
-                ]
-                .into(),
-                payloads: None,
-            }));
+        let insert_point_ops: PointOperations = Batch {
+            ids: vec![601.into(), 602.into(), 603.into()],
+            vectors: vec![
+                random_vector(&mut rng, dim),
+                random_vector(&mut rng, dim),
+                random_vector(&mut rng, dim),
+            ]
+            .into(),
+            payloads: None,
+        }
+        .into();
 
         process_point_operation(
             locked_holder.deref(),

commit 76aafec2136b8e8ee4459406748f19df86d60101
Author: Tim Visée <tim+github@visee.me>
Date:   Wed Dec 6 13:31:09 2023 +0100

    Hotfix for infinite optimization loop with `on_disk` and `mmap_threshold` fighting (#3167)
    
    * If on_disk is explicitly configured, prefer it over mmap threshold
    
    * review fix
    
    * Fix vector size in index optimizer not taking point count into account
    
    * Refactor vector size name, storage name is less ambiguous
    
    * Add on_disk and memmap_threshold conflict test
    
    * Return early in require optimization check, don't do useless work
    
    ---------
    
    Co-authored-by: generall <andrey@vasnetsov.com>

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index d162a7350..20347cd9a 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -106,7 +106,7 @@ impl IndexingOptimizer {
                 let segment_entry = segment.get();
                 let read_segment = segment_entry.read();
                 let point_count = read_segment.available_point_count();
-                let vector_size = point_count
+                let max_vector_size = point_count
                     * read_segment
                         .vector_dims()
                         .values()
@@ -121,25 +121,76 @@ impl IndexingOptimizer {
                     return None; // Never optimize already optimized segment
                 }
 
-                // Apply indexing to plain segments which have grown too big
-                let are_all_vectors_indexed = segment_config.are_all_vectors_indexed();
-                let is_any_on_disk = segment_config.is_any_on_disk();
-
-                let big_for_mmap = vector_size
-                    >= self
-                        .thresholds_config
-                        .memmap_threshold
-                        .saturating_mul(BYTES_IN_KB);
-                let big_for_index = vector_size
-                    >= self
-                        .thresholds_config
-                        .indexing_threshold
-                        .saturating_mul(BYTES_IN_KB);
+                let indexing_threshold_kb = self
+                    .thresholds_config
+                    .indexing_threshold
+                    .saturating_mul(BYTES_IN_KB);
+                let mmap_threshold_kb = self
+                    .thresholds_config
+                    .memmap_threshold
+                    .saturating_mul(BYTES_IN_KB);
+                let mut require_optimization = false;
+
+                for (vector_name, vector_config) in self.collection_params.vectors.params_iter() {
+                    if let Some(vector_data) = segment_config.vector_data.get(vector_name) {
+                        let is_indexed = vector_data.index.is_indexed();
+                        let is_on_disk = vector_data.storage_type.is_on_disk();
+                        let storage_size = point_count * vector_data.size * VECTOR_ELEMENT_SIZE;
+
+                        let is_big_for_index = storage_size >= indexing_threshold_kb;
+                        let is_big_for_mmap = storage_size >= mmap_threshold_kb;
+
+                        let optimize_for_index = is_big_for_index && !is_indexed;
+                        let optimize_for_mmap = if let Some(on_disk_config) = vector_config.on_disk
+                        {
+                            on_disk_config && !is_on_disk
+                        } else {
+                            is_big_for_mmap && !is_on_disk
+                        };
+
+                        if optimize_for_index || optimize_for_mmap {
+                            require_optimization = true;
+                            break;
+                        }
+                    }
+                }
 
-                let require_indexing = (big_for_mmap && !is_any_on_disk)
-                    || (big_for_index && !are_all_vectors_indexed);
+                if !require_optimization {
+                    if let Some(sparse_vectors_params) =
+                        self.collection_params.sparse_vectors.as_ref()
+                    {
+                        for (sparse_vector_name, sparse_vector_config) in sparse_vectors_params {
+                            if let Some(sparse_vector_data) =
+                                segment_config.sparse_vector_data.get(sparse_vector_name)
+                            {
+                                let vector_dim =
+                                    read_segment.vector_dim(sparse_vector_name).unwrap_or(0);
+                                let is_indexed = sparse_vector_data.is_indexed();
+                                let is_on_disk = sparse_vector_data.is_index_on_disk();
+                                let storage_size = point_count * vector_dim * VECTOR_ELEMENT_SIZE;
+
+                                let is_big_for_index = storage_size >= indexing_threshold_kb;
+                                let is_big_for_mmap = storage_size >= mmap_threshold_kb;
+
+                                let optimize_for_index = is_big_for_index && !is_indexed;
+                                let optimize_for_mmap = if let Some(on_disk_config) =
+                                    sparse_vector_config.index.and_then(|x| x.on_disk)
+                                {
+                                    on_disk_config && !is_on_disk
+                                } else {
+                                    is_big_for_mmap && !is_on_disk
+                                };
+
+                                if optimize_for_index || optimize_for_mmap {
+                                    require_optimization = true;
+                                    break;
+                                }
+                            }
+                        }
+                    }
+                }
 
-                require_indexing.then_some((*idx, vector_size))
+                require_optimization.then_some((*idx, max_vector_size))
             })
             .collect();
 
@@ -248,14 +299,16 @@ mod tests {
     use parking_lot::lock_api::RwLock;
     use rand::thread_rng;
     use segment::data_types::vectors::DEFAULT_VECTOR_NAME;
+    use segment::entry::entry_point::SegmentEntry;
     use segment::fixtures::index_fixtures::random_vector;
-    use segment::types::{Payload, PayloadSchemaType};
+    use segment::types::{Distance, Payload, PayloadSchemaType};
     use serde_json::json;
     use tempfile::Builder;
 
     use super::*;
     use crate::collection_manager::fixtures::{random_multi_vec_segment, random_segment};
-    use crate::collection_manager::holders::segment_holder::SegmentHolder;
+    use crate::collection_manager::holders::segment_holder::{LockedSegment, SegmentHolder};
+    use crate::collection_manager::optimizers::config_mismatch_optimizer::ConfigMismatchOptimizer;
     use crate::collection_manager::segments_updater::{
         process_field_index_operation, process_point_operation,
     };
@@ -639,4 +692,176 @@ mod tests {
         )
         .unwrap();
     }
+
+    /// This tests things are as we expect when we define both `on_disk: false` and `memmap_threshold`
+    ///
+    /// Before this PR (<https://github.com/qdrant/qdrant/pull/3167>) such configuration would create an infinite optimization loop.
+    ///
+    /// It tests whether:
+    /// - the on_disk flag is preferred over memmap_threshold
+    /// - the index optimizer and config mismatch optimizer don't conflict with this preference
+    /// - there is no infinite optiization loop with the above configuration
+    ///
+    /// In short, this is what happens in this test:
+    /// - create randomized segment as base with `on_disk: false` and `memmap_threshold`
+    /// - test that indexing optimizer and config mismatch optimizer dont trigger
+    /// - test that current storage is in memory
+    /// - change `on_disk: None`
+    /// - test that indexing optimizer now wants to optimize for `memmap_threshold`
+    /// - optimize with indexing optimizer to put storage on disk
+    /// - test that config mismatch optimizer doesn't try to revert on disk storage
+    #[test]
+    fn test_on_disk_memmap_threshold_conflict() {
+        // Collection configuration
+        let (point_count, dim) = (1000, 10);
+        let thresholds_config = OptimizerThresholds {
+            max_segment_size: std::usize::MAX,
+            memmap_threshold: 10,
+            indexing_threshold: std::usize::MAX,
+        };
+        let mut collection_params = CollectionParams {
+            vectors: VectorsConfig::Single(VectorParams {
+                size: dim.try_into().unwrap(),
+                distance: Distance::Dot,
+                hnsw_config: None,
+                quantization_config: None,
+                on_disk: Some(false),
+            }),
+            ..CollectionParams::empty()
+        };
+
+        // Base segment
+        let temp_dir = Builder::new().prefix("segment_temp_dir").tempdir().unwrap();
+        let dir = Builder::new().prefix("segment_dir").tempdir().unwrap();
+        let mut holder = SegmentHolder::default();
+
+        let segment = random_segment(dir.path(), 100, point_count, dim as usize);
+
+        let segment_id = holder.add(segment);
+        let locked_holder: Arc<parking_lot::RwLock<_>> = Arc::new(RwLock::new(holder));
+
+        let hnsw_config = HnswConfig {
+            m: 16,
+            ef_construct: 100,
+            full_scan_threshold: 10,
+            max_indexing_threads: 0,
+            on_disk: None,
+            payload_m: None,
+        };
+
+        {
+            // Optimizers used in test
+            let index_optimizer = IndexingOptimizer::new(
+                thresholds_config.clone(),
+                dir.path().to_owned(),
+                temp_dir.path().to_owned(),
+                collection_params.clone(),
+                hnsw_config.clone(),
+                Default::default(),
+            );
+            let config_mismatch_optimizer = ConfigMismatchOptimizer::new(
+                thresholds_config.clone(),
+                dir.path().to_owned(),
+                temp_dir.path().to_owned(),
+                collection_params.clone(),
+                hnsw_config.clone(),
+                Default::default(),
+            );
+
+            // Index optimizer should not optimize and put storage back in memory, nothing changed
+            let suggested_to_optimize =
+                index_optimizer.check_condition(locked_holder.clone(), &Default::default());
+            assert_eq!(
+                suggested_to_optimize.len(),
+                0,
+                "index optimizer should not run for index nor mmap"
+            );
+
+            // Config mismatch optimizer should not try to change the current state
+            let suggested_to_optimize = config_mismatch_optimizer
+                .check_condition(locked_holder.clone(), &Default::default());
+            assert_eq!(
+                suggested_to_optimize.len(),
+                0,
+                "config mismatch optimizer should not change anything"
+            );
+
+            // Ensure segment is not on disk
+            locked_holder
+                .read()
+                .iter()
+                .map(|(_, segment)| match segment {
+                    LockedSegment::Original(s) => s.read(),
+                    LockedSegment::Proxy(_) => unreachable!(),
+                })
+                .filter(|segment| segment.total_point_count() > 0)
+                .for_each(|segment| {
+                    assert!(
+                        !segment.config().vector_data[""].storage_type.is_on_disk(),
+                        "segment must not be on disk with mmap",
+                    );
+                });
+        }
+
+        // Remove explicit on_disk flag and go back to default
+        collection_params
+            .vectors
+            .get_params_mut("")
+            .unwrap()
+            .on_disk
+            .take();
+
+        // Optimizers used in test
+        let index_optimizer = IndexingOptimizer::new(
+            thresholds_config.clone(),
+            dir.path().to_owned(),
+            temp_dir.path().to_owned(),
+            collection_params.clone(),
+            hnsw_config.clone(),
+            Default::default(),
+        );
+        let config_mismatch_optimizer = ConfigMismatchOptimizer::new(
+            thresholds_config,
+            dir.path().to_owned(),
+            temp_dir.path().to_owned(),
+            collection_params,
+            hnsw_config.clone(),
+            Default::default(),
+        );
+
+        // Use indexing optimizer to build mmap
+        let changed = index_optimizer
+            .optimize(locked_holder.clone(), vec![segment_id], &false.into())
+            .unwrap();
+        assert!(
+            changed,
+            "optimizer should have rebuilt this segment for mmap"
+        );
+        assert!(
+            locked_holder.read().get(segment_id).is_none(),
+            "optimized segment should be gone",
+        );
+        assert_eq!(locked_holder.read().len(), 2, "mmap must be built");
+
+        // Mismatch optimizer should not optimize yet, HNSW config is not changed yet
+        let suggested_to_optimize =
+            config_mismatch_optimizer.check_condition(locked_holder.clone(), &Default::default());
+        assert_eq!(suggested_to_optimize.len(), 0);
+
+        // Ensure new segment is on disk now
+        locked_holder
+            .read()
+            .iter()
+            .map(|(_, segment)| match segment {
+                LockedSegment::Original(s) => s.read(),
+                LockedSegment::Proxy(_) => unreachable!(),
+            })
+            .filter(|segment| segment.total_point_count() > 0)
+            .for_each(|segment| {
+                assert!(
+                    segment.config().vector_data[""].storage_type.is_on_disk(),
+                    "segment must be on disk with mmap",
+                );
+            });
+    }
 }

commit cafab322d08b1dd38204063e756a9c1b59bd9a72
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Wed Dec 6 18:40:24 2023 +0100

    Optimizer detects on_disk update sparse vector index (#3160)
    
    * Optimizer detects on_disk update sparse vector index
    
    * Rename sparse vector index on disk check function to remove ambiguity
    
    * Appendable segments always have sparse index in memory
    
    Don't try to force these segments to have their index on disk if
    our collection configuration tells us to do it that way.
    
    * Fix compilation warning
    
    * Resolve merge conflict
    
    * In indexing optimizer, only put sparse vectors on disk if big
    
    * fix mutable->immutable optimization
    
    * fix negation
    
    * Disable config mismatch for sparse now, update sparse vector storage decision tree
    
    * Fix compilation error due to TODO
    
    * Fix flipped boolean
    
    * simplify config mismatch logic
    
    * simplify logic further
    
    ---------
    
    Co-authored-by: timvisee <tim@visee.me>
    Co-authored-by: generall <andrey@vasnetsov.com>

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 20347cd9a..c61b0d1b6 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -159,29 +159,23 @@ impl IndexingOptimizer {
                     if let Some(sparse_vectors_params) =
                         self.collection_params.sparse_vectors.as_ref()
                     {
-                        for (sparse_vector_name, sparse_vector_config) in sparse_vectors_params {
+                        for sparse_vector_name in sparse_vectors_params.keys() {
                             if let Some(sparse_vector_data) =
                                 segment_config.sparse_vector_data.get(sparse_vector_name)
                             {
                                 let vector_dim =
                                     read_segment.vector_dim(sparse_vector_name).unwrap_or(0);
-                                let is_indexed = sparse_vector_data.is_indexed();
-                                let is_on_disk = sparse_vector_data.is_index_on_disk();
+
+                                let is_index_immutable = sparse_vector_data.is_index_immutable();
+
                                 let storage_size = point_count * vector_dim * VECTOR_ELEMENT_SIZE;
 
                                 let is_big_for_index = storage_size >= indexing_threshold_kb;
                                 let is_big_for_mmap = storage_size >= mmap_threshold_kb;
 
-                                let optimize_for_index = is_big_for_index && !is_indexed;
-                                let optimize_for_mmap = if let Some(on_disk_config) =
-                                    sparse_vector_config.index.and_then(|x| x.on_disk)
-                                {
-                                    on_disk_config && !is_on_disk
-                                } else {
-                                    is_big_for_mmap && !is_on_disk
-                                };
+                                let is_big = is_big_for_index || is_big_for_mmap;
 
-                                if optimize_for_index || optimize_for_mmap {
+                                if is_big && !is_index_immutable {
                                     require_optimization = true;
                                     break;
                                 }

commit 680574347f3b3dd6f604f452b80734a8c6f2f7c6
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Mon Dec 25 14:26:21 2023 +0100

    Fix clippy 1.75 (#3270)

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index c61b0d1b6..0e6b7633d 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -709,9 +709,9 @@ mod tests {
         // Collection configuration
         let (point_count, dim) = (1000, 10);
         let thresholds_config = OptimizerThresholds {
-            max_segment_size: std::usize::MAX,
+            max_segment_size: usize::MAX,
             memmap_threshold: 10,
-            indexing_threshold: std::usize::MAX,
+            indexing_threshold: usize::MAX,
         };
         let mut collection_params = CollectionParams {
             vectors: VectorsConfig::Single(VectorParams {

commit 19514265330ac9a1049b9439517deb104a5a19ed
Author: Tim Visée <tim+github@visee.me>
Date:   Wed Jan 31 11:56:34 2024 +0100

    Dynamic CPU saturation internals (#3364)
    
    * Move CPU count function to common, fix wrong CPU count in visited list
    
    * Change default number of rayon threads to 8
    
    * Use CPU budget and CPU permits for optimizer tasks to limit utilization
    
    * Respect configured thread limits, use new sane defaults in config
    
    * Fix spelling issues
    
    * Fix test compilation error
    
    * Improve breaking if there is no CPU budget
    
    * Block optimizations until CPU budget, fix potentially getting stuck
    
    Our optimization worker now blocks until CPU budget is available to
    perform the task.
    
    Fix potential issue where optimization worker could get stuck. This
    would happen if no optimization task is started because there's no
    available CPU budget. This ensures the worker is woken up again to
    retry.
    
    * Utilize n-1 CPUs with optimization tasks
    
    * Better handle situations where CPU budget is drained
    
    * Dynamically scale rayon CPU count based on CPU size
    
    * Fix incorrect default for max_indexing_threads conversion
    
    * Respect max_indexing_threads for collection
    
    * Make max_indexing_threads optional, use none to set no limit
    
    * Update property documentation and comments
    
    * Property max_optimization_threads is per shard, not per collection
    
    * If we reached shard optimization limit, skip further checks
    
    * Add remaining TODOs
    
    * Fix spelling mistake
    
    * Align gRPC comment blocks
    
    * Fix compilation errors since last rebase
    
    * Make tests aware of CPU budget
    
    * Use new CPU budget calculation function everywhere
    
    * Make CPU budget configurable in settings, move static budget to common
    
    * Do not use static CPU budget, instance it and pass it through
    
    * Update CPU budget description
    
    * Move heuristic into defaults
    
    * Fix spelling issues
    
    * Move cpu_budget property to a better place
    
    * Move some things around
    
    * Minor review improvements
    
    * Use range match statement for CPU count heuristics
    
    * Systems with 1 or 2 CPUs do not keep cores unallocated by default
    
    * Fix compilation errors since last rebase
    
    * Update lib/segment/src/types.rs
    
    Co-authored-by: Luis Cossío <luis.cossio@qdrant.com>
    
    * Update lib/storage/src/content_manager/toc/transfer.rs
    
    Co-authored-by: Luis Cossío <luis.cossio@qdrant.com>
    
    * Rename cpu_budget to optimizer_cpu_budget
    
    * Update OpenAPI specification
    
    * Require at least half of the desired CPUs for optimizers
    
    This prevents running optimizations with just one CPU, which could be
    very slow.
    
    * Don't use wildcard in CPU heuristic match statements
    
    * Rename cpu_budget setting to optimizer_cpu_budget
    
    * Update CPU budget comments
    
    * Spell acquire correctly
    
    * Change if-else into match
    
    Co-authored-by: Luis Cossío <luis.cossio@qdrant.com>
    
    * Rename max_rayon_threads to num_rayon_threads, add explanation
    
    * Explain limit in update handler
    
    * Remove numbers for automatic selection of indexing threads
    
    * Inline max_workers variable
    
    * Remove CPU budget from ShardTransferConsensus trait, it is in collection
    
    * small allow(dead_code) => cfg(test)
    
    * Remove now obsolete lazy_static
    
    * Fix incorrect CPU calculation in CPU saturation test
    
    * Make waiting for CPU budget async, don't block current thread
    
    * Prevent deadlock on optimizer signal channel
    
    Do not block the optimization worker task anymore to wait for CPU budget
    to be available. That prevents our optimizer signal channel from being
    drained, blocking incoming updates because the cannot send another
    optimizer signal. Now, prevent blocking this task all together and
    retrigger the optimizers separately when CPU budget is available again.
    
    * Fix incorrect CPU calculation in optimization cancel test
    
    * Rename CPU budget wait function to notify
    
    * Detach API changes from CPU saturation internals
    
    This allows us to merge into a patch version of Qdrant. We can
    reintroduce the API changes in the upcoming minor release to make all of
    it fully functional.
    
    ---------
    
    Co-authored-by: Luis Cossío <luis.cossio@qdrant.com>
    Co-authored-by: Luis Cossío <luis.cossio@outlook.com>

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 0e6b7633d..5689e5410 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -289,12 +289,14 @@ mod tests {
     use std::sync::atomic::AtomicBool;
     use std::sync::Arc;
 
+    use common::cpu::CpuPermit;
     use itertools::Itertools;
     use parking_lot::lock_api::RwLock;
     use rand::thread_rng;
     use segment::data_types::vectors::DEFAULT_VECTOR_NAME;
     use segment::entry::entry_point::SegmentEntry;
     use segment::fixtures::index_fixtures::random_vector;
+    use segment::index::hnsw_index::num_rayon_threads;
     use segment::types::{Distance, Payload, PayloadSchemaType};
     use serde_json::json;
     use tempfile::Builder;
@@ -384,8 +386,16 @@ mod tests {
             index_optimizer.check_condition(locked_holder.clone(), &excluded_ids);
         assert!(suggested_to_optimize.contains(&large_segment_id));
 
+        let permit_cpu_count = num_rayon_threads(0);
+        let permit = CpuPermit::dummy(permit_cpu_count as u32);
+
         index_optimizer
-            .optimize(locked_holder.clone(), suggested_to_optimize, &stopped)
+            .optimize(
+                locked_holder.clone(),
+                suggested_to_optimize,
+                permit,
+                &stopped,
+            )
             .unwrap();
 
         let infos = locked_holder
@@ -516,22 +526,36 @@ mod tests {
         )
         .unwrap();
 
+        let permit_cpu_count = num_rayon_threads(0);
+        let permit = CpuPermit::dummy(permit_cpu_count as u32);
+
         // ------ Plain -> Mmap & Indexed payload
         let suggested_to_optimize =
             index_optimizer.check_condition(locked_holder.clone(), &excluded_ids);
         assert!(suggested_to_optimize.contains(&large_segment_id));
         eprintln!("suggested_to_optimize = {suggested_to_optimize:#?}");
         index_optimizer
-            .optimize(locked_holder.clone(), suggested_to_optimize, &stopped)
+            .optimize(
+                locked_holder.clone(),
+                suggested_to_optimize,
+                permit,
+                &stopped,
+            )
             .unwrap();
         eprintln!("Done");
 
         // ------ Plain -> Indexed payload
+        let permit = CpuPermit::dummy(permit_cpu_count as u32);
         let suggested_to_optimize =
             index_optimizer.check_condition(locked_holder.clone(), &excluded_ids);
         assert!(suggested_to_optimize.contains(&middle_segment_id));
         index_optimizer
-            .optimize(locked_holder.clone(), suggested_to_optimize, &stopped)
+            .optimize(
+                locked_holder.clone(),
+                suggested_to_optimize,
+                permit,
+                &stopped,
+            )
             .unwrap();
 
         // ------- Keep smallest segment without changes
@@ -643,12 +667,18 @@ mod tests {
         // ---- New appendable segment should be created if none left
 
         // Index even the smallest segment
+        let permit = CpuPermit::dummy(permit_cpu_count as u32);
         index_optimizer.thresholds_config.indexing_threshold = 20;
         let suggested_to_optimize =
             index_optimizer.check_condition(locked_holder.clone(), &Default::default());
         assert!(suggested_to_optimize.contains(&small_segment_id));
         index_optimizer
-            .optimize(locked_holder.clone(), suggested_to_optimize, &stopped)
+            .optimize(
+                locked_holder.clone(),
+                suggested_to_optimize,
+                permit,
+                &stopped,
+            )
             .unwrap();
 
         let new_infos2 = locked_holder
@@ -823,9 +853,17 @@ mod tests {
             Default::default(),
         );
 
+        let permit_cpu_count = num_rayon_threads(0);
+        let permit = CpuPermit::dummy(permit_cpu_count as u32);
+
         // Use indexing optimizer to build mmap
         let changed = index_optimizer
-            .optimize(locked_holder.clone(), vec![segment_id], &false.into())
+            .optimize(
+                locked_holder.clone(),
+                vec![segment_id],
+                permit,
+                &false.into(),
+            )
             .unwrap();
         assert!(
             changed,

commit d39a483017d14971051e30be5023dd4e969163b6
Author: xzfc <5121426+xzfc@users.noreply.github.com>
Date:   Tue Feb 20 14:55:57 2024 +0000

    Refactor: introduce details level enum (#3612)

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 5689e5410..66bcdbe5e 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -2,6 +2,7 @@ use std::collections::HashSet;
 use std::path::{Path, PathBuf};
 use std::sync::Arc;
 
+use common::types::TelemetryDetail;
 use parking_lot::Mutex;
 use segment::common::operation_time_statistics::{
     OperationDurationStatistics, OperationDurationsAggregator,
@@ -272,8 +273,8 @@ impl SegmentOptimizer for IndexingOptimizer {
         self.worst_segment(segments, excluded_ids)
     }
 
-    fn get_telemetry_data(&self) -> OperationDurationStatistics {
-        self.get_telemetry_counter().lock().get_statistics()
+    fn get_telemetry_data(&self, detail: TelemetryDetail) -> OperationDurationStatistics {
+        self.get_telemetry_counter().lock().get_statistics(detail)
     }
 
     fn get_telemetry_counter(&self) -> Arc<Mutex<OperationDurationsAggregator>> {

commit 19f43f5b30a81509fd8221f059824caa30fb2a84
Author: xzfc <5121426+xzfc@users.noreply.github.com>
Date:   Thu Feb 22 10:39:33 2024 +0000

    Prometheus histogram support (#3552)
    
    * Get rid of Arc in SegmentOptimizer::get_telemetry_counter()
    
    * Get rid of SegmentOptimizer::get_telemetry_data
    
    * Prometheus histogram support
    
    * Fixes, and sparse buckets
    
    * Preallocate in convert_histogram, merge_histograms
    
    * debug_assert to check boundaries are sorted
    
    * Generate histograms when details_level >= 3 or in /metrics

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 66bcdbe5e..6e3d8804f 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -2,11 +2,8 @@ use std::collections::HashSet;
 use std::path::{Path, PathBuf};
 use std::sync::Arc;
 
-use common::types::TelemetryDetail;
 use parking_lot::Mutex;
-use segment::common::operation_time_statistics::{
-    OperationDurationStatistics, OperationDurationsAggregator,
-};
+use segment::common::operation_time_statistics::OperationDurationsAggregator;
 use segment::types::{HnswConfig, QuantizationConfig, SegmentType, VECTOR_ELEMENT_SIZE};
 
 use crate::collection_manager::holders::segment_holder::{
@@ -273,12 +270,8 @@ impl SegmentOptimizer for IndexingOptimizer {
         self.worst_segment(segments, excluded_ids)
     }
 
-    fn get_telemetry_data(&self, detail: TelemetryDetail) -> OperationDurationStatistics {
-        self.get_telemetry_counter().lock().get_statistics(detail)
-    }
-
-    fn get_telemetry_counter(&self) -> Arc<Mutex<OperationDurationsAggregator>> {
-        self.telemetry_durations_aggregator.clone()
+    fn get_telemetry_counter(&self) -> &Mutex<OperationDurationsAggregator> {
+        &self.telemetry_durations_aggregator
     }
 }
 

commit 3beb4e3b4ff4b3f9585337f4e5b0826a14e247b6
Author: xzfc <5121426+xzfc@users.noreply.github.com>
Date:   Fri Feb 23 14:38:40 2024 +0000

    Introduce JsonPathString (#3674)
    
    * Introduce JsonPathString
    
    * Fix fomatting

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 6e3d8804f..5d960072a 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -291,6 +291,7 @@ mod tests {
     use segment::entry::entry_point::SegmentEntry;
     use segment::fixtures::index_fixtures::random_vector;
     use segment::index::hnsw_index::num_rayon_threads;
+    use segment::json_path::JsonPath;
     use segment::types::{Distance, Payload, PayloadSchemaType};
     use serde_json::json;
     use tempfile::Builder;
@@ -425,7 +426,7 @@ mod tests {
         let mut rng = thread_rng();
         let mut holder = SegmentHolder::default();
 
-        let payload_field = "number".to_owned();
+        let payload_field: JsonPath = "number".parse().unwrap();
 
         let stopped = AtomicBool::new(false);
         let dim = 256;
@@ -514,7 +515,7 @@ mod tests {
             locked_holder.deref(),
             opnum.next().unwrap(),
             &FieldIndexOperations::CreateIndex(CreateIndex {
-                field_name: payload_field.to_owned(),
+                field_name: payload_field.clone(),
                 field_schema: Some(PayloadSchemaType::Integer.into()),
             }),
         )

commit a6817c54671d824943515ebfc79a40248d94d5b0
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Fri Mar 15 13:59:03 2024 +0100

    Fix optimizations config (#3832)
    
    * fix updating of the max_optimization_threads param
    
    * fix logic of the indexig optimizer
    
    * fmt
    
    * Update lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs [no-ci]
    
    Co-authored-by: Tim Visée <tim+github@visee.me>
    
    * add test
    
    ---------
    
    Co-authored-by: Tim Visée <tim+github@visee.me>

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 5d960072a..2d5e35af1 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -21,6 +21,7 @@ const BYTES_IN_KB: usize = 1024;
 /// The process of index creation is slow and CPU-bounded, so it is convenient to perform
 /// index building in a same way as segment re-creation.
 pub struct IndexingOptimizer {
+    default_segments_number: usize,
     thresholds_config: OptimizerThresholds,
     segments_path: PathBuf,
     collection_temp_dir: PathBuf,
@@ -32,6 +33,7 @@ pub struct IndexingOptimizer {
 
 impl IndexingOptimizer {
     pub fn new(
+        default_segments_number: usize,
         thresholds_config: OptimizerThresholds,
         segments_path: PathBuf,
         collection_temp_dir: PathBuf,
@@ -40,6 +42,7 @@ impl IndexingOptimizer {
         quantization_config: Option<QuantizationConfig>,
     ) -> Self {
         IndexingOptimizer {
+            default_segments_number,
             thresholds_config,
             segments_path,
             collection_temp_dir,
@@ -86,7 +89,7 @@ impl IndexingOptimizer {
 
                 Some((idx, vector_size))
             })
-            .min_by_key(|(_, vector_size)| *vector_size)
+            .min_by_key(|(_, vector_size_bytes)| *vector_size_bytes)
             .map(|(idx, size)| (*idx, size))
     }
 
@@ -104,7 +107,7 @@ impl IndexingOptimizer {
                 let segment_entry = segment.get();
                 let read_segment = segment_entry.read();
                 let point_count = read_segment.available_point_count();
-                let max_vector_size = point_count
+                let max_vector_size_bytes = point_count
                     * read_segment
                         .vector_dims()
                         .values()
@@ -119,11 +122,11 @@ impl IndexingOptimizer {
                     return None; // Never optimize already optimized segment
                 }
 
-                let indexing_threshold_kb = self
+                let indexing_threshold_bytes = self
                     .thresholds_config
                     .indexing_threshold
                     .saturating_mul(BYTES_IN_KB);
-                let mmap_threshold_kb = self
+                let mmap_threshold_bytes = self
                     .thresholds_config
                     .memmap_threshold
                     .saturating_mul(BYTES_IN_KB);
@@ -133,10 +136,11 @@ impl IndexingOptimizer {
                     if let Some(vector_data) = segment_config.vector_data.get(vector_name) {
                         let is_indexed = vector_data.index.is_indexed();
                         let is_on_disk = vector_data.storage_type.is_on_disk();
-                        let storage_size = point_count * vector_data.size * VECTOR_ELEMENT_SIZE;
+                        let storage_size_bytes =
+                            point_count * vector_data.size * VECTOR_ELEMENT_SIZE;
 
-                        let is_big_for_index = storage_size >= indexing_threshold_kb;
-                        let is_big_for_mmap = storage_size >= mmap_threshold_kb;
+                        let is_big_for_index = storage_size_bytes >= indexing_threshold_bytes;
+                        let is_big_for_mmap = storage_size_bytes >= mmap_threshold_bytes;
 
                         let optimize_for_index = is_big_for_index && !is_indexed;
                         let optimize_for_mmap = if let Some(on_disk_config) = vector_config.on_disk
@@ -168,8 +172,8 @@ impl IndexingOptimizer {
 
                                 let storage_size = point_count * vector_dim * VECTOR_ELEMENT_SIZE;
 
-                                let is_big_for_index = storage_size >= indexing_threshold_kb;
-                                let is_big_for_mmap = storage_size >= mmap_threshold_kb;
+                                let is_big_for_index = storage_size >= indexing_threshold_bytes;
+                                let is_big_for_mmap = storage_size >= mmap_threshold_bytes;
 
                                 let is_big = is_big_for_index || is_big_for_mmap;
 
@@ -182,27 +186,36 @@ impl IndexingOptimizer {
                     }
                 }
 
-                require_optimization.then_some((*idx, max_vector_size))
+                require_optimization.then_some((*idx, max_vector_size_bytes))
             })
             .collect();
 
         // Select the largest unindexed segment, return if none
         let selected_segment = candidates
             .iter()
-            .max_by_key(|(_, vector_size)| *vector_size);
+            .max_by_key(|(_, vector_size_bytes)| *vector_size_bytes);
         if selected_segment.is_none() {
             return vec![];
         }
         let (selected_segment_id, selected_segment_size) = *selected_segment.unwrap();
 
+        let number_of_segments = segments_read_guard.len();
+
+        // If the number of segments if equal or bigger than the default_segments_number
+        // We want to make sure that we at least do not increase number of segments after optimization, thus we take more than one segment to optimize
+
+        if number_of_segments < self.default_segments_number {
+            return vec![selected_segment_id];
+        }
+
         // It is better for scheduling if indexing optimizer optimizes 2 segments.
         // Because result of the optimization is usually 2 segment - it should preserve
         // overall count of segments.
 
-        // Find smallest unindexed to check if we can index together
+        // Find the smallest unindexed to check if we can index together
         let smallest_unindexed = candidates
             .iter()
-            .min_by_key(|(_, vector_size)| *vector_size);
+            .min_by_key(|(_, vector_size_bytes)| *vector_size_bytes);
         if let Some((idx, size)) = smallest_unindexed {
             if *idx != selected_segment_id
                 && selected_segment_size + size
@@ -352,6 +365,7 @@ mod tests {
             .collect();
 
         let mut index_optimizer = IndexingOptimizer::new(
+            2,
             OptimizerThresholds {
                 max_segment_size: 300,
                 memmap_threshold: 1000,
@@ -452,6 +466,7 @@ mod tests {
         let large_segment_id = holder.add(large_segment);
 
         let mut index_optimizer = IndexingOptimizer::new(
+            2,
             OptimizerThresholds {
                 max_segment_size: 300,
                 memmap_threshold: 1000,
@@ -712,6 +727,101 @@ mod tests {
         .unwrap();
     }
 
+    /// Test that indexing optimizer maintain expected number of during the optimization duty
+    #[test]
+    fn test_indexing_optimizer_with_number_of_segments() {
+        init();
+
+        let mut holder = SegmentHolder::default();
+
+        let stopped = AtomicBool::new(false);
+        let dim = 256;
+
+        let segments_dir = Builder::new().prefix("segments_dir").tempdir().unwrap();
+        let segments_temp_dir = Builder::new()
+            .prefix("segments_temp_dir")
+            .tempdir()
+            .unwrap();
+        let mut opnum = 101..1000000;
+
+        let segments = vec![
+            random_segment(segments_dir.path(), opnum.next().unwrap(), 100, dim),
+            random_segment(segments_dir.path(), opnum.next().unwrap(), 100, dim),
+            random_segment(segments_dir.path(), opnum.next().unwrap(), 100, dim),
+            random_segment(segments_dir.path(), opnum.next().unwrap(), 100, dim),
+        ];
+
+        let number_of_segments = segments.len();
+        let segment_config = segments[0].segment_config.clone();
+
+        let _segment_ids: Vec<SegmentId> = segments
+            .into_iter()
+            .map(|segment| holder.add(segment))
+            .collect();
+
+        let locked_holder: Arc<RwLock<_, _>> = Arc::new(RwLock::new(holder));
+
+        let index_optimizer = IndexingOptimizer::new(
+            number_of_segments, // Keep the same number of segments
+            OptimizerThresholds {
+                max_segment_size: 1000,
+                memmap_threshold: 1000,
+                indexing_threshold: 10, // Always optimize
+            },
+            segments_dir.path().to_owned(),
+            segments_temp_dir.path().to_owned(),
+            CollectionParams {
+                vectors: VectorsConfig::Single(VectorParams {
+                    size: NonZeroU64::new(
+                        segment_config.vector_data[DEFAULT_VECTOR_NAME].size as u64,
+                    )
+                    .unwrap(),
+                    distance: segment_config.vector_data[DEFAULT_VECTOR_NAME].distance,
+                    hnsw_config: None,
+                    quantization_config: None,
+                    on_disk: None,
+                }),
+                ..CollectionParams::empty()
+            },
+            Default::default(),
+            Default::default(),
+        );
+
+        let permit_cpu_count = num_rayon_threads(0);
+
+        // Index until all segments are indexed
+        let mut numer_of_optimizations = 0;
+        loop {
+            let suggested_to_optimize =
+                index_optimizer.check_condition(locked_holder.clone(), &Default::default());
+            if suggested_to_optimize.is_empty() {
+                break;
+            }
+            log::debug!("suggested_to_optimize = {:#?}", suggested_to_optimize);
+
+            let permit = CpuPermit::dummy(permit_cpu_count as u32);
+            index_optimizer
+                .optimize(
+                    locked_holder.clone(),
+                    suggested_to_optimize,
+                    permit,
+                    &stopped,
+                )
+                .unwrap();
+            numer_of_optimizations += 1;
+            assert!(numer_of_optimizations <= number_of_segments);
+            let number_of_segments = locked_holder.read().len();
+            log::debug!(
+                "numer_of_optimizations = {}, number_of_segments = {}",
+                numer_of_optimizations,
+                number_of_segments
+            );
+        }
+
+        // Ensure that the total number of segments did not change
+        assert_eq!(locked_holder.read().len(), number_of_segments);
+    }
+
     /// This tests things are as we expect when we define both `on_disk: false` and `memmap_threshold`
     ///
     /// Before this PR (<https://github.com/qdrant/qdrant/pull/3167>) such configuration would create an infinite optimization loop.
@@ -771,6 +881,7 @@ mod tests {
         {
             // Optimizers used in test
             let index_optimizer = IndexingOptimizer::new(
+                2,
                 thresholds_config.clone(),
                 dir.path().to_owned(),
                 temp_dir.path().to_owned(),
@@ -832,6 +943,7 @@ mod tests {
 
         // Optimizers used in test
         let index_optimizer = IndexingOptimizer::new(
+            2,
             thresholds_config.clone(),
             dir.path().to_owned(),
             temp_dir.path().to_owned(),

commit db5399f9e47cfe9d740645ec2f27e8751444882b
Author: Ivan Pleshkov <pleshkov.ivan@gmail.com>
Date:   Mon Mar 18 13:31:55 2024 +0100

    Use rest vector type as non segment part (#3829)
    
    * use rest vector type as non-segment part
    
    * add todo
    
    * switch into -> from
    
    * review remarks
    
    * review remarks

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 2d5e35af1..e25e146b3 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -300,7 +300,7 @@ mod tests {
     use itertools::Itertools;
     use parking_lot::lock_api::RwLock;
     use rand::thread_rng;
-    use segment::data_types::vectors::DEFAULT_VECTOR_NAME;
+    use segment::data_types::vectors::{BatchVectorStruct, DEFAULT_VECTOR_NAME};
     use segment::entry::entry_point::SegmentEntry;
     use segment::fixtures::index_fixtures::random_vector;
     use segment::index::hnsw_index::num_rayon_threads;
@@ -630,11 +630,11 @@ mod tests {
         let point_payload: Payload = json!({"number":10000i64}).into();
         let insert_point_ops: PointOperations = Batch {
             ids: vec![501.into(), 502.into(), 503.into()],
-            vectors: vec![
+            vectors: BatchVectorStruct::from(vec![
                 random_vector(&mut rng, dim),
                 random_vector(&mut rng, dim),
                 random_vector(&mut rng, dim),
-            ]
+            ])
             .into(),
             payloads: Some(vec![
                 Some(point_payload.clone()),
@@ -709,11 +709,11 @@ mod tests {
 
         let insert_point_ops: PointOperations = Batch {
             ids: vec![601.into(), 602.into(), 603.into()],
-            vectors: vec![
+            vectors: BatchVectorStruct::from(vec![
                 random_vector(&mut rng, dim),
                 random_vector(&mut rng, dim),
                 random_vector(&mut rng, dim),
-            ]
+            ])
             .into(),
             payloads: None,
         }

commit 632ec541e28ffc8450909e52102c6ade5715a357
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Thu Apr 18 15:22:28 2024 +0200

    Byte storage api support (#4065)
    
    * wip: include datatype in vector params API
    
    * generate api schemas
    
    * propagate datatype to segment creation
    
    * fix review
    
    * fmt

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index e25e146b3..76ef555bf 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -291,7 +291,6 @@ impl SegmentOptimizer for IndexingOptimizer {
 #[cfg(test)]
 mod tests {
     use std::collections::BTreeMap;
-    use std::num::NonZeroU64;
     use std::ops::Deref;
     use std::sync::atomic::AtomicBool;
     use std::sync::Arc;
@@ -318,6 +317,7 @@ mod tests {
     };
     use crate::operations::point_ops::{Batch, PointOperations};
     use crate::operations::types::{VectorParams, VectorsConfig};
+    use crate::operations::vector_params_builder::VectorParamsBuilder;
     use crate::operations::{CreateIndex, FieldIndexOperations};
 
     fn init() {
@@ -353,13 +353,7 @@ mod tests {
             .map(|(name, params)| {
                 (
                     name.to_string(),
-                    VectorParams {
-                        size: NonZeroU64::new(params.size as u64).unwrap(),
-                        distance: params.distance,
-                        hnsw_config: None,
-                        quantization_config: None,
-                        on_disk: None,
-                    },
+                    VectorParamsBuilder::new(params.size as u64, params.distance).build(),
                 )
             })
             .collect();
@@ -475,16 +469,13 @@ mod tests {
             segments_dir.path().to_owned(),
             segments_temp_dir.path().to_owned(),
             CollectionParams {
-                vectors: VectorsConfig::Single(VectorParams {
-                    size: NonZeroU64::new(
+                vectors: VectorsConfig::Single(
+                    VectorParamsBuilder::new(
                         segment_config.vector_data[DEFAULT_VECTOR_NAME].size as u64,
+                        segment_config.vector_data[DEFAULT_VECTOR_NAME].distance,
                     )
-                    .unwrap(),
-                    distance: segment_config.vector_data[DEFAULT_VECTOR_NAME].distance,
-                    hnsw_config: None,
-                    quantization_config: None,
-                    on_disk: None,
-                }),
+                    .build(),
+                ),
                 ..CollectionParams::empty()
             },
             Default::default(),
@@ -771,16 +762,13 @@ mod tests {
             segments_dir.path().to_owned(),
             segments_temp_dir.path().to_owned(),
             CollectionParams {
-                vectors: VectorsConfig::Single(VectorParams {
-                    size: NonZeroU64::new(
+                vectors: VectorsConfig::Single(
+                    VectorParamsBuilder::new(
                         segment_config.vector_data[DEFAULT_VECTOR_NAME].size as u64,
+                        segment_config.vector_data[DEFAULT_VECTOR_NAME].distance,
                     )
-                    .unwrap(),
-                    distance: segment_config.vector_data[DEFAULT_VECTOR_NAME].distance,
-                    hnsw_config: None,
-                    quantization_config: None,
-                    on_disk: None,
-                }),
+                    .build(),
+                ),
                 ..CollectionParams::empty()
             },
             Default::default(),
@@ -849,13 +837,11 @@ mod tests {
             indexing_threshold: usize::MAX,
         };
         let mut collection_params = CollectionParams {
-            vectors: VectorsConfig::Single(VectorParams {
-                size: dim.try_into().unwrap(),
-                distance: Distance::Dot,
-                hnsw_config: None,
-                quantization_config: None,
-                on_disk: Some(false),
-            }),
+            vectors: VectorsConfig::Single(
+                VectorParamsBuilder::new(dim as u64, Distance::Dot)
+                    .with_on_disk(false)
+                    .build(),
+            ),
             ..CollectionParams::empty()
         };
 

commit 1d724579dfd6ed5adeda31429bab5821cab5af30
Author: xzfc <5121426+xzfc@users.noreply.github.com>
Date:   Thu May 16 06:47:47 2024 +0000

    InvertedIndexImmutableRam and index migrations (#4220)
    
    * Move StorageVersion from segment crate to common/io
    
    * Refine StorageVersion API
    
    * Move methods from SparseVectorDataConfig to enum SparseIndexType
    
    * Introduce InvertedIndexImmutableRam
    
    * Add migrate
    
    * Don't migrate

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 76ef555bf..2408cd298 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -168,7 +168,8 @@ impl IndexingOptimizer {
                                 let vector_dim =
                                     read_segment.vector_dim(sparse_vector_name).unwrap_or(0);
 
-                                let is_index_immutable = sparse_vector_data.is_index_immutable();
+                                let is_index_immutable =
+                                    sparse_vector_data.index.index_type.is_immutable();
 
                                 let storage_size = point_count * vector_dim * VECTOR_ELEMENT_SIZE;
 

commit aad9db1fe9c5d22dce24e1de27a92a28f7453c8d
Author: Tim Visée <tim+github@visee.me>
Date:   Mon May 27 19:03:02 2024 +0200

    Fix missing segments, use correct path for new segment created during snapshot (#4332)
    
    * Put temporary segment in correct path
    
    * Use shard directory rather than collection directory in test
    
    * Fix collection path getter, it actually returns segments path
    
    * Use segments path for temporary segment
    
    * The build segment function actually wants the segments path
    
    * Refactor parameter name

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 2408cd298..f5dbd23b9 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -252,7 +252,7 @@ impl SegmentOptimizer for IndexingOptimizer {
         "indexing"
     }
 
-    fn collection_path(&self) -> &Path {
+    fn segments_path(&self) -> &Path {
         self.segments_path.as_path()
     }
 

commit 21a3fb5f38a796f37883017adc993d0322bbca8f
Author: Ivan Pleshkov <pleshkov.ivan@gmail.com>
Date:   Tue May 28 16:38:56 2024 +0200

    Use correct vector storage size (#4312)
    
    * use correct vector storage size
    
    * remove dim from segment entry
    
    * are you happy fmt
    
    * codespell and proportions
    
    * remove obsolete comment
    
    * remove `try_vector_dim`
    
    * are you happy fmt
    
    * remove todo
    
    * revert code of conduct
    
    * check div 0
    
    * Simplify a bit with max iterator
    
    * Update lib/segment/src/index/hnsw_index/hnsw.rs
    
    Co-authored-by: Tim Visée <tim+github@visee.me>
    
    * are you happy fmt
    
    * Update lib/segment/src/index/plain_payload_index.rs
    
    Co-authored-by: Tim Visée <tim+github@visee.me>
    
    * review fix
    
    * set full scan threshold 0 for test
    
    * use u128 also for multivector storages
    
    * fix sparse vector size calculation
    
    * Move size calculation into if-branch
    
    ---------
    
    Co-authored-by: timvisee <tim@visee.me>
    Co-authored-by: Tim Visée <tim+github@visee.me>

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index f5dbd23b9..dedddb2d1 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -4,7 +4,7 @@ use std::sync::Arc;
 
 use parking_lot::Mutex;
 use segment::common::operation_time_statistics::OperationDurationsAggregator;
-use segment::types::{HnswConfig, QuantizationConfig, SegmentType, VECTOR_ELEMENT_SIZE};
+use segment::types::{HnswConfig, QuantizationConfig, SegmentType};
 
 use crate::collection_manager::holders::segment_holder::{
     LockedSegmentHolder, SegmentHolder, SegmentId,
@@ -65,15 +65,9 @@ impl IndexingOptimizer {
             .filter_map(|(idx, segment)| {
                 let segment_entry = segment.get();
                 let read_segment = segment_entry.read();
-                let point_count = read_segment.available_point_count();
-                let vector_size = point_count
-                    * read_segment
-                        .vector_dims()
-                        .values()
-                        .max()
-                        .copied()
-                        .unwrap_or(0)
-                    * VECTOR_ELEMENT_SIZE;
+                let vector_size = read_segment
+                    .max_available_vectors_size_in_bytes()
+                    .unwrap_or_default();
 
                 if read_segment.segment_type() == SegmentType::Special {
                     return None; // Never optimize already optimized segment
@@ -106,15 +100,9 @@ impl IndexingOptimizer {
             .filter_map(|(idx, segment)| {
                 let segment_entry = segment.get();
                 let read_segment = segment_entry.read();
-                let point_count = read_segment.available_point_count();
-                let max_vector_size_bytes = point_count
-                    * read_segment
-                        .vector_dims()
-                        .values()
-                        .max()
-                        .copied()
-                        .unwrap_or(0)
-                    * VECTOR_ELEMENT_SIZE;
+                let max_vector_size_bytes = read_segment
+                    .max_available_vectors_size_in_bytes()
+                    .unwrap_or_default();
 
                 let segment_config = read_segment.config();
 
@@ -136,8 +124,9 @@ impl IndexingOptimizer {
                     if let Some(vector_data) = segment_config.vector_data.get(vector_name) {
                         let is_indexed = vector_data.index.is_indexed();
                         let is_on_disk = vector_data.storage_type.is_on_disk();
-                        let storage_size_bytes =
-                            point_count * vector_data.size * VECTOR_ELEMENT_SIZE;
+                        let storage_size_bytes = read_segment
+                            .available_vectors_size_in_bytes(vector_name)
+                            .unwrap_or_default();
 
                         let is_big_for_index = storage_size_bytes >= indexing_threshold_bytes;
                         let is_big_for_mmap = storage_size_bytes >= mmap_threshold_bytes;
@@ -165,13 +154,12 @@ impl IndexingOptimizer {
                             if let Some(sparse_vector_data) =
                                 segment_config.sparse_vector_data.get(sparse_vector_name)
                             {
-                                let vector_dim =
-                                    read_segment.vector_dim(sparse_vector_name).unwrap_or(0);
-
                                 let is_index_immutable =
                                     sparse_vector_data.index.index_type.is_immutable();
 
-                                let storage_size = point_count * vector_dim * VECTOR_ELEMENT_SIZE;
+                                let storage_size = read_segment
+                                    .available_vectors_size_in_bytes(sparse_vector_name)
+                                    .unwrap_or_default();
 
                                 let is_big_for_index = storage_size >= indexing_threshold_bytes;
                                 let is_big_for_mmap = storage_size >= mmap_threshold_bytes;

commit a7f2e7a3c9861c90630917b96e5f59db70cedbe5
Author: Tim Visée <tim+github@visee.me>
Date:   Thu Jun 6 20:11:00 2024 +0200

    Fix deadlock caused by concurrent snapshot and optimization (#4402)
    
    * Rename segment addition functions, clarify this generates a new ID
    
    * Don't randomize segment IDs, auto increment to prevent duplicates
    
    * Rename swap to swap_new
    
    * On snapshot unproxy, put segments back with their original segment ID
    
    * Add sanity check to optimizer unproxy, must swap same number of segments
    
    * Clean up
    
    * Extend snapshot test, assert we end up with the same segment IDs

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index dedddb2d1..34a9c7dad 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -334,7 +334,7 @@ mod tests {
 
         let segment_config = large_segment.segment_config.clone();
 
-        let large_segment_id = holder.add(large_segment);
+        let large_segment_id = holder.add_new(large_segment);
 
         let vectors_config: BTreeMap<String, VectorParams> = segment_config
             .vector_data
@@ -443,10 +443,10 @@ mod tests {
 
         let segment_config = small_segment.segment_config.clone();
 
-        let small_segment_id = holder.add(small_segment);
-        let middle_low_segment_id = holder.add(middle_low_segment);
-        let middle_segment_id = holder.add(middle_segment);
-        let large_segment_id = holder.add(large_segment);
+        let small_segment_id = holder.add_new(small_segment);
+        let middle_low_segment_id = holder.add_new(middle_low_segment);
+        let middle_segment_id = holder.add_new(middle_segment);
+        let large_segment_id = holder.add_new(large_segment);
 
         let mut index_optimizer = IndexingOptimizer::new(
             2,
@@ -736,7 +736,7 @@ mod tests {
 
         let _segment_ids: Vec<SegmentId> = segments
             .into_iter()
-            .map(|segment| holder.add(segment))
+            .map(|segment| holder.add_new(segment))
             .collect();
 
         let locked_holder: Arc<RwLock<_, _>> = Arc::new(RwLock::new(holder));
@@ -841,7 +841,7 @@ mod tests {
 
         let segment = random_segment(dir.path(), 100, point_count, dim as usize);
 
-        let segment_id = holder.add(segment);
+        let segment_id = holder.add_new(segment);
         let locked_holder: Arc<parking_lot::RwLock<_>> = Arc::new(RwLock::new(holder));
 
         let hnsw_config = HnswConfig {

commit 106002c3034ac9eddc3e4cc3d2027a3f3aaa900f
Author: Tim Visée <tim+github@visee.me>
Date:   Mon Jun 10 18:45:53 2024 +0200

    Ensure we have any segment within capacity, otherwise add new one (#4416)
    
    * Extract logic for creating thresholds config
    
    * Put collection params and threshold config in update handler
    
    * Add function to add a new appendable segment if all are over capacity
    
    * Make new method static, call it before each optimization loop
    
    * Update error message formatting
    
    * Use exact point count in replication consensus test
    
    * Add a test to assert segment creation when all are over capacity
    
    * Suffix optimizer thresholds with _kb to clarify unit
    
    * Move segment capacity check logic, run if optimizers are disabled
    
    * fix: add -> mul
    
    ---------
    
    Co-authored-by: generall <andrey@vasnetsov.com>

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 34a9c7dad..faa6dacfc 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -112,11 +112,11 @@ impl IndexingOptimizer {
 
                 let indexing_threshold_bytes = self
                     .thresholds_config
-                    .indexing_threshold
+                    .indexing_threshold_kb
                     .saturating_mul(BYTES_IN_KB);
                 let mmap_threshold_bytes = self
                     .thresholds_config
-                    .memmap_threshold
+                    .memmap_threshold_kb
                     .saturating_mul(BYTES_IN_KB);
                 let mut require_optimization = false;
 
@@ -210,7 +210,7 @@ impl IndexingOptimizer {
                 && selected_segment_size + size
                     < self
                         .thresholds_config
-                        .max_segment_size
+                        .max_segment_size_kb
                         .saturating_mul(BYTES_IN_KB)
             {
                 return vec![selected_segment_id, *idx];
@@ -224,7 +224,7 @@ impl IndexingOptimizer {
                 && selected_segment_size + size
                     < self
                         .thresholds_config
-                        .max_segment_size
+                        .max_segment_size_kb
                         .saturating_mul(BYTES_IN_KB)
             {
                 return vec![selected_segment_id, idx];
@@ -350,9 +350,9 @@ mod tests {
         let mut index_optimizer = IndexingOptimizer::new(
             2,
             OptimizerThresholds {
-                max_segment_size: 300,
-                memmap_threshold: 1000,
-                indexing_threshold: 1000,
+                max_segment_size_kb: 300,
+                memmap_threshold_kb: 1000,
+                indexing_threshold_kb: 1000,
             },
             segments_dir.path().to_owned(),
             segments_temp_dir.path().to_owned(),
@@ -371,8 +371,8 @@ mod tests {
             index_optimizer.check_condition(locked_holder.clone(), &excluded_ids);
         assert!(suggested_to_optimize.is_empty());
 
-        index_optimizer.thresholds_config.memmap_threshold = 1000;
-        index_optimizer.thresholds_config.indexing_threshold = 50;
+        index_optimizer.thresholds_config.memmap_threshold_kb = 1000;
+        index_optimizer.thresholds_config.indexing_threshold_kb = 50;
 
         let suggested_to_optimize =
             index_optimizer.check_condition(locked_holder.clone(), &excluded_ids);
@@ -451,9 +451,9 @@ mod tests {
         let mut index_optimizer = IndexingOptimizer::new(
             2,
             OptimizerThresholds {
-                max_segment_size: 300,
-                memmap_threshold: 1000,
-                indexing_threshold: 1000,
+                max_segment_size_kb: 300,
+                memmap_threshold_kb: 1000,
+                indexing_threshold_kb: 1000,
             },
             segments_dir.path().to_owned(),
             segments_temp_dir.path().to_owned(),
@@ -480,30 +480,30 @@ mod tests {
             index_optimizer.check_condition(locked_holder.clone(), &excluded_ids);
         assert!(suggested_to_optimize.is_empty());
 
-        index_optimizer.thresholds_config.memmap_threshold = 1000;
-        index_optimizer.thresholds_config.indexing_threshold = 50;
+        index_optimizer.thresholds_config.memmap_threshold_kb = 1000;
+        index_optimizer.thresholds_config.indexing_threshold_kb = 50;
 
         let suggested_to_optimize =
             index_optimizer.check_condition(locked_holder.clone(), &excluded_ids);
         assert!(suggested_to_optimize.contains(&large_segment_id));
         assert!(suggested_to_optimize.contains(&middle_low_segment_id));
 
-        index_optimizer.thresholds_config.memmap_threshold = 1000;
-        index_optimizer.thresholds_config.indexing_threshold = 1000;
+        index_optimizer.thresholds_config.memmap_threshold_kb = 1000;
+        index_optimizer.thresholds_config.indexing_threshold_kb = 1000;
 
         let suggested_to_optimize =
             index_optimizer.check_condition(locked_holder.clone(), &excluded_ids);
         assert!(suggested_to_optimize.is_empty());
 
-        index_optimizer.thresholds_config.memmap_threshold = 50;
-        index_optimizer.thresholds_config.indexing_threshold = 1000;
+        index_optimizer.thresholds_config.memmap_threshold_kb = 50;
+        index_optimizer.thresholds_config.indexing_threshold_kb = 1000;
 
         let suggested_to_optimize =
             index_optimizer.check_condition(locked_holder.clone(), &excluded_ids);
         assert!(suggested_to_optimize.contains(&large_segment_id));
 
-        index_optimizer.thresholds_config.memmap_threshold = 150;
-        index_optimizer.thresholds_config.indexing_threshold = 50;
+        index_optimizer.thresholds_config.memmap_threshold_kb = 150;
+        index_optimizer.thresholds_config.indexing_threshold_kb = 50;
 
         // ----- CREATE AN INDEXED FIELD ------
         process_field_index_operation(
@@ -658,7 +658,7 @@ mod tests {
 
         // Index even the smallest segment
         let permit = CpuPermit::dummy(permit_cpu_count as u32);
-        index_optimizer.thresholds_config.indexing_threshold = 20;
+        index_optimizer.thresholds_config.indexing_threshold_kb = 20;
         let suggested_to_optimize =
             index_optimizer.check_condition(locked_holder.clone(), &Default::default());
         assert!(suggested_to_optimize.contains(&small_segment_id));
@@ -744,9 +744,9 @@ mod tests {
         let index_optimizer = IndexingOptimizer::new(
             number_of_segments, // Keep the same number of segments
             OptimizerThresholds {
-                max_segment_size: 1000,
-                memmap_threshold: 1000,
-                indexing_threshold: 10, // Always optimize
+                max_segment_size_kb: 1000,
+                memmap_threshold_kb: 1000,
+                indexing_threshold_kb: 10, // Always optimize
             },
             segments_dir.path().to_owned(),
             segments_temp_dir.path().to_owned(),
@@ -821,9 +821,9 @@ mod tests {
         // Collection configuration
         let (point_count, dim) = (1000, 10);
         let thresholds_config = OptimizerThresholds {
-            max_segment_size: usize::MAX,
-            memmap_threshold: 10,
-            indexing_threshold: usize::MAX,
+            max_segment_size_kb: usize::MAX,
+            memmap_threshold_kb: 10,
+            indexing_threshold_kb: usize::MAX,
         };
         let mut collection_params = CollectionParams {
             vectors: VectorsConfig::Single(

commit ac9313e00bc9fffebbacc4672d1cb157b2178063
Author: Tim Visée <tim+github@visee.me>
Date:   Tue Jun 11 12:59:05 2024 +0200

    When selecting a segment for writing, select the smallest one (#4440)
    
    * Preallocate list of entires to prevent some unnecessary reallocations
    
    * Implement Copy for OptimizerThresholds
    
    * Add shard holder function get smallest segment
    
    * Take the smallest segment in the segments updater
    
    * Add test to assert inserting into smallest segment
    
    * Fix compilation warnings

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index faa6dacfc..091ef99b3 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -857,7 +857,7 @@ mod tests {
             // Optimizers used in test
             let index_optimizer = IndexingOptimizer::new(
                 2,
-                thresholds_config.clone(),
+                thresholds_config,
                 dir.path().to_owned(),
                 temp_dir.path().to_owned(),
                 collection_params.clone(),
@@ -865,7 +865,7 @@ mod tests {
                 Default::default(),
             );
             let config_mismatch_optimizer = ConfigMismatchOptimizer::new(
-                thresholds_config.clone(),
+                thresholds_config,
                 dir.path().to_owned(),
                 temp_dir.path().to_owned(),
                 collection_params.clone(),
@@ -919,7 +919,7 @@ mod tests {
         // Optimizers used in test
         let index_optimizer = IndexingOptimizer::new(
             2,
-            thresholds_config.clone(),
+            thresholds_config,
             dir.path().to_owned(),
             temp_dir.path().to_owned(),
             collection_params.clone(),

commit 49a9d05e7c180c2a4828686a54b9a7a8fbc946f3
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Tue Jun 18 20:38:24 2024 +0200

    Fix multivector for unnamed vectors (#4482)
    
    * minor conversion improvement
    
    * use NamedVectors in update_vectors
    
    * remove merge from VectorStruct
    
    * rename Multi -> Named in vector struct
    
    * add multi-dense vectors option into VectorStruct
    
    * generate openapi
    
    * rename VectorStruct -> VectorStructInternal
    
    * add conversion for anonymous multivec in grpc
    
    * renames for BatchVectorStruct
    
    * implement multi-dense for batch
    
    * allow multi-dense in batch upserts
    
    * test and fixes

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 091ef99b3..34601f955 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -288,7 +288,7 @@ mod tests {
     use itertools::Itertools;
     use parking_lot::lock_api::RwLock;
     use rand::thread_rng;
-    use segment::data_types::vectors::{BatchVectorStruct, DEFAULT_VECTOR_NAME};
+    use segment::data_types::vectors::{BatchVectorStructInternal, DEFAULT_VECTOR_NAME};
     use segment::entry::entry_point::SegmentEntry;
     use segment::fixtures::index_fixtures::random_vector;
     use segment::index::hnsw_index::num_rayon_threads;
@@ -610,7 +610,7 @@ mod tests {
         let point_payload: Payload = json!({"number":10000i64}).into();
         let insert_point_ops: PointOperations = Batch {
             ids: vec![501.into(), 502.into(), 503.into()],
-            vectors: BatchVectorStruct::from(vec![
+            vectors: BatchVectorStructInternal::from(vec![
                 random_vector(&mut rng, dim),
                 random_vector(&mut rng, dim),
                 random_vector(&mut rng, dim),
@@ -689,7 +689,7 @@ mod tests {
 
         let insert_point_ops: PointOperations = Batch {
             ids: vec![601.into(), 602.into(), 603.into()],
-            vectors: BatchVectorStruct::from(vec![
+            vectors: BatchVectorStructInternal::from(vec![
                 random_vector(&mut rng, dim),
                 random_vector(&mut rng, dim),
                 random_vector(&mut rng, dim),

commit 07c278ad51084c98adf9a7093619ffc5a73f87c9
Author: xzfc <5121426+xzfc@users.noreply.github.com>
Date:   Mon Jul 22 08:19:19 2024 +0000

    Enable some of the pedantic clippy lints (#4715)
    
    * Use workspace lints
    
    * Enable lint: manual_let_else
    
    * Enable lint: enum_glob_use
    
    * Enable lint: filter_map_next
    
    * Enable lint: ref_as_ptr
    
    * Enable lint: ref_option_ref
    
    * Enable lint: manual_is_variant_and
    
    * Enable lint: flat_map_option
    
    * Enable lint: inefficient_to_string
    
    * Enable lint: implicit_clone
    
    * Enable lint: inconsistent_struct_constructor
    
    * Enable lint: unnecessary_wraps
    
    * Enable lint: needless_continue
    
    * Enable lint: unused_self
    
    * Enable lint: from_iter_instead_of_collect
    
    * Enable lint: uninlined_format_args
    
    * Enable lint: doc_link_with_quotes
    
    * Enable lint: needless_raw_string_hashes
    
    * Enable lint: used_underscore_binding
    
    * Enable lint: ptr_as_ptr
    
    * Enable lint: explicit_into_iter_loop
    
    * Enable lint: cast_lossless

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 34601f955..c5eb05f6d 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -54,7 +54,6 @@ impl IndexingOptimizer {
     }
 
     fn smallest_indexed_segment(
-        &self,
         segments: &SegmentHolder,
         excluded_ids: &HashSet<SegmentId>,
     ) -> Option<(SegmentId, usize)> {
@@ -218,7 +217,7 @@ impl IndexingOptimizer {
         }
 
         // Find smallest indexed to check if we can reindex together
-        let smallest_indexed = self.smallest_indexed_segment(&segments_read_guard, excluded_ids);
+        let smallest_indexed = Self::smallest_indexed_segment(&segments_read_guard, excluded_ids);
         if let Some((idx, size)) = smallest_indexed {
             if idx != selected_segment_id
                 && selected_segment_size + size

commit 70c46bbb6f49739acac3ee7ce55074029a40b5a1
Author: Kumar Shivendu <kshivendu1@gmail.com>
Date:   Tue Sep 10 16:52:38 2024 +0530

    Track number of points optimized and expose in telemetry (#5000)
    
    * Track number of points optimized and expose in telemetry
    
    * refactor
    
    * openapi specs
    
    * remove dbg
    
    * Return num points optimized from optimize() func
    
    * fmt
    
    * fix
    
    * fix type in tests
    
    * Store total points indexed on shard level instead of optimization level
    
    * fmt
    
    * fix test
    
    * trigger ci
    
    * fix openapi schema
    
    * review fixes
    
    * fmt
    
    * improvements and fix test
    
    * review fixes
    
    * use const for indexing optimizer name
    
    * fmt
    
    * return segment id from optimize() func
    
    * review fixes
    
    * fix
    
    * fix
    
    * fik
    
    * minor var name improvement
    
    * Use Option<usize> to return segment id
    
    * Use segment ID type rather than ambiguous usize
    
    * fix test
    
    * avoid intermediate check
    
    * review fixes
    
    * Rename total_indexed_points to total_optimized_points
    
    * Update openapi schema
    
    * optimize() should return number of points in new segment instead of segment id
    
    * add else condition
    
    * take read lock
    
    * fmt
    
    * remove flaky assert
    
    * Count points on new segment without locking
    
    ---------
    
    Co-authored-by: timvisee <tim@visee.me>
    Co-authored-by: generall <andrey@vasnetsov.com>

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index c5eb05f6d..9d507614c 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -947,7 +947,7 @@ mod tests {
             )
             .unwrap();
         assert!(
-            changed,
+            changed > 0,
             "optimizer should have rebuilt this segment for mmap"
         );
         assert!(

commit 1d0ee7ea32043598f8b240e6a3a52be20663fa44
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Wed Oct 9 10:15:46 2024 +0200

    Inference interface in REST and gRPC (#5165)
    
    * include document & image objects into grpc API
    
    * introduce image and object to rest api
    
    * minor refactoring
    
    * rename Vector -> VectorInternal
    
    * decompose vector data structures
    
    * add schema
    
    * fmt
    
    * grpc docs
    
    * fix conversion
    
    * fix clippy
    
    * fix another conversion
    
    * rename VectorInput -> VectorInputInternal
    
    * replace grpc TryFrom with async functions
    
    * fmt
    
    * replace rest TryFrom with async functions
    
    * add image and object into query rest
    
    * separate inference related conversions
    
    * move json-related conversions into a separate file
    
    * move vector-related transformations into a separate file
    
    * move more vector related-conversions into dedicated module

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 9d507614c..fa66b8248 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -287,7 +287,7 @@ mod tests {
     use itertools::Itertools;
     use parking_lot::lock_api::RwLock;
     use rand::thread_rng;
-    use segment::data_types::vectors::{BatchVectorStructInternal, DEFAULT_VECTOR_NAME};
+    use segment::data_types::vectors::DEFAULT_VECTOR_NAME;
     use segment::entry::entry_point::SegmentEntry;
     use segment::fixtures::index_fixtures::random_vector;
     use segment::index::hnsw_index::num_rayon_threads;
@@ -303,7 +303,9 @@ mod tests {
     use crate::collection_manager::segments_updater::{
         process_field_index_operation, process_point_operation,
     };
-    use crate::operations::point_ops::{Batch, PointOperations};
+    use crate::operations::point_ops::{
+        BatchPersisted, BatchVectorStructPersisted, PointInsertOperationsInternal, PointOperations,
+    };
     use crate::operations::types::{VectorParams, VectorsConfig};
     use crate::operations::vector_params_builder::VectorParamsBuilder;
     use crate::operations::{CreateIndex, FieldIndexOperations};
@@ -607,21 +609,23 @@ mod tests {
         }
 
         let point_payload: Payload = json!({"number":10000i64}).into();
-        let insert_point_ops: PointOperations = Batch {
+
+        let batch = BatchPersisted {
             ids: vec![501.into(), 502.into(), 503.into()],
-            vectors: BatchVectorStructInternal::from(vec![
+            vectors: BatchVectorStructPersisted::Single(vec![
                 random_vector(&mut rng, dim),
                 random_vector(&mut rng, dim),
                 random_vector(&mut rng, dim),
-            ])
-            .into(),
+            ]),
             payloads: Some(vec![
                 Some(point_payload.clone()),
                 Some(point_payload.clone()),
                 Some(point_payload),
             ]),
-        }
-        .into();
+        };
+
+        let insert_point_ops =
+            PointOperations::UpsertPoints(PointInsertOperationsInternal::from(batch));
 
         let smallest_size = infos
             .iter()
@@ -686,17 +690,18 @@ mod tests {
             "Testing that new segment is created if none left"
         );
 
-        let insert_point_ops: PointOperations = Batch {
+        let batch = BatchPersisted {
             ids: vec![601.into(), 602.into(), 603.into()],
-            vectors: BatchVectorStructInternal::from(vec![
+            vectors: BatchVectorStructPersisted::Single(vec![
                 random_vector(&mut rng, dim),
                 random_vector(&mut rng, dim),
                 random_vector(&mut rng, dim),
-            ])
-            .into(),
+            ]),
             payloads: None,
-        }
-        .into();
+        };
+
+        let insert_point_ops =
+            PointOperations::UpsertPoints(PointInsertOperationsInternal::from(batch));
 
         process_point_operation(
             locked_holder.deref(),

commit d4716da8e7be0111ba7ef810b3525e5bde2ae56a
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Mon Oct 14 13:13:58 2024 +0200

    fix lints for Clippy 1.82 (#5229)
    
    * fix lints for Clippy 1.82
    
    * regen openapi

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index fa66b8248..4861ea50e 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -17,6 +17,7 @@ use crate::config::CollectionParams;
 const BYTES_IN_KB: usize = 1024;
 
 /// Looks for the segments, which require to be indexed.
+///
 /// If segment is too large, but still does not have indexes - it is time to create some indexes.
 /// The process of index creation is slow and CPU-bounded, so it is convenient to perform
 /// index building in a same way as segment re-creation.

commit 28dfb3ef747ca8a2e0f3ab4aef096bcb13c0c835
Author: Arnaud Gourlay <arnaud.gourlay@gmail.com>
Date:   Fri Nov 8 13:02:23 2024 +0100

    Remove redundant clones (#5402)
    
    * Remove redundant clones
    
    * fmt

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 4861ea50e..7563bbace 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -936,7 +936,7 @@ mod tests {
             dir.path().to_owned(),
             temp_dir.path().to_owned(),
             collection_params,
-            hnsw_config.clone(),
+            hnsw_config,
             Default::default(),
         );
 

commit 38f478ddf7a9d03a1c783c5599f3b6ae33a05195
Author: Jojii <15957865+JojiiOfficial@users.noreply.github.com>
Date:   Thu Jan 16 14:25:55 2025 +0100

    Measure payload read IO (#5773)
    
    * Measure read io for payload storage
    
    * Add Hardware Counter to update functions
    
    * Fix tests and benches
    
    * Rename (some) *_measured functions back to original

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 7563bbace..5eda9640c 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -284,6 +284,7 @@ mod tests {
     use std::sync::atomic::AtomicBool;
     use std::sync::Arc;
 
+    use common::counter::hardware_counter::HardwareCounterCell;
     use common::cpu::CpuPermit;
     use itertools::Itertools;
     use parking_lot::lock_api::RwLock;
@@ -634,10 +635,13 @@ mod tests {
             .unwrap()
             .num_vectors;
 
+        let hw_counter = HardwareCounterCell::new();
+
         process_point_operation(
             locked_holder.deref(),
             opnum.next().unwrap(),
             insert_point_ops,
+            &hw_counter,
         )
         .unwrap();
 
@@ -708,6 +712,7 @@ mod tests {
             locked_holder.deref(),
             opnum.next().unwrap(),
             insert_point_ops,
+            &hw_counter,
         )
         .unwrap();
     }

commit e85a9f18b4f5219799c3625c2d3d19c5b3be4ed5
Author: xzfc <5121426+xzfc@users.noreply.github.com>
Date:   Fri Jan 24 01:29:01 2025 +0000

    Add `VectorName` type alias (#5763)
    
    * Add VectorName/VectorNameBuf type aliases [1/2]
    
    * Add VectorName/VectorNameBuf type aliases [2/2]

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 5eda9640c..b9b4afe44 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -294,12 +294,14 @@ mod tests {
     use segment::fixtures::index_fixtures::random_vector;
     use segment::index::hnsw_index::num_rayon_threads;
     use segment::json_path::JsonPath;
-    use segment::types::{Distance, Payload, PayloadSchemaType};
+    use segment::types::{Distance, Payload, PayloadSchemaType, VectorNameBuf};
     use serde_json::json;
     use tempfile::Builder;
 
     use super::*;
-    use crate::collection_manager::fixtures::{random_multi_vec_segment, random_segment};
+    use crate::collection_manager::fixtures::{
+        random_multi_vec_segment, random_segment, VECTOR1_NAME, VECTOR2_NAME,
+    };
     use crate::collection_manager::holders::segment_holder::{LockedSegment, SegmentHolder};
     use crate::collection_manager::optimizers::config_mismatch_optimizer::ConfigMismatchOptimizer;
     use crate::collection_manager::segments_updater::{
@@ -339,12 +341,12 @@ mod tests {
 
         let large_segment_id = holder.add_new(large_segment);
 
-        let vectors_config: BTreeMap<String, VectorParams> = segment_config
+        let vectors_config: BTreeMap<VectorNameBuf, VectorParams> = segment_config
             .vector_data
             .iter()
             .map(|(name, params)| {
                 (
-                    name.to_string(),
+                    name.to_owned(),
                     VectorParamsBuilder::new(params.size as u64, params.distance).build(),
                 )
             })
@@ -414,8 +416,8 @@ mod tests {
 
         for config in configs {
             assert_eq!(config.vector_data.len(), 2);
-            assert_eq!(config.vector_data.get("vector1").unwrap().size, dim1);
-            assert_eq!(config.vector_data.get("vector2").unwrap().size, dim2);
+            assert_eq!(config.vector_data.get(VECTOR1_NAME).unwrap().size, dim1);
+            assert_eq!(config.vector_data.get(VECTOR2_NAME).unwrap().size, dim2);
         }
     }
 
@@ -912,7 +914,9 @@ mod tests {
                 .filter(|segment| segment.total_point_count() > 0)
                 .for_each(|segment| {
                     assert!(
-                        !segment.config().vector_data[""].storage_type.is_on_disk(),
+                        !segment.config().vector_data[DEFAULT_VECTOR_NAME]
+                            .storage_type
+                            .is_on_disk(),
                         "segment must not be on disk with mmap",
                     );
                 });
@@ -921,7 +925,7 @@ mod tests {
         // Remove explicit on_disk flag and go back to default
         collection_params
             .vectors
-            .get_params_mut("")
+            .get_params_mut(DEFAULT_VECTOR_NAME)
             .unwrap()
             .on_disk
             .take();
@@ -983,7 +987,9 @@ mod tests {
             .filter(|segment| segment.total_point_count() > 0)
             .for_each(|segment| {
                 assert!(
-                    segment.config().vector_data[""].storage_type.is_on_disk(),
+                    segment.config().vector_data[DEFAULT_VECTOR_NAME]
+                        .storage_type
+                        .is_on_disk(),
                     "segment must be on disk with mmap",
                 );
             });

commit 6e1316bfb5e916378e41a4776a0205b555e950cd
Author: xzfc <5121426+xzfc@users.noreply.github.com>
Date:   Tue Jan 28 09:35:02 2025 +0000

    Add payload_json! macro (#5881)
    
    * Add payload_json! macro
    
    * Replace usage of `json!({...})` with `payload_json! {...}`
    
    * Drop `impl From<Value> for Payload`

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index b9b4afe44..57f9194d4 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -294,8 +294,8 @@ mod tests {
     use segment::fixtures::index_fixtures::random_vector;
     use segment::index::hnsw_index::num_rayon_threads;
     use segment::json_path::JsonPath;
-    use segment::types::{Distance, Payload, PayloadSchemaType, VectorNameBuf};
-    use serde_json::json;
+    use segment::payload_json;
+    use segment::types::{Distance, PayloadSchemaType, VectorNameBuf};
     use tempfile::Builder;
 
     use super::*;
@@ -612,7 +612,7 @@ mod tests {
             );
         }
 
-        let point_payload: Payload = json!({"number":10000i64}).into();
+        let point_payload = payload_json! {"number": 10000i64};
 
         let batch = BatchPersisted {
             ids: vec![501.into(), 502.into(), 503.into()],

commit f11032829662bbf68fd2bf3cbd8483152fa92b44
Author: Luis Cossío <luis.cossio@qdrant.com>
Date:   Tue Jan 28 12:19:11 2025 -0300

    bump and migrate to `rand` 0.9.0 (#5892)
    
    * bump and migrate to rand 0.9.0
    
    also bump rand_distr to 0.5.0 to match it
    
    * Migrate AVX2 and SSE implementations
    
    * Remove unused thread_rng placeholders
    
    * More random migrations
    
    * Migrate GPU tests
    
    * bump seed
    
    ---------
    
    Co-authored-by: timvisee <tim@visee.me>
    Co-authored-by: Arnaud Gourlay <arnaud.gourlay@gmail.com>

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 57f9194d4..bec24654b 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -288,7 +288,7 @@ mod tests {
     use common::cpu::CpuPermit;
     use itertools::Itertools;
     use parking_lot::lock_api::RwLock;
-    use rand::thread_rng;
+    use rand::rng;
     use segment::data_types::vectors::DEFAULT_VECTOR_NAME;
     use segment::entry::entry_point::SegmentEntry;
     use segment::fixtures::index_fixtures::random_vector;
@@ -425,7 +425,7 @@ mod tests {
     fn test_indexing_optimizer() {
         init();
 
-        let mut rng = thread_rng();
+        let mut rng = rng();
         let mut holder = SegmentHolder::default();
 
         let payload_field: JsonPath = "number".parse().unwrap();

commit cf3240d923ed0d85b1101f49d10068d885c68f1c
Author: xzfc <5121426+xzfc@users.noreply.github.com>
Date:   Thu Jan 30 20:15:33 2025 +0000

    Use `simple_segment_constructor` (#5919)
    
    * VECTOR1_NAME and VECTOR2_NAME
    
    * Use simple_segment_constructor

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index bec24654b..995115ccb 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -295,13 +295,12 @@ mod tests {
     use segment::index::hnsw_index::num_rayon_threads;
     use segment::json_path::JsonPath;
     use segment::payload_json;
+    use segment::segment_constructor::simple_segment_constructor::{VECTOR1_NAME, VECTOR2_NAME};
     use segment::types::{Distance, PayloadSchemaType, VectorNameBuf};
     use tempfile::Builder;
 
     use super::*;
-    use crate::collection_manager::fixtures::{
-        random_multi_vec_segment, random_segment, VECTOR1_NAME, VECTOR2_NAME,
-    };
+    use crate::collection_manager::fixtures::{random_multi_vec_segment, random_segment};
     use crate::collection_manager::holders::segment_holder::{LockedSegment, SegmentHolder};
     use crate::collection_manager::optimizers::config_mismatch_optimizer::ConfigMismatchOptimizer;
     use crate::collection_manager::segments_updater::{

commit caed5729e5b7ff3db9dcb4531a4af0929b186682
Author: Andrey Vasnetsov <andrey@vasnetsov.com>
Date:   Thu Feb 20 09:05:00 2025 +0100

    IO resource usage permit (#6015)
    
    * rename cpu_budget -> resource_budget
    
    * clippy
    
    * add io budget to resources
    
    * fmt
    
    * move budget structures into a separate file
    
    * add extend permit function
    
    * dont extend existing permit
    
    * switch from IO to CPU permit
    
    * do not release resource before aquiring an extension
    
    * fmt
    
    * Review remarks
    
    * Improve resource permit number assertion
    
    * Make resource permit replace_with only acquire extra needed permits
    
    * Remove obsolete drop implementation
    
    * allocate IO budget same as CPU
    
    * review fixes
    
    ---------
    
    Co-authored-by: timvisee <tim@visee.me>

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 995115ccb..7d6cce1a4 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -284,8 +284,8 @@ mod tests {
     use std::sync::atomic::AtomicBool;
     use std::sync::Arc;
 
+    use common::budget::ResourceBudget;
     use common::counter::hardware_counter::HardwareCounterCell;
-    use common::cpu::CpuPermit;
     use itertools::Itertools;
     use parking_lot::lock_api::RwLock;
     use rand::rng;
@@ -383,13 +383,15 @@ mod tests {
         assert!(suggested_to_optimize.contains(&large_segment_id));
 
         let permit_cpu_count = num_rayon_threads(0);
-        let permit = CpuPermit::dummy(permit_cpu_count as u32);
+        let budget = ResourceBudget::new(permit_cpu_count, permit_cpu_count);
+        let permit = budget.try_acquire(0, permit_cpu_count).unwrap();
 
         index_optimizer
             .optimize(
                 locked_holder.clone(),
                 suggested_to_optimize,
                 permit,
+                budget.clone(),
                 &stopped,
             )
             .unwrap();
@@ -521,7 +523,8 @@ mod tests {
         .unwrap();
 
         let permit_cpu_count = num_rayon_threads(0);
-        let permit = CpuPermit::dummy(permit_cpu_count as u32);
+        let budget = ResourceBudget::new(permit_cpu_count, permit_cpu_count);
+        let permit = budget.try_acquire(0, permit_cpu_count).unwrap();
 
         // ------ Plain -> Mmap & Indexed payload
         let suggested_to_optimize =
@@ -533,13 +536,14 @@ mod tests {
                 locked_holder.clone(),
                 suggested_to_optimize,
                 permit,
+                budget.clone(),
                 &stopped,
             )
             .unwrap();
         eprintln!("Done");
 
         // ------ Plain -> Indexed payload
-        let permit = CpuPermit::dummy(permit_cpu_count as u32);
+        let permit = budget.try_acquire(0, permit_cpu_count).unwrap();
         let suggested_to_optimize =
             index_optimizer.check_condition(locked_holder.clone(), &excluded_ids);
         assert!(suggested_to_optimize.contains(&middle_segment_id));
@@ -548,6 +552,7 @@ mod tests {
                 locked_holder.clone(),
                 suggested_to_optimize,
                 permit,
+                budget.clone(),
                 &stopped,
             )
             .unwrap();
@@ -666,7 +671,7 @@ mod tests {
         // ---- New appendable segment should be created if none left
 
         // Index even the smallest segment
-        let permit = CpuPermit::dummy(permit_cpu_count as u32);
+        let permit = budget.try_acquire(0, permit_cpu_count).unwrap();
         index_optimizer.thresholds_config.indexing_threshold_kb = 20;
         let suggested_to_optimize =
             index_optimizer.check_condition(locked_holder.clone(), &Default::default());
@@ -676,6 +681,7 @@ mod tests {
                 locked_holder.clone(),
                 suggested_to_optimize,
                 permit,
+                budget.clone(),
                 &stopped,
             )
             .unwrap();
@@ -776,6 +782,7 @@ mod tests {
         );
 
         let permit_cpu_count = num_rayon_threads(0);
+        let budget = ResourceBudget::new(permit_cpu_count, permit_cpu_count);
 
         // Index until all segments are indexed
         let mut numer_of_optimizations = 0;
@@ -787,12 +794,13 @@ mod tests {
             }
             log::debug!("suggested_to_optimize = {:#?}", suggested_to_optimize);
 
-            let permit = CpuPermit::dummy(permit_cpu_count as u32);
+            let permit = budget.try_acquire(0, permit_cpu_count).unwrap();
             index_optimizer
                 .optimize(
                     locked_holder.clone(),
                     suggested_to_optimize,
                     permit,
+                    budget.clone(),
                     &stopped,
                 )
                 .unwrap();
@@ -949,7 +957,8 @@ mod tests {
         );
 
         let permit_cpu_count = num_rayon_threads(0);
-        let permit = CpuPermit::dummy(permit_cpu_count as u32);
+        let budget = ResourceBudget::new(permit_cpu_count, permit_cpu_count);
+        let permit = budget.try_acquire(0, permit_cpu_count).unwrap();
 
         // Use indexing optimizer to build mmap
         let changed = index_optimizer
@@ -957,6 +966,7 @@ mod tests {
                 locked_holder.clone(),
                 vec![segment_id],
                 permit,
+                budget.clone(),
                 &false.into(),
             )
             .unwrap();

commit 8ad2b34265448ec01b89d4093de5fbb1a86dcd4d
Author: Tim Visée <tim+github@visee.me>
Date:   Tue Feb 25 11:21:25 2025 +0100

    Bump Rust edition to 2024 (#6042)
    
    * Bump Rust edition to 2024
    
    * gen is a reserved keyword now
    
    * Remove ref mut on references
    
    * Mark extern C as unsafe
    
    * Wrap unsafe function bodies in unsafe block
    
    * Geo hash implements Copy, don't reference but pass by value instead
    
    * Replace secluded self import with parent
    
    * Update execute_cluster_read_operation with new match semantics
    
    * Fix lifetime issue
    
    * Replace map_or with is_none_or
    
    * set_var is unsafe now
    
    * Reformat

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 7d6cce1a4..b6dd3bd36 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -281,8 +281,8 @@ impl SegmentOptimizer for IndexingOptimizer {
 mod tests {
     use std::collections::BTreeMap;
     use std::ops::Deref;
-    use std::sync::atomic::AtomicBool;
     use std::sync::Arc;
+    use std::sync::atomic::AtomicBool;
 
     use common::budget::ResourceBudget;
     use common::counter::hardware_counter::HardwareCounterCell;

commit 5cd7239b61d1a6944984132283f762850275670f
Author: Jojii <15957865+JojiiOfficial@users.noreply.github.com>
Date:   Mon Mar 24 19:39:17 2025 +0100

    Measure Payload Index IO Writes (#6137)
    
    * Prepare measurement of index creation + Remove vector deletion
    measurement
    
    * add hw_counter to add_point functions
    
    * Adjust add_point(..) function signatures
    
    * Add new measurement type: payload index IO write
    
    * Measure payload index IO writes
    
    * Some Hw measurement performance improvements
    
    * Review remarks
    
    * Fix measurements in distributed setups
    
    * review fixes
    
    ---------
    
    Co-authored-by: generall <andrey@vasnetsov.com>

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index b6dd3bd36..51f1e87b8 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -512,6 +512,8 @@ mod tests {
         index_optimizer.thresholds_config.indexing_threshold_kb = 50;
 
         // ----- CREATE AN INDEXED FIELD ------
+        let hw_counter = HardwareCounterCell::new();
+
         process_field_index_operation(
             locked_holder.deref(),
             opnum.next().unwrap(),
@@ -519,6 +521,7 @@ mod tests {
                 field_name: payload_field.clone(),
                 field_schema: Some(PayloadSchemaType::Integer.into()),
             }),
+            &hw_counter,
         )
         .unwrap();
 

commit f230629fa0e62e069e683cce60e24319ab3cc84b
Author: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Date:   Tue Mar 25 10:08:21 2025 +0100

    build(deps): bump log from 0.4.26 to 0.4.27 (#6247)
    
    * build(deps): bump log from 0.4.26 to 0.4.27
    
    Bumps [log](https://github.com/rust-lang/log) from 0.4.26 to 0.4.27.
    - [Release notes](https://github.com/rust-lang/log/releases)
    - [Changelog](https://github.com/rust-lang/log/blob/master/CHANGELOG.md)
    - [Commits](https://github.com/rust-lang/log/compare/0.4.26...0.4.27)
    
    ---
    updated-dependencies:
    - dependency-name: log
      dependency-type: direct:production
      update-type: version-update:semver-patch
    ...
    
    Signed-off-by: dependabot[bot] <support@github.com>
    
    * put variables inside the strings for log macros
    
    * also for pyroscope
    
    ---------
    
    Signed-off-by: dependabot[bot] <support@github.com>
    Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
    Co-authored-by: Luis Cossío <luis.cossio@outlook.com>

diff --git a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
index 51f1e87b8..60ca8cb27 100644
--- a/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
+++ b/lib/collection/src/collection_manager/optimizers/indexing_optimizer.rs
@@ -795,7 +795,7 @@ mod tests {
             if suggested_to_optimize.is_empty() {
                 break;
             }
-            log::debug!("suggested_to_optimize = {:#?}", suggested_to_optimize);
+            log::debug!("suggested_to_optimize = {suggested_to_optimize:#?}");
 
             let permit = budget.try_acquire(0, permit_cpu_count).unwrap();
             index_optimizer
@@ -811,9 +811,7 @@ mod tests {
             assert!(numer_of_optimizations <= number_of_segments);
             let number_of_segments = locked_holder.read().len();
             log::debug!(
-                "numer_of_optimizations = {}, number_of_segments = {}",
-                numer_of_optimizations,
-                number_of_segments
+                "numer_of_optimizations = {numer_of_optimizations}, number_of_segments = {number_of_segments}"
             );
         }
 

</code></pre>
        </section>
    </main>
    <footer>
        <p>LoCoDiff-bench - <a href="https://github.com/AbanteAI/LoCoDiff-bench">GitHub Repository</a></p>
    </footer>
    
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            hljs.highlightAll();
        });
    </script>
</body>
</html>
    