<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Actual Output: apps/dotcom/sync-worker/src/TLPostgresReplicator.ts - o4-mini-high</title>
    <link rel="stylesheet" href="../../../../styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/default.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
    <style>
        .empty-content-notice {
            background-color: #f8f8f8;
            border: 1px dashed #ccc;
            border-radius: 4px;
            padding: 20px;
            text-align: center;
            color: #666;
        }
        
        .empty-content-notice p:first-child {
            font-weight: bold;
            margin-bottom: 10px;
        }
        
        .info-message {
            background-color: #f1f8ff;
            border: 1px solid #c8e1ff;
            border-radius: 4px;
            padding: 15px;
            margin-bottom: 15px;
            color: #0366d6;
        }
        
        .info-message p:first-child {
            font-weight: bold;
            margin-bottom: 5px;
        }
    </style>
</head>
<body>
    <header>
        <h1>Actual Output: apps/dotcom/sync-worker/src/TLPostgresReplicator.ts</h1>
        <p><a href="../../../cases/openai_o4-mini-high/tldraw_apps_dotcom_sync-worker_src_TLPostgresReplicator.ts.html">‚Üê Back to Case</a> | <a href="../../../index.html">Home</a></p>
    </header>
    <main>
        
        <section>
            <h2>Raw Model Response</h2>
            
            <pre><code class="language-plaintext">```typescript
import { DB, TlaFile, TlaFileState, TlaRow, TlaUser, ZTable } from '@tldraw/dotcom-shared'
import {
	executionQueue as ExecutionQueue,
	assert,
	assertExists,
	exhaustiveSwitchError,
	groupBy,
	promiseWithResolve,
	sleep,
	stringEnum,
	throttle,
	uniqueId,
} from '@tldraw/utils'
import { createSentry } from '@tldraw/worker-shared'
import { DurableObject } from 'cloudflare:workers'
import { Kysely, sql } from 'kysely'
import { LogicalReplicationService, Wal2Json, Wal2JsonPlugin } from 'pg-logical-replication'
import { Logger } from './Logger'
import { UserChangeCollator } from './UserChangeCollator'
import { ZReplicationEventWithoutSequenceInfo } from './UserDataSyncer'
import { createPostgresConnectionPool } from './postgres'
import {
	Analytics,
	Environment,
	TLPostgresReplicatorEvent,
	TLPostgresReplicatorRebootSource,
} from './types'
import { EventData, writeDataPoint } from './utils/analytics'
import {
	getRoomDurableObject,
	getStatsDurableObjct,
	getUserDurableObject,
} from './utils/durableObjects'
import { getR2KeyForRoom } from './r2'

interface Change {
	event: ReplicationEvent
	userId: string
	fileId: string | null
	row: TlaRow
	previous?: TlaRow
}

interface Migration {
	id: string
	code: string
}

const migrations: Migration[] = [
	{
		id: '000_seed',
		code: `
			CREATE TABLE IF NOT EXISTS active_user (
				id TEXT PRIMARY KEY,
				sequenceNumber INTEGER NOT NULL DEFAULT 0,
				sequenceIdSuffix TEXT NOT NULL DEFAULT '',
				lastUpdatedAt INTEGER NOT NULL DEFAULT 0
			);
			CREATE TABLE IF NOT EXISTS user_file_subscriptions (
				userId TEXT,
				fileId TEXT,
				PRIMARY KEY (userId, fileId),
				FOREIGN KEY (userId) REFERENCES active_user(id) ON DELETE CASCADE
			);
			CREATE TABLE IF NOT EXISTS migrations (
				id TEXT PRIMARY KEY,
				code TEXT NOT NULL
			);
			CREATE TABLE IF NOT EXISTS meta (
				lsn TEXT PRIMARY KEY,
				slotName TEXT NOT NULL
			);
			INSERT INTO meta (lsn, slotName) VALUES ('0/0', 'init');
		`,
	},
	{
		id: '001_add_sequence_number',
		code: `
			ALTER TABLE active_user ADD COLUMN sequenceNumber INTEGER NOT NULL DEFAULT 0;
			ALTER TABLE active_user ADD COLUMN sequenceIdSuffix TEXT NOT NULL DEFAULT '';
		`,
	},
	{
		id: '002_add_last_updated_at',
		code: `
			ALTER TABLE active_user ADD COLUMN lastUpdatedAt INTEGER NOT NULL DEFAULT 0;
		`,
	},
	{
		id: '003_add_lsn_tracking',
		code: `
			CREATE TABLE IF NOT EXISTS meta (
				lsn TEXT PRIMARY KEY,
				slotName TEXT NOT NULL
			);
			INSERT INTO meta (lsn, slotName) VALUES ('0/0', 'init');
		`,
	},
	{
		id: '004_keep_event_log',
		code: `
			CREATE TABLE history (
				lsn TEXT NOT NULL,
				userId TEXT NOT NULL,
				fileId TEXT,
				json TEXT NOT NULL,
				timestamp INTEGER NOT NULL DEFAULT 0
			);
			CREATE INDEX history_lsn_userId ON history (lsn, userId);
			CREATE INDEX history_lsn_fileId ON history (lsn, fileId);
			PRAGMA optimize;
		`,
	},
	{
		id: '005_add_history_timestamp',
		code: `
			ALTER TABLE history ADD COLUMN timestamp INTEGER NOT NULL DEFAULT 0;
		`,
	},
]

const ONE_MINUTE = 60 * 1000
const PRUNE_INTERVAL = 10 * ONE_MINUTE
const MAX_HISTORY_ROWS = 20_000

type PromiseWithResolve = ReturnType<typeof promiseWithResolve>

type ReplicationEvent = {
	command: 'insert' | 'update' | 'delete'
	table: keyof typeof relevantTables
}

const relevantTables = stringEnum('user', 'file', 'file_state', 'user_mutation_number')

type Row =
	| TlaRow
	| {
			bootId: string
			userId: string
	  }
	| {
			mutationNumber: number
			userId: string
	  }

export class TLPostgresReplicator extends DurableObject<Environment> {
	private sqlite: SqlStorage
	private db: Kysely<DB>
	private state: BootState
	private measure: Analytics
	private postgresUpdates = 0
	private lastPostgresMessageTime = Date.now()
	private lastRpmLogTime = Date.now()
	private lastUserPruneTime = Date.now()
	private log: Logger
	private readonly replicationService: LogicalReplicationService
	private readonly slotName: string
	private readonly wal2jsonPlugin = new Wal2JsonPlugin({
		addTables:
			'public.user,public.file,public.file_state,public.user_mutation_number,public.replicator_boot_id',
	})
	private userDispatchQueues: Map<string, ExecutionQueue> = new Map()

	constructor(ctx: DurableObjectState, env: Environment) {
		super(ctx, env)
		this.measure = env.MEASURE
		this.sentry = createSentry(ctx, env)
		this.sqlite = this.ctx.storage.sql
		this.state = {
			type: 'init',
			promise: promiseWithResolve(),
		}

		const slotNameMaxLength = 63
		const slotNamePrefix = 'tlpr_'
		const durableObjectId = this.ctx.id.toString()
		this.slotName = slotNamePrefix + durableObjectId.slice(0, slotNameMaxLength - slotNamePrefix.length)

		this.log = new Logger(env, 'TLPostgresReplicator', this.sentry)
		this.db = createPostgresConnectionPool(env, 'TLPostgresReplicator', 100)

		this.replicationService = new LogicalReplicationService(
			{
				database: 'postgres',
				connectionString: env.BOTCOM_POSTGRES_CONNECTION_STRING,
				application_name: this.slotName,
			},
			{
				acknowledge: {
					auto: false,
					timeoutSeconds: 10,
				},
			}
		)

		this.ctx.blockConcurrencyWhile(async () => {
			await this._migrate().catch((e) => {
				this.captureException(e)
				throw e
			})
			if (
				this.sqlite.exec('select slotName from meta').one().slotName !==
				this.slotName
			) {
				this.sqlite.exec('UPDATE meta SET slotName = ?, lsn = null', this.slotName)
			}
			await sql`
				SELECT pg_create_logical_replication_slot(
					${this.slotName},
					'wal2json'
				) WHERE NOT EXISTS (
					SELECT 1 FROM pg_replication_slots WHERE slot_name = ${this.slotName}
				)
			`.execute(this.db)
			this.pruneHistory()
		})

		this.alarm()
		this.reboot('constructor', false).catch((e) => {
			this.captureException(e)
			this.__test__panic()
		})
	}

	private async _migrate() {
		let appliedMigrations: Migration[]
		try {
			appliedMigrations = (this.sqlite
				.exec('select code, id from migrations order by id asc')
				.toArray() as any) as Migration[]
		} catch {
			this._applyMigration(0)
			appliedMigrations = [migrations[0]]
		}
		for (let i = 0; i < appliedMigrations.length; i++) {
			if (appliedMigrations[i].id !== migrations[i].id) {
				throw new Error(
					'TLPostgresReplicator migrations have changed!! this is an append-only array!!'
				)
			}
		}
		for (let i = appliedMigrations.length; i < migrations.length; i++) {
			this._applyMigration(i)
		}
	}

	private _applyMigration(index: number) {
		this.log.debug('running migration', migrations[index].id)
		this.sqlite.exec(migrations[index].code)
		this.sqlite.exec(
			'insert into migrations (id, code) values (?, ?)',
			migrations[index].id,
			migrations[index].code
		)
		this.log.debug('ran migration', migrations[index].id)
	}

	override async alarm() {
		try {
			this.ctx.storage.setAlarm(Date.now() + 3000)
			this.maybeLogRpm()
			if (Date.now() - this.lastPostgresMessageTime > 10000) {
				this.log.debug('rebooting due to inactivity')
				this.reboot('inactivity')
			} else if (Date.now() - this.lastPostgresMessageTime > 5000) {
				this.log.debug('triggering heartbeat due to inactivity')
				await this.replicationService.acknowledge('0/0')
			}
			await this.maybePrune()
		} catch (e) {
			this.captureException(e)
		}
	}

	private async maybePrune() {
		const now = Date.now()
		if (now - this.lastUserPruneTime < PRUNE_INTERVAL) return
		const cutoffTime = now - PRUNE_INTERVAL
		const usersWithoutRecentUpdates = this.sqlite
			.exec('SELECT id FROM active_user WHERE lastUpdatedAt < ?', cutoffTime)
			.toArray() as { id: string }[]
		for (const { id } of usersWithoutRecentUpdates) {
			await this.unregisterUser(id)
		}
		this.pruneHistory()
		this.lastUserPruneTime = Date.now()
	}

	private pruneHistory() {
		this.sqlite.exec(`
      WITH max AS (
        SELECT MAX(rowid) AS max_id FROM history
      )
      DELETE FROM history
      WHERE rowid < (SELECT max_id FROM max) - ${MAX_HISTORY_ROWS};
    `)
	}

	private maybeLogRpm() {
		const now = Date.now()
		if (this.postgresUpdates > 0 && now - this.lastRpmLogTime > ONE_MINUTE) {
			this.logEvent({
				type: 'rpm',
				rpm: this.postgresUpdates,
			})
			this.postgresUpdates = 0
			this.lastRpmLogTime = now
		}
	}

	async __test__forceReboot() {
		this.reboot('test')
	}

	async __test__panic() {
		this.ctx.abort()
	}

	private async reboot(
		source: TLPostgresReplicatorRebootSource,
		delay = true
	) {
		this.logEvent({ type: 'reboot', source })
		if (!this.queue.isEmpty()) {
			this.log.debug('reboot is already in progress.', source)
			return
		}
		await this.queue.push(async () => {
			if (delay) {
				await sleep(2000)
			}
			const start = Date.now()
			this.log.debug('rebooting', source)
			const res = await Promise.race([
				this.boot().then(() => 'ok'),
				sleep(3000).then(() => 'timeout'),
			]).catch((e) => {
				this.logEvent({ type: 'reboot_error' })
				this.log.debug('reboot error', (e as any).stack)
				this.captureException(e)
				return 'error'
			})
			if (res === 'ok') {
				this.logEvent({
					type: 'reboot_duration',
					duration: Date.now() - start,
				})
			} else {
				this.reboot('retry')
			}
		})
	}

	private async boot() {
		this.log.debug('booting')
		this.lastPostgresMessageTime = Date.now()
		this.replicationService.removeAllListeners()
		this.log.debug('stopping replication')
		this.replicationService.stop().catch(this.captureException)
		this.log.debug('terminating backend')
		await sql`
      SELECT pg_terminate_backend(active_pid)
      FROM pg_replication_slots
      WHERE slot_name = ${this.slotName} AND active
    `.execute(this.db)
		this.log.debug('done')

		const promise = 'promise' in this.state ? this.state.promise : promiseWithResolve()
		this.state = {
			type: 'connecting',
			promise,
		}
		this.replicationService.on('heartbeat', (lsn: string) => {
			this.lastPostgresMessageTime = Date.now()
			this.reportPostgresUpdate()
			this.replicationService.acknowledge(lsn).catch(this.captureException)
		})
		this.replicationService.addListener('data', (lsn, log) => {
			try {
				if (this.state.type !== 'connected') return
				const collator = new UserChangeCollator()
				for (const _change of log.change) {
					if (
						(_change as any).kind === 'message' &&
						(_change as any).prefix === 'requestLsnUpdate'
					) {
						this.requestLsnUpdate((_change as any).content as string)
						continue
					}
					const change = this.parseChange(_change as Wal2Json.Change)
					if (!change) {
						this.log.debug('IGNORING CHANGE', _change)
						continue
					}
					this.handleEvent(collator, change, false)
					this.sqlite.exec(
						'INSERT INTO history (lsn, userId, fileId, json, timestamp) VALUES (?, ?, ?, ?, ?)',
						lsn,
						change.userId,
						change.fileId,
						JSON.stringify(change),
						Date.now()
					)
				}
				this.log.debug('changes', collator.changes.size)
				for (const [userId, changes] of collator.changes) {
					this._messageUser(userId, { type: 'changes', changes, lsn })
				}
				this.commitLsn(lsn)
			} catch (e) {
				this.captureException(e)
			}
		})
		this.replicationService.addListener('start', () => {
			if (!this.getCurrentLsn()) {
				sql`
          INSERT INTO replicator_boot_id ("replicatorId", "bootId")
          VALUES (${this.ctx.id.toString()}, ${uniqueId()})
          ON CONFLICT ("replicatorId") DO UPDATE
            SET "bootId" = excluded."bootId"
        `.execute(this.db)
			}
		})

		const handleError = (e: Error) => {
			this.captureException(e)
			this.reboot('retry')
		}
		this.replicationService.on('error', handleError)
		this.replicationService
			.subscribe(this.wal2jsonPlugin, this.slotName)
			.catch(handleError)

		this.state = {
			type: 'connected',
		}
		promise.resolve(null)
	}

	private getCurrentLsn() {
		return this.sqlite.exec('SELECT lsn FROM meta').one().lsn as string | null
	}

	private async commitLsn(lsn: string) {
		const result = await this.replicationService.acknowledge(lsn)
		if (result) {
			const prevLsn = this.getCurrentLsn()
			this.sqlite.exec('UPDATE meta SET lsn = ?', lsn)
			if (!prevLsn) {
				this.onDidSequenceBreak()
			}
		} else {
			this.captureException(new Error('acknowledge failed'))
			this.reboot('retry')
		}
	}

	private onDidSequenceBreak() {
		const users = this.sqlite.exec('SELECT id FROM active_user').toArray()
		const BATCH_SIZE = 5
		const tick = () => {
			if (users.length === 0) return
			const batch = users.splice(0, BATCH_SIZE)
			for (const user of batch) {
				this._messageUser(user.id as string, { type: 'maybe_force_reboot' })
			}
			setTimeout(tick, 10)
		}
		tick()
	}

	private parseChange(change: Wal2Json.Change): Change | null {
		const table = change.table as ReplicationEvent['table']
		if (change.kind === 'truncate' || change.kind === 'message' || !(table in relevantTables)) {
			return null
		}
		const row = {} as any
		const previous = {} as any
		if (change.kind === 'delete') {
			const oldkeys = change.oldkeys!
			oldkeys.keynames.forEach((key, i) => {
				row[key] = oldkeys.keyvalues![i]
			})
		} else if (change.kind === 'update') {
			const oldkeys = change.oldkeys!
			oldkeys.keynames.forEach((key, i) => {
				previous[key] = oldkeys.keyvalues![i]
			})
			change.columnnames.forEach((col, i) => {
				row[col] = change.columnvalues[i]
			})
		} else {
			change.columnnames.forEach((col, i) => {
				row[col] = change.columnvalues[i]
			})
		}

		let userId: string | null = null
		let fileId: string | null = null
		switch (table) {
			case 'user':
				userId = (row as TlaUser).id
				break
			case 'file':
				userId = (row as TlaFile).ownerId
				fileId = (row as TlaFile).id
				break
			case 'file_state':
				userId = (row as TlaFileState).userId
				fileId = (row as TlaFileState).fileId
				break
			case 'user_mutation_number':
				userId = (row as any).userId
				break
			default:
				const _x: never = table
		}
		if (!userId) return null
		return { row, previous, event: { command: change.kind, table }, userId, fileId }
	}

	private handleEvent(collator: UserChangeCollator, change: Change, isReplay: boolean) {
		const { command, table } = change.event
		this.log.debug('handleEvent', change)
		switch (table) {
			case 'user_mutation_number':
				this.handleMutationConfirmationEvent(collator, change.row, change.event)
				break
			case 'file_state':
				this.handleFileStateEvent(collator, change.row, change.event)
				break
			case 'file':
				this.handleFileEvent(collator, change.row, change.previous, change.event, isReplay)
				break
			case 'user':
				this.handleUserEvent(collator, change.row, change.event)
				break
			default:
				const _x: never = table
				this.captureException(new Error(`Unhandled table: ${table}`), { change })
				break
		}
	}

	private handleMutationConfirmationEvent(
		collator: UserChangeCollator,
		row: Row,
		event: ReplicationEvent
	) {
		if (event.command === 'delete') return
		collator.addChange(row.userId, {
			type: 'mutation_commit',
			mutationNumber: (row as any).mutationNumber,
			userId: row.userId,
		})
	}

	private handleFileStateEvent(
		collator: UserChangeCollator,
		row: Row,
		event: ReplicationEvent
	) {
		if (!this.userIsActive(row.userId)) return
		if (event.command === 'insert') {
			this.sqlite.exec(
				`INSERT INTO user_file_subscriptions (userId, fileId) VALUES (?, ?) ON CONFLICT (userId, fileId) DO NOTHING`,
				row.userId,
				row.fileId
			)
		} else if (event.command === 'delete') {
			this.sqlite.exec(
				`DELETE FROM user_file_subscriptions WHERE userId = ? AND fileId = ?`,
				row.userId,
				row.fileId
			)
		}
		collator.addChange(row.userId, {
			type: 'row_update',
			row: row as any,
			table: event.table as ZTable,
			event: event.command,
			userId: row.userId,
		})
	}

	private handleFileEvent(
		collator: UserChangeCollator,
		row: Row,
		previous: Row | undefined,
		event: ReplicationEvent,
		isReplay: boolean
	) {
		assert('id' in row && 'ownerId' in row, 'row id is required')
		const impactedUserIds = [
			row.ownerId,
			...this.sqlite
				.exec('SELECT userId FROM user_file_subscriptions WHERE fileId = ?', row.id)
				.toArray()
				.map((x) => x.userId as string),
		]
		if (event.command === 'delete') {
			if (!isReplay) getRoomDurableObject(this.env, row.id).appFileRecordDidDelete(row)
			this.sqlite.exec(`DELETE FROM user_file_subscriptions WHERE fileId = ?`, row.id)
		} else if (event.command === 'update') {
			if (!isReplay) getRoomDurableObject(this.env, row.id).appFileRecordDidUpdate(row)
			if (previous && !isReplay) {
				const prevFile = previous as TlaFile
				if (row.published && !prevFile.published) {
					this.publishSnapshot(row)
				} else if (!row.published && prevFile.published) {
					this.unpublishSnapshot(row)
				} else if (
					row.published &&
					row.lastPublished > (previous as TlaFile).lastPublished
				) {
					this.publishSnapshot(row)
				}
			}
		} else if (event.command === 'insert') {
			if (!isReplay) getRoomDurableObject(this.env, row.id).appFileRecordCreated(row)
		}
		for (const userId of impactedUserIds) {
			collator.addChange(userId, {
				type: 'row_update',
				row: row as any,
				table: event.table as ZTable,
				event: event.command,
				userId,
			})
		}
	}

	private handleUserEvent(
		collator: UserChangeCollator,
		row: Row,
		event: ReplicationEvent
	) {
		assert('id' in row, 'user id is required')
		collator.addChange(row.id, {
			type: 'row_update',
			row: row as any,
			table: event.table as ZTable,
			event: event.command,
			userId: row.id,
		})
	}

	private userIsActive(userId: string) {
		return (
			this.sqlite.exec(`SELECT * FROM active_user WHERE id = ?`, userId).toArray().length >
			0
		)
	}

	async requestLsnUpdate(userId: string) {
		try {
			this.log.debug('requestLsnUpdate', userId)
			this.logEvent({ type: 'request_lsn_update' })
			const lsn = assertExists(this.getCurrentLsn(), 'lsn should exist')
			this._messageUser(userId, { type: 'changes', changes: [], lsn })
		} catch (e) {
			this.captureException(e)
			throw e
		}
		return
	}

	private async _messageUser(
		userId: string,
		event: ZReplicationEventWithoutSequenceInfo
	) {
		this.log.debug('messageUser', userId, event)
		if (!this.userIsActive(userId)) {
			this.log.debug('user is not active', userId)
			return
		}
		try {
			let q = this.userDispatchQueues.get(userId)
			if (!q) {
				q = new ExecutionQueue()
				this.userDispatchQueues.set(userId, q)
			}

			const { sequenceNumber, sequenceIdSuffix } = this.sqlite
				.exec(
					'UPDATE active_user SET sequenceNumber = sequenceNumber + 1, lastUpdatedAt = ? WHERE id = ? RETURNING sequenceNumber, sequenceIdSuffix',
					Date.now(),
					userId
				)
				.one()
			assert(typeof sequenceNumber === 'number', 'sequenceNumber should be a number')
			assert(typeof sequenceIdSuffix === 'string', 'sequenceIdSuffix should be a string')

			await q.push(async () => {
				const user = getUserDurableObject(this.env, userId)
				const res = await user.handleReplicationEvent({
					...event,
					sequenceNumber,
					sequenceId: this.slotName + sequenceIdSuffix,
				})
				if (res === 'unregister') {
					this.log.debug('unregistering user', userId, event)
					this.unregisterUser(userId)
				}
			})
		} catch (e) {
			this.captureException(e)
		}
	}

	async registerUser({
		userId,
		lsn,
		guestFileIds,
		bootId,
	}: {
		userId: string
		lsn: string
		guestFileIds: string[]
		bootId: string
	}): Promise<
		| { type: 'done'; sequenceId: string; sequenceNumber: number }
		| { type: 'reboot' }
	> {
		while (!this.getCurrentLsn()) {
			await sleep(100)
		}
		this.log.debug('registering user', userId, lsn, bootId, guestFileIds)
		this.logEvent({ type: 'register_user' })

		this.sqlite.exec(`DELETE FROM active_user WHERE id = ?`, userId)
		this.sqlite.exec(
			`INSERT INTO active_user (id, sequenceNumber, sequenceIdSuffix, lastUpdatedAt) VALUES (?, 0, ?, ?)`,
			userId,
			bootId,
			Date.now()
		)
		this.sqlite.exec(`DELETE FROM user_file_subscriptions WHERE userId = ?`, userId)
		for (const fileId of guestFileIds) {
			this.sqlite.exec(
				`INSERT INTO user_file_subscriptions (userId, fileId) VALUES (?, ?) ON CONFLICT (userId, fileId) DO NOTHING`,
				userId,
				fileId
			)
		}
		this.reportActiveUsers()
		this.log.debug('inserted active user')

		const resume = this.getResumeType(lsn, userId, guestFileIds)
		if (resume.type === 'reboot') {
			return { type: 'reboot' }
		}
		if (resume.messages) {
			for (const message of resume.messages) {
				this._messageUser(userId, message)
			}
		}

		return {
			type: 'done',
			sequenceId: this.slotName + bootId,
			sequenceNumber: 0,
		}
	}

	async unregisterUser(userId: string) {
		this.logEvent({ type: 'unregister_user' })
		this.sqlite.exec(`DELETE FROM active_user WHERE id = ?`, userId)
		this.userDispatchQueues.get(userId)?.close()
		this.reportActiveUsers()
	}

	private getResumeType(
		lsn: string,
		userId: string,
		guestFileIds: string[]
	):
		| { type: 'done'; messages?: ZReplicationEventWithoutSequenceInfo[] }
		| { type: 'reboot' } {
		const currentLsn = assertExists(this.getCurrentLsn(), 'lsn should exist')
		if (lsn >= currentLsn) {
			this.log.debug('getResumeType: resuming from current lsn', lsn, '>=', currentLsn)
			return { type: 'done' }
		}
		const earliestLsn = this.sqlite
			.exec<{ lsn: string }>('SELECT lsn FROM history ORDER BY rowid ASC LIMIT 1')
			.toArray()[0]?.lsn
		if (!earliestLsn || lsn < earliestLsn) {
			this.log.debug('getResumeType: not enough history', lsn, '<', earliestLsn)
			return { type: 'reboot' }
		}
		const history = this.sqlite
			.exec<{ json: string; lsn: string }>(
				`
			SELECT lsn, json
			FROM history
			WHERE
			  lsn > ?
				AND (
				  userId = ? 
					OR fileId IN (${guestFileIds.map((_, i) => `$${i + 1}`).join(', ')})
				)
			ORDER BY rowid ASC
		`,
				lsn,
				userId,
				...guestFileIds
			)
			.toArray()
			.map(({ json, lsn }) => ({ change: JSON.parse(json) as Change, lsn }))

		if (history.length === 0) {
			this.log.debug('getResumeType: no history to replay, all good', lsn)
			return { type: 'done' }
		}

		const changesByLsn = groupBy(history, (x) => x.lsn)
		const messages: ZReplicationEventWithoutSequenceInfo[] = []
		for (const lsn of Object.keys(changesByLsn).sort()) {
			const collator = new UserChangeCollator()
			for (const change of changesByLsn[lsn]) {
				this.handleEvent(collator, change.change, true)
			}
			const changes = collator.changes.get(userId)
			if (changes?.length) {
				messages.push({ type: 'changes', changes, lsn })
			}
		}
		this.log.debug('getResumeType: resuming', messages.length, messages)
		return { type: 'done', messages }
	}

	async getDiagnostics() {
		const earliestHistoryRow = this.sqlite
			.exec('SELECT * FROM history ORDER BY rowid ASC LIMIT 1')
			.toArray()[0]
		const latestHistoryRow = this.sqlite
			.exec('SELECT * FROM history ORDER BY rowid DESC LIMIT 1')
			.toArray()[0]
		const activeUsers = this.sqlite.exec('SELECT COUNT(*) as count FROM active_user').one().count as number
		const meta = this.sqlite.exec('SELECT * FROM meta').one()
		return {
			earliestHistoryRow,
			latestHistoryRow,
			activeUsers,
			meta,
		}
	}

	async requestLsnUpdate(userId: string) {
		try {
			this.log.debug('requestLsnUpdate', userId)
			this.logEvent({ type: 'request_lsn_update' })
			const lsn = assertExists(this.getCurrentLsn(), 'lsn should exist')
			this._messageUser(userId, { type: 'changes', changes: [], lsn })
		} catch (e) {
			this.captureException(e)
			throw e
		}
		return
	}

	async getFileRecord(fileId: string) {
		this.logEvent({ type: 'get_file_record' })
		await this.waitUntilConnected()
		const res = await sql`SELECT * FROM public.file WHERE id = ${fileId}`.execute(this.db)
		return res.rows[0] as TlaFile | null
	}

	private publishSnapshot(file: TlaFile) {
		getRoomDurableObject(this.env, file.id).awaitPersist().then(async () => {
			const snapshot = await this.env.ROOMS.get(
				getR2KeyForRoom({ slug: file.id, isApp: true })
			)
			if (!snapshot) {
				throw new Error('Snapshot not found')
			}
			const blob = await snapshot.blob()
			await this.env.SNAPSHOT_SLUG_TO_PARENT_SLUG.put(file.publishedSlug, file.id)
			await this.env.ROOM_SNAPSHOTS.put(
				getR2KeyForRoom({ slug: `${file.id}/${file.publishedSlug}`, isApp: true }),
				blob
			)
			const currentTime = new Date().toISOString()
			await this.env.ROOM_SNAPSHOTS.put(
				getR2KeyForRoom({ slug: `${file.id}/${file.publishedSlug}|${currentTime}`, isApp: true }),
				blob
			)
		}).catch((e) => {
			this.log.debug('Error publishing snapshot', e)
		})
	}

	private unpublishSnapshot(file: TlaFile) {
		getRoomDurableObject(this.env, file.id)
			.appFileRecordDidUnpublish?.(file.publishedSlug)
		this.env.SNAPSHOT_SLUG_TO_PARENT_SLUG.delete(file.publishedSlug).catch((e) => {
			this.log.debug('Error unpublishing snapshot', e)
		})
		this.env.ROOM_SNAPSHOTS
			.delete(getR2KeyForRoom({ slug: `${file.id}/${file.publishedSlug}`, isApp: true }))
			.catch((e) => {
				this.log.debug('Error deleting published snapshot', e)
			})
	}

	ping() {
		this.log.debug('ping')
		return { sequenceId: this.slotName }
	}

	private async waitUntilConnected() {
		while (this.state.type !== 'connected') {
			await this.state.promise
		}
	}

	private reportActiveUsers() {
		try {
			const { count } = this.sqlite.exec('SELECT COUNT(*) as count FROM active_user').one()
			this.logEvent({ type: 'active_users', count: count as number })
		} catch (e) {
			this.captureException(e)
		}
	}

	private writeEvent(eventData: EventData) {
		try {
			writeDataPoint(this.sentry, this.measure, this.env, 'replicator', eventData)
		} catch {
			// swallow
		}
	}

	logEvent(event: TLPostgresReplicatorEvent) {
		switch (event.type) {
			case 'reboot':
				this.writeEvent({ blobs: [event.type, event.source] })
				break
			case 'reboot_error':
			case 'register_user':
			case 'unregister_user':
			case 'request_lsn_update':
			case 'prune':
			case 'get_file_record':
				this.writeEvent({
					blobs: [event.type],
				})
				break
			case 'reboot_duration':
				this.writeEvent({
					blobs: [event.type],
					doubles: [event.duration],
				})
				break
			case 'rpm':
				this.writeEvent({
					blobs: [event.type],
					doubles: [event.rpm],
				})
				break
			case 'active_users':
				this.writeEvent({
					blobs: [event.type],
					doubles: [event.count],
				})
				break
			default:
				exhaustiveSwitchError(event)
		}
	}
}
```</code></pre>
        </section>
        
    </main>
    <footer>
        <p>LoCoDiff-bench - <a href="https://github.com/AbanteAI/LoCoDiff-bench">GitHub Repository</a></p>
    </footer>
    
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            hljs.highlightAll();
        });
    </script>
</body>
</html>
    