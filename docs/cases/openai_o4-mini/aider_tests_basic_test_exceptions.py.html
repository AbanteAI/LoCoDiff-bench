<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Case: tests/basic/test_exceptions.py - o4-mini-medium</title>
    <link rel="stylesheet" href="../../styles.css">
</head>
<body>
    <header>
        <h1>Case: tests/basic/test_exceptions.py</h1>
        <p><a href="../../models/openai_o4-mini.html">‚Üê Back to o4-mini-medium Cases</a> | <a href="../../index.html">Home</a></p>
    </header>
    <main>
        <section class="case-details">
            <div class="case-info">
                <h2>Benchmark Case Information</h2>
                <p><strong>Model:</strong> o4-mini-medium</p>
                <p><strong>Status:</strong> <span class="failure">Failure</span></p>
                <p><strong>Prompt Tokens:</strong> 3360</p>
                <p><strong>Output Tokens:</strong> N/A</p>
                <p><strong>Native Prompt Tokens:</strong> 3408</p>
                <p><strong>Native Completion Tokens:</strong> 6905</p>
                <p><strong>Native Tokens Reasoning:</strong> 6272</p>
                <p><strong>Native Finish Reason:</strong> stop</p>
                <p><strong>Cost:</strong> $0.0341308</p>
            </div>
            
            <div class="content-links">
                <h2>View Content</h2>
                <ul>
                    <li><a href="../../content/openai_o4-mini/aider_tests_basic_test_exceptions.py/prompt.html" class="content-link">View Prompt</a></li>
                    <li><a href="../../content/openai_o4-mini/aider_tests_basic_test_exceptions.py/expected.html" class="content-link">View Expected Output</a></li>
                    <li><a href="../../content/openai_o4-mini/aider_tests_basic_test_exceptions.py/actual.html" class="content-link">View Actual Output</a></li>
                </ul>
            </div>
            
            <div class="diff-section">
                <h2>Diff (Expected vs Actual)</h2>
                <div id="diff-output">
                    <pre class="diff"><div></div><div>index aebedbf6..16ea5775 100644</div><div class="diff-header">--- a/aider_tests_basic_test_exceptions.py_expectedoutput.txt (expected):tmp/tmpom9zfqer_expected.txt	</div><div class="diff-header">+++ b/aider_tests_basic_test_exceptions.py_extracted.txt (actual):tmp/tmpiapiexaf_actual.txt	</div><div class="diff-info">@@ -1,19 +1,16 @@</div><div> from aider.exceptions import ExInfo, LiteLLMExceptions</div><div> </div><div class="diff-removed">-</div><div> def test_litellm_exceptions_load():</div><div>     """Test that LiteLLMExceptions loads without errors"""</div><div>     ex = LiteLLMExceptions()</div><div>     assert len(ex.exceptions) > 0</div><div> </div><div class="diff-removed">-</div><div> def test_exceptions_tuple():</div><div>     """Test that exceptions_tuple returns a non-empty tuple"""</div><div>     ex = LiteLLMExceptions()</div><div>     assert isinstance(ex.exceptions_tuple(), tuple)</div><div>     assert len(ex.exceptions_tuple()) > 0</div><div> </div><div class="diff-removed">-</div><div> def test_get_ex_info():</div><div>     """Test get_ex_info returns correct ExInfo"""</div><div>     ex = LiteLLMExceptions()</div><div class="diff-info">@@ -41,18 +38,18 @@ def test_get_ex_info():</div><div>     assert ex_info.retry is None</div><div>     assert ex_info.description is None</div><div> </div><div class="diff-removed">-</div><div> def test_rate_limit_error():</div><div>     """Test specific handling of RateLimitError"""</div><div>     ex = LiteLLMExceptions()</div><div>     from litellm import RateLimitError</div><div> </div><div class="diff-removed">-    rate_error = RateLimitError(message="Rate limit exceeded", llm_provider="openai", model="gpt-4")</div><div class="diff-added">+    rate_error = RateLimitError(</div><div class="diff-added">+        message="Rate limit exceeded", llm_provider="openai", model="gpt-4"</div><div class="diff-added">+    )</div><div>     ex_info = ex.get_ex_info(rate_error)</div><div>     assert ex_info.retry is True</div><div>     assert "rate limited" in ex_info.description.lower()</div><div> </div><div class="diff-removed">-</div><div> def test_context_window_error():</div><div>     """Test specific handling of ContextWindowExceededError"""</div><div>     ex = LiteLLMExceptions()</div><div class="diff-info">@@ -64,7 +61,6 @@ def test_context_window_error():</div><div>     ex_info = ex.get_ex_info(ctx_error)</div><div>     assert ex_info.retry is False</div><div> </div><div class="diff-removed">-</div><div> def test_openrouter_error():</div><div>     """Test specific handling of OpenRouter API errors"""</div><div>     ex = LiteLLMExceptions()</div><div></div></pre>
                </div>
            </div>
        </section>
    </main>
    <footer>
        <p>LoCoDiff-bench - <a href="https://github.com/AbanteAI/LoCoDiff-bench">GitHub Repository</a></p>
    </footer>
</body>
</html>
    