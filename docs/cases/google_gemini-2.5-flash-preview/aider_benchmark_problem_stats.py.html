<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Case: benchmark/problem_stats.py - Gemini 2.5 Flash</title>
    <link rel="stylesheet" href="../../styles.css">
</head>
<body>
    <header>
        <h1>Case: benchmark/problem_stats.py</h1>
        <h2>Model: Gemini 2.5 Flash</h2>
        <p><a href="../../models/google_gemini-2.5-flash-preview.html">All Gemini 2.5 Flash Cases</a> | <a href="../../cases.html">All Cases</a> | <a href="../../index.html">Home</a></p>
    </header>
    <main>
        <section class="case-details">
            <div class="case-info">
                <h2>Benchmark Case Information</h2>
                <p><strong>Model:</strong> Gemini 2.5 Flash</p>
                <p><strong>Status:</strong> <span class="failure">Failure</span></p>
                <p><strong>Prompt Tokens:</strong> 29665</p>
                <p><strong>Native Prompt Tokens:</strong> 37033</p>
                <p><strong>Native Completion Tokens:</strong> 3707</p>
                <p><strong>Native Tokens Reasoning:</strong> 38</p>
                <p><strong>Native Finish Reason:</strong> STOP</p>
                <p><strong>Cost:</strong> $0.00777915</p>
            </div>
            
            <div class="content-links">
                <h2>View Content</h2>
                <ul>
                    <li><a href="../../content/google_gemini-2.5-flash-preview/aider_benchmark_problem_stats.py/prompt.html" class="content-link">View Prompt</a></li>
                    <li><a href="../../content/google_gemini-2.5-flash-preview/aider_benchmark_problem_stats.py/expected.html" class="content-link">View Expected Output</a></li>
                    <li><a href="../../content/google_gemini-2.5-flash-preview/aider_benchmark_problem_stats.py/actual.html" class="content-link">View Actual Output</a></li>
                </ul>
            </div>
            
            <div class="diff-section">
                <h2>Diff (Expected vs Actual)</h2>
                <div id="diff-output">
                    <pre class="diff"><div></div><div>index 36481d11..85e8fd31 100644</div><div class="diff-header">--- a/aider_benchmark_problem_stats.py_expectedoutput.txt (expected):tmp/tmp84a38cd4_expected.txt	</div><div class="diff-header">+++ b/aider_benchmark_problem_stats.py_extracted.txt (actual):tmp/tmpmi3vewp7_actual.txt	</div><div class="diff-info">@@ -36,6 +36,7 @@ def load_results(dirname):</div><div>     # Look in language subdirectories under exercises/practice</div><div>     for fname in benchmark_dir.glob("*/exercises/practice/*/.aider.results.json"):</div><div>         error = False</div><div class="diff-added">+        results = None</div><div>         try:</div><div>             results = json.loads(fname.read_text())</div><div>             error = "testcase" not in results</div><div class="diff-info">@@ -51,8 +52,9 @@ def load_results(dirname):</div><div>         if error:</div><div>             # Track the parse error for this exercise/model combination</div><div>             lang = fname.parts[-5]</div><div class="diff-removed">-            exercise = f"{fname.parts[-2]}/{lang}"  # Use directory name as testcase</div><div class="diff-removed">-            parse_errors.append(exercise)</div><div class="diff-added">+            exercise = f"{fname.parts[-2]}"  # Use directory name as testcase</div><div class="diff-added">+            # Store as exercise/language to match the solved set format</div><div class="diff-added">+            parse_errors.append(f"{exercise}/{lang}")</div><div>             print(f"Bad results file {fname}")</div><div>             continue</div><div> </div><div class="diff-info">@@ -69,12 +71,12 @@ def analyze_exercise_solutions(dirs=None, topn=None, copy_hard_set=False):</div><div>         # Use provided directories, with dirname as model name</div><div>         dir_entries = [(d, d) for d in dirs]</div><div> </div><div class="diff-added">+    dump(dir_entries)</div><div class="diff-added">+</div><div>     # Filter out entries that don't load and sort by pass rate</div><div>     valid_entries = []</div><div>     parse_errors_by_model = {}  # Track which exercises had parse errors for each model</div><div> </div><div class="diff-removed">-    dump(dir_entries)</div><div class="diff-removed">-</div><div>     for dirname, model in dir_entries:</div><div>         results_data = load_results(dirname)</div><div> </div><div class="diff-info">@@ -105,16 +107,15 @@ def analyze_exercise_solutions(dirs=None, topn=None, copy_hard_set=False):</div><div>     if topn:</div><div>         valid_entries = valid_entries[:topn]</div><div> </div><div class="diff-removed">-    # Get all exercise names from a complete run</div><div class="diff-added">+    # Get all unique exercise names (exercise/language format) from all results</div><div>     all_exercises = set()</div><div>     exercise_solutions = defaultdict(list)</div><div> </div><div class="diff-removed">-    # Get all unique exercise names from all results</div><div class="diff-removed">-    all_exercises = set()</div><div>     for (dirname, model), results, _ in valid_entries:</div><div>         if results:</div><div>             for result in results:</div><div>                 try:</div><div class="diff-added">+                    # Store as exercise/language</div><div>                     all_exercises.add(result["testcase"] + "/" + result["language"])</div><div>                 except KeyError:</div><div>                     print(f"Warning: Missing testcase in {dirname}", json.dumps(result, indent=4))</div><div class="diff-info">@@ -132,6 +133,7 @@ def analyze_exercise_solutions(dirs=None, topn=None, copy_hard_set=False):</div><div>             if not lang:</div><div>                 continue</div><div> </div><div class="diff-added">+            # Store as exercise/language</div><div>             testcase = f"{testcase}/{lang}"</div><div>             # Consider it solved if the last test attempt passed</div><div>             tests_outcomes = result.get("tests_outcomes", [])</div><div class="diff-info">@@ -145,39 +147,32 @@ def analyze_exercise_solutions(dirs=None, topn=None, copy_hard_set=False):</div><div>     print("\nExercise Solution Statistics:")</div><div>     print("-" * 40)</div><div> </div><div class="diff-removed">-    # Add exercises that were never solved</div><div class="diff-removed">-    for exercise in all_exercises:</div><div class="diff-removed">-        if exercise not in exercise_solutions:</div><div class="diff-removed">-            exercise_solutions[exercise] = []</div><div class="diff-removed">-</div><div>     # Create list of (language, exercise) pairs with solution stats</div><div>     exercise_stats = []</div><div>     total_models = len(valid_entries)</div><div> </div><div>     for testcase in all_exercises:</div><div class="diff-removed">-        # Language is already in the testcase string</div><div class="diff-removed">-        lang = testcase.split("/")[0]  # First part is the language</div><div class="diff-added">+        # Language/Exercise are already in the testcase string</div><div class="diff-added">+        lang = testcase.split("/")[1]  # Second part is the language</div><div class="diff-added">+        exercise_name = testcase.split("/")[0]  # First part is the exercise name</div><div>         models = exercise_solutions[testcase]</div><div>         num_solved = len(models)</div><div>         percent = (num_solved / total_models) * 100</div><div class="diff-removed">-        testcase = testcase.replace("exercises/", "")  # Remove the exercises/ prefix</div><div class="diff-removed">-        # Remove duplicate language prefix (e.g. javascript/javascript/ -> javascript/)</div><div class="diff-removed">-        if testcase.startswith(f"{lang}/{lang}/"):</div><div class="diff-removed">-            testcase = testcase[len(lang) + 1 :]</div><div class="diff-removed">-        exercise_stats.append((lang, testcase, num_solved, percent))</div><div class="diff-added">+        exercise_stats.append((lang, exercise_name, num_solved, percent))</div><div> </div><div>     # Sort all exercises by solve rate, then by exercise name</div><div class="diff-removed">-    exercise_stats.sort(</div><div class="diff-removed">-        key=lambda x: (-x[2], x[1])</div><div class="diff-removed">-    )  # -x[2] for descending solve rate, x[1] for ascending exercise name</div><div class="diff-added">+    # -x[2] for descending solve rate, x[1] for ascending exercise name</div><div class="diff-added">+    exercise_stats.sort(key=lambda x: (-x[2], x[1]))</div><div> </div><div>     # Calculate max lengths for alignment after cleaning up paths</div><div class="diff-removed">-    max_name_len = max(len(f"{lang}/{testcase}") for lang, testcase, _, _ in exercise_stats)</div><div class="diff-added">+    max_name_len = max(len(f"{ex}/{lang}") for lang, ex, _, _ in exercise_stats)</div><div> </div><div>     # Print all exercises sorted by solve rate</div><div>     print("\nAll Exercises (sorted by solve rate):")</div><div class="diff-removed">-    for i, (lang, testcase, num_solved, percent) in enumerate(exercise_stats, 1):</div><div class="diff-removed">-        print(f"{i:>3}. {testcase:<{max_name_len}} : {num_solved:>3} solved ({percent:>5.1f}%)")</div><div class="diff-added">+    for i, (lang, exercise_name, num_solved, percent) in enumerate(exercise_stats, 1):</div><div class="diff-added">+        print(</div><div class="diff-added">+            f"{i:>3}. {exercise_name}/{lang:<{max_name_len - len(exercise_name) - 1}} : {num_solved:>3} solved ({percent:>5.1f}%)"</div><div class="diff-added">+        )</div><div> </div><div>     print("\nSummary:")</div><div>     solved_at_least_once = len([ex for ex, models in exercise_solutions.items() if models])</div><div class="diff-info">@@ -190,12 +185,12 @@ def analyze_exercise_solutions(dirs=None, topn=None, copy_hard_set=False):</div><div>     print(f"Never solved by any model: {solved_by_none}")</div><div>     if solved_by_none > 0:</div><div>         print("\nExercises never solved by any model:")</div><div class="diff-removed">-        unsolved = [ex for ex, models in exercise_solutions.items() if not models]</div><div class="diff-removed">-        for ex in sorted(unsolved):</div><div class="diff-added">+        unsolved_list = [ex for ex, models in exercise_solutions.items() if not models]</div><div class="diff-added">+        for ex in sorted(unsolved_list):</div><div>             # Split into language and exercise parts</div><div class="diff-removed">-            lang, exercise = ex.split("/")</div><div class="diff-added">+            exercise_name, lang = ex.split("/")</div><div>             # Reconstruct path in desired format</div><div class="diff-removed">-            formatted_path = f"{lang}/exercises/practice/{exercise}"</div><div class="diff-added">+            formatted_path = f"{lang}/exercises/practice/{exercise_name}"</div><div>             print(f"  {formatted_path}")</div><div>     print(f"\nSolved by all models: {solved_by_all}")</div><div>     print(</div><div class="diff-info">@@ -235,9 +230,12 @@ def analyze_exercise_solutions(dirs=None, topn=None, copy_hard_set=False):</div><div>             " errors:"</div><div>         )</div><div>         for ex in sorted(disqualified_exercises):</div><div class="diff-removed">-            print(f"  {ex} ({parse_error_counts[ex]} parse errors)")</div><div class="diff-added">+            lang = ex.split("/")[1]</div><div class="diff-added">+            exercise_name = ex.split("/")[0]</div><div class="diff-added">+            formatted_path = f"{lang}/exercises/practice/{exercise_name}"</div><div class="diff-added">+            print(f"  {formatted_path} ({parse_error_counts[ex]} parse errors)")</div><div> </div><div class="diff-removed">-    # Collect the hard set (exercises solved by HARD_SET_NUM or fewer models)</div><div class="diff-added">+    # Collect the hard set (exercises solved by HARD_SET_NUM or fewer models), excluding disqualified</div><div>     print(f"\nHard Set Analysis (exercises solved by ≤{HARD_SET_NUM} models):")</div><div>     print("-" * 60)</div><div>     hard_set = {</div><div class="diff-info">@@ -253,6 +251,7 @@ def analyze_exercise_solutions(dirs=None, topn=None, copy_hard_set=False):</div><div>     lang_hard_set = defaultdict(int)</div><div> </div><div>     for exercise in all_exercises:</div><div class="diff-added">+        # lang/exercise</div><div>         lang = exercise.split("/")[1]  # Get language from path</div><div>         lang_totals[lang] += 1</div><div>         if not exercise_solutions[exercise]:  # No models solved this exercise</div><div class="diff-info">@@ -261,48 +260,52 @@ def analyze_exercise_solutions(dirs=None, topn=None, copy_hard_set=False):</div><div>             lang_hard_set[lang] += 1</div><div> </div><div>     print("\nUnsolved and hard set problems by language:")</div><div class="diff-removed">-    print(f"{'Language':<12} {'Unsolved':>8} {'Hard Set':>9} {'Total':>7} {'%hardUnsolved':>8}")</div><div class="diff-added">+    print(f"{'Language':<12} {'Unsolved':>8} {'Hard Set':>9} {'Total':>7} {'%Unsolved':>8}")</div><div>     print("-" * 47)</div><div>     for lang in sorted(lang_totals.keys()):</div><div>         count = lang_unsolved[lang]</div><div>         hard = lang_hard_set[lang]</div><div>         total = lang_totals[lang]</div><div class="diff-removed">-        pct = (count / hard) * 100 if hard else -1</div><div class="diff-added">+        pct = (count / total) * 100</div><div>         print(f"{lang:<12} {count:>8} {hard:>9} {total:>7} {pct:>7.1f}%")</div><div>     print()</div><div> </div><div>     # For each model, compute performance on hard set</div><div>     model_hard_stats = []</div><div class="diff-removed">-    for (dirname, model), results, _ in valid_entries:</div><div class="diff-removed">-        if not results:</div><div class="diff-removed">-            continue</div><div class="diff-removed">-</div><div class="diff-removed">-        solved_hard = 0</div><div class="diff-removed">-        for result in results:</div><div class="diff-removed">-            testcase = result.get("testcase")</div><div class="diff-removed">-            if not testcase:</div><div class="diff-removed">-                continue</div><div class="diff-removed">-            lang = result.get("language")</div><div class="diff-removed">-            if not lang:</div><div class="diff-added">+    if len(hard_set) > 0:</div><div class="diff-added">+        for (dirname, model), results, _ in valid_entries:</div><div class="diff-added">+            if not results:</div><div>                 continue</div><div> </div><div class="diff-removed">-            testcase = f"{testcase}/{lang}"</div><div class="diff-removed">-            if testcase in hard_set:</div><div class="diff-removed">-                tests_outcomes = result.get("tests_outcomes", [])</div><div class="diff-removed">-                if tests_outcomes and tests_outcomes[-1]:</div><div class="diff-removed">-                    solved_hard += 1</div><div class="diff-removed">-</div><div class="diff-removed">-        pct = (solved_hard / len(hard_set)) * 100</div><div class="diff-removed">-        model_hard_stats.append((model, solved_hard, pct))</div><div class="diff-removed">-</div><div class="diff-removed">-    # Sort by number solved</div><div class="diff-removed">-    model_hard_stats.sort(key=lambda x: x[1], reverse=True)</div><div class="diff-added">+            solved_hard = 0</div><div class="diff-added">+            for result in results:</div><div class="diff-added">+                testcase = result.get("testcase")</div><div class="diff-added">+                if not testcase:</div><div class="diff-added">+                    continue</div><div class="diff-added">+                lang = result.get("language")</div><div class="diff-added">+                if not lang:</div><div class="diff-added">+                    continue</div><div class="diff-added">+</div><div class="diff-added">+                testcase = f"{testcase}/{lang}"</div><div class="diff-added">+                if testcase in hard_set:</div><div class="diff-added">+                    tests_outcomes = result.get("tests_outcomes", [])</div><div class="diff-added">+                    if tests_outcomes and tests_outcomes[-1]:</div><div class="diff-added">+                        solved_hard += 1</div><div class="diff-added">+</div><div class="diff-added">+            pct = (solved_hard / len(hard_set)) * 100</div><div class="diff-added">+            model_hard_stats.append((model, solved_hard, pct))</div><div class="diff-added">+</div><div class="diff-added">+        # Sort by number solved</div><div class="diff-added">+        model_hard_stats.sort(key=lambda x: x[1], reverse=True)</div><div class="diff-added">+</div><div class="diff-added">+        print("\nModel performance on hard set:")</div><div class="diff-added">+        print(f"{'Model':<55} {'Solved':<8} {'Percent':>7}")</div><div class="diff-added">+        print("-" * 50)</div><div class="diff-added">+        for model, solved, pct in model_hard_stats:</div><div class="diff-added">+            print(f"{model:<55} {solved:>6d}   {pct:>6.1f}%")</div><div class="diff-added">+    else:</div><div class="diff-added">+        print("\nNo hard set problems to analyze.")</div><div> </div><div class="diff-removed">-    print("\nModel performance on hard set:")</div><div class="diff-removed">-    print(f"{'Model':<55} {'Solved':<8} {'Percent':>7}")</div><div class="diff-removed">-    print("-" * 50)</div><div class="diff-removed">-    for model, solved, pct in model_hard_stats:</div><div class="diff-removed">-        print(f"{model:<55} {solved:>6d}   {pct:>6.1f}%")</div><div> </div><div>     if copy_hard_set:</div><div>         # Create hard set directory</div><div></div></pre>
                </div>
            </div>
        </section>
    </main>
    <footer>
        <p>LoCoDiff-bench - <a href="https://github.com/AbanteAI/LoCoDiff-bench">GitHub Repository</a></p>
    </footer>
</body>
</html>
    