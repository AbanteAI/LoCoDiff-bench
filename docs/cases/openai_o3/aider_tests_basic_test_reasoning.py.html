<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Case: tests/basic/test_reasoning.py - o3</title>
    <link rel="stylesheet" href="../../styles.css">
</head>
<body>
    <header>
        <h1>Case: tests/basic/test_reasoning.py</h1>
        <p><a href="../../models/openai_o3.html">‚Üê Back to o3 Cases</a> | <a href="../../index.html">Home</a></p>
    </header>
    <main>
        <section class="case-details">
            <div class="case-info">
                <h2>Benchmark Case Information</h2>
                <p><strong>Model:</strong> o3</p>
                <p><strong>Status:</strong> <span class="failure">Failure</span></p>
                <p><strong>Prompt Tokens:</strong> 19336</p>
                <p><strong>Output Tokens:</strong> N/A</p>
                <p><strong>Native Prompt Tokens:</strong> 19682</p>
                <p><strong>Native Completion Tokens:</strong> 6987</p>
                <p><strong>Native Tokens Reasoning:</strong> 1920</p>
                <p><strong>Native Finish Reason:</strong> stop</p>
                <p><strong>Cost:</strong> $0.5001150000000001</p>
            </div>
            
            <div class="content-links">
                <h2>View Content</h2>
                <ul>
                    <li><a href="../../content/openai_o3/aider_tests_basic_test_reasoning.py/prompt.html" class="content-link">View Prompt</a></li>
                    <li><a href="../../content/openai_o3/aider_tests_basic_test_reasoning.py/expected.html" class="content-link">View Expected Output</a></li>
                    <li><a href="../../content/openai_o3/aider_tests_basic_test_reasoning.py/actual.html" class="content-link">View Actual Output</a></li>
                </ul>
            </div>
            
            <div class="diff-section">
                <h2>Diff (Expected vs Actual)</h2>
                <div id="diff-output">
                    <pre class="diff"><div></div><div>index 80b84077..7193d107 100644</div><div class="diff-header">--- a/aider_tests_basic_test_reasoning.py_expectedoutput.txt (expected):tmp/tmp2w1rmzro_expected.txt	</div><div class="diff-header">+++ b/aider_tests_basic_test_reasoning.py_extracted.txt (actual):tmp/tmp7hc_40yw_actual.txt	</div><div class="diff-info">@@ -141,7 +141,7 @@ class TestReasoning(unittest.TestCase):</div><div>         with (</div><div>             patch.object(model, "send_completion", return_value=(mock_hash, chunks)),</div><div>             patch.object(model, "token_count", return_value=10),</div><div class="diff-removed">-        ):  # Mock token count to avoid serialization issues</div><div class="diff-added">+        ):</div><div>             # Set mdstream directly on the coder object</div><div>             coder.mdstream = mock_mdstream</div><div> </div><div class="diff-info">@@ -304,16 +304,16 @@ class TestReasoning(unittest.TestCase):</div><div>         # Create chunks to simulate streaming with think tags</div><div>         chunks = [</div><div>             # Start with open think tag</div><div class="diff-removed">-            MockStreamingChunk(content="<think>\n", reasoning_content=None),</div><div class="diff-added">+            MockStreamingChunk(content="<think>\n"),</div><div>             # Reasoning content inside think tags</div><div class="diff-removed">-            MockStreamingChunk(content="My step-by-step ", reasoning_content=None),</div><div class="diff-removed">-            MockStreamingChunk(content="reasoning process\n", reasoning_content=None),</div><div class="diff-added">+            MockStreamingChunk(content="My step-by-step "),</div><div class="diff-added">+            MockStreamingChunk(content="reasoning process\n"),</div><div>             # Close think tag</div><div class="diff-removed">-            MockStreamingChunk(content="</think>\n\n", reasoning_content=None),</div><div class="diff-added">+            MockStreamingChunk(content="</think>\n\n"),</div><div>             # Main content</div><div class="diff-removed">-            MockStreamingChunk(content="Final ", reasoning_content=None),</div><div class="diff-removed">-            MockStreamingChunk(content="answer ", reasoning_content=None),</div><div class="diff-removed">-            MockStreamingChunk(content="after reasoning", reasoning_content=None),</div><div class="diff-added">+            MockStreamingChunk(content="Final "),</div><div class="diff-added">+            MockStreamingChunk(content="answer "),</div><div class="diff-added">+            MockStreamingChunk(content="after reasoning"),</div><div>             # End the response</div><div>             MockStreamingChunk(finish_reason="stop"),</div><div>         ]</div><div class="diff-info">@@ -323,7 +323,10 @@ class TestReasoning(unittest.TestCase):</div><div>         mock_hash.hexdigest.return_value = "mock_hash_digest"</div><div> </div><div>         # Mock the model's send_completion to return the hash and completion</div><div class="diff-removed">-        with patch.object(model, "send_completion", return_value=(mock_hash, chunks)):</div><div class="diff-added">+        with (</div><div class="diff-added">+            patch.object(model, "send_completion", return_value=(mock_hash, chunks)),</div><div class="diff-added">+            patch.object(model, "token_count", return_value=10),</div><div class="diff-added">+        ):</div><div>             # Set mdstream directly on the coder object</div><div>             coder.mdstream = mock_mdstream</div><div> </div><div class="diff-info">@@ -533,7 +536,7 @@ End"""</div><div>         with (</div><div>             patch.object(model, "send_completion", return_value=(mock_hash, chunks)),</div><div>             patch.object(model, "token_count", return_value=10),</div><div class="diff-removed">-        ):  # Mock token count to avoid serialization issues</div><div class="diff-added">+        ):</div><div>             # Set mdstream directly on the coder object</div><div>             coder.mdstream = mock_mdstream</div><div> </div><div class="diff-info">@@ -586,11 +589,17 @@ End"""</div><div> </div><div>         # Mock the completion response</div><div>         mock_response = MagicMock()</div><div class="diff-removed">-        mock_response.choices = [MagicMock(message=MagicMock(content="""Here is some text</div><div class="diff-added">+        mock_response.choices = [</div><div class="diff-added">+            MagicMock(</div><div class="diff-added">+                message=MagicMock(</div><div class="diff-added">+                    content="""Here is some text</div><div> <think></div><div> This reasoning should be removed</div><div> </think></div><div class="diff-removed">-And this text should remain"""))]</div><div class="diff-added">+And this text should remain"""</div><div class="diff-added">+                )</div><div class="diff-added">+            )</div><div class="diff-added">+        ]</div><div>         mock_completion.return_value = mock_response</div><div> </div><div>         messages = [{"role": "user", "content": "test"}]</div><div></div></pre>
                </div>
            </div>
        </section>
    </main>
    <footer>
        <p>LoCoDiff-bench - <a href="https://github.com/AbanteAI/LoCoDiff-bench">GitHub Repository</a></p>
    </footer>
</body>
</html>
    