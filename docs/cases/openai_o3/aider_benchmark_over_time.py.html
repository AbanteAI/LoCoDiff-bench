<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Case: benchmark/over_time.py - o3</title>
    <link rel="stylesheet" href="../../styles.css">
</head>
<body>
    <header>
        <h1>Case: benchmark/over_time.py</h1>
        <p><a href="../../models/openai_o3.html">‚Üê Back to o3 Cases</a> | <a href="../../index.html">Home</a></p>
    </header>
    <main>
        <section class="case-details">
            <div class="case-info">
                <h2>Benchmark Case Information</h2>
                <p><strong>Model:</strong> o3</p>
                <p><strong>Status:</strong> <span class="failure">Failure</span></p>
                <p><strong>Prompt Tokens:</strong> 35454</p>
                <p><strong>Output Tokens:</strong> N/A</p>
                <p><strong>Native Prompt Tokens:</strong> 35588</p>
                <p><strong>Native Completion Tokens:</strong> 4341</p>
                <p><strong>Native Tokens Reasoning:</strong> 3008</p>
                <p><strong>Native Finish Reason:</strong> stop</p>
                <p><strong>Cost:</strong> $0.5559959999999999</p>
            </div>
            
            <div class="content-links">
                <h2>View Content</h2>
                <ul>
                    <li><a href="../../content/openai_o3/aider_benchmark_over_time.py/prompt.html" class="content-link">View Prompt</a></li>
                    <li><a href="../../content/openai_o3/aider_benchmark_over_time.py/expected.html" class="content-link">View Expected Output</a></li>
                    <li><a href="../../content/openai_o3/aider_benchmark_over_time.py/actual.html" class="content-link">View Actual Output</a></li>
                </ul>
            </div>
            
            <div class="diff-section">
                <h2>Diff (Expected vs Actual)</h2>
                <div id="diff-output">
                    <pre class="diff"><div></div><div>index 5dea59a5..60a76191 100644</div><div class="diff-header">--- a/aider_benchmark_over_time.py_expectedoutput.txt (expected):tmp/tmpt9gpg5fh_expected.txt	</div><div class="diff-header">+++ b/aider_benchmark_over_time.py_extracted.txt (actual):tmp/tmpdngcsi_o_actual.txt	</div><div class="diff-info">@@ -79,7 +79,7 @@ class BenchmarkPlotter:</div><div>         with open(yaml_file, "r") as file:</div><div>             data = yaml.safe_load(file)</div><div> </div><div class="diff-removed">-        models = []</div><div class="diff-added">+        models: List[ModelData] = []</div><div>         for entry in data:</div><div>             if "released" in entry and "pass_rate_2" in entry:</div><div>                 model = ModelData(</div><div class="diff-info">@@ -102,9 +102,7 @@ class BenchmarkPlotter:</div><div>         # Group models by color</div><div>         color_groups: Dict[str, List[ModelData]] = {}</div><div>         for model in models:</div><div class="diff-removed">-            if model.color not in color_groups:</div><div class="diff-removed">-                color_groups[model.color] = []</div><div class="diff-removed">-            color_groups[model.color].append(model)</div><div class="diff-added">+            color_groups.setdefault(model.color, []).append(model)</div><div> </div><div>         # Plot each color group</div><div>         for color, group in color_groups.items():</div><div></div></pre>
                </div>
            </div>
        </section>
    </main>
    <footer>
        <p>LoCoDiff-bench - <a href="https://github.com/AbanteAI/LoCoDiff-bench">GitHub Repository</a></p>
    </footer>
</body>
</html>
    