<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Case: tests/basic/test_models.py - o4-mini-high</title>
    <link rel="stylesheet" href="../../styles.css">
</head>
<body>
    <header>
        <h1>Case: tests/basic/test_models.py</h1>
        <p><a href="../../models/openai_o4-mini-high.html">‚Üê Back to o4-mini-high Cases</a> | <a href="../../index.html">Home</a></p>
    </header>
    <main>
        <section class="case-details">
            <div class="case-info">
                <h2>Benchmark Case Information</h2>
                <p><strong>Model:</strong> o4-mini-high</p>
                <p><strong>Status:</strong> <span class="failure">Failure</span></p>
                <p><strong>Prompt Tokens:</strong> 34611</p>
                <p><strong>Output Tokens:</strong> N/A</p>
                <p><strong>Native Prompt Tokens:</strong> 35097</p>
                <p><strong>Native Completion Tokens:</strong> 56328</p>
                <p><strong>Native Tokens Reasoning:</strong> 51648</p>
                <p><strong>Native Finish Reason:</strong> stop</p>
                <p><strong>Runtime:</strong> N/As</p>
                <p><strong>Cost:</strong> $0.2575155</p>
            </div>
            
            <div class="content-links">
                <h2>View Content</h2>
                <ul>
                    <li><a href="../../content/openai_o4-mini-high/aider_tests_basic_test_models.py/prompt.html" class="content-link">View Prompt</a></li>
                    <li><a href="../../content/openai_o4-mini-high/aider_tests_basic_test_models.py/expected.html" class="content-link">View Expected Output</a></li>
                    <li><a href="../../content/openai_o4-mini-high/aider_tests_basic_test_models.py/actual.html" class="content-link">View Actual Output</a></li>
                </ul>
            </div>
            
            <div class="diff-section">
                <h2>Diff (Expected vs Actual)</h2>
                <div id="diff-output">
                    <pre class="diff"><div class="diff-header">--- aider_tests_basic_test_models.py_expectedoutput.txt (expected)+++ aider_tests_basic_test_models.py_extracted.txt (actual)@@ -24,6 +24,21 @@ </div><div>         MODEL_SETTINGS.clear()</div><div>         MODEL_SETTINGS.extend(self._original_settings)</div><div class="diff-added">+</div><div class="diff-added">+    @patch("aider.models.check_for_dependencies")</div><div class="diff-added">+    def test_sanity_check_model_calls_check_dependencies(self, mock_check_deps):</div><div class="diff-added">+        """Test that sanity_check_model calls check_for_dependencies"""</div><div class="diff-added">+        mock_io = MagicMock()</div><div class="diff-added">+        model = MagicMock()</div><div class="diff-added">+        model.name = "test-model"</div><div class="diff-added">+        model.missing_keys = []</div><div class="diff-added">+        model.keys_in_environment = True</div><div class="diff-added">+        model.info = {"some": "info"}</div><div class="diff-added">+</div><div class="diff-added">+        sanity_check_model(mock_io, model)</div><div class="diff-added">+</div><div class="diff-added">+        # Verify check_for_dependencies was called with the model name</div><div class="diff-added">+        mock_check_deps.assert_called_once_with(mock_io, "test-model")</div><div> </div><div>     def test_get_model_info_nonexistent(self):</div><div>         manager = ModelInfoManager()</div><div class="diff-info">@@ -94,31 +109,14 @@             result</div><div>         )  # Should return True because there's a problem with the editor model</div><div>         mock_io.tool_warning.assert_called_with(ANY)  # Ensure a warning was issued</div><div class="diff-removed">-</div><div>         warning_messages = [</div><div>             warning_call.args[0] for warning_call in mock_io.tool_warning.call_args_list</div><div>         ]</div><div>         print("Warning messages:", warning_messages)  # Add this line</div><div class="diff-removed">-</div><div>         self.assertGreaterEqual(mock_io.tool_warning.call_count, 1)  # Expect two warnings</div><div>         self.assertTrue(</div><div>             any("bogus-model" in msg for msg in warning_messages)</div><div>         )  # Check that one of the warnings mentions the bogus model</div><div class="diff-removed">-</div><div class="diff-removed">-    @patch("aider.models.check_for_dependencies")</div><div class="diff-removed">-    def test_sanity_check_model_calls_check_dependencies(self, mock_check_deps):</div><div class="diff-removed">-        """Test that sanity_check_model calls check_for_dependencies"""</div><div class="diff-removed">-        mock_io = MagicMock()</div><div class="diff-removed">-        model = MagicMock()</div><div class="diff-removed">-        model.name = "test-model"</div><div class="diff-removed">-        model.missing_keys = []</div><div class="diff-removed">-        model.keys_in_environment = True</div><div class="diff-removed">-        model.info = {"some": "info"}</div><div class="diff-removed">-</div><div class="diff-removed">-        sanity_check_model(mock_io, model)</div><div class="diff-removed">-</div><div class="diff-removed">-        # Verify check_for_dependencies was called with the model name</div><div class="diff-removed">-        mock_check_deps.assert_called_once_with(mock_io, "test-model")</div><div> </div><div>     def test_model_aliases(self):</div><div>         # Test common aliases</div><div class="diff-info">@@ -160,50 +158,9 @@         self.assertEqual(model.name, "github/o1-preview")</div><div>         self.assertEqual(model.use_temperature, False)</div><div> </div><div class="diff-removed">-    def test_parse_token_value(self):</div><div class="diff-removed">-        # Create a model instance to test the parse_token_value method</div><div class="diff-removed">-        model = Model("gpt-4")</div><div class="diff-removed">-</div><div class="diff-removed">-        # Test integer inputs</div><div class="diff-removed">-        self.assertEqual(model.parse_token_value(8096), 8096)</div><div class="diff-removed">-        self.assertEqual(model.parse_token_value(1000), 1000)</div><div class="diff-removed">-</div><div class="diff-removed">-        # Test string inputs</div><div class="diff-removed">-        self.assertEqual(model.parse_token_value("8096"), 8096)</div><div class="diff-removed">-</div><div class="diff-removed">-        # Test k/K suffix (kilobytes)</div><div class="diff-removed">-        self.assertEqual(model.parse_token_value("8k"), 8 * 1024)</div><div class="diff-removed">-        self.assertEqual(model.parse_token_value("8K"), 8 * 1024)</div><div class="diff-removed">-        self.assertEqual(model.parse_token_value("10.5k"), 10.5 * 1024)</div><div class="diff-removed">-        self.assertEqual(model.parse_token_value("0.5K"), 0.5 * 1024)</div><div class="diff-removed">-</div><div class="diff-removed">-        # Test m/M suffix (megabytes)</div><div class="diff-removed">-        self.assertEqual(model.parse_token_value("1m"), 1 * 1024 * 1024)</div><div class="diff-removed">-        self.assertEqual(model.parse_token_value("1M"), 1 * 1024 * 1024)</div><div class="diff-removed">-        self.assertEqual(model.parse_token_value("0.5M"), 0.5 * 1024 * 1024)</div><div class="diff-removed">-</div><div class="diff-removed">-        # Test with spaces</div><div class="diff-removed">-        self.assertEqual(model.parse_token_value(" 8k "), 8 * 1024)</div><div class="diff-removed">-</div><div class="diff-removed">-        # Test conversion from other types</div><div class="diff-removed">-        self.assertEqual(model.parse_token_value(8.0), 8)</div><div class="diff-removed">-</div><div class="diff-removed">-    def test_set_thinking_tokens(self):</div><div class="diff-removed">-        # Test that set_thinking_tokens correctly sets the tokens with different formats</div><div class="diff-removed">-        model = Model("gpt-4")</div><div class="diff-removed">-</div><div class="diff-removed">-        # Test with integer</div><div class="diff-removed">-        model.set_thinking_tokens(8096)</div><div class="diff-removed">-        self.assertEqual(model.extra_params["thinking"]["budget_tokens"], 8096)</div><div class="diff-removed">-        self.assertFalse(model.use_temperature)</div><div class="diff-removed">-</div><div class="diff-removed">-        # Test with string</div><div class="diff-removed">-        model.set_thinking_tokens("10k")</div><div class="diff-removed">-        self.assertEqual(model.extra_params["thinking"]["budget_tokens"], 10 * 1024)</div><div class="diff-removed">-</div><div class="diff-removed">-        # Test with decimal value</div><div class="diff-removed">-        model.set_thinking_tokens("0.5M")</div><div class="diff-removed">-        self.assertEqual(model.extra_params["thinking"]["budget_tokens"], 0.5 * 1024 * 1024)</div><div class="diff-added">+        # Test non-alias passes through unchanged</div><div class="diff-added">+        model = Model("gpt-4")</div><div class="diff-added">+        self.assertEqual(model.name, "gpt-4")</div><div> </div><div>     @patch("aider.models.check_pip_install_extra")</div><div>     def test_check_for_dependencies_bedrock(self, mock_check_pip):</div><div class="diff-info">@@ -215,11 +172,16 @@         # Test with a Bedrock model</div><div>         from aider.models import check_for_dependencies</div><div> </div><div class="diff-removed">-        check_for_dependencies(io, "bedrock/anthropic.claude-3-sonnet-20240229-v1:0")</div><div class="diff-added">+        check_for_dependencies(</div><div class="diff-added">+            io, "bedrock/anthropic.claude-3-sonnet-20240229-v1:0"</div><div class="diff-added">+        )</div><div> </div><div>         # Verify check_pip_install_extra was called with correct arguments</div><div>         mock_check_pip.assert_called_once_with(</div><div class="diff-removed">-            io, "boto3", "AWS Bedrock models require the boto3 package.", ["boto3"]</div><div class="diff-added">+            io,</div><div class="diff-added">+            "boto3",</div><div class="diff-added">+            "AWS Bedrock models require the boto3 package.",</div><div class="diff-added">+            ["boto3"],</div><div>         )</div><div> </div><div>     @patch("aider.models.check_pip_install_extra")</div><div class="diff-info">@@ -257,126 +219,8 @@         # Verify check_pip_install_extra was not called</div><div>         mock_check_pip.assert_not_called()</div><div> </div><div class="diff-removed">-    def test_get_repo_map_tokens(self):</div><div class="diff-removed">-        # Test default case (no max_input_tokens in info)</div><div class="diff-removed">-        model = Model("gpt-4")</div><div class="diff-removed">-        model.info = {}</div><div class="diff-removed">-        self.assertEqual(model.get_repo_map_tokens(), 1024)</div><div class="diff-removed">-</div><div class="diff-removed">-        # Test minimum boundary (max_input_tokens < 8192)</div><div class="diff-removed">-        model.info = {"max_input_tokens": 4096}</div><div class="diff-removed">-        self.assertEqual(model.get_repo_map_tokens(), 1024)</div><div class="diff-removed">-</div><div class="diff-removed">-        # Test middle range (max_input_tokens = 16384)</div><div class="diff-removed">-        model.info = {"max_input_tokens": 16384}</div><div class="diff-removed">-        self.assertEqual(model.get_repo_map_tokens(), 2048)</div><div class="diff-removed">-</div><div class="diff-removed">-        # Test maximum boundary (max_input_tokens > 32768)</div><div class="diff-removed">-        model.info = {"max_input_tokens": 65536}</div><div class="diff-removed">-        self.assertEqual(model.get_repo_map_tokens(), 4096)</div><div class="diff-removed">-</div><div class="diff-removed">-        # Test exact boundary values</div><div class="diff-removed">-        model.info = {"max_input_tokens": 8192}</div><div class="diff-removed">-        self.assertEqual(model.get_repo_map_tokens(), 1024)</div><div class="diff-removed">-</div><div class="diff-removed">-        model.info = {"max_input_tokens": 32768}</div><div class="diff-removed">-        self.assertEqual(model.get_repo_map_tokens(), 4096)</div><div class="diff-removed">-</div><div class="diff-removed">-    def test_configure_model_settings(self):</div><div class="diff-removed">-        # Test o3-mini case</div><div class="diff-removed">-        model = Model("something/o3-mini")</div><div class="diff-removed">-        self.assertEqual(model.edit_format, "diff")</div><div class="diff-removed">-        self.assertTrue(model.use_repo_map)</div><div class="diff-removed">-        self.assertFalse(model.use_temperature)</div><div class="diff-removed">-</div><div class="diff-removed">-        # Test o1-mini case</div><div class="diff-removed">-        model = Model("something/o1-mini")</div><div class="diff-removed">-        self.assertTrue(model.use_repo_map)</div><div class="diff-removed">-        self.assertFalse(model.use_temperature)</div><div class="diff-removed">-        self.assertFalse(model.use_system_prompt)</div><div class="diff-removed">-</div><div class="diff-removed">-        # Test o1-preview case</div><div class="diff-removed">-        model = Model("something/o1-preview")</div><div class="diff-removed">-        self.assertEqual(model.edit_format, "diff")</div><div class="diff-removed">-        self.assertTrue(model.use_repo_map)</div><div class="diff-removed">-        self.assertFalse(model.use_temperature)</div><div class="diff-removed">-        self.assertFalse(model.use_system_prompt)</div><div class="diff-removed">-</div><div class="diff-removed">-        # Test o1 case</div><div class="diff-removed">-        model = Model("something/o1")</div><div class="diff-removed">-        self.assertEqual(model.edit_format, "diff")</div><div class="diff-removed">-        self.assertTrue(model.use_repo_map)</div><div class="diff-removed">-        self.assertFalse(model.use_temperature)</div><div class="diff-removed">-        self.assertFalse(model.streaming)</div><div class="diff-removed">-</div><div class="diff-removed">-        # Test deepseek v3 case</div><div class="diff-removed">-        model = Model("deepseek-v3")</div><div class="diff-removed">-        self.assertEqual(model.edit_format, "diff")</div><div class="diff-removed">-        self.assertTrue(model.use_repo_map)</div><div class="diff-removed">-        self.assertEqual(model.reminder, "sys")</div><div class="diff-removed">-        self.assertTrue(model.examples_as_sys_msg)</div><div class="diff-removed">-</div><div class="diff-removed">-        # Test deepseek reasoner case</div><div class="diff-removed">-        model = Model("deepseek-r1")</div><div class="diff-removed">-        self.assertEqual(model.edit_format, "diff")</div><div class="diff-removed">-        self.assertTrue(model.use_repo_map)</div><div class="diff-removed">-        self.assertTrue(model.examples_as_sys_msg)</div><div class="diff-removed">-        self.assertFalse(model.use_temperature)</div><div class="diff-removed">-        self.assertEqual(model.reasoning_tag, "think")</div><div class="diff-removed">-</div><div class="diff-removed">-        # Test provider/deepseek-r1 case</div><div class="diff-removed">-        model = Model("someprovider/deepseek-r1")</div><div class="diff-removed">-        self.assertEqual(model.edit_format, "diff")</div><div class="diff-removed">-        self.assertTrue(model.use_repo_map)</div><div class="diff-removed">-        self.assertTrue(model.examples_as_sys_msg)</div><div class="diff-removed">-        self.assertFalse(model.use_temperature)</div><div class="diff-removed">-        self.assertEqual(model.reasoning_tag, "think")</div><div class="diff-removed">-</div><div class="diff-removed">-        # Test provider/deepseek-v3 case</div><div class="diff-removed">-        model = Model("anotherprovider/deepseek-v3")</div><div class="diff-removed">-        self.assertEqual(model.edit_format, "diff")</div><div class="diff-removed">-        self.assertTrue(model.use_repo_map)</div><div class="diff-removed">-        self.assertEqual(model.reminder, "sys")</div><div class="diff-removed">-        self.assertTrue(model.examples_as_sys_msg)</div><div class="diff-removed">-</div><div class="diff-removed">-        # Test llama3 70b case</div><div class="diff-removed">-        model = Model("llama3-70b")</div><div class="diff-removed">-        self.assertEqual(model.edit_format, "diff")</div><div class="diff-removed">-        self.assertTrue(model.use_repo_map)</div><div class="diff-removed">-        self.assertTrue(model.send_undo_reply)</div><div class="diff-removed">-        self.assertTrue(model.examples_as_sys_msg)</div><div class="diff-removed">-</div><div class="diff-removed">-        # Test gpt-4 case</div><div class="diff-removed">-        model = Model("gpt-4")</div><div class="diff-removed">-        self.assertEqual(model.edit_format, "diff")</div><div class="diff-removed">-        self.assertTrue(model.use_repo_map)</div><div class="diff-removed">-        self.assertTrue(model.send_undo_reply)</div><div class="diff-removed">-</div><div class="diff-removed">-        # Test gpt-3.5 case</div><div class="diff-removed">-        model = Model("gpt-3.5")</div><div class="diff-removed">-        self.assertEqual(model.reminder, "sys")</div><div class="diff-removed">-</div><div class="diff-removed">-        # Test 3.5-sonnet case</div><div class="diff-removed">-        model = Model("claude-3.5-sonnet")</div><div class="diff-removed">-        self.assertEqual(model.edit_format, "diff")</div><div class="diff-removed">-        self.assertTrue(model.use_repo_map)</div><div class="diff-removed">-        self.assertTrue(model.examples_as_sys_msg)</div><div class="diff-removed">-        self.assertEqual(model.reminder, "user")</div><div class="diff-removed">-</div><div class="diff-removed">-        # Test o1- prefix case</div><div class="diff-removed">-        model = Model("o1-something")</div><div class="diff-removed">-        self.assertFalse(model.use_system_prompt)</div><div class="diff-removed">-        self.assertFalse(model.use_temperature)</div><div class="diff-removed">-</div><div class="diff-removed">-        # Test qwen case</div><div class="diff-removed">-        model = Model("qwen-coder-2.5-32b")</div><div class="diff-removed">-        self.assertEqual(model.edit_format, "diff")</div><div class="diff-removed">-        self.assertEqual(model.editor_edit_format, "editor-diff")</div><div class="diff-removed">-        self.assertTrue(model.use_repo_map)</div><div class="diff-removed">-</div><div>     def test_aider_extra_model_settings(self):</div><div>         import tempfile</div><div class="diff-removed">-</div><div>         import yaml</div><div> </div><div>         # Create temporary YAML file with test settings</div><div class="diff-info">@@ -391,7 +235,6 @@         ]</div><div> </div><div>         # Write to a regular file instead of NamedTemporaryFile</div><div class="diff-removed">-        # for better cross-platform compatibility</div><div>         tmp = tempfile.mktemp(suffix=".yml")</div><div>         try:</div><div>             with open(tmp, "w") as f:</div><div class="diff-info">@@ -400,8 +243,6 @@             # Register the test settings</div><div>             register_models([tmp])</div><div> </div><div class="diff-removed">-            # Test that defaults are applied when no exact match</div><div class="diff-removed">-            model = Model("claude-3-5-sonnet-20240620")</div><div>             # Test that both the override and existing headers are present</div><div>             model = Model("claude-3-5-sonnet-20240620")</div><div>             self.assertEqual(model.extra_params["extra_headers"]["Foo"], "bar")</div><div class="diff-info">@@ -425,11 +266,35 @@             except OSError:</div><div>                 pass</div><div> </div><div class="diff-added">+    def test_get_repo_map_tokens(self):</div><div class="diff-added">+        # Test default case (no max_input_tokens in info)</div><div class="diff-added">+        model = Model("gpt-4")</div><div class="diff-added">+        model.info = {}</div><div class="diff-added">+        self.assertEqual(model.get_repo_map_tokens(), 1024)</div><div class="diff-added">+</div><div class="diff-added">+        # Test minimum boundary (max_input_tokens < 8192)</div><div class="diff-added">+        model.info = {"max_input_tokens": 4096}</div><div class="diff-added">+        self.assertEqual(model.get_repo_map_tokens(), 1024)</div><div class="diff-added">+</div><div class="diff-added">+        # Test middle range (max_input_tokens = 16384)</div><div class="diff-added">+        model.info = {"max_input_tokens": 16384}</div><div class="diff-added">+        self.assertEqual(model.get_repo_map_tokens(), 2048)</div><div class="diff-added">+</div><div class="diff-added">+        # Test maximum boundary (max_input_tokens > 32768)</div><div class="diff-added">+        model.info = {"max_input_tokens": 65536}</div><div class="diff-added">+        self.assertEqual(model.get_repo_map_tokens(), 4096)</div><div class="diff-added">+</div><div class="diff-added">+        # Test exact boundary values</div><div class="diff-added">+        model.info = {"max_input_tokens": 8192}</div><div class="diff-added">+        self.assertEqual(model.get_repo_map_tokens(), 1024)</div><div class="diff-added">+</div><div class="diff-added">+        model.info = {"max_input_tokens": 32768}</div><div class="diff-added">+        self.assertEqual(model.get_repo_map_tokens(), 4096)</div><div class="diff-added">+</div><div>     @patch("aider.models.litellm.completion")</div><div>     @patch.object(Model, "token_count")</div><div>     def test_ollama_num_ctx_set_when_missing(self, mock_token_count, mock_completion):</div><div>         mock_token_count.return_value = 1000</div><div class="diff-removed">-</div><div>         model = Model("ollama/llama3")</div><div>         messages = [{"role": "user", "content": "Hello"}]</div><div> </div><div class="diff-info">@@ -497,6 +362,39 @@         self.assertEqual(model.use_temperature, 0.7)</div><div> </div><div>     @patch("aider.models.litellm.completion")</div><div class="diff-added">+    def test_use_temperature_in_send_completion(self, mock_completion):</div><div class="diff-added">+        # Test use_temperature=True sends temperature=0</div><div class="diff-added">+        model = Model("gpt-4")</div><div class="diff-added">+        messages = [{"role": "user", "content": "Hello"}]</div><div class="diff-added">+        model.send_completion(messages, functions=None, stream=False)</div><div class="diff-added">+        mock_completion.assert_called_with(</div><div class="diff-added">+            model=model.name,</div><div class="diff-added">+            messages=messages,</div><div class="diff-added">+            stream=False,</div><div class="diff-added">+            temperature=0,</div><div class="diff-added">+            timeout=600,</div><div class="diff-added">+        )</div><div class="diff-added">+</div><div class="diff-added">+        # Test use_temperature=False doesn't send temperature</div><div class="diff-added">+        model = Model("github/o1-mini")</div><div class="diff-added">+        messages = [{"role": "user", "content": "Hello"}]</div><div class="diff-added">+        model.send_completion(messages, functions=None, stream=False)</div><div class="diff-added">+        self.assertNotIn("temperature", mock_completion.call_args.kwargs)</div><div class="diff-added">+</div><div class="diff-added">+        # Test use_temperature as float sends that value</div><div class="diff-added">+        model = Model("gpt-4")</div><div class="diff-added">+        model.use_temperature = 0.7</div><div class="diff-added">+        messages = [{"role": "user", "content": "Hello"}]</div><div class="diff-added">+        model.send_completion(messages, functions=None, stream=False)</div><div class="diff-added">+        mock_completion.assert_called_with(</div><div class="diff-added">+            model=model.name,</div><div class="diff-added">+            messages=messages,</div><div class="diff-added">+            stream=False,</div><div class="diff-added">+            temperature=0.7,</div><div class="diff-added">+            timeout=600,</div><div class="diff-added">+        )</div><div class="diff-added">+</div><div class="diff-added">+    @patch("aider.models.litellm.completion")</div><div>     def test_request_timeout_default(self, mock_completion):</div><div>         # Test default timeout is used when not specified in extra_params</div><div>         model = Model("gpt-4")</div><div class="diff-info">@@ -507,14 +405,14 @@             messages=messages,</div><div>             stream=False,</div><div>             temperature=0,</div><div class="diff-removed">-            timeout=600,  # Default timeout</div><div class="diff-added">+            timeout=600,</div><div>         )</div><div> </div><div>     @patch("aider.models.litellm.completion")</div><div>     def test_request_timeout_from_extra_params(self, mock_completion):</div><div>         # Test timeout from extra_params overrides default</div><div>         model = Model("gpt-4")</div><div class="diff-removed">-        model.extra_params = {"timeout": 300}  # 5 minutes</div><div class="diff-added">+        model.extra_params = {"timeout": 300}</div><div>         messages = [{"role": "user", "content": "Hello"}]</div><div>         model.send_completion(messages, functions=None, stream=False)</div><div>         mock_completion.assert_called_with(</div><div class="diff-info">@@ -522,41 +420,145 @@             messages=messages,</div><div>             stream=False,</div><div>             temperature=0,</div><div class="diff-removed">-            timeout=300,  # From extra_params</div><div class="diff-removed">-        )</div><div class="diff-removed">-</div><div class="diff-removed">-    @patch("aider.models.litellm.completion")</div><div class="diff-removed">-    def test_use_temperature_in_send_completion(self, mock_completion):</div><div class="diff-removed">-        # Test use_temperature=True sends temperature=0</div><div class="diff-removed">-        model = Model("gpt-4")</div><div class="diff-removed">-        messages = [{"role": "user", "content": "Hello"}]</div><div class="diff-removed">-        model.send_completion(messages, functions=None, stream=False)</div><div class="diff-removed">-        mock_completion.assert_called_with(</div><div class="diff-removed">-            model=model.name,</div><div class="diff-removed">-            messages=messages,</div><div class="diff-removed">-            stream=False,</div><div class="diff-removed">-            temperature=0,</div><div class="diff-removed">-            timeout=600,</div><div class="diff-removed">-        )</div><div class="diff-removed">-</div><div class="diff-removed">-        # Test use_temperature=False doesn't send temperature</div><div class="diff-removed">-        model = Model("github/o1-mini")</div><div class="diff-removed">-        messages = [{"role": "user", "content": "Hello"}]</div><div class="diff-removed">-        model.send_completion(messages, functions=None, stream=False)</div><div class="diff-removed">-        self.assertNotIn("temperature", mock_completion.call_args.kwargs)</div><div class="diff-removed">-</div><div class="diff-removed">-        # Test use_temperature as float sends that value</div><div class="diff-removed">-        model = Model("gpt-4")</div><div class="diff-removed">-        model.use_temperature = 0.7</div><div class="diff-removed">-        messages = [{"role": "user", "content": "Hello"}]</div><div class="diff-removed">-        model.send_completion(messages, functions=None, stream=False)</div><div class="diff-removed">-        mock_completion.assert_called_with(</div><div class="diff-removed">-            model=model.name,</div><div class="diff-removed">-            messages=messages,</div><div class="diff-removed">-            stream=False,</div><div class="diff-removed">-            temperature=0.7,</div><div class="diff-removed">-            timeout=600,</div><div class="diff-removed">-        )</div><div class="diff-added">+            timeout=300,</div><div class="diff-added">+        )</div><div class="diff-added">+</div><div class="diff-added">+    def test_configure_model_settings(self):</div><div class="diff-added">+        # Test o3-mini case</div><div class="diff-added">+        model = Model("something/o3-mini")</div><div class="diff-added">+        self.assertEqual(model.edit_format, "diff")</div><div class="diff-added">+        self.assertTrue(model.use_repo_map)</div><div class="diff-added">+        self.assertFalse(model.use_temperature)</div><div class="diff-added">+</div><div class="diff-added">+        # Test o1-mini case</div><div class="diff-added">+        model = Model("something/o1-mini")</div><div class="diff-added">+        self.assertTrue(model.use_repo_map)</div><div class="diff-added">+        self.assertFalse(model.use_temperature)</div><div class="diff-added">+        self.assertFalse(model.use_system_prompt)</div><div class="diff-added">+</div><div class="diff-added">+        # Test o1-preview case</div><div class="diff-added">+        model = Model("something/o1-preview")</div><div class="diff-added">+        self.assertEqual(model.edit_format, "diff")</div><div class="diff-added">+        self.assertTrue(model.use_repo_map)</div><div class="diff-added">+        self.assertFalse(model.use_temperature)</div><div class="diff-added">+        self.assertFalse(model.use_system_prompt)</div><div class="diff-added">+</div><div class="diff-added">+        # Test o1 case</div><div class="diff-added">+        model = Model("something/o1")</div><div class="diff-added">+        self.assertEqual(model.edit_format, "diff")</div><div class="diff-added">+        self.assertTrue(model.use_repo_map)</div><div class="diff-added">+        self.assertFalse(model.use_temperature)</div><div class="diff-added">+        self.assertFalse(model.streaming)</div><div class="diff-added">+</div><div class="diff-added">+        # Test deepseek v3 case</div><div class="diff-added">+        model = Model("deepseek-v3")</div><div class="diff-added">+        self.assertEqual(model.edit_format, "diff")</div><div class="diff-added">+        self.assertTrue(model.use_repo_map)</div><div class="diff-added">+        self.assertEqual(model.reminder, "sys")</div><div class="diff-added">+        self.assertTrue(model.examples_as_sys_msg)</div><div class="diff-added">+</div><div class="diff-added">+        # Test deepseek reasoner case</div><div class="diff-added">+        model = Model("deepseek-r1")</div><div class="diff-added">+        self.assertEqual(model.edit_format, "diff")</div><div class="diff-added">+        self.assertTrue(model.use_repo_map)</div><div class="diff-added">+        self.assertTrue(model.examples_as_sys_msg)</div><div class="diff-added">+        self.assertFalse(model.use_temperature)</div><div class="diff-added">+        self.assertEqual(model.reasoning_tag, "think")</div><div class="diff-added">+</div><div class="diff-added">+        # Test provider/deepseek-r1 case</div><div class="diff-added">+        model = Model("someprovider/deepseek-r1")</div><div class="diff-added">+        self.assertEqual(model.edit_format, "diff")</div><div class="diff-added">+        self.assertTrue(model.use_repo_map)</div><div class="diff-added">+        self.assertTrue(model.examples_as_sys_msg)</div><div class="diff-added">+        self.assertFalse(model.use_temperature)</div><div class="diff-added">+        self.assertEqual(model.reasoning_tag, "think")</div><div class="diff-added">+</div><div class="diff-added">+        # Test provider/deepseek-v3 case</div><div class="diff-added">+        model = Model("anotherprovider/deepseek-v3")</div><div class="diff-added">+        self.assertEqual(model.edit_format, "diff")</div><div class="diff-added">+        self.assertTrue(model.use_repo_map)</div><div class="diff-added">+        self.assertEqual(model.reminder, "sys")</div><div class="diff-added">+        self.assertTrue(model.examples_as_sys_msg)</div><div class="diff-added">+</div><div class="diff-added">+        # Test llama3 70b case</div><div class="diff-added">+        model = Model("llama3-70b")</div><div class="diff-added">+        self.assertEqual(model.edit_format, "diff")</div><div class="diff-added">+        self.assertTrue(model.use_repo_map)</div><div class="diff-added">+        self.assertTrue(model.send_undo_reply)</div><div class="diff-added">+        self.assertTrue(model.examples_as_sys_msg)</div><div class="diff-added">+</div><div class="diff-added">+        # Test gpt-4 case</div><div class="diff-added">+        model = Model("gpt-4")</div><div class="diff-added">+        self.assertEqual(model.edit_format, "diff")</div><div class="diff-added">+        self.assertTrue(model.use_repo_map)</div><div class="diff-added">+        self.assertTrue(model.send_undo_reply)</div><div class="diff-added">+</div><div class="diff-added">+        # Test gpt-3.5 case</div><div class="diff-added">+        model = Model("gpt-3.5")</div><div class="diff-added">+        self.assertEqual(model.reminder, "sys")</div><div class="diff-added">+</div><div class="diff-added">+        # Test 3.5-sonnet case</div><div class="diff-added">+        model = Model("claude-3.5-sonnet")</div><div class="diff-added">+        self.assertEqual(model.edit_format, "diff")</div><div class="diff-added">+        self.assertTrue(model.use_repo_map)</div><div class="diff-added">+        self.assertTrue(model.examples_as_sys_msg)</div><div class="diff-added">+        self.assertEqual(model.reminder, "user")</div><div class="diff-added">+</div><div class="diff-added">+        # Test o1- prefix case</div><div class="diff-added">+        model = Model("o1-something")</div><div class="diff-added">+        self.assertFalse(model.use_system_prompt)</div><div class="diff-added">+        self.assertFalse(model.use_temperature)</div><div class="diff-added">+</div><div class="diff-added">+        # Test qwen case</div><div class="diff-added">+        model = Model("qwen-coder-2.5-32b")</div><div class="diff-added">+        self.assertEqual(model.edit_format, "diff")</div><div class="diff-added">+        self.assertEqual(model.editor_edit_format, "editor-diff")</div><div class="diff-added">+        self.assertTrue(model.use_repo_map)</div><div class="diff-added">+</div><div class="diff-added">+    def test_parse_token_value(self):</div><div class="diff-added">+        # Create a model instance to test the parse_token_value method</div><div class="diff-added">+        model = Model("gpt-4")</div><div class="diff-added">+</div><div class="diff-added">+        # Test integer inputs</div><div class="diff-added">+        self.assertEqual(model.parse_token_value(8096), 8096)</div><div class="diff-added">+        self.assertEqual(model.parse_token_value(1000), 1000)</div><div class="diff-added">+</div><div class="diff-added">+        # Test string inputs</div><div class="diff-added">+        self.assertEqual(model.parse_token_value("8096"), 8096)</div><div class="diff-added">+</div><div class="diff-added">+        # Test k/K suffix (kilobytes)</div><div class="diff-added">+        self.assertEqual(model.parse_token_value("8k"), 8 * 1024)</div><div class="diff-added">+        self.assertEqual(model.parse_token_value("8K"), 8 * 1024)</div><div class="diff-added">+        self.assertEqual(model.parse_token_value("10.5k"), 10.5 * 1024)</div><div class="diff-added">+        self.assertEqual(model.parse_token_value("0.5K"), 0.5 * 1024)</div><div class="diff-added">+</div><div class="diff-added">+        # Test m/M suffix (megabytes)</div><div class="diff-added">+        self.assertEqual(model.parse_token_value("1m"), 1 * 1024 * 1024)</div><div class="diff-added">+        self.assertEqual(model.parse_token_value("1M"), 1 * 1024 * 1024)</div><div class="diff-added">+        self.assertEqual(model.parse_token_value("0.5M"), 0.5 * 1024 * 1024)</div><div class="diff-added">+</div><div class="diff-added">+        # Test with spaces</div><div class="diff-added">+        self.assertEqual(model.parse_token_value(" 8k "), 8 * 1024)</div><div class="diff-added">+</div><div class="diff-added">+        # Test conversion from other types</div><div class="diff-added">+        self.assertEqual(model.parse_token_value(8.0), 8)</div><div class="diff-added">+</div><div class="diff-added">+    def test_set_thinking_tokens(self):</div><div class="diff-added">+        # Test that set_thinking_tokens correctly sets the tokens with different formats</div><div class="diff-added">+        model = Model("gpt-4")</div><div class="diff-added">+</div><div class="diff-added">+        # Test with integer</div><div class="diff-added">+        model.set_thinking_tokens(8096)</div><div class="diff-added">+        self.assertEqual(model.extra_params["thinking"]["budget_tokens"], 8096)</div><div class="diff-added">+        self.assertFalse(model.use_temperature)</div><div class="diff-added">+</div><div class="diff-added">+        # Test with string</div><div class="diff-added">+        model.set_thinking_tokens("10k")</div><div class="diff-added">+        self.assertEqual(model.extra_params["thinking"]["budget_tokens"], 10 * 1024)</div><div class="diff-added">+</div><div class="diff-added">+        # Test with decimal value</div><div class="diff-added">+        model.set_thinking_tokens("0.5M")</div><div class="diff-added">+        self.assertEqual(model.extra_params["thinking"]["budget_tokens"], 0.5 * 1024 * 1024)</div><div> </div><div> </div><div> if __name__ == "__main__":</div><div></div></pre>
                </div>
            </div>
        </section>
    </main>
    <footer>
        <p>LoCoDiff-bench - <a href="https://github.com/AbanteAI/LoCoDiff-bench">GitHub Repository</a></p>
    </footer>
</body>
</html>
    