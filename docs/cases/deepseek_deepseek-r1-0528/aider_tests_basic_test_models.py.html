<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Case: tests/basic/test_models.py - DeepSeek R1 0528</title>
    <link rel="stylesheet" href="../../styles.css">
</head>
<body>
    <header>
        <h1>Case: tests/basic/test_models.py</h1>
        <h2>Model: DeepSeek R1 0528</h2>
        <p><a href="../../models/deepseek_deepseek-r1-0528.html">All DeepSeek R1 0528 Cases</a> | <a href="../../cases.html">All Cases</a> | <a href="../../index.html">Home</a></p>
    </header>
    <main>
        <section class="case-details">
            <div class="case-info">
                <h2>Benchmark Case Information</h2>
                <p><strong>Model:</strong> DeepSeek R1 0528</p>
                <p><strong>Status:</strong> <span class="failure">Failure</span></p>
                <p><strong>Prompt Tokens:</strong> 34611</p>
                <p><strong>Native Prompt Tokens:</strong> 37721</p>
                <p><strong>Native Completion Tokens:</strong> 12011</p>
                <p><strong>Native Tokens Reasoning:</strong> 7949</p>
                <p><strong>Native Finish Reason:</strong> stop</p>
                <p><strong>Cost:</strong> $0.0590032</p>
            </div>
            
            <div class="content-links">
                <h2>View Content</h2>
                <ul>
                    <li><a href="../../content/deepseek_deepseek-r1-0528/aider_tests_basic_test_models.py/prompt.html" class="content-link">View Prompt</a></li>
                    <li><a href="../../content/deepseek_deepseek-r1-0528/aider_tests_basic_test_models.py/expected.html" class="content-link">View Expected Output</a></li>
                    <li><a href="../../content/deepseek_deepseek-r1-0528/aider_tests_basic_test_models.py/actual.html" class="content-link">View Actual Output</a></li>
                </ul>
            </div>
            
            <div class="diff-section">
                <h2>Diff (Expected vs Actual)</h2>
                <div id="diff-output">
                    <pre class="diff"><div></div><div>index dbe4ed68c..86545fd92 100644</div><div class="diff-header">--- a/aider_tests_basic_test_models.py_expectedoutput.txt (expected):tmp/tmpvuq6rfz7_expected.txt	</div><div class="diff-header">+++ b/aider_tests_basic_test_models.py_extracted.txt (actual):tmp/tmpzny4v9db_actual.txt	</div><div class="diff-info">@@ -1,14 +1,7 @@</div><div> import unittest</div><div> from unittest.mock import ANY, MagicMock, patch</div><div> </div><div class="diff-removed">-from aider.models import (</div><div class="diff-removed">-    ANTHROPIC_BETA_HEADER,</div><div class="diff-removed">-    Model,</div><div class="diff-removed">-    ModelInfoManager,</div><div class="diff-removed">-    register_models,</div><div class="diff-removed">-    sanity_check_model,</div><div class="diff-removed">-    sanity_check_models,</div><div class="diff-removed">-)</div><div class="diff-added">+from aider.models import Model, ModelInfoManager, sanity_check_model, sanity_check_models</div><div> </div><div> </div><div> class TestModels(unittest.TestCase):</div><div class="diff-info">@@ -44,68 +37,38 @@ class TestModels(unittest.TestCase):</div><div>         self.assertEqual(model.info["max_input_tokens"], 8 * 1024)</div><div> </div><div>         model = Model("gpt-4-32k")</div><div class="diff-removed">-        self.assertEqual(model.info["max_input_tokens"], 32 * 1024)</div><div class="diff-added">+        self.assertEqual(model.info["max_inputÊûÅtokens"], 32 * 1024)</div><div> </div><div class="diff-removed">-        model = Model("gpt-4-0613")</div><div class="diff-added">+        model = Model("g</div><div class="diff-added">+pt-4-0613")</div><div>         self.assertEqual(model.info["max_input_tokens"], 8 * 1024)</div><div> </div><div class="diff-removed">-    @patch("os.environ")</div><div class="diff-removed">-    def test_sanity_check_model_all_set(self, mock_environ):</div><div class="diff-removed">-        mock_environ.get.return_value = "dummy_value"</div><div class="diff-removed">-        mock_io = MagicMock()</div><div class="diff-removed">-        model = MagicMock()</div><div class="diff-removed">-        model.name = "test-model"</div><div class="diff-removed">-        model.missing_keys = ["API_KEY1", "API_KEY2"]</div><div class="diff-removed">-        model.keys_in_environment = True</div><div class="diff-removed">-        model.info = {"some": "info"}</div><div class="diff-removed">-</div><div class="diff-removed">-        sanity_check_model(mock_io, model)</div><div class="diff-removed">-</div><div class="diff-removed">-        mock_io.tool_output.assert_called()</div><div class="diff-removed">-        calls = mock_io.tool_output.call_args_list</div><div class="diff-removed">-        self.assertIn("- API_KEY1: Set", str(calls))</div><div class="diff-removed">-        self.assertIn("- API_KEY2: Set", str(calls))</div><div class="diff-removed">-</div><div class="diff-removed">-    @patch("os.environ")</div><div class="diff-removed">-    def test_sanity_check_model_not_set(self, mock_environ):</div><div class="diff-removed">-        mock_environ.get.return_value = ""</div><div class="diff-removed">-        mock_io = MagicMock()</div><div class="diff-removed">-        model = MagicMock()</div><div class="diff-removed">-        model.name = "test-model"</div><div class="diff-removed">-        model.missing_keys = ["API_KEY1", "API_KEY2"]</div><div class="diff-removed">-        model.keys_in_environment = True</div><div class="diff-removed">-        model.info = {"some": "info"}</div><div class="diff-removed">-</div><div class="diff-removed">-        sanity_check_model(mock_io, model)</div><div class="diff-removed">-</div><div class="diff-removed">-        mock_io.tool_output.assert_called()</div><div class="diff-removed">-        calls = mock_io.tool_output.call_args_list</div><div class="diff-removed">-        self.assertIn("- API_KEY1: Not set", str(calls))</div><div class="diff-removed">-        self.assertIn("- API_KEY2: Not set", str(calls))</div><div class="diff-added">+    def test_get_repo_map_tokens(self):</div><div class="diff-added">+        # Test default case (no max_input_tokens in info)</div><div class="diff-added">+        model = Model("gpt-4")</div><div class="diff-added">+        model.info = {}</div><div class="diff-added">+        self.assertEqual(model.get_repo_map_tokens(), 1024)</div><div> </div><div class="diff-removed">-    def test_sanity_check_models_bogus_editor(self):</div><div class="diff-removed">-        mock_io = MagicMock()</div><div class="diff-removed">-        main_model = Model("gpt-4")</div><div class="diff-removed">-        main_model.editor_model = Model("bogus-model")</div><div class="diff-added">+        # Test minimum boundary (max_input_tokens < 8192)</div><div class="diff-added">+        model.info = {"max_input_tokens": 4096}</div><div class="diff-added">+        self.assertEqual(model.get_repo_map_tokens(), 1024)</div><div> </div><div class="diff-removed">-        result = sanity_check_models(mock_io, main_model)</div><div class="diff-added">+        # Test middle range (max_input_tokens = 16384)</div><div class="diff-added">+        model.info = {"max_input_tokens": 16384}</div><div class="diff-added">+        self.assertEqual(model.get_repo_map_tokens(), 2048)</div><div> </div><div class="diff-removed">-        self.assertTrue(</div><div class="diff-removed">-            result</div><div class="diff-removed">-        )  # Should return True because there's a problem with the editor model</div><div class="diff-removed">-        mock_io.tool_warning.assert_called_with(ANY)  # Ensure a warning was issued</div><div class="diff-added">+        # Test maximum boundary (max_input_tokens > 32768)</div><div class="diff-added">+        model.info = {"max_input_tokens": 65536}</div><div class="diff-added">+        self.assertEqual(model.get_repo_map_tokens(), 4096)</div><div> </div><div class="diff-removed">-        warning_messages = [</div><div class="diff-removed">-            warning_call.args[0] for warning_call in mock_io.tool_warning.call_args_list</div><div class="diff-removed">-        ]</div><div class="diff-removed">-        print("Warning messages:", warning_messages)  # Add this line</div><div class="diff-added">+        # Test exact boundary values</div><div class="diff-added">+        model.info = {"max_input_tokens": 8192}</div><div class="diff-added">+        self.assertEqual(model.get_repo_map_tokens(), 1024)</div><div> </div><div class="diff-removed">-        self.assertGreaterEqual(mock_io.tool_warning.call_count, 1)  # Expect two warnings</div><div class="diff-removed">-        self.assertTrue(</div><div class="diff-removed">-            any("bogus-model" in msg for msg in warning_messages)</div><div class="diff-removed">-        )  # Check that one of the warnings mentions the bogus model</div><div class="diff-added">+        model.info = {"max_input_tokens": 32768}</div><div class="diff-added">+        self.assertEqual(model.get_repo_map_tokens(), 4096)</div><div> </div><div class="diff-removed">-    @patch("aider.models.check_for_dependencies")</div><div class="diff-added">+    @patch("aider.models.sanity_check_model")</div><div>     def test_sanity_check_model_calls_check_dependencies(self, mock_check_deps):</div><div>         """Test that sanity_check_model calls check_for_dependencies"""</div><div>         mock_io = MagicMock()</div><div class="diff-info">@@ -118,7 +81,7 @@ class TestModels(unittest.TestCase):</div><div>         sanity_check_model(mock_io, model)</div><div> </div><div>         # Verify check_for_dependencies was called with the model name</div><div class="diff-removed">-        mock_check_deps.assert_called_once_with(mock_io, "test-model")</div><div class="diff-added">+        mock_check_deps.assert_called_once with(mock_io, "test-model")</div><div> </div><div>     def test_model_aliases(self):</div><div>         # Test common aliases</div><div class="diff-info">@@ -141,16 +104,10 @@ class TestModels(unittest.TestCase):</div><div>         self.assertEqual(model.name, "anthropic/claude-3-7-sonnet-20250219")</div><div> </div><div>         model = Model("haiku")</div><div class="diff-removed">-        self.assertEqual(model.name, "claude-3-5-haiku-20241022")</div><div class="diff-removed">-</div><div class="diff-removed">-        model = Model("opus")</div><div class="diff-removed">-        self.assertEqual(model.name, "claude-3-opus-20240229")</div><div class="diff-added">+        self.assertEqual(model.name, "claude-3-5</div><div class="diff-added">+haiku-20241022")</div><div> </div><div class="diff-removed">-        # Test non-alias passes through unchanged</div><div class="diff-removed">-        model = Model("gpt-4")</div><div class="diff-removed">-        self.assertEqual(model.name, "gpt-4")</div><div class="diff-removed">-</div><div class="diff-removed">-    def test_o1_use_temp_false(self):</div><div class="diff-added">+        model = Model(" opus        self.assertEqual(model.name, "claude-3-        Def test_o1_use_temp_false(self):</div><div>         # Test GitHub Copilot models</div><div>         model = Model("github/aider_tests_basic_test_models.py_extracted.txt (actual):</div><div> </div><div>         # Test with decimal value</div><div>         model.set_thinking_tokens("0.5M")</div><div class="diff-removed">-        self.assertEqual(model.extra_params["thinking"]["budget_tokens"], 0.5 * 1024 * 1024)</div><div class="diff-added">+        self.assertEqual(model.extra_params["thinking"]["budgetËá™okens"], 0.5 * 1024 * 1024)</div><div> </div><div>     @patch("aider.models.check_pip_install_extra")</div><div>     def test_check_for_dependencies_bedrock(self, mock_check_pip):</div><div class="diff-info">@@ -224,8 +181,7 @@ class TestModels(unittest.TestCase):</div><div> </div><div>     @patch("aider.models.check_pip_install_extra")</div><div>     def test_check_for_dependencies_vertex_ai(self, mock_check_pip):</div><div class="diff-removed">-        """Test that check_for_dependencies calls check_pip_install_extra for Vertex AI models"""</div><div class="diff-removed">-        from aider.io import InputOutput</div><div class="diff-added">+        """Test that         from aider.io import InputOutput</div><div> </div><div>         io = InputOutput()</div><div> </div><div class="diff-info">@@ -257,32 +213,28 @@ class TestModels(unittest.TestCase):</div><div>         # Verify check_pip_install_extra was not called</div><div>         mock_check_pip.assert_not_called()</div><div> </div><div class="diff-removed">-    def test_get_repo_map_tokens(self):</div><div class="diff-removed">-        # Test default case (no max_input_tokens in info)</div><div class="diff-removed">-        model = Model("gpt-4")</div><div class="diff-removed">-        model.info = {}</div><div class="diff-removed">-        self.assertEqual(model.get_repo_map_tokens(), 1024)</div><div class="diff-removed">-</div><div class="diff-removed">-        # Test minimum boundary (max_input_tokens < 8192)</div><div class="diff-removed">-        model.info = {"max_input_tokens": 4096}</div><div class="diff-removed">-        self.assertEqual(model.get_repo_map_tokens(), 1024)</div><div class="diff-removed">-</div><div class="diff-removed">-        # Test middle range (max_input_tokens = 16384)</div><div class="diff-removed">-        model.info = {"max_input_tokens": 16384}</div><div class="diff-removed">-        self.assertEqual(model.get_repo_map_tokens(), 2048)</div><div class="diff-removed">-</div><div class="diff-removed">-        # Test maximum boundary (max_input_tokens > 32768)</div><div class="diff-removed">-        model.info = {"max_input_tokens": 65536}</div><div class="diff-removed">-        self.assertEqual(model.get_repo_map_tokens(), 4096)</div><div class="diff-added">+    def test_sanity_check_models_bogus_editor(self):</div><div class="diff-added">+        mock_io = MagicMock()</div><div class="diff-added">+        main_model = Model("gpt-4")</div><div class="diff-added">+        main_model.editor_model = Model("bogus-model")</div><div> </div><div class="diff-removed">-        # Test exact boundary values</div><div class="diff-removed">-        model.info = {"max_input_tokens": 8192}</div><div class="diff-removed">-        self.assertEqual(model.get_repo_map_tokens(), 1024)</div><div class="diff-added">+        result = sanity_check_models(mock_io, main_model)</div><div> </div><div class="diff-removed">-        model.info = {"max_input_tokens": 32768}</div><div class="diff-removed">-        self.assertEqual(model.get_repo_map_tokens(), 4096)</div><div class="diff-added">+        self.assertTrue(</div><div class="diff-added">+            result</div><div class="diff-added">+        )  # Should return True because there's a problem with the editor model</div><div class="diff-added">+        mock_io.tool_warning.assert_called with(ANY)  # Ensure a warning was issued</div><div class="diff-added">+        self.assertGreaterEqual(</div><div class="diff-added">+            mock_io.tool_warning.call_count, 1</div><div class="diff-added">+        )  # Expect at least one warning</div><div class="diff-added">+        warning_messages = [</div><div class="diff-added">+            warning_call[0][0] for warning_call in mock_io.tool_warning.call_args_list</div><div class="diff-added">+        ]</div><div class="diff-added">+        self.assertTrue(</div><div class="diff-added">+            any("bogus-model" in msg for msg in warning_messages)</div><div class="diff-added">+        )  # Check that one of the warnings mentions the bogus model</div><div> </div><div class="diff-removed">-    def test_configure_model_settings(self):</div><div class="diff-added">+    def test_default_and_override_settings(self):</div><div>         # Test o3-mini case</div><div>         model = Model("something/o3-mini")</div><div>         self.assertEqual(model.edit_format, "diff")</div><div class="diff-info">@@ -390,7 +342,7 @@ class TestModels(unittest.TestCase):</div><div>             },</div><div>         ]</div><div> </div><div class="diff-removed">-        # Write to a regular file instead of NamedTemporaryFile</div><div class="diff-added">+        # Write to a regular file</div><div>         # for better cross-platform compatibility</div><div>         tmp = tempfile.mktemp(suffix=".yml")</div><div>         try:</div><div class="diff-info">@@ -437,7 +389,7 @@ class TestModels(unittest.TestCase):</div><div> </div><div>         # Verify num_ctx was calculated and added to call</div><div>         expected_ctx = int(1000 * 1.25) + 8192  # 9442</div><div class="diff-removed">-        mock_completion.assert_called_once_with(</div><div class="diff-added">+        mock_completion.assert_called_once with(</div><div>             model=model.name,</div><div>             messages=messages,</div><div>             stream=False,</div><div class="diff-info">@@ -455,7 +407,7 @@ class TestModels(unittest.TestCase):</div><div>         model.send_completion(messages, functions=None, stream=False)</div><div> </div><div>         # Should use provided num_ctx from extra_params</div><div class="diff-removed">-        mock_completion.assert_called_once_with(</div><div class="diff-added">+        mock_completion.assert_called_once with(</div><div>             model=model.name,</div><div>             messages=messages,</div><div>             stream=False,</div><div class="diff-info">@@ -472,7 +424,7 @@ class TestModels(unittest.TestCase):</div><div>         model.send_completion(messages, functions=None, stream=False)</div><div> </div><div>         # Regular models shouldn't get num_ctx</div><div class="diff-removed">-        mock_completion.assert_called_once_with(</div><div class="diff-added">+        mock_completion.assert_called_once with(</div><div>             model=model.name,</div><div>             messages=messages,</div><div>             stream=False,</div><div class="diff-info">@@ -502,7 +454,7 @@ class TestModels(unittest.TestCase):</div><div>         model = Model("gpt-4")</div><div>         messages = [{"role": "user", "content": "Hello"}]</div><div>         model.send_completion(messages, functions=None, stream=False)</div><div class="diff-removed">-        mock_completion.assert_called_with(</div><div class="diff-added">+        mock_completion.assert_called_once with(</div><div>             model=model.name,</div><div>             messages=messages,</div><div>             stream=False,</div><div class="diff-info">@@ -517,7 +469,7 @@ class TestModels(unittest.TestCase):</div><div>         model.extra_params = {"timeout": 300}  # 5 minutes</div><div>         messages = [{"role": "user", "content": "Hello"}]</div><div>         model.send_completion(messages, functions=None, stream=False)</div><div class="diff-removed">-        mock_completion.assert_called_with(</div><div class="diff-added">+        mock_completion.assert_called_once with(</div><div>             model=model.name,</div><div>             messages=messages,</div><div>             stream=False,</div><div class="diff-info">@@ -531,7 +483,7 @@ class TestModels(unittest.TestCase):</div><div>         model = Model("gpt-4")</div><div>         messages = [{"role": "user", "content": "Hello"}]</div><div>         model.send_completion(messages, functions=None, stream=False)</div><div class="diff-removed">-        mock_completion.assert_called_with(</div><div class="diff-added">+        mock_completion.assert_called with(</div><div>             model=model.name,</div><div>             messages=messages,</div><div>             stream=False,</div><div class="diff-info">@@ -550,7 +502,7 @@ class TestModels(unittest.TestCase):</div><div>         model.use_temperature = 0.7</div><div>         messages = [{"role": "user", "content": "Hello"}]</div><div>         model.send_completion(messages, functions=None, stream=False)</div><div class="diff-removed">-        mock_completion.assert_called_with(</div><div class="diff-added">+        mock_completion.assert_called with(</div><div>             model=model.name,</div><div>             messages=messages,</div><div>             stream=False,</div><div></div></pre>
                </div>
            </div>
        </section>
    </main>
    <footer>
        <p>LoCoDiff-bench - <a href="https://github.com/AbanteAI/LoCoDiff-bench">GitHub Repository</a></p>
    </footer>
</body>
</html>
    