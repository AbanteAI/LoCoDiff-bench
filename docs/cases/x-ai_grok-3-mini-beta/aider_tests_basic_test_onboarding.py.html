<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Case: tests/basic/test_onboarding.py - Grok 3 Mini</title>
    <link rel="stylesheet" href="../../styles.css">
</head>
<body>
    <header>
        <h1>Case: tests/basic/test_onboarding.py</h1>
        <h2>Model: Grok 3 Mini</h2>
        <p><a href="../../models/x-ai_grok-3-mini-beta.html">All Grok 3 Mini Cases</a> | <a href="../../cases.html">All Cases</a> | <a href="../../index.html">Home</a></p>
    </header>
    <main>
        <section class="case-details">
            <div class="case-info">
                <h2>Benchmark Case Information</h2>
                <p><strong>Model:</strong> Grok 3 Mini</p>
                <p><strong>Status:</strong> <span class="failure">Failure</span></p>
                <p><strong>Prompt Tokens:</strong> 16586</p>
                <p><strong>Native Prompt Tokens:</strong> 16708</p>
                <p><strong>Native Completion Tokens:</strong> 6330</p>
                <p><strong>Native Tokens Reasoning:</strong> 2085</p>
                <p><strong>Native Finish Reason:</strong> stop</p>
                <p><strong>Cost:</strong> $0.0081774</p>
            </div>
            
            <div class="content-links">
                <h2>View Content</h2>
                <ul>
                    <li><a href="../../content/x-ai_grok-3-mini-beta/aider_tests_basic_test_onboarding.py/prompt.html" class="content-link">View Prompt</a></li>
                    <li><a href="../../content/x-ai_grok-3-mini-beta/aider_tests_basic_test_onboarding.py/expected.html" class="content-link">View Expected Output</a></li>
                    <li><a href="../../content/x-ai_grok-3-mini-beta/aider_tests_basic_test_onboarding.py/actual.html" class="content-link">View Actual Output</a></li>
                </ul>
            </div>
            
            <div class="diff-section">
                <h2>Diff (Expected vs Actual)</h2>
                <div id="diff-output">
                    <pre class="diff"><div></div><div>index ceab82fc..390aadc7 100644</div><div class="diff-header">--- a/aider_tests_basic_test_onboarding.py_expectedoutput.txt (expected):tmp/tmp9y0b7xm0_expected.txt	</div><div class="diff-header">+++ b/aider_tests_basic_test_onboarding.py_extracted.txt (actual):tmp/tmp4mfpnhgd_actual.txt	</div><div class="diff-info">@@ -18,13 +18,11 @@ from aider.onboarding import (</div><div>     try_to_select_default_model,</div><div> )</div><div> </div><div class="diff-removed">-</div><div> # Mock the Analytics class as it's used in some functions</div><div> class DummyAnalytics:</div><div>     def event(self, *args, **kwargs):</div><div>         pass</div><div> </div><div class="diff-removed">-</div><div> # Mock the InputOutput class</div><div> class DummyIO:</div><div>     def tool_output(self, *args, **kwargs):</div><div class="diff-info">@@ -42,7 +40,6 @@ class DummyIO:</div><div>     def offer_url(self, *args, **kwargs):</div><div>         pass</div><div> </div><div class="diff-removed">-</div><div> class TestOnboarding(unittest.TestCase):</div><div>     @patch("requests.get")</div><div>     def test_check_openrouter_tier_free(self, mock_get):</div><div class="diff-info">@@ -286,8 +283,6 @@ class TestOnboarding(unittest.TestCase):</div><div>             f"Error exchanging code for OpenRouter key: {req_exception}"</div><div>         )</div><div> </div><div class="diff-removed">-    # --- Tests for select_default_model ---</div><div class="diff-removed">-</div><div>     @patch("aider.onboarding.try_to_select_default_model", return_value="gpt-4o")</div><div>     @patch("aider.onboarding.offer_openrouter_oauth")</div><div>     def test_select_default_model_already_specified(self, mock_offer_oauth, mock_try_select):</div><div class="diff-info">@@ -363,17 +358,8 @@ class TestOnboarding(unittest.TestCase):</div><div>         self.assertEqual(selected_model, "openrouter/google/gemini-2.5-pro-exp-03-25:free")</div><div>         self.assertEqual(mock_try_select.call_count, 2)  # Called before and after oauth</div><div>         mock_offer_oauth.assert_called_once_with(io_mock, analytics_mock)</div><div class="diff-removed">-        # Only one warning is expected: "No LLM model..."</div><div>         self.assertEqual(io_mock.tool_warning.call_count, 1)</div><div class="diff-removed">-        io_mock.tool_warning.assert_called_once_with(</div><div class="diff-removed">-            "No LLM model was specified and no API keys were provided."</div><div class="diff-removed">-        )</div><div class="diff-removed">-        # The second call to try_select finds the model, so the *outer* function logs the usage.</div><div class="diff-removed">-        # Note: The warning comes from the second call within select_default_model,</div><div class="diff-removed">-        # not try_select itself.</div><div class="diff-removed">-        # We verify the final state and model returned.</div><div> </div><div class="diff-removed">-    # --- Tests for offer_openrouter_oauth ---</div><div>     @patch("aider.onboarding.start_openrouter_oauth_flow", return_value="new_or_key")</div><div>     @patch.dict(os.environ, {}, clear=True)  # Ensure no key exists initially</div><div>     def test_offer_openrouter_oauth_confirm_yes_success(self, mock_start_oauth):</div><div class="diff-info">@@ -391,8 +377,6 @@ class TestOnboarding(unittest.TestCase):</div><div>         self.assertEqual(os.environ.get("OPENROUTER_API_KEY"), "new_or_key")</div><div>         analytics_mock.event.assert_any_call("oauth_flow_initiated", provider="openrouter")</div><div>         analytics_mock.event.assert_any_call("oauth_flow_success")</div><div class="diff-removed">-        # Clean up env var</div><div class="diff-removed">-        del os.environ["OPENROUTER_API_KEY"]</div><div> </div><div>     @patch("aider.onboarding.start_openrouter_oauth_flow", return_value=None)  # OAuth fails</div><div>     @patch.dict(os.environ, {}, clear=True)</div><div class="diff-info">@@ -431,9 +415,6 @@ class TestOnboarding(unittest.TestCase):</div><div>         mock_start_oauth.assert_not_called()</div><div>         analytics_mock.event.assert_not_called()  # No OAuth events if declined</div><div> </div><div class="diff-removed">-    # --- More complex test for start_openrouter_oauth_flow (simplified) ---</div><div class="diff-removed">-    # This test focuses on the successful path, mocking heavily</div><div class="diff-removed">-</div><div> </div><div> if __name__ == "__main__":</div><div>     unittest.main()</div><div>\ No newline at end of file</div><div></div></pre>
                </div>
            </div>
        </section>
    </main>
    <footer>
        <p>LoCoDiff-bench - <a href="https://github.com/AbanteAI/LoCoDiff-bench">GitHub Repository</a></p>
    </footer>
</body>
</html>
    