<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Case: aider/history.py - Grok 3 Mini</title>
    <link rel="stylesheet" href="../../styles.css">
</head>
<body>
    <header>
        <h1>Case: aider/history.py</h1>
        <p><a href="../../models/x-ai_grok-3-mini-beta.html">‚Üê Back to Grok 3 Mini Cases</a> | <a href="../../index.html">Home</a></p>
    </header>
    <main>
        <section class="case-details">
            <div class="case-info">
                <h2>Benchmark Case Information</h2>
                <p><strong>Model:</strong> Grok 3 Mini</p>
                <p><strong>Status:</strong> <span class="failure">Failure</span></p>
                <p><strong>Prompt Tokens:</strong> 18915</p>
                <p><strong>Output Tokens:</strong> N/A</p>
                <p><strong>Native Prompt Tokens:</strong> 18765</p>
                <p><strong>Native Completion Tokens:</strong> 4113</p>
                <p><strong>Native Tokens Reasoning:</strong> 3162</p>
                <p><strong>Native Finish Reason:</strong> stop</p>
                <p><strong>Runtime:</strong> N/As</p>
                <p><strong>Cost:</strong> $0.007686</p>
            </div>
            
            <div class="content-links">
                <h2>View Content</h2>
                <ul>
                    <li><a href="../../content/x-ai_grok-3-mini-beta/aider_aider_history.py/prompt.html" class="content-link">View Prompt</a></li>
                    <li><a href="../../content/x-ai_grok-3-mini-beta/aider_aider_history.py/expected.html" class="content-link">View Expected Output</a></li>
                    <li><a href="../../content/x-ai_grok-3-mini-beta/aider_aider_history.py/actual.html" class="content-link">View Actual Output</a></li>
                </ul>
            </div>
            
            <div class="diff-section">
                <h2>Diff (Expected vs Actual)</h2>
                <div id="diff-output">
                    <pre class="diff"><div class="diff-header">--- aider_aider_history.py_expectedoutput.txt (expected)+++ aider_aider_history.py_extracted.txt (actual)@@ -47,7 +47,6 @@         split_index = len(messages)</div><div>         half_max_tokens = self.max_tokens // 2</div><div> </div><div class="diff-removed">-        # Iterate over the messages in reverse order</div><div>         for i in range(len(sized) - 1, -1, -1):</div><div>             tokens, _msg = sized[i]</div><div>             if tail_tokens + tokens < half_max_tokens:</div><div class="diff-info">@@ -56,8 +55,7 @@             else:</div><div>                 break</div><div> </div><div class="diff-removed">-        # Ensure the head ends with an assistant message</div><div class="diff-removed">-        while messages[split_index - 1]["role"] != "assistant" and split_index > 1:</div><div class="diff-added">+        while split_index > 1 and messages[split_index - 1]["role"] != "assistant":</div><div>             split_index -= 1</div><div> </div><div>         if split_index <= min_split:</div><div class="diff-info">@@ -72,7 +70,6 @@         keep = []</div><div>         total = 0</div><div> </div><div class="diff-removed">-        # These sometimes come set with value = None</div><div>         model_max_input_tokens = self.models[0].info.get("max_input_tokens") or 4096</div><div>         model_max_input_tokens -= 512</div><div> </div><div class="diff-info">@@ -128,16 +125,15 @@     parser.add_argument("filename", help="Markdown file to parse")</div><div>     args = parser.parse_args()</div><div> </div><div class="diff-removed">-    model_names = ["gpt-3.5-turbo", "gpt-4"]  # Add more model names as needed</div><div class="diff-added">+    model_names = ["gpt-3.5-turbo", "gpt-4"]</div><div>     model_list = [models.Model(name) for name in model_names]</div><div>     summarizer = ChatSummary(model_list)</div><div> </div><div>     with open(args.filename, "r") as f:</div><div>         text = f.read()</div><div> </div><div class="diff-removed">-    summary = summarizer.summarize_chat_history_markdown(text)</div><div class="diff-added">+    summary = summarizer.summarize(messages[-40:])</div><div>     dump(summary)</div><div class="diff-removed">-</div><div> </div><div> if __name__ == "__main__":</div><div>     main()</div></pre>
                </div>
            </div>
        </section>
    </main>
    <footer>
        <p>LoCoDiff-bench - <a href="https://github.com/AbanteAI/LoCoDiff-bench">GitHub Repository</a></p>
    </footer>
</body>
</html>
    