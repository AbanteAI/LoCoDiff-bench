<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Case: tests/consensus_tests/test_cluster_rejoin.py - GPT OSS 120B</title>
    <link rel="stylesheet" href="../../styles.css">
</head>
<body>
    <header>
        <h1>Case: tests/consensus_tests/test_cluster_rejoin.py</h1>
        <h2>Model: GPT OSS 120B</h2>
        <p><a href="../../models/openai_gpt-oss-120b.html">All GPT OSS 120B Cases</a> | <a href="../../cases.html">All Cases</a> | <a href="../../index.html">Home</a></p>
    </header>
    <main>
        <section class="case-details">
            <div class="case-info">
                <h2>Benchmark Case Information</h2>
                <p><strong>Model:</strong> GPT OSS 120B</p>
                <p><strong>Status:</strong> <span class="failure">Failure</span></p>
                <p><strong>Prompt Tokens:</strong> 7673</p>
                <p><strong>Native Prompt Tokens:</strong> 7748</p>
                <p><strong>Native Completion Tokens:</strong> 6988</p>
                <p><strong>Native Tokens Reasoning:</strong> 5438</p>
                <p><strong>Native Finish Reason:</strong> stop</p>
                <p><strong>Cost:</strong> $0.0064032</p>
            </div>
            
            <div class="content-links">
                <h2>View Content</h2>
                <ul>
                    <li><a href="../../content/openai_gpt-oss-120b/qdrant_tests_consensus_tests_test_cluster_rejoin.py/prompt.html" class="content-link">View Prompt</a></li>
                    <li><a href="../../content/openai_gpt-oss-120b/qdrant_tests_consensus_tests_test_cluster_rejoin.py/expected.html" class="content-link">View Expected Output</a></li>
                    <li><a href="../../content/openai_gpt-oss-120b/qdrant_tests_consensus_tests_test_cluster_rejoin.py/actual.html" class="content-link">View Actual Output</a></li>
                </ul>
            </div>
            
            <div class="diff-section">
                <h2>Diff (Expected vs Actual)</h2>
                <div id="diff-output">
                    <pre class="diff"><div></div><div>index 95fb168d6..2bc70d1b4 100644</div><div class="diff-header">--- a/qdrant_tests_consensus_tests_test_cluster_rejoin.py_expectedoutput.txt (expected):tmp/tmpu62gz1kv_expected.txt	</div><div class="diff-header">+++ b/qdrant_tests_consensus_tests_test_cluster_rejoin.py_extracted.txt (actual):tmp/tmpgvo3463b_actual.txt	</div><div class="diff-info">@@ -1,8 +1,10 @@</div><div> import io</div><div class="diff-added">+import json</div><div> import pathlib</div><div> import shutil</div><div class="diff-added">+import pytest</div><div> from time import sleep</div><div class="diff-removed">-from typing import Any</div><div class="diff-added">+from typing import Any, Callable</div><div> </div><div> from consensus_tests.fixtures import create_collection, upsert_random_points, drop_collection</div><div> import requests</div><div class="diff-info">@@ -17,10 +19,16 @@ N_SHARDS = 3</div><div> def test_rejoin_cluster(tmp_path: pathlib.Path, uris_in_env):</div><div>     assert_project_root()</div><div>     # Start cluster</div><div class="diff-removed">-    peer_api_uris, peer_dirs, bootstrap_uri = start_cluster(tmp_path, N_PEERS, port_seed=10000, uris_in_env=uris_in_env)</div><div class="diff-added">+    peer_api_uris, peer_dirs, bootstrap_uri = start_cluster(</div><div class="diff-added">+        tmp_path, N_PEERS, port_seed=10000, uris_in_env=uris_in_env</div><div class="diff-added">+    )</div><div> </div><div class="diff-removed">-    create_collection(peer_api_uris[0], shard_number=N_SHARDS, replication_factor=N_REPLICA)</div><div class="diff-removed">-    wait_collection_exists_and_active_on_all_peers(collection_name="test_collection", peer_api_uris=peer_api_uris)</div><div class="diff-added">+    create_collection(</div><div class="diff-added">+        peer_api_uris[0], shard_number=N_SHARDS, replication_factor=N_REPLICA</div><div class="diff-added">+    )</div><div class="diff-added">+    wait_collection_exists_and_active_on_all_peers(</div><div class="diff-added">+        collection_name="test_collection", peer_api_uris=peer_api_uris</div><div class="diff-added">+    )</div><div>     upsert_random_points(peer_api_uris[0], 100)</div><div> </div><div>     # Stop last node</div><div class="diff-info">@@ -39,7 +47,12 @@ def test_rejoin_cluster(tmp_path: pathlib.Path, uris_in_env):</div><div>         # Drop test_collection</div><div>         drop_collection(peer_api_uris[0], "test_collection", timeout=5)</div><div>         # Re-create test_collection</div><div class="diff-removed">-        create_collection(peer_api_uris[0], shard_number=N_SHARDS, replication_factor=N_REPLICA, timeout=3)</div><div class="diff-added">+        create_collection(</div><div class="diff-added">+            peer_api_uris[0],</div><div class="diff-added">+            shard_number=N_SHARDS,</div><div class="diff-added">+            replication_factor=N_REPLICA,</div><div class="diff-added">+            timeout=3,</div><div class="diff-added">+        )</div><div>         # Collection might not be ready yet, we don't care</div><div>         upsert_random_points(peer_api_uris[0], 100)</div><div>         print(f"before recovery end {i}")</div><div class="diff-info">@@ -52,12 +65,17 @@ def test_rejoin_cluster(tmp_path: pathlib.Path, uris_in_env):</div><div>         "test_collection2",</div><div>         shard_number=N_SHARDS,</div><div>         replication_factor=N_REPLICA,</div><div class="diff-removed">-        timeout=3</div><div class="diff-added">+        timeout=3,</div><div>     )</div><div> </div><div>     # Restart last node</div><div class="diff-removed">-    new_url = start_peer(peer_dirs[-1], "peer_0_restarted.log", bootstrap_uri, port=20000, uris_in_env=uris_in_env)</div><div class="diff-removed">-</div><div class="diff-added">+    new_url = start_peer(</div><div class="diff-added">+        peer_dirs[-1],</div><div class="diff-added">+        "peer_0_restarted.log",</div><div class="diff-added">+        bootstrap_uri,</div><div class="diff-added">+        port=20000,</div><div class="diff-added">+        uris_in_env=uris_in_env,</div><div class="diff-added">+    )</div><div>     peer_api_uris[-1] = new_url</div><div> </div><div>     # Wait for restarted node to be up and ready</div><div class="diff-info">@@ -68,8 +86,13 @@ def test_rejoin_cluster(tmp_path: pathlib.Path, uris_in_env):</div><div>         print(f"after recovery start {i}")</div><div>         # Drop test_collection</div><div>         drop_collection(peer_api_uris[0], "test_collection", timeout=5)</div><div class="diff-removed">-        # Re-create test_collection</div><div class="diff-removed">-        create_collection(peer_api_uris[0], shard_number=N_SHARDS, replication_factor=N_REPLICA, timeout=3)</div><div class="diff-added">+        # Re-test collection</div><div class="diff-added">+        create_collection(</div><div class="diff-added">+            peer_api_uris[0],</div><div class="diff-added">+            shard_number=N_SHARDS,</div><div class="diff-added">+            replication_factor=N_REPLICA,</div><div class="diff-added">+            timeout=3,</div><div class="diff-added">+        )</div><div>         upsert_random_points(peer_api_uris[0], 500, fail_on_error=False)</div><div>         print(f"after recovery end {i}")</div><div>         res = requests.get(f"{new_url}/collections")</div><div class="diff-info">@@ -89,10 +112,9 @@ def test_rejoin_origin_from_wal(tmp_path: pathlib.Path):</div><div>       when bootstrapping new peer</div><div>     - add new peer to the cluster (bootstrapping from second peer), and check that it has valid</div><div>       state after it syncs with consensus</div><div class="diff-removed">-    - if new peer has valid state at the end of the test, it means it received correct origin peer</div><div class="diff-removed">-      ID and URL from consensus</div><div class="diff-added">+    - if new peer has valid state at the end of the test, it means it received correct</div><div class="diff-added">+      origin peer ID and URL from consensus</div><div>     """</div><div class="diff-removed">-</div><div>     # Overwrite `first_voter` peer</div><div>     def overwrite_first_voter(state: dict[str, Any], _: Any):</div><div>         state["first_voter"] = state["this_peer_id"]</div><div class="diff-info">@@ -100,104 +122,6 @@ def test_rejoin_origin_from_wal(tmp_path: pathlib.Path):</div><div> </div><div>     rejoin_cluster_test(tmp_path, start_cluster, overwrite_first_voter)</div><div> </div><div class="diff-removed">-def test_rejoin_origin_from_state(tmp_path: pathlib.Path):</div><div class="diff-removed">-    """</div><div class="diff-removed">-    This test checks that Qdrant persists origin peer ID (`first_voter` field in `raft_state.json`)</div><div class="diff-removed">-    and propagates fake origin peer URL when bootstrapping new peer.</div><div class="diff-removed">-</div><div class="diff-removed">-    - start cluster using *preconfigured* origin peer that does *not* have origin peer ID and URL</div><div class="diff-removed">-      committed to consensus</div><div class="diff-removed">-    - remove origin peer from cluster</div><div class="diff-removed">-    - assert that second peer's `raft_state.json` contains valid origin peer ID</div><div class="diff-removed">-    - add new peer to the cluster (bootstrapping from second peer), and check that it has valid</div><div class="diff-removed">-      state after it syncs with consensus</div><div class="diff-removed">-    - if new peer has valid state at the end of the test, it means it received correct origin peer</div><div class="diff-removed">-      ID and (fake) URL from second peer during bootstrap</div><div class="diff-removed">-    """</div><div class="diff-removed">-</div><div class="diff-removed">-    # Assert origin peer ID is persisted as `first_voter`</div><div class="diff-removed">-    def assert_first_voter(state: dict[str, Any], origin_peer_id: int):</div><div class="diff-removed">-        assert state["first_voter"] == origin_peer_id</div><div class="diff-removed">-</div><div class="diff-removed">-    rejoin_cluster_test(tmp_path, start_preconfigured_cluster, assert_first_voter)</div><div class="diff-removed">-</div><div class="diff-removed">-@pytest.mark.skip("this test simulates and asserts past, incorrect behavior")</div><div class="diff-removed">-def test_rejoin_no_origin(tmp_path: pathlib.Path):</div><div class="diff-removed">-    """</div><div class="diff-removed">-    This test checks that `rejoin_cluster_test` is sufficient to reproduce "missing origin peer" bug.</div><div class="diff-removed">-</div><div class="diff-removed">-    It simulates *earlier* behavior of Qdrant (bypassing all fixes to commit/persist/recover origin</div><div class="diff-removed">-    peer ID/URL), and then checks that new peer added to such cluster has *invalid* state.</div><div class="diff-removed">-</div><div class="diff-removed">-    This test is disabled by default, but it's useful to "test the tests" and reproduce original bug.</div><div class="diff-removed">-    """</div><div class="diff-removed">-</div><div class="diff-removed">-    # Overwrite `first_voter` peer</div><div class="diff-removed">-    def overwrite_first_voter(state: dict[str, Any], _: Any):</div><div class="diff-removed">-        state["first_voter"] = 1337</div><div class="diff-removed">-        return state</div><div class="diff-removed">-</div><div class="diff-removed">-    rejoin_cluster_test(tmp_path, start_preconfigured_cluster, overwrite_first_voter, expected_shards=2)</div><div class="diff-removed">-</div><div class="diff-removed">-</div><div class="diff-removed">-def test_rejoin_recover_origin(tmp_path: pathlib.Path):</div><div class="diff-removed">-    """</div><div class="diff-removed">-    This test checks that Qdrant recovers origin peer ID from WAL, if origin peer was not yet</div><div class="diff-removed">-    removed from the cluster.</div><div class="diff-removed">-    """</div><div class="diff-removed">-</div><div class="diff-removed">-    collection = "test_collection"</div><div class="diff-removed">-    peers = 3</div><div class="diff-removed">-    shards = 3</div><div class="diff-removed">-</div><div class="diff-removed">-    # Start cluster</div><div class="diff-removed">-    peer_uris, peer_dirs, bootstrap_uri = start_preconfigured_cluster(tmp_path, peers)</div><div class="diff-removed">-</div><div class="diff-removed">-    # Get origin peer ID</div><div class="diff-removed">-    origin_peer_id = get_cluster_info(peer_uris[0])["peer_id"]</div><div class="diff-removed">-</div><div class="diff-removed">-    # Wait a few seconds for consensus to catch up</div><div class="diff-removed">-    sleep(5)</div><div class="diff-removed">-</div><div class="diff-removed">-    # Kill second peer</div><div class="diff-removed">-    second_peer = processes.pop(1)</div><div class="diff-removed">-    second_peer.kill()</div><div class="diff-removed">-</div><div class="diff-removed">-    # Remove `first_voter` from `raft_state.json`</div><div class="diff-removed">-    with open(f"{peer_dirs[1]}/storage/raft_state.json", "r+") as file:</div><div class="diff-removed">-        state = json.load(file)</div><div class="diff-removed">-</div><div class="diff-removed">-        del state["first_voter"]</div><div class="diff-removed">-</div><div class="diff-removed">-        file.seek(0, io.SEEK_SET)</div><div class="diff-removed">-        file.truncate()</div><div class="diff-removed">-        json.dump(state, file)</div><div class="diff-removed">-</div><div class="diff-removed">-    # Restart second peer with the same URI and ports</div><div class="diff-removed">-    second_peer_uri, bootstrap_uri = start_first_peer(peer_dirs[1], "peer_0_1_restarted.log", second_peer.p2p_port)</div><div class="diff-removed">-    wait_for_peer_online(second_peer_uri)</div><div class="diff-removed">-</div><div class="diff-removed">-    # Assert second peer recovered `first_voter` from WAL</div><div class="diff-removed">-    with open(f"{peer_dirs[1]}/storage/raft_state.json", "r") as file:</div><div class="diff-removed">-        state = json.load(file)</div><div class="diff-removed">-        assert state["first_voter"] == origin_peer_id</div><div class="diff-removed">-</div><div class="diff-removed">-    # Create collection, move all shards from first peer, remove first peer from cluster</div><div class="diff-removed">-    create_collection(peer_uris[0], collection, shards, 1)</div><div class="diff-removed">-    move_all_shards_from_peer(peer_uris[0], collection)</div><div class="diff-removed">-    remove_peer(peer_uris[0])</div><div class="diff-removed">-    processes.pop(0).kill()</div><div class="diff-removed">-</div><div class="diff-removed">-    # Wait a few seconds for new leader</div><div class="diff-removed">-    sleep(5)</div><div class="diff-removed">-</div><div class="diff-removed">-    # Add new peer to cluster</div><div class="diff-removed">-    new_peer_uri, new_peer_dir = add_new_peer(tmp_path, peers, bootstrap_uri, collection)</div><div class="diff-removed">-</div><div class="diff-removed">-    # Assert that new peer observe expected number of remote shards</div><div class="diff-removed">-    info = get_collection_cluster_info(new_peer_uri, collection)</div><div class="diff-removed">-    assert len(info["remote_shards"]) == shards</div><div class="diff-removed">-</div><div> </div><div> def rejoin_cluster_test(</div><div>     tmp_path: pathlib.Path,</div><div class="diff-info">@@ -209,149 +133,149 @@ def rejoin_cluster_test(</div><div>     expected_shards: int = 3,</div><div> ):</div><div>     """</div><div class="diff-removed">-    Parameterized test body, that tests adding new peer after origin peer was removed from the cluster.</div><div class="diff-removed">-    See: <https://github.com/qdrant/qdrant/issues/5138></div><div class="diff-added">+    Parameterized test body, that tests adding new peer after origin peer was removed.</div><div>     """</div><div class="diff-removed">-</div><div>     # Start cluster</div><div>     peer_uris, peer_dirs, bootstrap_uri = start_cluster(tmp_path, peers)</div><div> </div><div>     # Get origin peer ID</div><div>     origin_peer_id = get_cluster_info(peer_uris[0])["peer_id"]</div><div> </div><div class="diff-removed">-    # Create collection, move all shards from first peer, remove first peer from cluster</div><div class="diff-added">+    # Create collection, move all shards from first peer, remove first peer</div><div>     create_collection(peer_uris[0], collection, shards, 1)</div><div>     move_all_shards_from_peer(peer_uris[0], collection)</div><div>     remove_peer(peer_uris[0])</div><div>     processes.pop(0).kill()</div><div> </div><div class="diff-removed">-    # Generally, we could use *any* (second/third/random/last/etc) peer to bootstrap new peer from,</div><div class="diff-removed">-    # but using second peer allows to (trivially) catch a single additional corner case in how we</div><div class="diff-removed">-    # initialize consensus state when bootstrapping new peer.</div><div class="diff-removed">-</div><div>     # Kill second peer</div><div>     second_peer = processes.pop(0)</div><div>     second_peer.kill()</div><div> </div><div class="diff-removed">-    # Check/modify last peer `raft_state.json`</div><div class="diff-added">+    # Modify second peer's `raft_state.json`</div><div>     with open(f"{peer_dirs[1]}/storage/raft_state.json", "r+") as file:</div><div>         state = json.load(file)</div><div class="diff-removed">-</div><div>         if new_state := raft_state(state, origin_peer_id):</div><div>             file.seek(0, io.SEEK_SET)</div><div>             file.truncate()</div><div>             json.dump(new_state, file)</div><div> </div><div class="diff-removed">-    # Restart second peer with the same URI and ports</div><div class="diff-removed">-    second_peer_uri, bootstrap_uri = start_first_peer(peer_dirs[1], "peer_0_1_restarted.log", second_peer.p2p_port)</div><div class="diff-added">+    # Restart second peer</div><div class="diff-added">+    second_peer_uri, bootstrap_uri = start_first_peer(</div><div class="diff-added">+        peer_dirs[1], "peer_0_1_restarted.log", second_peer.p2p_port</div><div class="diff-added">+    )</div><div>     wait_for_peer_online(second_peer_uri)</div><div> </div><div class="diff-removed">-    # Add new peer to cluster</div><div class="diff-removed">-    new_peer_uri, new_peer_dir = add_new_peer(tmp_path, peers, bootstrap_uri, collection)</div><div class="diff-added">+    # Add new peer</div><div class="diff-added">+    new_peer_uri, new_peer_dir = add_new_peer(</div><div class="diff-added">+        tmp_path, peers, bootstrap_uri, collection</div><div class="diff-added">+    )</div><div> </div><div class="diff-removed">-    # Assert that new peer observe expected number of remote shards</div><div class="diff-added">+    # Assert new peer observed expected remote shards</div><div>     info = get_collection_cluster_info(new_peer_uri, collection)</div><div>     assert len(info["remote_shards"]) == expected_shards</div><div> </div><div class="diff-removed">-def start_preconfigured_cluster(tmp_path: pathlib.Path, peers: int = 3):</div><div class="diff-removed">-    assert_project_root()</div><div class="diff-removed">-</div><div class="diff-removed">-    # Collect peer URIs</div><div class="diff-removed">-    peer_uris = []</div><div class="diff-removed">-</div><div class="diff-removed">-    # Create peer directories</div><div class="diff-removed">-    peer_dirs = make_peer_folders(tmp_path, peers)</div><div class="diff-removed">-</div><div class="diff-removed">-    # Copy first peer Raft state and WAL from `test_cluster_rejoin_data`.</div><div class="diff-removed">-    #</div><div class="diff-removed">-    # It's just an "empty" peer, but its peer ID is *not* committed into WAL. We can use this peer to</div><div class="diff-removed">-    # test that first peer ID is correctly recovered/propagated, even when it's not committed into WAL.</div><div class="diff-removed">-    shutil.copytree("tests/consensus_tests/test_cluster_rejoin_data", f"{peer_dirs[0]}/storage")</div><div class="diff-removed">-</div><div class="diff-removed">-    # Modify peer URI in Raft state to prevent URI change on startup 🙄</div><div class="diff-removed">-    p2p_port = get_port()</div><div class="diff-removed">-    grpc_port = get_port()</div><div class="diff-removed">-    http_port = get_port()</div><div class="diff-removed">-</div><div class="diff-removed">-    with open(f"{peer_dirs[0]}/storage/raft_state.json", "r+") as file:</div><div class="diff-removed">-        state = json.load(file)</div><div class="diff-removed">-</div><div class="diff-removed">-        state["peer_address_by_id"][str(state["this_peer_id"])] = f"http://127.0.0.1:{p2p_port}"</div><div class="diff-removed">-</div><div class="diff-removed">-        file.seek(0, io.SEEK_SET)</div><div class="diff-removed">-        file.truncate()</div><div class="diff-removed">-        json.dump(state, file)</div><div class="diff-removed">-</div><div class="diff-removed">-    # Start first peer</div><div class="diff-removed">-    first_peer_uri, bootstrap_uri = start_first_peer(peer_dirs[0], "peer_0_0.log", p2p_port)</div><div class="diff-removed">-    peer_uris.append(first_peer_uri)</div><div class="diff-removed">-</div><div class="diff-removed">-    wait_for_peer_online(first_peer_uri)</div><div> </div><div class="diff-removed">-    # Bootstrap other peers</div><div class="diff-removed">-    for peer_idx in range(1, peers):</div><div class="diff-removed">-        peer_uri = start_peer(peer_dirs[peer_idx], f"peer_0_{peer_idx}.log", bootstrap_uri)</div><div class="diff-removed">-        peer_uris.append(peer_uri)</div><div class="diff-removed">-</div><div class="diff-removed">-    wait_all_peers_up(peer_uris)</div><div class="diff-removed">-</div><div class="diff-removed">-    return peer_uris, peer_dirs, bootstrap_uri</div><div class="diff-removed">-</div><div class="diff-removed">-</div><div class="diff-removed">-def move_all_shards_from_peer(peer_uri: str, collection: str = "test_collection") -> tuple[int, int]:</div><div class="diff-added">+def move_all_shards_from_peer(</div><div class="diff-added">+    peer_uri: str, collection: str = "test_collection"</div><div class="diff-added">+) -> tuple[int, int]:</div><div>     """</div><div class="diff-removed">-    Moves all shards from peer at `peer_uri` to another (random) peer in the cluster.</div><div class="diff-added">+    Moves all shards from peer at `peer_uri` to another (random) peer.</div><div>     """</div><div class="diff-removed">-</div><div class="diff-removed">-    # Find peer to move shards to</div><div>     info = get_cluster_info(peer_uri)</div><div class="diff-removed">-</div><div>     current_peer_id = info["peer_id"]</div><div>     other_peer_id = None</div><div> </div><div class="diff-removed">-    for peer_id, info in info["peers"].items():</div><div class="diff-removed">-        peer_id = int(peer_id)</div><div class="diff-removed">-</div><div class="diff-removed">-        if peer_id != current_peer_id:</div><div class="diff-removed">-            other_peer_id = peer_id</div><div class="diff-added">+    for pid, pinfo in info["peers"].items():</div><div class="diff-added">+        pid = int(pid)</div><div class="diff-added">+        if pid != current_peer_id:</div><div class="diff-added">+            other_peer_id = pid</div><div>             break</div><div> </div><div>     assert other_peer_id</div><div> </div><div class="diff-removed">-    # Move all shards from first peer to second peer</div><div>     info = get_collection_cluster_info(peer_uri, collection)</div><div> </div><div>     for shard in info["local_shards"]:</div><div class="diff-removed">-        resp = requests.post(f"{peer_uri}/collections/{collection}/cluster", json={</div><div class="diff-removed">-            "move_shard": {</div><div class="diff-removed">-                "from_peer_id": current_peer_id,</div><div class="diff-removed">-                "to_peer_id": other_peer_id,</div><div class="diff-removed">-                "shard_id": shard["shard_id"],</div><div class="diff-removed">-            }</div><div class="diff-removed">-        })</div><div class="diff-removed">-</div><div class="diff-added">+        resp = requests.post(</div><div class="diff-added">+            f"{peer_uri}/collections/{collection}/cluster",</div><div class="diff-added">+            json={</div><div class="diff-added">+                "move_shard": {</div><div class="diff-added">+                    "from_peer_id": current_peer_id,</div><div class="diff-added">+                    "to_peer_id": other_peer_id,</div><div class="diff-added">+                    "shard_id": shard["shard_id"],</div><div class="diff-added">+                }</div><div class="diff-added">+            },</div><div class="diff-added">+        )</div><div>         assert_http_ok(resp)</div><div> </div><div class="diff-removed">-    # Wait until all transfers finished</div><div>     wait_for_collection_shard_transfers_count(peer_uri, collection, 0)</div><div> </div><div>     return current_peer_id, other_peer_id</div><div> </div><div class="diff-added">+</div><div> def remove_peer(peer_uri: str, peer_id: int | None = None):</div><div>     if peer_id is None:</div><div>         info = get_cluster_info(peer_uri)</div><div>         peer_id = info["peer_id"]</div><div> </div><div class="diff-removed">-    resp = requests.delete(f"{peer_uri}/cluster/peer/{peer_id}")</div><div class="diff-added">+    resp = requests.delete(f"{uri}/cluster/peer/{peer_id}")</div><div>     assert_http_ok(resp)</div><div> </div><div class="diff-removed">-def add_new_peer(tmp_path: pathlib.Path, peer_idx: int, bootstrap_uri: str, collection: str | None = None):</div><div class="diff-removed">-    peer_dir = make_peer_folder(tmp_path, peer_idx)</div><div class="diff-removed">-    peer_uri = start_peer(peer_dir, f"peer_0_{peer_idx}.log", bootstrap_uri)</div><div> </div><div class="diff-added">+def add_new_peer(</div><div class="diff-added">+    tmp_path: pathlib.Path,</div><div class="diff-added">+    peer_idx: int,</div><div class="diff-added">+    bootstrap_uri: str,</div><div class="diff-added">+    collection: str | None = None,</div><div class="diff-added">+):</div><div class="diff-added">+    peer_dir = make_peer_folder(tmp_path, peer_idx)</div><div class="diff-added">+    peer_uri = start_peer(</div><div class="diff-added">+        peer_dir, f"peer_0_{peer_idx}.log", bootstrap_uri</div><div class="diff-added">+    )</div><div>     wait_for_peer_online(peer_uri)</div><div> </div><div>     if collection is not None:</div><div>         wait_collection_on_all_peers(collection, [peer_uri])</div><div> </div><div class="diff-removed">-    return peer_uri, peer_dir</div><div>\ No newline at end of file</div><div class="diff-added">+    return peer_uri, peer_dir</div><div class="diff-added">+</div><div class="diff-added">+</div><div class="diff-added">+def start_preconfigured_cluster(</div><div class="diff-added">+    tmp_path: pathlib.Path, peers: int = 3</div><div class="diff-added">+):</div><div class="diff-added">+    assert_project_root()</div><div class="diff-added">+    peer_uris = []</div><div class="diff-added">+    peer_dirs = make_peer_folders(tmp_path, peers)</div><div class="diff-added">+</div><div class="diff-added">+    # Copy first peer state and WAL from test data</div><div class="diff-added">+    shutil.copytree(</div><div class="diff-added">+        "tests/consensus_tests/test_cluster_rejoin_data",</div><div class="diff-added">+        f"{peer_dirs[0]}/storage",</div><div class="diff-added">+    )</div><div class="diff-added">+</div><div class="diff-added">+    # Adjust p2p port etc.</div><div class="diff-added">+    p2p_port = get_port()</div><div class="diff-added">+    grpc_port = get_port()</div><div class="diff-added">+    http_port = get_port()</div><div class="diff-added">+</div><div class="diff-added">+    with open(f"{peer_dirs[0]}/storage/raft_state.json", "r+") as file:</div><div class="diff-added">+        state = json.load(file)</div><div class="diff-added">+        state["peer_address_by_id"][str(state["this_peer_id"])] = f"http://127.0.0.1:{p2p_port}"</div><div class="diff-added">+        file.seek(0, io.SEEK_SET)</div><div class="diff-added">+        file.truncate()</div><div class="diff-added">+        json.dump(state, file)</div><div class="diff-added">+</div><div class="diff-added">+    first_uri, bootstrap_uri = start_first_peer(</div><div class="diff-added">+        peer_dirs[0], "peer_0_0.log", p2p_port</div><div class="diff-added">+    )</div><div class="diff-added">+    peer_uris.append(first_uri)</div><div class="diff-added">+    wait_for_peer_online(first_uri)</div><div class="diff-added">+</div><div class="diff-added">+    for idx in range(1, peers):</div><div class="diff-added">+        uri = start_peer(</div><div class="diff-added">+            f"{peer_dirs[idx]}", f"peer_0_{idx}.log", bootstrap_uri</div><div class="diff-added">+        )</div><div class="diff-added">+        peer_uris.append(uri)</div><div class="diff-added">+</div><div class="diff-added">+    wait_all_peers_up(peer_uris)</div><div class="diff-added">+    return peer_uris, peer_dirs, bootstrap_uri</div><div>\ No newline at end of file</div><div></div></pre>
                </div>
            </div>
        </section>
    </main>
    <footer>
        <p>LoCoDiff-bench - <a href="https://github.com/AbanteAI/LoCoDiff-bench">GitHub Repository</a></p>
    </footer>
</body>
</html>
    