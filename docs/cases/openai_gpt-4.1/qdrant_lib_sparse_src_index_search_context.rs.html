<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Case: lib/sparse/src/index/search_context.rs - GPT-4.1</title>
    <link rel="stylesheet" href="../../styles.css">
</head>
<body>
    <header>
        <h1>Case: lib/sparse/src/index/search_context.rs</h1>
        <h2>Model: GPT-4.1</h2>
        <p><a href="../../models/openai_gpt-4.1.html">All GPT-4.1 Cases</a> | <a href="../../cases.html">All Cases</a> | <a href="../../index.html">Home</a></p>
    </header>
    <main>
        <section class="case-details">
            <div class="case-info">
                <h2>Benchmark Case Information</h2>
                <p><strong>Model:</strong> GPT-4.1</p>
                <p><strong>Status:</strong> <span class="failure">Failure</span></p>
                <p><strong>Prompt Tokens:</strong> 73797</p>
                <p><strong>Native Prompt Tokens:</strong> 73776</p>
                <p><strong>Native Completion Tokens:</strong> 3631</p>
                <p><strong>Native Tokens Reasoning:</strong> 0</p>
                <p><strong>Native Finish Reason:</strong> stop</p>
                <p><strong>Cost:</strong> $0.00883</p>
            </div>
            
            <div class="content-links">
                <h2>View Content</h2>
                <ul>
                    <li><a href="../../content/openai_gpt-4.1/qdrant_lib_sparse_src_index_search_context.rs/prompt.html" class="content-link">View Prompt</a></li>
                    <li><a href="../../content/openai_gpt-4.1/qdrant_lib_sparse_src_index_search_context.rs/expected.html" class="content-link">View Expected Output</a></li>
                    <li><a href="../../content/openai_gpt-4.1/qdrant_lib_sparse_src_index_search_context.rs/actual.html" class="content-link">View Actual Output</a></li>
                </ul>
            </div>
            
            <div class="diff-section">
                <h2>Diff (Expected vs Actual)</h2>
                <div id="diff-output">
                    <pre class="diff"><div></div><div>index 8be5822c..3c7f1b59 100644</div><div class="diff-header">--- a/qdrant_lib_sparse_src_index_search_context.rs_expectedoutput.txt (expected):tmp/tmp2swge9tr_expected.txt	</div><div class="diff-header">+++ b/qdrant_lib_sparse_src_index_search_context.rs_extracted.txt (actual):tmp/tmp0s38l5f4_actual.txt	</div><div class="diff-info">@@ -133,7 +133,7 @@ impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {</div><div>             // Accumulate the sum of the length of the retrieved sparse vector and the query vector length</div><div>             // as measurement for CPU usage of plain search.</div><div>             cpu_counter</div><div class="diff-removed">-                .incr_delta(self.query.indices.len() + values.len() * size_of::<DimWeight>());</div><div class="diff-added">+                .incr_delta(self.query.indices.len() + values.len() * std::mem::size_of::<DimWeight>());</div><div> </div><div>             // reconstruct sparse vector and score against query</div><div>             let sparse_score =</div><div class="diff-info">@@ -305,6 +305,7 @@ impl<'a, 'b, T: PostingListIter> SearchContext<'a, 'b, T> {</div><div>                 start_batch_id + ADVANCE_BATCH_SIZE as u32,</div><div>                 self.max_record_id,</div><div>             );</div><div class="diff-added">+            let batch_len = last_batch_id - start_batch_id + 1;</div><div> </div><div>             // advance and score posting lists iterators</div><div>             self.advance_batch(start_batch_id, last_batch_id, filter_condition);</div><div></div></pre>
                </div>
            </div>
        </section>
    </main>
    <footer>
        <p>LoCoDiff-bench - <a href="https://github.com/AbanteAI/LoCoDiff-bench">GitHub Repository</a></p>
    </footer>
</body>
</html>
    