# LoCoDiff Benchmark

LoCoDiff (Local Code Diff) is a novel long-context benchmark for evaluating language models' ability to understand git history and reconstruct code. Developed by the [Mentat AI](https://mentat.ai) team, this benchmark offers several unique strengths:

- Tests comprehension of **naturally interconnected content** (not artificially generated or padded)
- Focused on code, can be constructed for any repo and language
- **Simple and easy to understand** prompt generation and output evaluation
- Strains models' abilities to handle long outputs
- Surprisingly **difficult for reasoning models** to reason about

# [üîç Interactive Benchmark Results Site](https://abanteai.github.io/LoCoDiff-bench/)
